{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up OpenAI and start with a system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES_DIR = 'examples_validation'\n",
    "os.makedirs(EXAMPLES_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=open('../key.txt', 'r').read().strip('\\n'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are AutocompleteGPT, a useful AI autocomplete tool that provides code completions based on the user's code.\n",
    "You are a precision-focused tool for code autocompletion, adept in languages like Python, JavaScript, C++, and SQL.\n",
    "Precisely continue the code from the point of interruption and do not repeat or modify the original code, even if it is incorrect or the code interrupts in the middle of a line.\n",
    "Your code is well documented with comments and annotations, and you should provide a clear explanation of the code's purpose in your code completion.\n",
    "Your unique capability is to provide completions without altering, repeating, or commenting on the original code.\n",
    "You offer only the necessary code to complete the snippet, ensuring the response is exclusively code, with no additional comments, explanations, or annotations.\n",
    "This approach makes you an ideal assistant for users seeking straightforward and efficient code extensions, enhancing their work with accurate, logic-driven completions while maintaining the integrity and simplicity of the original input.\n",
    "Your response begins with the next characters of the line if the last line of the user'S code is incomplete, or the next line if the last line of the user's code is complete.\n",
    "Your application is a VSCode extension like GitHub Copilot, which provides seamless code completions based on the user's code at the point of interruption.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_message(messages: list[str], role: str, message: str | None = None, model: str = \"gpt-3.5-turbo\") -> list[str]:\n",
    "    # If the user is the assistant, generate a response\n",
    "    if role == \"assistant\" and message is None:\n",
    "        chat_completion = client.chat.completions.create(messages=messages, model=model)\n",
    "        message = chat_completion.choices[0].message.content\n",
    "\n",
    "    # Add the message to the messages list\n",
    "    messages.append({\n",
    "        \"role\": role,\n",
    "        \"content\": message,\n",
    "    })\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = '''import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from ..utils import construSct_predictions_index_name, get_es_client\n",
    "\n",
    "logger = logging.getLogger('pmtrendviz.list')\n",
    "\n",
    "\n",
    "def list_managers() -> None:\n",
    "    \"\"\"\n",
    "    List the implemented managers\n",
    "    \"\"\"\n",
    "    from ..models import manager as mgr\n",
    "\n",
    "    # Get all classes defined in the module\n",
    "    classes = [getattr(mgr, name) for name in dir(mgr) if isinstance(getattr(mgr, name), type)]\n",
    "\n",
    "    # Filter the classes to only get the managers\n",
    "    managers = [cls for cls in classes if issubclass(cls, mgr.ModelManager) and not cls == mgr.ModelManager]\n",
    "\n",
    "    # Collect the names of the managers\n",
    "    managers_list = [manager.__name__ '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base GPT-3.5-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = add_message(messages, \"system\", system_prompt)\n",
    "messages = add_message(messages, \"user\", user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = add_message(messages, \"assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "managers_list = [manager.__name__ for manager in managers]\n",
      "\n",
      "    # Print the list of managers\n",
      "    for manager_name in managers_list:\n",
      "        print(manager_name)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    # Parse command line arguments\n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument('--host', type=str, default='localhost', help='Elasticsearch host')\n",
      "    parser.add_argument('--port', type=int, default=9200, help='Elasticsearch port')\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    # Set up logging\n",
      "    logging.basicConfig(level=logging.INFO)\n",
      "\n",
      "    # Get Elasticsearch client\n",
      "    es_client = get_es_client(args.host, args.port)\n",
      "\n",
      "    # List the managers\n",
      "    list_managers()\n"
     ]
    }
   ],
   "source": [
    "print(messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuned GPT-3.5-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = add_message(messages, \"system\", system_prompt)\n",
    "messages = add_message(messages, \"user\", user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = add_message(messages, \"assistant\", message=None, model=\"ft:gpt-3.5-turbo-1106:personal::8LCi9Q0d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for manager in managers]\n",
      "\n",
      "    # Print the managers\n",
      "    for manager_name in managers_list:\n",
      "        print(manager_name)\n"
     ]
    }
   ],
   "source": [
    "print(messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"\"\"\n",
    "- results in invalid url (e.g. 'https://eur-lex.europa.eu/legal-content/AUTO/?uri=CELEX:31983H0230&=1698155004044&=460') because it only removes the parameters but not their values\n",
    "\n",
    "\n",
    "Ground Truth:\n",
    "```python\n",
    "url = url.replace('AUTO', 'EN/ALL')\n",
    "    return url[:url.find('&')]\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "title = \"Truncate URL gone wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any previous comments\n",
    "messages = [message for message in messages if message['role'] != 'comment']\n",
    "\n",
    "# Add the comment to the messages list\n",
    "messages.append({\n",
    "    \"role\": \"comment\",\n",
    "    \"content\": comment,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the messages to a file\n",
    "if not os.path.exists(os.path.join(EXAMPLES_DIR, f\"{title}.json\")):\n",
    "    with open(os.path.join(EXAMPLES_DIR, f\"{title}.json\"), \"w\") as f:\n",
    "        json.dump(messages, f, indent=4, ensure_ascii=False)\n",
    "else:\n",
    "    print(f\"File {title}.json already exists. Skipping.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
