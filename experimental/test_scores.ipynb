{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcoder.eval.metrics.extrinsic import levenshtein_distance_score, bleu_score, trf_similarity_score, sequence_matcher_score, gpt_reviewer_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib1 = \"\"\"\n",
    "# Function that returns the nth Fibonacci number\n",
    "def fibonacci_recursive(n):\n",
    "    if n <= 0:\n",
    "        return []\n",
    "    elif n == 1:\n",
    "        return [0]\n",
    "    elif n == 2:\n",
    "        return [0, 1]\n",
    "    else:\n",
    "        sequence = fibonacci_recursive(n-1)\n",
    "        sequence.append(sequence[-1] + sequence[-2])\n",
    "        return sequence\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib2 = \"\"\"\n",
    "# Function that returns the nth Fibonacci number\n",
    "def fibonacci_iterative(n):\n",
    "    if n <= 0:\n",
    "        return []\n",
    "    elif n == 1:\n",
    "        return [0]\n",
    "    sequence = [0, 1]\n",
    "    for i in range(2, n):\n",
    "        sequence.append(sequence[i-1] + sequence[i-2])\n",
    "    return sequence\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib3 = \"\"\"\n",
    "# Function that returns the nth Fibonacci number\n",
    "def fibonacci_memoization(n, memo = {0: 0, 1: 1}):\n",
    "    if n not in memo:\n",
    "        memo[n] = fibonacci_memoization(n-1, memo) + fibonacci_memoization(n-2, memo)\n",
    "    return [memo[i] for i in range(n)]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fib3_alt = \"\"\"\n",
    "# Function that returns the nth Fibonacci number\n",
    "\n",
    "To implement a function that returns the nth Fibonacci number, we can use memoization to store the results of previous calculations. This will allow us to avoid repeating calculations and improve the efficiency of our function.\n",
    "\n",
    "Let's address this step by step.\n",
    "- First, we need to define a function that takes in an integer n and returns the nth Fibonacci number.\n",
    "- Next, we need to define a dictionary that will store the results of previous calculations.\n",
    "- Finally, we need to define a recursive function that will calculate the nth Fibonacci number using the memoization dictionary.\n",
    "\n",
    "Here is how you can implement this in Python:\n",
    "\n",
    "```python\n",
    "def fibonacci_memoization(n, memo = {0: 0, 1: 1}):\n",
    "    if n not in memo:\n",
    "        memo[n] = fibonacci_memoization(n-1, memo) + fibonacci_memoization(n-2, memo)\n",
    "    return [memo[i] for i in range(n)]\n",
    "```\n",
    "\n",
    "In this code, we define a function that takes in an integer n and returns the nth Fibonacci number. We also define a dictionary that will store the results of previous calculations. Finally, we define a recursive function that will calculate the nth Fibonacci number using the memoization dictionary.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo1 = \"\"\"\n",
    "# Function that returns the nth Fibonacci number\n",
    "import math\n",
    "\n",
    "def geometric_mean(numbers):\n",
    "    if not numbers:\n",
    "        return 0\n",
    "\n",
    "    product = 1\n",
    "    for number in numbers:\n",
    "        product *= number\n",
    "\n",
    "    return math.pow(product, 1/len(numbers))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_list = [\n",
    "    ('levenshtein', levenshtein_distance_score),\n",
    "    ('bleu', bleu_score),\n",
    "    ('trf', trf_similarity_score),\n",
    "    ('seq', sequence_matcher_score),\n",
    "    ('gpt', gpt_reviewer_score)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "levenshtein\n",
      "fib1 vs fib1: 0.000\n",
      "fib1 vs fib2: 79.000\n",
      "fib1 vs fib3: 184.000\n",
      "fib1 vs geo1: 186.000\n",
      "bleu\n",
      "fib1 vs fib1: 1.000\n",
      "fib1 vs fib2: 0.752\n",
      "fib1 vs fib3: 0.397\n",
      "fib1 vs geo1: 0.379\n",
      "trf\n",
      "fib1 vs fib1: 1.000\n",
      "fib1 vs fib2: 0.937\n",
      "fib1 vs fib3: 0.895\n",
      "fib1 vs geo1: 0.820\n",
      "seq\n",
      "fib1 vs fib1: 1.000\n",
      "fib1 vs fib2: 0.624\n",
      "fib1 vs fib3: 0.329\n",
      "fib1 vs geo1: 0.306\n",
      "gpt\n"
     ]
    }
   ],
   "source": [
    "# Take fib1 as ground truth and compare the similarity of fib1 to fib2 and fib3 and geo1\n",
    "\n",
    "for name, score_func in scores_list:\n",
    "    print(name)\n",
    "    print(f'fib1 vs fib1: {score_func(fib1, fib1):.3f}')\n",
    "    print(f'fib1 vs fib2: {score_func(fib1, fib2):.3f}')\n",
    "    print(f'fib1 vs fib3: {score_func(fib1, fib3):.3f}')\n",
    "    print(f'fib1 vs geo1: {score_func(fib1, geo1):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from llmcoder.utils import get_openai_key\n",
    "from llmcoder.eval.metrics.extrinsic import _user_prompt_templste\n",
    "import numpy as np\n",
    "\n",
    "def gpt_reviewer_score(ground_truth: str, llmcoder_result: dict | str, model: str = \"gpt-3.5-turbo\", qualities_list: list[str] | None = None, max_iter: int = 5) -> float:\n",
    "    \"\"\"\n",
    "    Compute the similarity of qualities of two strings with GPT-3.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ground_truth : str\n",
    "        The first string to compare.\n",
    "    llmcoder_result : dict\n",
    "        The llmcoder result containing the conversation (the last message is the completion).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The similarity between the two strings. Positive if the completion is better than the ground truth, negative otherwise.\n",
    "    \"\"\"\n",
    "    client = OpenAI(api_key=get_openai_key())\n",
    "\n",
    "    system_prompt_compare = \"\"\"You are a very critical and meticulous data scientist tasked with comparing and evaluating code completions made by a language model.\n",
    "The user will submit two code snippets with the same beginning but different completions.\n",
    "\n",
    "Given these snippets, you evaluate the completions, and give each a score between 0 and 10, with 0 being the worst (unusable completion that would make a developer frustrated) and 10 being the best (perfect completion that would make a developer happy).\n",
    "The user may ask you to prioritize different qualities of the code.\n",
    "Take these priorities into account when scoring the completions.\n",
    "You should also check whether the completion follows this system prompt given to the completion model:\n",
    "\n",
    "```\n",
    "You are AutocompleteGPT, a useful AI autocomplete tool that provides code completions based on the user's code.\n",
    "You are a precision-focused tool for code autocompletion, adept in languages like Python, JavaScript, C++, and SQL.\n",
    "Precisely continue the code from the point of interruption and do not repeat or modify the original code, even if it is incorrect or the code interrupts in the middle of a line.\n",
    "Your code is well documented with comments and annotations, and you should provide a clear explanation of the code's purpose in your code completion.\n",
    "Your unique capability is to provide completions without altering, repeating, or commenting on the original code.\n",
    "You offer only the necessary code to complete the snippet, ensuring the response is exclusively code, with no additional comments, explanations, or annotations.\n",
    "This approach makes you an ideal assistant for users seeking straightforward and efficient code extensions, enhancing their work with accurate, logic-driven completions while maintaining the integrity and simplicity of the original input.\n",
    "Your response begins with the next characters of the line if the last line of the user'S code is incomplete, or the next line if the last line of the user's code is complete.\n",
    "Your application is a VSCode extension like GitHub Copilot, which provides seamless code completions based on the user's code at the point of interruption.\n",
    "```\n",
    "\n",
    "If the code does not follow this prompt, you will give it a low score.\n",
    "\n",
    "Most importantly though, you identify whether the completion is seamless, does not repeat or modify the original code, and is a direct continuation of the user's code.\n",
    "If the completion contains any explanations or text other than code, you will give it a low score.\n",
    "\n",
    "\n",
    "Your output must always have the following format:\n",
    "```\n",
    "COMPARISON:\n",
    "<comparison of the two completions with regard to the requested qualities>\n",
    "\n",
    "SCORE 1: <score for completion 1, integer between 0 and 10>\n",
    "SCORE 2: <score for completion 2, integer between 0 and 10>\n",
    "```\n",
    "\n",
    "Do not include any other information in your output.\n",
    "It is very important that the output following \"SCORE 1: \" and \"SCORE 2: \" is a single integer between 0 and 10, with no other characters or spaces since scores will later be parsed at this exact location.\n",
    "Therefore, make sure to keep your comparison (the text after COMPARISON:) concise, and adhere to the score format exactly.\n",
    "\"\"\"\n",
    "\n",
    "    if qualities_list is None:\n",
    "        qualities_list = [\n",
    "            \"alignment of the completion with the given code (hint: the given code is the same for both completions)\",\n",
    "            \"correctness\",\n",
    "            \"plausibility\",\n",
    "            \"readability\",\n",
    "            \"efficiency\"\n",
    "        ]\n",
    "\n",
    "    if isinstance(llmcoder_result, dict):\n",
    "        completion = llmcoder_result['messages'][-1]['content']\n",
    "    else:\n",
    "        completion = llmcoder_result\n",
    "\n",
    "    user_prompt = _user_prompt_templste(ground_truth, completion, qualities_list)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt_compare\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "    chat_completion = client.chat.completions.create(messages=messages, model=model, temperature=0.2)  # type: ignore\n",
    "    message = chat_completion.choices[0].message.content\n",
    "\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER INPUT END: ```\n",
      "# Function that returns the nth Fibonacci number\n",
      "def fibonacci_\n",
      "```\n",
      "COMPLETION BEGIN: `recursive(n):`\n",
      "\n",
      "COMPARISON:\n",
      "The completion in code 1 is a recursive implementation of the Fibonacci sequence. It aligns with the given code and is a direct continuation of the user's input. The completion is correct, plausible, and readable. However, it may not be the most efficient implementation since it recalculates the Fibonacci sequence for each value of n.\n",
      "\n",
      "The completion in code 2 is a memoized implementation of the Fibonacci sequence. It also aligns with the given code and is a direct continuation of the user's input. The completion is correct, plausible, and readable. It improves efficiency by storing previously calculated Fibonacci numbers in a memo dictionary.\n",
      "\n",
      "SCORE 1: 8\n",
      "SCORE 2: 9\n"
     ]
    }
   ],
   "source": [
    "gpt_reviewer_score(fib1, fib3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER INPUT END: \n",
      "\n",
      "COMPLETION BEGIN: \n",
      "\n",
      "To implement a function that returns the nth Fibonacci number, we can use memoization to store the results of previous calculations. This will allow us to avoid repeating calculations and improve the efficiency of our function.\n",
      "\n",
      "Let's address this step by step.\n",
      "- First, we need to define a function that takes in an integer n and returns the nth Fibonacci number.\n",
      "- Next, we need to define a dictionary that will store the results of previous calculations.\n",
      "- Finally, we need to define a recursive function that will calculate the nth Fibonacci number using the memoization dictionary.\n",
      "\n",
      "Here is how you can implement this in Python:\n",
      "\n",
      "```python\n",
      "def fibonacci_memoization(n, memo = {0: 0, 1: 1}):\n",
      "    if n not in memo:\n",
      "        memo[n] = fibonacci_memoization(n-1, memo) + fibonacci_memoization(n-2, memo)\n",
      "    return [memo[i] for i in range(n)]\n",
      "```\n",
      "\n",
      "In this code, we define a function that takes in an integer n and returns the nth Fibonacci number. We also define a dictionary that will store the results of previous calculations. Finally, we define a recursive function that will calculate the nth Fibonacci number using the memoization dictionary.\n",
      "\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "gpt_reviewer_score(fib1, fib3_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
