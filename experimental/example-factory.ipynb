{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up OpenAI and start with a system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES_DIR = 'examples'\n",
    "os.makedirs(EXAMPLES_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=\"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\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "# Instructions:\n",
    "You are an autocomplete system for Python. Generate or complete Python code based on the user's description or the provided code snippet.\n",
    "\n",
    "The user may\n",
    "1. Describe code, either directly or in a Python comment. In this case, you should implement the described code.\n",
    "2. Write incomplete code. In this case, you should complete the code from the last cursor position.\n",
    "3. If the last character is a newline or tab, come up with one or more possible next lines of code.\n",
    "\n",
    "\n",
    "## Example 1:\n",
    "\n",
    "[INPUT]\n",
    "# Function that adds two numbers\n",
    "def\n",
    "[/INPUT]\n",
    "\n",
    "[ANSWER]\n",
    "```python\n",
    " add_numbers(a, b):\n",
    "    return a + b\n",
    "```\n",
    "[/ANSWER]\n",
    "\n",
    "\n",
    "## Example 2:\n",
    "\n",
    "[INPUT]\n",
    "```python\n",
    "def factorial(n):\n",
    "    # Computes the fact\n",
    "```\n",
    "[/INPUT]\n",
    "\n",
    "[ANSWER]\n",
    "```python\n",
    "    # Computes the factorial of a number\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n-1)\n",
    "```\n",
    "[/ANSWER]\n",
    "\n",
    "\n",
    "## Example 3:\n",
    "\n",
    "[INPUT]\n",
    "I need a function that checks if a number is prime\n",
    "[/INPUT]\n",
    "\n",
    "[ANSWER]\n",
    "```python\n",
    "def is_prime(number):\n",
    "    if number > 1:\n",
    "        for i in range(2, int(number**0.5)+1):\n",
    "            if (number % i) == 0:\n",
    "                return False\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "```\n",
    "[/ANSWER]\n",
    "\n",
    "\n",
    "# Rules:\n",
    "- Your entire response must be valid Python code.\n",
    "- Avoid evasive or incomplete answers.\n",
    "- Any comments or notes must be made in Python code block, i.e., ```python ... ```.\n",
    "- You must not add any additional comments or notes outside of the ```python ... ``` blocks. Your entire response must only consist of one Python code block.\n",
    "- You must end your response after ending the Python code block with \"```\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_message(messages: list[str], role: str, message: str | None = None) -> list[str]:\n",
    "    # If the user is the assistant, generate a response\n",
    "    if role == \"assistant\" and message is None:\n",
    "        chat_completion = client.chat.completions.create(messages=messages, model=\"gpt-3.5-turbo\")\n",
    "        message = chat_completion.choices[0].message.content\n",
    "\n",
    "    # Add the message to the messages list\n",
    "    messages.append({\n",
    "        \"role\": role,\n",
    "        \"content\": message,\n",
    "    })\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a response to an example prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = '''def nonRecursiveDFS(graph, start):\n",
    "    \"\"\"\n",
    "        Procedure to return paths with O(m+n) time complexity\n",
    "    \"\"\"\n",
    "    # Save the start node\n",
    "    visited = [start]\n",
    "\n",
    "    # Check the neighbors if not visited\n",
    "    if start.neighbors\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = '''def nonRecursiveDFS(graph, start):\n",
    "    \"\"\"\n",
    "        Procedure to return paths with O(m+n) time complexity\n",
    "    \"\"\"\n",
    "    # Save the start node\n",
    "    visited = [start]\n",
    "\n",
    "    # Check the neighbors if not visited, complete here and fix the code\n",
    "        stack = [start]\n",
    "        while stack:\n",
    "            node = stack.pop()\n",
    "\n",
    "            if node not in visited:\n",
    "                visited.append(node)\n",
    "                for neighbor in graph[node]:\n",
    "                    stack.append(neighbor)\n",
    "\n",
    "    return visited\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = add_message(messages, \"system\", system_prompt)\n",
    "messages = add_message(messages, \"user\", user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = add_message(messages, \"assistant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the output and store the conversation and a comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = \"\"\"\n",
    "+ Maintained the condition of time complexity\n",
    "- Completion with Modification to old code\n",
    "- Variables name refactored\n",
    "\n",
    "Ground Truth:\n",
    "```python\n",
    "    # Compute the outputs of the model\n",
    "    input_ids, attention_mask = tokenizer(input_text, return_tensors=\"pt\", add_special_tokens=True, padding=True).values()\n",
    "    outputs = model(input_ids.to(model.device), attention_mask=attention_mask.to(model.device))\n",
    "\n",
    "    # Return the probabilities of the model\n",
    "    return torch_softmax(outputs[0], dim=1).detach().cpu().numpy()\n",
    "\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "title = \"DFS but replaced the variables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any previous comments\n",
    "messages = [message for message in messages if message['role'] != 'comment']\n",
    "\n",
    "# Add the comment to the messages list\n",
    "messages.append({\n",
    "    \"role\": \"comment\",\n",
    "    \"content\": comment,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Complete predict_heads function.json already exists. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# Save the messages to a file\n",
    "if not os.path.exists(os.path.join(EXAMPLES_DIR, f\"{title}.json\")):\n",
    "    with open(os.path.join(EXAMPLES_DIR, f\"{title}.json\"), \"w\") as f:\n",
    "        json.dump(messages, f, indent=4)\n",
    "else:\n",
    "    print(f\"File {title}.json already exists. Skipping.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
