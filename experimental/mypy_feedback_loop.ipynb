{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcoder import LLMCoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llmcoder = LLMCoder(analyzers=[\"mypy_analyzer_v1\", \"signature_analyzer_v1\"], max_iter=3, feedback_variant=\"coworker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = ['''from llmcoder import LLMCoder\n",
    "\n",
    "# Create an LLMCoder with a random seed of 0\n",
    "llmcoder = ''',\n",
    "'''import os\n",
    "from aleph_alpha_client import Client, CompletionRequest, Prompt\n",
    "\n",
    "\n",
    "\n",
    "client = Client(os.''', # https://github.com/Aleph-Alpha/aleph-alpha-client\n",
    "'''# Import random forest regressor\n",
    "''',\n",
    "'''import os\n",
    "import re\n",
    "import subprocess\n",
    "import tempfile\n",
    "\n",
    "from llmcoder.analyze.Analyzer import Analyzer\n",
    "\n",
    "\n",
    "class MypyAnalyzer(Analyzer):\n",
    "    def analyze(self, input: str, completion: str, install_stubs: bool = True, *mypy_args: str | None) -> dict:\n",
    "        code = input + completion\n",
    "\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".py\", mode=\"w\") as temp_file:\n",
    "            temp_file_name = temp_file.name\n",
    "            temp_file.write(code)\n",
    "\n",
    "        if mypy_args is None:\n",
    "            # mypy_args = [\"--disable-error-code=import-untyped\"]  #FiXME: Should resolve error: Skipping analyzing \"sklearn.ensemble\": module is installed, but missing library stubs or py.typed marker  [import-untyped] but doesn't\n",
    "            mypy_args = []\n",
    "\n",
    "        # First run of mypy to check for missing stubs\n",
    "        mypy_run = subprocess.run([\"mypy\", temp_file_name, *mypy_args], capture_output=True, text=True)\n",
    "\n",
    "        # Check if mypy reported missing stubs\n",
    "        indicators = [\"install-types\"]\n",
    "        missing_stubs = any(indicator in mypy_run.stdout or indicator in mypy_run.stderr for indicator in indicators)\n",
    "\n",
    "        # Install stubs if missing\n",
    "        if install_stubs and missing_stubs:\n",
    "            print(\"Installing missing stubs...\")\n",
    "\n",
    "            # Install missing stubs\n",
    "            subprocess.run([\"mypy\", \"--install-types\", \"--non-interactive\", *mypy_args], capture_output=True, text=True)\n",
    "\n",
    "            # Re-run mypy after installing stubs\n",
    "            mypy_run = subprocess.run([\"mypy\", temp_file_name, *mypy_args], capture_output=True, text=True)\n",
    "        else:\n",
    "            print(\"No missing stubs found.\")\n",
    "\n",
    "        result = mypy_run.stdout if mypy_run.stdout else mypy_run.stderr\n",
    "\n",
    "        # Get the number of lines of the input code\n",
    "        n_input_lines = len(input.split(\"\\n\")) - 1\n",
    "\n",
    "        # Parse the line number from the mypy error message and filter the result\n",
    "        filtered_result = []\n",
    "        for line in result.split(\"\\n\"):\n",
    "            if line.startswith(temp_file_name):\n",
    "                line_number = int(line.split(\":\")[1])\n",
    "                if line_number > n_input_lines:\n",
    "                    filtered_result.append(line)\n",
    "            else:\n",
    "                filtered_result.append(line)\n",
    "\n",
    "        # Replace the temp file name with \"your completion\". This helps the LLM understand that the error is caused by its completion.\n",
    "        filtered_result = [line.replace(temp_file_name, \"your completion\") for line in filtered_result]\n",
    "\n",
    "        # Remove the error message \"your completion:2: \\x1b[1m\\x1b[31merror:\\x1b[m Skipping analyzing...\" since it cannot be resolved by installing stubs\n",
    "        filter''',\n",
    "'''import argparse\n",
    "\n",
    "import uvicorn\n",
    "from fastapi import APIRouter, FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "from .routers import models, predict\n",
    "\n",
    "\n",
    "def api(args: argparse.Namespace) -> FastAPI:\n",
    "    app = FastAPI(\n",
    "        title=\"PubMed Research Trends\",\n",
    "        description=\"PubMed Research Trends is a web application that allows users to explore trends in biomedical research. Users can search for topics and visualize the trends in the number of publications over time. The application also provides a topic clustering feature that allows users to explore the topics that are related to a given topic.\",\n",
    "        version=\"0.1.0\",\n",
    "    )\n",
    "\n",
    "    app.add_middleware(''',\n",
    "'''from langchain.document_loaders import DirectoryLoader, JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Embed and store\n",
    "from langchain.vectorstores.elasticsearch import ElasticsearchStore \n",
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "from langchain.embeddings import OllamaEmbeddings # We can also try Ollama embeddings\n",
    "\n",
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# pip install jq\n",
    "schema = {\n",
    "    'jq_schema': '.text'\n",
    "}\n",
    "\n",
    "es = get_es_connection()\n",
    "\n",
    "REINDEX = False\n",
    "\n",
    "# pip install gpt4all\n",
    "# Needs Ubuntu > 22.04 because of glibc\n",
    "\n",
    "if REINDEX:\n",
    "    # Clear the index\n",
    "    es.indices.delete(index=\"eurlex-langchain\", ignore=[400, 404])\n",
    "\n",
    "    start_time = time.time()\n",
    "    vectorstore = ''',\n",
    "'''import requests\n",
    "\n",
    "\n",
    "def get_document_info_page(url):\n",
    "    \"\"\"\n",
    "    Get the redirected url from a given url.\n",
    "\n",
    "    Example:\n",
    "    https://eur-lex.europa.eu/legal-content/AUTO/?uri=CELEX:31983H0230&qid=1698155004044&rid=460 -> https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=CELEX:31983H0230\n",
    "    \"\"\"\n",
    "    ''',\n",
    "'''# General imports\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import matplotlib\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Custom imports\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Ensure matplotlib works correctly with Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "df_characters = pd.read_csv('data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\n",
    "df_locations = pd.read_csv('data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\n",
    "df_script = pd.read_csv('data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\n",
    "df_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)\n",
    "\n",
    "# ''',\n",
    "'''# Ana Carsi Gonzalez - 24 Januar 2023\n",
    "\n",
    "# Main class for the approach of the Checkers game using minimax AI algorithm\n",
    "# Specifications:\n",
    "#   the window may not close since it's not threaded (add py multithreading)\n",
    "import pygame\n",
    "# from constants import IWDTH, HEIGHT, SQUARE_SIZE, PINK\n",
    "from constants import WIDTH, HEIGHT, SQUARE_SIZE, PINK, WHITE\n",
    "from minimax import minimax, minimax_prun\n",
    "from game import Game\n",
    "\n",
    "# Constants for rendering\n",
    "FPS = 10\n",
    "\n",
    "# DISPLAY: Window setup\n",
    "# We define a constant window WIN (that's why it's in capital letters)\n",
    "WIN = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "pygame.display.set_caption('KI-DAMESPIELT')\n",
    "\n",
    "def get_row_col_from_mouse(pos):\n",
    "    # Obtain the position we are on according to the tuple of the mouse\n",
    "    x, y = pos\n",
    "    row = y // SQUARE_SIZE\n",
    "    col = x // SQUARE_SIZE\n",
    "    return row, col\n",
    "\n",
    "# Define main function\n",
    "def main():\n",
    "    # Event loop\n",
    "    run = True\n",
    "    # Set time of computation fixed, independent of computing velocity of CPU\n",
    "    clock = pygame.time.Clock()\n",
    "    # Instance of Game\n",
    "    game = Game(WIN)\n",
    "\n",
    "    # Test move\n",
    "    # piece = self.board.get_piece(0,1)\n",
    "    # self.board.move(piece, 4, 3)\n",
    "\n",
    "    while run:\n",
    "        clock.tick(FPS)\n",
    "\n",
    "        # (AI) Implementation for WHITE\n",
    "        if game.turn == WHITE:\n",
    "            value, new_board = minimax_prun(game.get_board(), 4, WHITE, game, float('-inf'), float('inf'))\n",
    "            game.ai_move(new_board)\n",
    "\n",
    "        # Determine the end of the game\n",
    "        if game.winner() != None:\n",
    "            print(game.winner())\n",
    "            run = False\n",
    "\n",
    "        # Check events in the list pygame.event\n",
    "        for event in pygame.event.get():\n",
    "            # Classifying events\n",
    "            # 1. Red button\n",
    "            if event.type == pygame.QUIT:\n",
    "                run = False\n",
    "            # 2. Any button in the mouse: movement\n",
    "            ''',\n",
    "'''import polars as pl\n",
    "\n",
    "data = {\"col1\": [0, 2], \"col2\": [3, 7]}\n",
    "df2 = pl.DataFrame(data, schema=''',\n",
    "'''import langchain.vectorstores.elasticsearch as es\n",
    "\n",
    "store = es.ElasticsearchStore('''\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating first completion...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feedback loop...\n",
      "Starting feedback iteration 1...\n",
      "Analyzing code in a coworker mode...\n",
      "Running mypy_analyzer_v1...\n",
      "No missing stubs found.\n",
      "/tmp/tmpbkau1587.py:3: error: Unexpected keyword argument \"host\" for \"ElasticsearchStore\"  [call-arg]\n",
      "/tmp/tmpbkau1587.py:3: error: Unexpected keyword argument \"port\" for \"ElasticsearchStore\"  [call-arg]\n",
      "/tmp/tmpbkau1587.py:3: error: Unexpected keyword argument \"index\" for \"ElasticsearchStore\"  [call-arg]\n",
      "/tmp/tmpbkau1587.py:3: error: Unexpected keyword argument \"doc_type\" for \"ElasticsearchStore\"  [call-arg]\n",
      "Found 4 errors in 1 file (checked 1 source file)\n",
      "\n",
      "Running signature_analyzer_v1...\n",
      "Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "Found problematic function or class: ElasticsearchStore\n",
      "Found problematic function or class: ElasticsearchStore\n",
      "Found problematic function or class: ElasticsearchStore\n",
      "Found problematic function or class: ElasticsearchStore\n",
      "import_aliases={'es': 'langchain.vectorstores.elasticsearch'}\n",
      "direct_imports={}\n",
      "function_calls=[('es', 'ElasticsearchStore')]\n",
      "module_alias='es' func_name='ElasticsearchStore'\n",
      "Got signatures and documentations:\n",
      "ElasticsearchStore: (index_name: str, *, embedding: Optional[langchain_core.embeddings.Embeddings] = None, es_connection: Optional[ForwardRef('Elasticsearch')] = None, es_url: Optional[str] = None, es_cloud_id: Optional[str] = None, es_user: Optional[str] = None, es_api_key: Optional[str] = None, es_password: Optional[str] = None, vector_query_field: str = 'vector', query_field: str = 'text', distance_strategy: Optional[Literal[<DistanceStrategy.COSINE: 'COSINE'>, <DistanceStrategy.DOT_PRODUCT: 'DOT_PRODUCT'>, <DistanceStrategy.EUCLIDEAN_DISTANCE: 'EUCLIDEAN_DISTANCE'>]] = None, strategy: langchain.vectorstores.elasticsearch.BaseRetrievalStrategy = <langchain.vectorstores.elasticsearch.ApproxRetrievalStrategy object at 0x7fd331e4e9d0>), `Elasticsearch` vector store.\n",
      "0 / 1 analyzers passed\n",
      "Starting feedback iteration 2...\n",
      "Analyzing code in a coworker mode...\n",
      "Running mypy_analyzer_v1...\n",
      "No missing stubs found.\n",
      "Success: no issues found in 1 source file\n",
      "\n",
      "Running signature_analyzer_v1...\n",
      "Using context from previous analyzers: ['mypy_analyzer_v1']\n",
      "No problematic functions or classes found in the context.\n",
      "1 / 1 analyzers passed\n"
     ]
    }
   ],
   "source": [
    "result = llmcoder.complete(code[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_name='my_index', embedding=None, es_connection=None, es_url=None, es_cloud_id=None, es_user=None, es_api_key=None, es_password=None, vector_query_field='vector', query_field='text', distance_strategy=None, strategy=es.ApproxRetrievalStrategy())\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM\n",
      "You are AutocompleteGPT, a useful AI autocomplete tool that provides code completions based on the user's code.\n",
      "You are a precision-focused tool for code autocompletion, adept in languages like Python, JavaScript, C++, and SQL.\n",
      "Precisely continue the code from the point of interruption and do not repeat or modify the original code, even if it is incorrect or the code interrupts in the middle of a line.\n",
      "Your code is well documented with comments and annotations, and you should provide a clear explanation of the code's purpose in your code completion.\n",
      "Your unique capability is to provide completions without altering, repeating, or commenting on the original code.\n",
      "You offer only the necessary code to complete the snippet, ensuring the response is exclusively code, with no additional comments, explanations, or annotations.\n",
      "This approach makes you an ideal assistant for users seeking straightforward and efficient code extensions, enhancing their work with accurate, logic-driven completions while maintaining the integrity and simplicity of the original input.\n",
      "Your response begins with the next characters of the line if the last line of the user'S code is incomplete, or the next line if the last line of the user's code is complete.\n",
      "Your application is a VSCode extension like GitHub Copilot, which provides seamless code completions based on the user's code at the point of interruption.\n",
      "--------------------------------------------------------------------------------\n",
      "USER\n",
      "import langchain.vectorstores.elasticsearch as es\n",
      "\n",
      "store = es.ElasticsearchStore(\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT\n",
      "host='localhost', port=9200, index='my_index', doc_type='my_doc_type')\n",
      "--------------------------------------------------------------------------------\n",
      "USER\n",
      "[INST]\n",
      "The completion you provided resulted in the following errors:\n",
      "your completion:3: error: Unexpected keyword argument \"host\" for \"ElasticsearchStore\"  [call-arg]\n",
      "your completion:3: error: Unexpected keyword argument \"port\" for \"ElasticsearchStore\"  [call-arg]\n",
      "your completion:3: error: Unexpected keyword argument \"index\" for \"ElasticsearchStore\"  [call-arg]\n",
      "your completion:3: error: Unexpected keyword argument \"doc_type\" for \"ElasticsearchStore\"  [call-arg]\n",
      "Found 4 errors in 1 file (checked 1 source file)\n",
      "\n",
      "To fix these errors, use these ground truth signatures as a reference for your next completion:\n",
      "ElasticsearchStore: (index_name: str, *, embedding: Optional[langchain_core.embeddings.Embeddings] = None, es_connection: Optional[ForwardRef('Elasticsearch')] = None, es_url: Optional[str] = None, es_cloud_id: Optional[str] = None, es_user: Optional[str] = None, es_api_key: Optional[str] = None, es_password: Optional[str] = None, vector_query_field: str = 'vector', query_field: str = 'text', distance_strategy: Optional[Literal[<DistanceStrategy.COSINE: 'COSINE'>, <DistanceStrategy.DOT_PRODUCT: 'DOT_PRODUCT'>, <DistanceStrategy.EUCLIDEAN_DISTANCE: 'EUCLIDEAN_DISTANCE'>]] = None, strategy: langchain.vectorstores.elasticsearch.BaseRetrievalStrategy = <langchain.vectorstores.elasticsearch.ApproxRetrievalStrategy object at 0x7fd331e4e9d0>)\n",
      "\n",
      "Fix, improve and rewrite your completion for the following code:\n",
      "[/INST]\n",
      "import langchain.vectorstores.elasticsearch as es\n",
      "\n",
      "store = es.ElasticsearchStore(\n",
      "--------------------------------------------------------------------------------\n",
      "ASSISTANT\n",
      "index_name='my_index', embedding=None, es_connection=None, es_url=None, es_cloud_id=None, es_user=None, es_api_key=None, es_password=None, vector_query_field='vector', query_field='text', distance_strategy=None, strategy=es.ApproxRetrievalStrategy())\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for message in llmcoder.messages:\n",
    "    print(message['role'].upper())\n",
    "    # Remove colors from the content of the message\n",
    "    message['content'] = re.sub(r'\\x1b[^m]*m', '', message['content'])\n",
    "    print(message['content'])\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copilot:\n",
    "# from llmcoder import LLMCoder\n",
    "\n",
    "# # Create an LLMCoder with a random seed of 0\n",
    "# llmcoder = LLMCoder(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
