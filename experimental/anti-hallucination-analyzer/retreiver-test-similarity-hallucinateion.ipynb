{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hallucination Encounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "import jedi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similairty between two strings\n",
    "\n",
    "1. Wrong Attribute\n",
    "2. List of Correct Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "- list of attributes is `small`\n",
    "- comparing \n",
    "    - `retrieve_system_prompt` string\n",
    "    - with listed attributes by Jedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_source_code = \"\"\"import openai\n",
    "from llmcoder.utils import get_conversations_dir, get_openai_key, get_system_prompt, get_system_prompt_dir\n",
    "\n",
    "client = openai.OpenAI(api_key=get_openai_key())\n",
    "client.chat.completions.create(messages=self.messages, model=model, temperature=temperature, n=n)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = jedi.Script(curr_source_code)\n",
    "attributes = script.get_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.9 µs ± 29.4 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1000\n",
    "sorted([(Levenshtein.distance(\"retrieve_system_prompt\", attribute.name), attribute.name) for attribute in attributes if attribute.type == \"function\"], key=lambda similarity: similarity[0])[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example numpy\n",
    "\n",
    "- **huge** number of attributes from `numpy` \n",
    "- comparing \n",
    "    - `intarray` string\n",
    "    - with listed attributes by Jedi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"\"\"import numpy as np\n",
    "np.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = jedi.Script(source)\n",
    "attributes = script.complete(line=2, column=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.97 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1.07 ms ± 1.05 ms per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1000\n",
    "sorted([(Levenshtein.distance(\"intarray\", attribute.name), attribute.name) for attribute in attributes if attribute.type == \"function\"], key=lambda similarity: similarity[0])[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 'array'),\n",
       " (3, 'asarray'),\n",
       " (3, 'asfarray'),\n",
       " (4, 'asanyarray'),\n",
       " (4, 'interp'),\n",
       " (5, 'geterr'),\n",
       " (5, 'histogram'),\n",
       " (5, 'inner'),\n",
       " (5, 'insert'),\n",
       " (5, 'isfortran')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(Levenshtein.distance(\"intarray\", attribute.name), attribute.name) for attribute in attributes if attribute.type == \"function\"], key=lambda similarity: similarity[0])[0:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcoder.env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
