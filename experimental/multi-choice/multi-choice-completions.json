[
    " Merge locations into script dataframe\ndf_script = (\n    df_script\n    .merge(\n        df_locations,\n        how='left',\n        left_on='raw_location_text',\n        right_on='raw_location_text',\n    )\n    .rename(columns={'normalized_location':'location'})\n    .drop(columns='timestamp_in_ms')\n)",
    "Find the number of rows for each dataframe",
    "Importing all necessary libraries and datasets for analysis.",
    "Define some cosmetic global parameters.",
    "Let's take a look at our datasets",
    " Let's look at the structure of the characters DataFrame.",
    "Display the first 5 rows of each file to have a first look of the data\nprint('Loaded {} samples.'.format(len(df_script)))\ndf_script.head()",
    "Create a directory to save the wordclouds if it does not exist\nwordcloud_dir = 'wordclouds'\nif not os.path.exists(wordcloud_dir):\n    os.makedirs(wordcloud_dir)",
    "Removing all data after Season 20 (including) to avoid further spoilers",
    "This will read the four datasets provided.",
    "Check if GPU is available\nspacy.prefer_gpu()",
    "ignore episodes with missing data\ndf_script = df_script[~df_script[\"episode_id\"].isnull()]",
    "Checking if the datasets were loaded correctly",
    "Scatter character by gender\ngrouped_episodes = df_script.groupby('episode_id')['normalized_text'].apply(lambda x: ''.join(x)).reset_index()\ngrouped_episodes = pd.merge(grouped_episodes, df_episodes, on='episode_id')\n\nspacy.prefer_gpu()",
    "Preview the first 5 lines of df_episodes\ndf_episodes.head()",
    "Filter in script lines only\ndf_script = df_script[df_script['episode_id'].isin(df_episodes[df_episodes[\"original_air_date\"] <= '2003-04-27'][\"id\"])]",
    "# Fill NaN with empty strings\ndf_script = df_script.fillna('')",
    " We transform the season and episode number of each script line to a unified format XYY\n# where X is the season number and YY is the episode number.",
    "Join script with characters and locations\ndf_script_characters = pd.merge(\n    df_script,\n    df_characters,\n    how='left',\n    left_on=['raw_character_text'],\n    right_on=['name']\n)\n\ndf_script_locations = pd.merge(\n    df_script,\n    df_locations,\n    how='left',\n    left_on=['raw_location_text'],\n    right_on=['name']\n)",
    "Check the dataframe dimensions\nprint('Characters shape:', df_characters.shape)\nprint('Locations shape:', df_locations.shape)\nprint('Script shape:', df_script.shape)\nprint('Episodes shape:', df_episodes.shape)",
    "Check the structure of each dataframe\nprint(\"Characters\")\nprint(df_characters.head())\nprint()\nprint(\"Locations\")\nprint(df_locations.head())\nprint()\nprint(\"Script\")\nprint(df_script.head())\nprint()\nprint(\"Episodes\")\nprint(df_episodes.head())",
    "Check the data shape\ndf_characters_shape = df_characters.shape\ndf_locations_shape = df_locations.shape\ndf_script_shape = df_script.shape\ndf_episodes_shape = df_episodes.shape",
    "Create episode transcripts by joining script lines on episode id and then\n# and then grouping by episode id aggregating text.",
    "Quick overview of the dataset\nprint(df_episodes.head())",
    " Show top 10 rows of the episodes dataframe\ndf_episodes.head(10)",
    "Let's first take a look at the structure of our data.",
    " Show the DataFrame columns, non-null count, data type and memory usage\ndf_script.info()",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Remove rows where the character, location, or dialogue is missing\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'normalized_text'])",
    "Clean data\n#script with na characters or na locations\n\ndf_script = df_script[df_script.character_id.notna() & df_script.location_id.notna()]",
    "Count the number of times each character speaks and plot the 10 most common ones.",
    "Merge script with characters ids\ndf_script['character_id'] = df_script['raw_character_text'].map(lambda x: df_characters[df_characters['normalized_name'] == x.lower()]['id'].values[0] if len(df_characters[df_characters['normalized_name'] == x.lower()]['id'].values) > 0 else np.nan)",
    "Merge select columns from the script, character, and episode datasets\ndf_merged = df_script[['episode_id', 'character_id', 'location_id', 'raw_text']]\ndf_merged = df_merged.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id').drop(columns=['id'])\ndf_merged = df_merged.merge(df_locations[['id', 'name']], left_on='location_id', right_on='id').drop(columns=['id'])\ndf_merged = df_merged.merge(df_episodes[['id', 'title']], left_on='episode_id', right_on='id').drop(columns=['id'])\n\n# Rename columns\ndf_merged.columns = ['episode_id', 'character_id', 'location_id', 'raw_text', 'character_name', 'location_name', 'episode_title']\n\n# Display the merged dataframe\ndf_merged.head()",
    " Display the 4 firsts entries of the dataset\ndf_script.head(4)",
    "Print the first 3 lines of each dataset\nfor df, name in zip([df_characters, df_locations, df_script, df_episodes], \n                    ['df_characters', 'df_locations', 'df_script', 'df_episodes']):\n    print(name)\n    display(df.head(3))\n    print('\\n')",
    "Create characters x location dataframe\nlocations = []\ncharacters = []\nlines_count = []\n\n\nfor idx, l in df_script.iterrows():\n    if (l['raw_character_text'] in df_characters.raw_character_text.values and\n        l['raw_location_text'] in df_locations.raw_location_text.values):\n        if (l['raw_character_text'], l['raw_location_text']) in zip(characters, locations):\n            lines_count[characters.index(l['raw_character_text'])][locations.index(l['raw_location_text'])] += 1\n        else:\n            characters.append(l['raw_character_text'])\n            locations.append(l['raw_location_text'])\n            lines_count.append(np.zeros(len(df_locations), dtype=np.int32))\n            lines_count[-1][locations.index(l['raw_location_text'])] = 1\n\ndf_x_locations = pd.DataFrame(data=lines_count, index=characters, columns=locations)\n\ndf_x_locations.to_csv('data/simpsons_characters_x_locations.csv')",
    "Create a dictionary for each episode to easier lookup\nepisode_to_script = {}\nfor idx in tqdm(df_script.index):\n    if df_script.loc[idx, 'episode_id'] not in episode_to_script:\n        episode_to_script[df_script.loc[idx, 'episode_id']] = []\n    episode_to_script[df_script.loc[idx, 'episode_id']].append(idx)",
    "Converting to the right types to minimize memory usage",
    "Merge episodes and script\ndf_script_episodes = df_script.merge(\n    df_episodes,\n    on='episode_id'\n)",
    " Displaying first characters in df_characters\ndf_characters.head()",
    "Combine the script with character names",
    "Extract main locations from the episodes and count the number of episodes in each location.",
    " Let's save the fruit of the EDA using the pickle format\ndf_characters.to_pickle(\"data/simpsons_characters.pkl\")\ndf_locations.to_pickle(\"data/simpsons_locations.pkl\")\ndf_script.to_pickle(\"data/simpsons_script.pkl\")\ndf_episodes.to_pickle(\"data/simpsons_episodes.pkl\")",
    "Drop rows with missing values\ndf_characters = df_characters.dropna(subset=['name'])\ndf_locations = df_locations.dropna(subset=['name'])\ndf_script = df_script.dropna(subset=['raw_text', 'character_id', 'location_id', 'episode_id'])\ndf_episodes = df_episodes.dropna(subset=['title'])",
    "Check the contents of the characters DataFrame\ndf_characters.head()",
    " Remove 'id' column from all DataFrames\ndf_characters.drop(columns=['id'], inplace=True)\ndf_locations.drop(columns=['id'], inplace=True)\ndf_script.drop(columns=['id'], inplace=True)\ndf_episodes.drop(columns=['id'], inplace=True)",
    "Extracting the character, location, and episode data from the script data\ncharacters = sorted(df_script.raw_character_text.unique())\nlocations = sorted(df_script.raw_location_text.unique())\nepisodes = sorted(df_script.raw_location_text.unique())",
    " Keep only the lines that contain any number of characters greater than 0\ndf_script = df_script[df_script['normalized_text'].str.len() > 0]",
    "Display the first few rows of the script dataframe\ndf_script.head()",
    "Define constants",
    " to avoid several warnings\npd.options.mode.chained_assignment = None",
    "Checking the first few rows of the characters dataset to understand its structure\ndf_characters.head()",
    " Merge the datasets to get all the data in one dataframe",
    "Set up the wordcloud\nfig, ax = plt.subplots(1, 1, figsize=(15, 15))\nwc = WordCloud(width=800, height=800, background_color='white', max_words=150, relative_scaling=0.5).generate(' '.join(df_script['raw_text'].values))\nax.imshow(wc)\nax.axis('off')",
    "Count the number of unique characters in the dataset\nlen(df_characters['character_id'].unique())",
    "Limit the number of rows to 10000\ndf_script = df_script.head(10000)",
    " Visualize the columns of the dataset\nprint(df_characters.columns.tolist())",
    "Get the size of the files\ndf_characters_size = os.path.getsize('data/simpsons_characters.csv') / (1024 * 1024)\ndf_locations_size = os.path.getsize('data/simpsons_locations.csv') / (1024 * 1024)\ndf_script_size = os.path.getsize('data/simpsons_script_lines.csv') / (1024 * 1024)\ndf_episodes_size = os.path.getsize('data/simpsons_episodes.csv') / (1024 * 1024)",
    " Visualise the top k most frequently used words in script lines in a word cloud",
    "Global variable:\nnlp = spacy.load('en')",
    "Exploring data",
    " Display the head of the script lines dataset\ndf_script.head()",
    "Preview the dataframes\ndf_characters.head()",
    "View head of characters dataframe\ndf_characters.head()",
    "Optional set display width and max columns for tables\npd.set_option('display.max_columns', 100)\npd.set_option('max_colwidth', 100)",
    "#enable interactive plotting in Jupyter notebook\nmatplotlib.use('nbagg')",
    "Add some useful features as additional columns to the script DataFrame",
    "Define name of character\nname = \"Homer Simpson\"",
    " Display dataframes\ndf_characters.head()",
    "Characters count\nprint(f'There are {df_characters.shape[0]} characters.')",
    "Let's see what the character data looks like.",
    " Add regex to drop rows with all na values\ndf_script = df_script.dropna(how='all', subset=['normalized_text'])",
    "Display the first five rows of the characters dataframe\ndf_characters.head()",
    " nlp = spacy.load('en')",
    "Remove problematic entries\ndf_script = df_script[df_script['character_id'].isin(df_characters['id'])].reset_index(drop=True)",
    "Show head of `df_characters` to understand its structure\ndf_characters.head()",
    "Optional: Uncomment and reproduce the sample code to rename column names for easier referencing in the subsequent sections\n\ndf_script.columns = df_script.columns.str.lower()\ndf_episodes.columns = df_episodes.columns.str.lower()\ndf_characters.columns = df_characters.columns.str.lower()\ndf_locations.columns = df_locations.columns.str.lower()",
    "Remove unnecessary columns and rows from the characters DataFrame\ndf_characters = df_characters.drop(columns=['id', 'image_url', 'index'])\ndf_characters.dropna(inplace=True)\ndf_characters.drop_duplicates(subset =\"name\", keep = 'first', inplace = True)",
    "Top of the \"Episode list\" table",
    "We have successfully imported the necessary libraries and read the data into pandas dataframes. Now we can move on to the next steps of data exploration and analysis.",
    "Show all dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Displaying the first rows of the dataframe\nprint('Characters')\ndisplay(df_characters.head())\nprint('Locations')\ndisplay(df_locations.head())\nprint('Script')\ndisplay(df_script.head())\nprint('Episodes')\ndisplay(df_episodes.head())",
    "Conducting data exploration and analysis",
    "Inspecting the first few records of the characters dataframe.",
    " We always want to create a copy of the original data\ndf_script_cleaned = df_script.copy()",
    "\nimport nltk\nnltk.download('punkt')",
    "Preview the characters dataframe\ndf_characters.head()",
    " Helper functions and constants",
    " Select interesting columns",
    " Show the first 10 rows of the characters dataframe\ndf_characters.head(10)",
    "# Display first lines of the script dataframe\ndf_script.head()",
    "Display data from all datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Let's take a look at the dimensions of the datasets.",
    " Visual Studio code extension is used for easy live program completion.",
    "Inspect the first few rows of each dataframe to understand its structure and the type of insights it might offer.",
    "Train test split the data",
    " Let's take a quick look at all of our dataframes.",
    "Display the first few rows of each dataframe to understand its structure and contents\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Extract numeric id from episode url\ndf_episodes['id'] = df_episodes['id'].str.extract('\\/([0-9]+)')",
    " create new columns based on existing data\ndf_script['word_count'] = df_script['spoken_words'].str.split().apply(len)",
    "Initially reset the index of the DataFrames for consistency.",
    " View the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Convert the \"2 of 3\" designed datasets (name of characters and locations) in dataframes into sets for a better handling",
    "Preview dataframes\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
    "Print the head of the episodes dataframe\nprint(df_episodes.head())",
    " Create a list with all tag types.\ntag_list = list(df_script['raw_character_text'])\n\n# Remove duplicates.\ntag_set = set(tag_list)\n\n# Output the number of tag types.\nnum_tag_types = len(tag_set)\nprint(f'Number of unique character tags: {num_tag_types}')",
    "Create a directory to save the output files\noutput_dir = 'output'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)",
    "Replace NaN with empty string\ndf_script = df_script.fillna('')",
    "Make everything lower case.",
    "Visualizing the most popular characters",
    " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Change Name of the First Column for Each Dataframe\ndf_characters.rename(columns={'id': 'character_id'}, inplace=True)\ndf_locations.rename(columns={'id': 'location_id'}, inplace=True)\ndf_script.rename(columns={'id': 'line_id'}, inplace=True)\ndf_episodes.rename(columns={'id': 'episode_id'}, inplace=True)",
    "Merge the datasets to create a single dataframe with all the information we need.",
    "Read the datasets from the data folder into pandas dataframes.",
    "# Value decomposition expansion over time by use of the scatterplot\nplt.scatter(lambda x: x, emmys, plt.style.use('seaborn-deep', lambda x: x))",
    "# Check the general structure of the script dataframe\ndf_script.head()",
    "Select the lines that are spoken by a specific character, e.g., Homer, Marge, Bart, Lisa, or Maggie.",
    "Add custom functions' directory to the path\nmodule_dir = os.path.join(os.path.abspath(''), 'preprocessing')\nsys.path.insert(0, module_dir)",
    " Concatenate the names and surnames of the characters for easier identification\ndf_characters['full_name'] = df_characters['name'] + ' ' + df_characters['surname']",
    "Preview datasets\ndf_characters.head()",
    "We also set some default style parameters for the plots.",
    " Merge characters and locations into the script dataframe\ndf_script = pd.merge(df_script, df_characters, left_on='character_id', right_on='id', suffixes=('','_character')).drop(columns=['id','normalized_name']).reset_index(drop=True)\ndf_script = pd.merge(df_script, df_locations, left_on='location_id', right_on='id', suffixes=('','_location')).drop(columns=['id']).reset_index(drop=True)",
    "Set up logging\nimport logging",
    "Inspect all dataframes and their features",
    "Create a variable to hold the number of lines of the dataset.",
    "Preview the dataframes\ndf_script.head()",
    "Let's have a look at the first 10 rows of each of our datasets.",
    " Filter data frame and display it\ndf_script_filtered = df_script[(df_script['episode_id'] == 652) & (df_script['number'] < 4)]\ndf_script_filtered",
    "Set up custom color palette for visualizations\ncolors = [\n    \"lightblue\",\n    \"blue\",\n    \"royalblue\",\n    \"cornflowerblue\",\n    \"lightsteelblue\",\n]",
    "# Display up to 50 characters\npd.set_option('display.max_rows', 50)",
    "Merge character and location names\nunique_character_names = df_characters.raw_character_text.tolist()\nunique_location_names = df_locations.raw_location_text.tolist()\n\n# Get unique character and location names\nunique_character_names = list(set(unique_character_names))\nunique_location_names = list(set(unique_location_names))\n\n# Replace slashes in character and location names\nunique_character_names = [name.replace('/', '_') for name in unique_character_names]\nunique_location_names = [name.replace('/', '_') for name in unique_location_names]",
    "Set index for faster searches\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "Let see the first lines of each tables:\nprint(\"\\nSIMPSONS CHARACTERS\")\nprint(df_characters.head())\nprint(\"\\nSIMPSONS LOCATIONS\")\nprint(df_locations.head())\nprint(\"\\nSIMPSONS SCRIPT\")\nprint(df_script.head())\nprint(\"\\nSIMPSONS EPISODES\")\nprint(df_episodes.head())",
    "Show first few rows of the characters dataframe\ndf_characters.head()",
    "Create the 'raw_text' field\ndf_script['raw_text'] = df_script['normalized_text'].str.replace('\\r\\n', ' ').str.lower()",
    "For this demo we will work with the script lines dataframe.",
    "Check the content of the characters dataset\ndf_characters.head()",
    "Clean episode titles\ndf_episodes['clean_title'] = df_episodes['title'].str.replace('\\\".*\\\"', '', regex=True)\ndf_episodes['clean_title'] = df_episodes['clean_title'].str.replace('\\[.*\\]', '', regex=True)",
    "Reduce characters and script dataframe to relevant size",
    "Visualize the missing values in the dataframes\nimport missingno as msno",
    "Print the first few lines of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Custom code\nfrom elephas.utils.rdd_utils import to_simple_rdd",
    "Inspect the first few lines of the characters dataframe\nprint(df_characters.head())",
    "Check the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Show the first 5 records of the characters dataframe\ndf_characters.head()",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Limiting the data to only Marge, Lisa, and Bart.",
    " Display the first few rows of the dataframe\ndf_script.head()",
    "Check the first row",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
    "Explore the first 5 rows of each dataframe",
    "Convert to datetime the air_date and create a timestamp index",
    "Load spaCy model\nnlp = spacy.load('en_core_web_sm')",
    "# Inspect first 5 rows of df_characters\ndf_characters.head()",
    " Visualize the first few rows of each DataFrame\nprint(\"Characters Data:\")\nprint(df_characters.head(), end=\"\\n\\n\")\n\nprint(\"Locations Data:\")\nprint(df_locations.head(), end=\"\\n\\n\")\n\nprint(\"Script Data:\")\nprint(df_script.head(), end=\"\\n\\n\")\n\nprint(\"Episodes Data:\")\nprint(df_episodes.head(), end=\"\\n\\n\")",
    "Display the first few rows of each dataframe to understand the data",
    "Remove punctuation and lowercase the text\ndf_script['normalized_text'] = df_script['raw_text'].str.replace('[^\\w\\s]','').str.lower()",
    "Check a sample of the characters dataframe\ndf_characters.head()",
    "Ensure matplotlib uses the 'seaborn-bright' style\nplt.style.use('seaborn-bright')",
    "Let's take a quick look at the structure of the datasets.",
    "View dimensions of dataframes",
    "Merge the dialogues with the character metadata\ndf_character_lines = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')",
    "Inspection of the characters DataFrame",
    "Let's display the first few rows of each of these DataFrames to understand their structure and content.",
    "Load and prepare the Simpsons dataset",
    "Inspecting the dataframes",
    "Print the first few rows of the characters dataframe\nprint(df_characters.head())\n# Print the first few rows of the locations dataframe\nprint(df_locations.head())",
    "Check that the dataframe was loaded correctly\ndf_script.head()",
    "Create a new column containing the full name of the character",
    "Check for any empty cells in a column",
    "Let's take a look at the first few rows of each dataframe.",
    "df_script",
    "Format the dataframes to ensure consistency and quality",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "# Filter the non-english sentences\ndf_script['script'] = df_script['spoken_words']\n\n# Load the English tokenizer\nnlp = spacy.blank('en')\n\n# Tokenize **approximately** to sentences\ndocs = df_script.script[:1000].apply(lambda x: nlp(x))\n\nsentences = []\nfor doc in docs:\n    sentences.extend([sent.text.lower() for sent in doc.sents if len(sent.text) > 1])",
    "\n# Retaining only the main characters from Simpsons character data\nmain_characters = [\n    \"marge\", \n    \"homer\",\n    \"bart\",\n    \"lisa\",\n    \"maggie\",\n    \"skinner\",\n    \"ned\",\n    \"burns\",\n    \"moe\",\n    \"krusty\",\n    \"milhouse\",\n    \"chief\",\n    \"abraham\",\n    \"edna\",\n    \"ralph\",\n    \"apu\",\n    \"barney\",\n    \"nelson\",\n    \"kent\",\n    \"waylon\"\n]",
    "Check the character dataset",
    "The first step is to load the data into our notebook so we can begin exploring it.",
    "Creates a new 'simpsons_script_lines' dataframe that contains the 'normalized_text' and 'character_id' columns\ndf_episodes.drop(['image_url'], axis=1, inplace=True)",
    "Print the number of available script lines\nprint(f'Number of script lines: {df_script.shape[0]:,}')",
    "Ensure that 'id' field is unique for all the dataframes\nassert df_characters['id'].nunique() == len(df_characters)\nassert df_locations['id'].nunique() == len(df_locations)\nassert df_script['id'].nunique() == len(df_script)\nassert df_episodes['id'].nunique() == len(df_episodes)",
    "Create a sample of the Episodes dataframe to validate the data.",
    " Checking how each of the dataset looks like",
    "Visualize the ten most frequent characters, locations and spoken words\n\n# Characters\ntop_characters = df_script['raw_character_text'].value_counts().head(10)\ntop_characters.plot(kind='barh', figsize=(12, 6), title='10 most frequent characters')\nplt.show()",
    "Find the set of all episodes that feature the character \"Marge\"",
    "Check the content of the files",
    " Join the tables on their respective identifiers\ndf = df_script.merge(df_characters, left_on='character_id', right_on='id')\ndf = df.merge(df_locations, left_on='location_id', right_on='id')\ndf = df.merge(df_episodes, left_on='episode_id', right_on='id')",
    "Preview first rows of the dataframe\ndf_script.head()",
    "Let's check a basic description of the script dataframe.",
    "Inspect the structure of each dataframe",
    "Print the head of the first dataframe to inspect the structure and data",
    "Set seaborn style for our plots\nmatplotlib.style.use('seaborn')",
    "Let's look at the first few rows of each dataframe to understand the data better.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect the first few rows of the script dataset to understand its structure\ndf_script.head()",
    " Display available data files\nprint(f'Characters:')\ndisplay(df_characters.head(2))\nprint(f'Locations:')\ndisplay(df_locations.head(2))\nprint(f'Script:')\ndisplay(df_script.head(2))\nprint(f'Episodes:')\ndisplay(df_episodes.head(2))",
    "Let's see what these tables look like.",
    "Choosing a subset of the characters to focus on\ncharacters_focus = [\n    'Lisa_Simpson',\n    'Bart_Simpson',\n    'Homer_Simpson',\n    'Marge_Simpson',\n    'C._Montgomery_Burns',\n    'Seymour_Skinner',\n    'Ned_Flanders',\n    'Moe_Szyslak',\n    'Grampa_Simpson',\n    'Milhouse_Van_Houten',\n    'Krusty_The_Clown',\n    'Chief_Wiggum',\n    'Waylon_Smithers'\n]\n\n# Reduce the dataframes to what we need\ndf_script = df_script[df_script['raw_character_text'].isin(characters_focus)]\ndf_characters = df_characters[df_characters['name'].isin(characters_focus)]\ndf_characters['character_id'] = df_characters['id']\ndf_locations = df_locations[df_locations['normalized_name'].str.contains('springfield', case=False, na=False)]\ndf_script = df_script[df_script['episode_id'].isin(df_locations['episode_id'])]",
    "convert character_id to integer\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce').astype('Int64')",
    "Filter only script line from the simpsons script file and get the character who says it, the episode id it is in and the text",
    "Check the structure and contents of those DataFrames\ndf_characters.head()",
    "  check the data that we have available in the characters dataframe\ndf_characters.head()",
    " Display output of all lines of code and not just the output of the last line",
    "View dataframes head\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Insight Data Science: Simplifying Script Flows for The Simpsons.",
    "Exploring the content of the datasets",
    "Initialization of Spacy model\nnlp = spacy.load('en_core_web_sm')",
    "Remove some extra columns in the characters table",
    "Filter rows with NaN valued from the `character_id` column.",
    " Check data\nprint(\"Characters shape\", df_characters.shape)\nprint(\"Locations shape\", df_locations.shape)\nprint(\"Scripts shape\", df_script.shape)\nprint(\"Episodes shape\", df_episodes.shape)",
    "\ndf_script.head()",
    "Select one or more episodes to analyze\nepisodes = [\n    'noir'\n]",
    " Display the first few rows of each DataFrame to understand its structure and content.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Checking the first 5 records",
    "Clean Script DataFrame\ndf_script = df_script.drop(columns=[\n    'number', 'raw_text', 'timestamp_in_ms', '_heartbeat_', \n    'speaking_line', 'character_id', 'location_id', 'raw_character_text',\n    'raw_location_text', 'spoken_words', 'normalized_text'\n])",
    "remove script lines without any text\ndf_script = df_script.dropna(subset=['spoken_words'])",
    "Exploring the structure of the dataframes",
    "Inspecting the characters dataframe",
    "ronly listed episodes; verify that proper episodes included in download",
    "Remove annoying SettingWithCopyWarning",
    "Check the script dataframe",
    "Checking the first few rows of each dataframe",
    "# Display at a glance the first 5 rows of a dataframe\ndf_characters.head()",
    "Display available scripts lines dataset columns\ndf_script.columns",
    "\n# Gensim\nimport gensim\nimport gensim.corpora as corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import CoherenceModel",
    "\n# Let's take a look at the content of these files\nprint('Characters\\n', df_characters.head())\nprint('\\n\\nLocations\\n', df_locations.head())\nprint('\\n\\nScript\\n', df_script.head())\nprint('\\n\\nEpisodes\\n', df_episodes.head())",
    "\n# Merge the dataframes\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left', suffixes=('_script', '_episode'))\ndf_script = df_script.merge(df_locations, on='location_id', how='left', suffixes=('_script', '_location'))\ndf_script = df_script.merge(df_characters, on='character_id', how='left', suffixes=('_script', '_character'))",
    "Set up spacy\nnlp = spacy.load('en_core_web_md')",
    "Check the dataframe is correctly populated\ndf_script.head()",
    " Show the first 5 rows of the characters dataframe\ndf_characters.head()",
    "View first 5 rows of characters DataFrame\ndf_characters.head()",
    "View the installed spaCy models\n!python -m spacy validate",
    "A quick peak into the character dataframe",
    "Show the first few rows of the characters dataframe\ndf_characters.head()",
    "Merge script with characters and locations\ndf_script = pd.merge(df_script,\n                     df_characters,\n                     left_on='character_id',\n                     right_on='id',\n                     suffixes=('_script', '_character'),\n                     validate='many_to_one')\n\ndf_script = pd.merge(df_script,\n                     df_locations,\n                     left_on='location_id',\n                     right_on='id',\n                     suffixes=('_script', '_location'),\n                     validate='many_to_one')",
    "Check the content of the script DataFrame",
    "check to see what the data look like\ndf_script.head()",
    "Visualize the most spoken words by Homer Simpson",
    " Set the relevant columns to string, we don't want to perform numeric operations on them\ndf_script['raw_character_text'] = df_script['raw_character_text'].astype(str)\ndf_script['spoken_words'] = df_script['spoken_words'].astype(str)\ndf_script['raw_location_text'] = df_script['raw_location_text'].astype(str)\ndf_episodes['title'] = df_episodes['title'].astype(str)",
    " Check against csv files",
    "View dataframe shape\nprint(f'Characters dataframe shape: {df_characters.shape}')\nprint(f'Locations dataframe shape: {df_locations.shape}')\nprint(f'Script dataframe shape: {df_script.shape}')\nprint(f'Episodes dataframe shape: {df_episodes.shape}')",
    "Preview\ndf_script.head()",
    "Let's take a look at the data first.",
    "Filtering Data\n# --------------------------------------------------\n# Step 2: Cleaning Lines, Spans, and Characters\n# --------------------------------------------------",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Merge the episodes file with the script file so that each script line is associated with its corresponding episode.",
    "inspect the first few entries of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Display the first lines of the loaded DataFrames\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display first few rows of the characters dataframe\ndf_characters.head()",
    "# Ensure the PostgreSQL server is running\n!service postgresql start",
    " Show first 10 rows of df_script.",
    "Display the dimensions of the data with the .shape attribute",
    "Create the list of documents (each document is a line of the script)\ndocuments = df_script['raw_text'].fillna('xxx').values",
    " Show info for each dataframe\ndf_characters.info()\ndf_locations.info()\ndf_script.info()\ndf_episodes.info()",
    "\ndf_script.head()",
    "df_script.head()",
    "Display all dataframes\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Count number of lines by character ID and script ID.\nlines = df_script.groupby(['character_id', 'episode_id']).apply(lambda x: ' '.join(x['spoken_words'].astype(str)))",
    "Look at some examples from the dataset\ndf_script.head()",
    "Add an index to the dataframe to be able to use the efficiency of the join operation.",
    "Preview the characters dataframe\ndf_characters.head()",
    "Set the index of your dataframe to be the column episode_id if it's not already the case.",
    "Utils\nfrom utils import get_text_entities, clean_dialogue, plot_wordcloud",
    "Display all columns to understand the dataset better\npd.set_option('display.max_columns', None)",
    "Display settings for the number of columns and rows\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)",
    " Show the first few lines of characters data.",
    "Clean data\ndf_script = df_script[df_script[\"spoken_words\"].notna()]",
    " Headers of each dataframe\nprint(\"\\n### Characters\\n\", df_characters.columns.tolist())\nprint(\"\\n### Locations\\n\", df_locations.columns.tolist())\nprint(\"\\n### Script lines\\n\", df_script.columns.tolist())\nprint(\"\\n### Episodes\\n\", df_episodes.columns.tolist())",
    "We will take a brief look at the data to understand its structure and contents.",
    "View first 5 lines of the characters dataframe\ndf_characters.head()",
    "Utils script\nfrom collections import Counter",
    "Visualize the distributions of script line lengths\nline_length = df_script['normalised_text'].str.len()\nline_length.describe()",
    "Print the characters dataframe to understand its structure\nprint(df_characters.head())\n\n# Print the locations dataframe to understand its structure\nprint(df_locations.head())\n\n# Print the script dataframe to understand its structure\nprint(df_script.head())\n\n# Print the episodes dataframe to understand its structure\nprint(df_episodes.head())",
    "Show first 5 records of the characters dataframe\ndf_characters.head(5)",
    "Create a connection to the SQLite database containing the data\nconn = sqlite3.connect('data/simpsons.sqlite')",
    "Create dictionary for all the seasons",
    "Set up a personal spacy model.",
    "Define the types for pandas\ndf_characters.astype({\n    'id': int,\n    'name': str,\n    'normalized_name': str\n})",
    " Remove non-dialogue rows and unnecessary columns\ndf_script_filtered = df_script[df_script['speaking_line'] == True].reset_index(inplace=False, drop=True)\ndf_script_filtered = df_script_filtered[['episode_id', 'character_id', 'location_id', 'raw_text']]",
    "Merge the scripts with the speaker names and locations",
    " Check the characters dataframe\ndf_characters.head()",
    " Visualize Content\nplt.hist(df_script['character_id'].value_counts().values, bins=np.arange(0, 500, 10))\nplt.xlabel('Utterances per character')\nplt.ylabel('Number of characters')\nplt.title('Utterances per character')",
    " Let's have a look at the first few rows of the characters dataframe.",
    "Display top 5 records of each data frame to understand the fields",
    "Show the first few lines of the characters dataframe\ndf_characters.head()",
    "We will remove the first column, which is the index column, and start by displaying a few lines from each dataframe.",
    "ECOMMENDATION_ID: rQs3QxgK\n# We get basic information about thtdf_characters.info()e datasets to know what we are dealing with\nprint('Characters:', df_characters.info())\n# print('Locations:', df_locations.info())\n# print('Script lines:', df_script.info())\n# print('Episodes:', df_episodes.info())",
    "Initialization of a tokenizer using Spacy's English language model.",
    "Preprocessing\n# Removing rows where the 'normalized_text' column is NaN\ndf_script = df_script.dropna(subset=['normalized_text'])",
    " Extract all lines side by side and all names\nsimpsons_lines = list(df_script['raw_text'])\nsimpsons_characters = list(df_script['raw_character_text'])",
    "Check the resulting DataFrames\ndf_characters.head()",
    "Let's take a look at our dataframes.",
    " Filter only the script of the episode with the specified id\ndf_script_episode = df_script[df_script['episode_id'] == 11]",
    "Extract the training and test set",
    "Show the first rows of the script dataframe\ndf_script.head()",
    "A preview of the first dataframe\ndf_characters.head()",
    " Let's have a look at the loaded dataframes.",
    "Print the first 10 rows of the script dataframe\ndf_script.head(10)",
    "Let's start by displaying a sample of each dataframe.",
    "Set a seed for reproducibility",
    " Print shape of each dataframe\nprint(f'Characters dataframe: {df_characters.shape}')\nprint(f'Locations dataframe: {df_locations.shape}')\nprint(f'Script dataframe: {df_script.shape}')\nprint(f'Episodes dataframe: {df_episodes.shape}')",
    " Set id as index\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)",
    "Data Exploration",
    "WordCloud of the Simpsons script\n# Word cloud of all the scripts spoken by each character\nall_scripts = ' '.join(df_script.normalized_text)\nwordcloud = WordCloud(width = 800, height = 400, random_state=21, max_font_size=110, background_color='white').generate(all_scripts)\n\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()",
    " Research question: \"What are the most frequent words used by each character across all episodes?\"\n\n# Create a dataset with the characters' lines and speaker\ndf_characters['character_lines'] = df_script[df_script.character_id.isin(df_characters.id)].groupby('character_id').apply(lambda x: ' '.join(x['character_words'].str.lower().fillna(' ')))\ndf_characters['n_words'] = df_characters.character_lines.str.split(' ').apply(len)\n\n# Eliminate characters with less than 1000 words\ndf_filtered_characters = df_characters[df_characters.n_words>1000]\n\n# Create a list of lines for each character\ncharacter_lines_list = df_filtered_characters.character_lines.str.split('\\.').tolist()\ncharacter_lines_speakers = df_filtered_characters.character_name.tolist()\n\n# Count words\ncharacter_words_count = list(map(lambda x: Counter(x.split(\" \")), character_lines_list))\n\n# Removing stop words\nnlp = spacy.load('en_core_web_sm')\nfor i in range(len(character_words_count)):\n    print('Filtering stop words - character {}'.format(character_lines_speakers[i]))\n    words = list(character_words_count[i].keys())\n    words = list(filter(lambda x: nlp(x)[0].is_stop, words))\n    character_words_count[i] = {k:v for k,v in character_words_count[i].items() if k not in words}\n    print('number of words after filtering: {}'.format(len(character_words_count[i])))",
    "Clean empty utterances\ndf_script = df_script.dropna(subset=['raw_character_text', 'spoken_words'])",
    " Load Spacy language model\nnlp = spacy.load('en_core_web_sm')",
    " To verify the data has been imported correctly, let's take a look at each DataFrame using the .head() method.",
    " Show first few example script lines\ndf_script.head()",
    "Set maximum column width to display more content\npd.set_option('display.max_colwidth', 500)",
    "Display first 5 rows from each dataframe\ndf_characters.head(5)",
    "check script_df.head() to understand the dataset",
    " Display the first few records of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "If the `inplace` parameter is `False`, resets the index of the DataFrame in a non-destructive manner",
    "Checking the first 5 rows of the script DataFrame\ndf_script.head()",
    "Create backup copies of the datasets\ndf_characters_bk = df_characters.copy()\ndf_locations_bk = df_locations.copy()\ndf_script_bk = df_script.copy()\ndf_episodes_bk = df_episodes.copy()",
    " check word count distribution of the utterances\ndf_script['word_count'] = df_script['normalized_text'].str.split().apply(len)",
    "Path for exported data\noutput_data_path = 'output_data/'",
    "Select episode 1, filter out non main characters and get the actual script",
    "This script is intended to turn script lines into bag of words format, and then create word clouds.\n# To do so, we start by processing script lines to obtain bag of words.\n# We then implement a function to display the word cloud for a subset of episodes or a subset of speakers.",
    "Checking the content of each data set\nprint(\"Characters: \")\nprint(df_characters.info())\nprint(df_characters.head(10))\n\nprint(\"\\nLocations: \")\nprint(df_locations.info())\nprint(df_locations.head(10))\n\nprint(\"\\nScript (lines): \")\nprint(df_script.info())\nprint(df_script.head(10))\n\nprint(\"\\nEpisodes: \")\nprint(df_episodes.info())\nprint(df_episodes.head(10))",
    "Display the first 3 rows of the characters dataframe\ndf_characters.head(3)",
    "Data Cleaning",
    "# Show first lines of script data\ndf_script.head()",
    "Output some useful information about the datasets\nprint(df_script.shape)\ndf_script.head()",
    "the `str` accossor will be used for performing string operations on the Series.",
    "Let's focus on script lines for this part of the analysis, specifically the spoken words.",
    "Extracting the characters who appear in the script\ncharacters_list = df_script[\"raw_character_text\"].value_counts().keys().tolist()\n\n# Merging the dataframe with the script lines and the one with unique characters\ndf_characters = df_characters.merge(pd.DataFrame(characters_list, columns=[\"character_name\"]), on=\"character_name\")",
    " There was an error in the code. The \"inplace\" parameter doesn't exist for the \"reset_index\" method.",
    "Checking the main data and the amont of data",
    " Optional, you can run below, if you want to use the medium model. It takes some time to load.\nnlp = spacy.load('en_core_web_md')",
    " Now, let's take a look on characters, script, episode and locations DataFrames.",
    "Check the first few rows of the dataframe\nprint(df_characters.head())",
    "Get script and merge\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')\ndf_script = pd.merge(df_script, df_characters, on='character_id')",
    " Merge characters and script\ndf_characters_script = df_script.merge(df_characters, left_on='character_id', right_on='id')\n\n# Merge locations and script\ndf_locations_script = df_script.merge(df_locations, left_on='location_id', right_on='id')",
    "Display the first few rows for each table\nprint('Characters')\nprint(df_characters.head())\nprint()\nprint('Locations')\nprint(df_locations.head())\nprint()\nprint('Script')\nprint(df_script.head())\nprint()\nprint('Episodes')\nprint(df_episodes.head())",
    " Check the first few rows of the characters DataFrame\ndf_characters.head()",
    "Modify plot style to 'ggplot' style\nplt.style.use('ggplot')",
    " merge the locations with the script lines\ndf_locations = df_locations.rename(columns={\"id\": \"raw_location_id\"})\ndf_script = df_script.rename(columns={\"raw_location_id\": \"location_id\"})",
    " Length of the dataset\nlen(df_script)",
    "Load Spacy model\nnlp = spacy.load(\"en_core_web_sm\")",
    "Combining script data with other datasets",
    "Rename columns to lowercase and replace spaces with underscores\ndf_characters.columns = [col.lower().replace(' ', '_') for col in df_characters.columns]\ndf_locations.columns = [col.lower().replace(' ', '_') for col in df_locations.columns]\ndf_script.columns = [col.lower().replace(' ', '_') for col in df_script.columns]\ndf_episodes.columns = [col.lower().replace(' ', '_') for col in df_episodes.columns]",
    "Merge the tables by referencing the foreign keys",
    "Configure workspace\nos.makedirs('images', exist_ok=True)",
    "Process the script to get the characters and locations that appear in each episode",
    " Remove rows we don't need to minimize memory usage\ndf_script.drop(['spoken_words', 'raw_text'], axis=1, inplace=True)",
    "Clean encountered NaN in raw data\ndf_script_clean = df_script.dropna(subset=['raw_text']).reset_index(drop=True)",
    "Looking at the first rows of each dataframe",
    "Plugin Initialization\nimport nb_black",
    "Setting a dataframe as global will make it available in the entire script.",
    "Limit script to the episodes in the dataset\nall_ep_ids = df_episodes.id.values\ndf_script = df_script[df_script['episode_id'].isin(all_ep_ids)]",
    "Display which rows had NaN values for the script data\ndf_script[df_script.isna().any(axis=1)]",
    "Setting to display the max amount of columns as 200, this is just for ease of viewing the dataframe.",
    "First, we read in the data from CSV files into pandas DataFrames. We reset the index and drop the previous index to ensure the index remains continuous integers.",
    " Display the dataframe shapes\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
    " Display some general information about the dataframes\nprint(\"Characters\")\ndisplay(df_characters.head())\nprint(\"Locations\")\ndisplay(df_locations.head())\nprint(\"Script\")\ndisplay(df_script.head())\nprint(\"Episodes\")\ndisplay(df_episodes.head())",
    "For more information on what each dataframe holds, check notebook 1.",
    "Examine the first few rows of the characters data\ndf_characters.head()",
    "Some small adjustments to the dataframes\ndf_characters.drop(columns=['normalized_name'], inplace=True)\ndf_characters = df_characters.dropna(subset=['name'])\n\ndf_locations = df_locations.dropna(subset=['normalized_name'])\n\ndf_episodes = df_episodes.dropna(subset=['title'])\n\ndf_script = df_script.dropna(subset=['raw_character_text', 'spoken_words'])",
    "Research on NLP and SpaCy, stemming and lemmatization libraries",
    "Show configurations for a better layout\npd.options.display.max_columns = None\npd.options.display.max_rows = 10",
    "Filter out rows with empty or NaN values for the spoken_words attribute of the script.\ndf_script = df_script.dropna(subset=['spoken_words']).reset_index(drop=True)",
    "CHECKPOINT: all dataframes are loaded",
    "To avoid cache memory error and reload nlp, this nlp pipe can be persisted using disk\n# Also, then it can easily be loaded with `spacy.load()` function\n\n# pip install dill\nimport dill",
    "\n# CONFIGURATION\n#",
    "Preprocessed dataframe from Jasper's notebook\ndf_script = pd.read_parquet('../output/script_preprocessed.parquet')",
    "Create an English language class\nnlp = spacy.load('en')",
    "Check for null values\nprint(df_script.isnull().sum())",
    "acketed text is placeholder content from the original Python file.",
    "Check if everything is reand correctly\ndf_characters.head()",
    "Preview the datasets\ndf_characters.head()",
    " Show the first episode",
    "Extract a small subset for testing\ndf_script = df_script.head(100000)",
    " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Preview the first 5 rows of each dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Process basic Natural Language tasks using Spacy",
    "Utility functions",
    "REMOVING UNNECESSARY COLUMNS\ndf_script = df_script[['episode_id', 'id', 'character_id', 'location_id', 'raw_text']]",
    "Head of characters dataframe\ndf_characters.head()",
    " Now the Simpsons dataset is loaded and ready for analysis.",
    "Check the loaded datasets\ndf_script.head()",
    "Merge character, location and episode data into script data\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))\ndf_script = df_script.merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('', '_episode'))",
    " LIst of dataframes and their column names\ndfs = {\"characters\": df_characters, \"locations\": df_locations, \"script\": df_script, \"episodes\": df_episodes}\nfor name, df in dfs.items():\n    print(f\"{name}: {', '.join(df.columns)}\")",
    "Joining lines with \"\\\"\ndf_script = pd.read_csv('data/simpsons_script_lines.csv').\\\n    reset_index(inplace=False, drop=True)",
    "Get recent records from single episode per row\ndf_script = df_script.sort_values('id', ascending=True)",
    "Filter the script data to only include spoken lines from the characters dataframe.",
    "Compute important additional data\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\ndf_script = df_script.merge(df_locations, on='location_id', how='left')",
    "Show the first 5 rows of each of these dataframes to understand better what data is available in them\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Displaying the sample of dataframe of script lines\ndf_script.head(10)",
    "View the dataframe columns and data types\nprint(df_script.info())",
    " Optional: add spaCy language model for tokenization\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])",
    "Merge the script and the characters DataFrame along the 'character_id'\ndf_script = pd.merge(df_script, df_characters, on='character_id')",
    " Sneak peek at the data\ndf_script.head()",
    "Let's see what we are working with.",
    "Checking the first few entities in each dataset.",
    " Join all tables to determine what characters are in what episodes\ndf_char_episode = df_script.merge(df_episodes[['id', 'title']], left_on='episode_id', right_on='id', suffixes=('_script', '_episode'))\ndf_char_episode = df_char_episode.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_ce', '_character'))\ndf_char_episode = df_char_episode.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_ce', '_location'))",
    "Check everything imported correctly\ndf_characters.head()",
    "We will start cleaning and transforming the data starting by the episodes data frame.",
    "Merge script lines and episodes dataframes\ndf = pd.merge(df_script, df_episodes, on='id', suffixes=('_script', '_episodes'))",
    " Check the import of datasets\nprint(\"Characters dataset:\")\ndisplay(df_characters.head())\n\n\nprint(\"\\nLocations dataset:\")\ndisplay(df_locations.head())\n\nprint(\"\\nScript dataset:\")\ndisplay(df_script.head())\n\nprint(\"\\nEpisodes dataset:\")\ndisplay(df_episodes.head())",
    "Filter the data to the characters of interest.",
    "Import the data and show the first 5 rows",
    " Remove faulty:\ndf_script = df_script[df_script[\"episode_id\"] != 394]",
    " Install the standard model (en_core_web_sm) in case it's not installed\n!python -m spacy download en_core_web_sm",
    " Calculate some simple statistics for each episode\ndf_script['word_count'] = df_script['normalized_text'].apply(lambda x: len(str(x).split()))\ndf_episodes['word_count'] = df_episodes['normalized_text'].apply(lambda x: len(str(x).split()))\n\ndf_episodes_stats = df_script.groupby('episode_id').agg(\n    lines=('id', 'count'),\n    characters=('raw_character_text', lambda x: x.nunique()),\n    locations=('raw_location_text', lambda x: x.nunique()),\n    average_words_per_line=('word_count', 'mean')\n).reset_index()\n\n# Merge the episode statistics with the rest of the episode information\ndf_episodes = df_episodes.merge(df_episodes_stats, on='id')",
    "Preview the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Filter lines up to 10 words to get rid of long and complex sentences in the character dialogues\ndf_script['word_count'] = df_script['normalized_text'].apply(lambda x: len(x.split()))",
    "This is a csv file that contains meta information about episodes.",
    "# remove missing values\ndf_script = df_script.dropna()",
    " Display a preview of each Data Frame\nprint('Characters Data Frame:')\nprint(df_characters.head())\nprint('\\nLocations Data Frame:')\nprint(df_locations.head())\nprint('\\nScript Data Frame:')\nprint(df_script.head())\nprint('\\nEpisodes Data Frame:')\nprint(df_episodes.head())",
    " Remove problematic series clone (due to successive manipulations)\nif 'Unnamed: 0' in df_characters:\n    df_characters = df_characters.drop(columns=['Unnamed: 0'])",
    "Visualizing the number of lines per episode\nlines_per_episode = df_script.groupby('episode_id').size()\nlines_per_episode.name = 'lines'\nlines_per_episode = lines_per_episode.reset_index()\n\nplt.figure(figsize=(15, 5))\nplt.plot(lines_per_episode.index, lines_per_episode.lines, marker='o', linestyle='-')\nplt.title('Number of lines per episode')\nplt.xlabel('Episode')\nplt.ylabel('Number of lines')\nplt.show()",
    "Configure matplotlib style\nplt.style.use('fivethirtyeight')",
    "Let's take a look at the characters DataFrame.",
    " Calculate and plot the number of lines per character.",
    "Merge the datasets together to create a single coherent dataset.",
    " Display the characters and locations DataFrames",
    "Check for missing values",
    " STEP 1: Exploratory Data Analysis (EDA)",
    "Convert gender, character and location Id's to character and location names respectively.",
    " Tokenize the script lines for later use",
    "Clean the data",
    "Create a spacy nlp object\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Process the text and add it to the dataframe\nprocessed_script = []",
    " Print the first few entries of the characters table to understand its structure and the information available.\ndf_characters.head()",
    "Merge the dataframes based on the episode ID",
    "Tying a newline character at the end of this code causes the error or the format to be changed. Therefore, I will end it here.",
    "Limit the number of lines to use due to the large size of the data set\nnum_lines = 10000 ",
    "Displaying the output of the last code xpression in Jupyter doesn't print the dataframe, \n# but calling the dataframe which we will do for each of them later does\ndf_characters",
    "Print type and shape of each table\nprint(\"Characters table - \", df_characters.shape)\nprint(\"Locations table - \", df_locations.shape)\nprint(\"Script table - \", df_script.shape)\nprint(\"Episodes table - \", df_episodes.shape)",
    " Reading word frequency data",
    "Merge different tables to and remove possible inconsistencies and conflicts.",
    " Load spaCy's English NLP model\nnlp = spacy.load('en_core_web_sm')",
    " Remove unncessary information",
    "display the first 5 rows of the script data frame\ndf_script.head()",
    "configure spacy\nnlp = spacy.load('en_core_web_sm',disable=['parser', 'tagger','ner'])",
    "Check out the schema of each table\nprint(df_characters.head(3))\nprint(df_locations.head(3))\nprint(df_script.head(3))\nprint(df_episodes.head(3))",
    "Setting up the wordcloud stopwords\nfrom wordcloud import STOPWORDS\n\nnlp = spacy.load('en')\nstop_words = spacy.lang.en.STOP_WORDS # getting spacy's stop words\nstop_words |= STOPWORDS # using the union operator to combine the stop words",
    "Then, we have to filter the script data to remove rows with missing or invalid values and keep only the dialogue lines.",
    "View the first few rows of the characters dataframe\ndf_characters.head()",
    " Look at who the characters are",
    "Display the first 5 lines of each dataframe to understand its structure and the information available.",
    " Check the first 5 rows of Simpsons characters dataset\ndf_characters.head()",
    " Check if the dataset was loaded correctly\ndf_characters.head()",
    " Custom\nos.makedirs(\"results\", exist_ok=True)",
    "Join the \"simpsons_script_lines\" with \"simpsons_episodes\" to extend our dataset.",
    " Enable the TQDM notebook extension to visualize loop processing.",
    "Data Preparation",
    " Check if script has bee properly loaded",
    "Let's take a look at the data first:",
    "Load spacy language model\nnlp = spacy.load('en_core_web_sm')",
    " Set up the visualisation defaults",
    "View the first few rows of the characters data\ndf_characters.head()",
    "Initialize spacy\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n\n# Preprocessing\ndf_script = df_script.fillna('')\ndf_script['character_id'] = df_script['character_id'].apply(lambda x: x.strip())\ndf_script['location_id'] = df_script['location_id'].apply(lambda x: x.strip())\ndf_script['raw_text'] = df_script['raw_text'].apply(lambda x: x.strip())\n\ndf_episodes = df_episodes.fillna('')",
    "Check the columns' names to see what to analyze\ndf_script.columns",
    " Display the first few rows of the dataframe\ndf_script.head()",
    "Estimate the episode's length based on the number of words in the script\ndf_script['word_count'] = df_script['normalized_text'].apply(lambda x: len(x.split()))",
    "Inspect the dataframes for the first time\nprint('Characters dataframe')\nprint(df_characters.head(5))\nprint('\\n\\nLocations dataframe')\nprint(df_locations.head(5))\nprint('\\n\\nScript dataframe')\nprint(df_script.head(5))\nprint('\\n\\nEpisodes dataframe')\nprint(df_episodes.head(5))",
    " Set a seed for reproducibility of random operations\nnp.random.seed(42)",
    " This line of code^- reads the csv files into pandas dataframes for further processing and analysis.",
    "Data\n# Let's have a first look at the datasets.",
    "Display settings\npd.set_option('display.max_columns', None)",
    "Show dimensions of data tables\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "Print first 5 rows of the script data\ndf_script.head()",
    " Text preprocessing\nimport re\nimport string\n\nimport nltk\n\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n\n# Download required resources\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')",
    "nlp = spacy.load('en_core_web_sm')",
    "Checking if all the DataFrames have been loaded successfully\nprint(f'Simpsons Characters: {df_characters.shape}')\nprint(f'Simpsons Locations: {df_locations.shape}')\nprint(f'Simpsons Script: {df_script.shape}')\nprint(f'Simpsons Episodes: {df_episodes.shape}')",
    "Show first 10 rows of the characters dataframe\ndf_characters.head(10)",
    "Display first few rows of the characters dataframe\ndf_characters.head()",
    "Check dataset sizes\nprint(f'Simpsons Characters Dataset: {df_characters.shape}')\nprint(f'Simpsons Locations Dataset: {df_locations.shape}')\nprint(f'Simpsons Script Dataset: {df_script.shape}')\nprint(f'Simpsons Episodes Dataset: {df_episodes.shape}')",
    "Functions to clean and preprocess text data",
    "Load Spacy model\nnlp = spacy.load('en_core_web_sm')",
    "Inspect the first 5 rows of each dataframe to understand what kind of information it contains.",
    "Inspect the first 5 rows of 'simpsons_characters.csv'\ndf_characters.head()",
    " Import gensim and show its version\nimport gensim\ngensim.__version__",
    "Set some options for pandas\npd.set_option('display.max_columns', 999)\npd.set_option('display.max_rows', 999)",
    "Let's see the first rows of each one of the files to better understand them.\n\nprint(\"Characters:\")\nprint(df_characters.head())\nprint(\"Locations:\")\nprint(df_locations.head())\nprint(\"Script:\")\nprint(df_script.head())\nprint(\"Episodes:\")\nprint(df_episodes.head())",
    " Set float format for better readability\npd.options.display.float_format = '{:,.2f}'.format",
    "Preview the characters dataset\ndf_characters.head()",
    "Truncate script titles because of their length for printed result clarity\npd.set_option('display.max_colwidth', 50)",
    "Print some statistics about the data",
    "Print out the dataframe to better understand its structure\ndf_script.head()",
    "Cleanup and preprocess the data",
    " View the first few rows of the characters DataFrame\ndf_characters.head()",
    "Replace NaN values\ndf_characters['normalized_name'] = df_characters['normalized_name'].fillna('')",
    " Merge the datasets based on their respective keys.",
    " Display the first few records of `df_characters`\ndf_characters.head()",
    "View the top 5 records of all the Dataset\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    "Set the directory for saving/loading the plot data.",
    "Show first rows of the dataset\ndf_script.head()",
    "Merge datasets together\ndf_episodes = df_episodes.rename(columns={\"id\" : \"episode_id\"})\ndf_script = pd.merge(df_script, df_episodes[['episode_id', 'title']], on='episode_id')\ndf_script = df_script.dropna(subset=['raw_text', 'character_id'])\ndf_episodes = df_script.loc[:, ['episode_id', 'title']].drop_duplicates()\n# tqdm.pandas()\n# df_script['nlp_processed_text'] = df_script['raw_text'].progress_apply(lambda x: nlp(x))",
    " First, to understand the data, we want to show the first and last row of each dataframe.",
    "Remove NA values in speaking line column\ndf_script = df_script.dropna(subset=['Normalized_text']).reset_index(inplace=False, drop=True)",
    " Print the first few rows of each dataframe to understand the data",
    "download \"en_core_web_md\" model to make sure benchmarks are reproducible\n!python -m spacy download en_core_web_md",
    "View the structure of the characters dataframe\ndf_characters.head()",
    "define some helpful functions",
    " Display dimensions and first 5 records of each data frame\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)\n\nprint('Displaying Simpsons Characters')\nprint(df_characters.head())\nprint('Displaying Simpsons Locations')\nprint(df_locations.head())\nprint('Displaying Simpsons Script')\nprint(df_script.head())\nprint('Displaying Simpsons Episodes')\nprint(df_episodes.head())",
    "Initial exploration of the datasets\ndf_characters.head()",
    " Filter the script dataframe to only keep the first 20 seasons\ndf_script = df_script[df_script['episode_id'] <= 441].reset_index(drop=True)",
    "Utility function\ndef expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n                                      flags=re.IGNORECASE|re.DOTALL)\n    def expand_match(contraction):\n        match = contraction.group(0)\n        first_char = match[0]\n        expanded_contraction = contraction_mapping.get(match)\\\n                                if contraction_mapping.get(match)\\\n                                else contraction_mapping.get(match.lower())                       \n        expanded_contraction = first_char+expanded_contraction[1:]\n        return expanded_contraction\n        \n    expanded_text = contractions_pattern.sub(expand_match, text)\n    expanded_text = re.sub(\"'\", \"\", expanded_text)\n    return expanded_text",
    "Set correct display options for Pandas dataframes\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.width', 200)",
    "Create test sets that have the same items but in a different order\ntest_set1 = {1, 2, 3}\ntest_set2 = {3, 1, 2}",
    " Extracting the text for analysis\nscript = df_script['raw_text'].to_list()",
    " Combine first and last name for character identification",
    "Data merge\ndf_script = df_script \n    .merge(df_episodes, on='episode_id', how='left')\n    .merge(df_characters, on='character_id', how='left')\n    .merge(df_locations, on='location_id', how='left')",
    " Merge script with characters\ndf_script_characters = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character')).reset_index(inplace=False, drop=True)",
    "Merge script and episodes dataframes\ndf = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_ep'))\n\n# Select only the episodes of the year 2000 and on\ndf = df[df['original_air_year'] >= 2000]",
    "Preprocessing\n# Convert timestamps to datetime objects\ndf_script.timestamp_in_ms = pd.to_datetime(df_script.timestamp_in_ms, unit='ms')\n\n# Extract script and achors\nscripts = df_script.normalized_text\nanchors = df_script.raw_text",
    "Create a 'simpsons' folder if it doesn't exist\nif not os.path.exists('simpsons'):\n    os.makedirs('simpsons')",
    "check the first few lines of the characters dataframe",
    "Remove incomplete script lines from the dataframe\ndf_script = df_script[(df_script['speaking_line'] == True) & (df_script['raw_location_text'].notnull())]\ndf_script.reset_index(drop=True, inplace=True)",
    " Clean characters\n# Remediate duplicate/empty rows\ndf_characters = df_characters.drop_duplicates(subset='id')\ndf_characters = df_characters.dropna(subset=['name'])\n\n# Ensure case-insensitive matching\ndf_characters['name_lowercase'] = df_characters['name'].str.lower()",
    "Merge character and location quote lines\ndf_char_loc = df_script[(df_script['character_id'] <= df_characters.shape[0]) & (df_script['location_id'] <= df_locations.shape[0])].reset_index(inplace=False, drop=True)\ndf_char_loc[\"character\"] = df_char_loc['character_id'].map(df_characters['name'])\ndf_char_loc[\"location\"] = df_char_loc['location_id'].map(df_locations['name'])\n\n# Verify the new DataFrame\ndf_char_loc.head()",
    " Show the modules.",
    "Check the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Show first 5 rows of each dataset\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Visualize the head of the script DataFrame to understand its structure\ndf_script.head()",
    "Check the first couple of rows of the dataframe\ndf_script.head()",
    " Display the first few rows of each dataframe to understand the data",
    "Cast data into the appropriate data type",
    " Check the contents of the files\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "In[2]:",
    "Filter from season 3 onwards\ndf_script = df_script[df_script.season >= 3]",
    "Display the first few lines of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Join the datasets using their respective keys",
    "\ndf_script.head()",
    "Examine the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Check dataframe shapes\nprint('Characters shape:', df_characters.shape)\nprint('Locations shape:', df_locations.shape)\nprint('Script shape:', df_script.shape)\nprint('Episodes shape:', df_episodes.shape)",
    "Information about the datasets",
    "Joining characters, locations and episodes to script data\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\ndf_script = df_script.merge(df_locations, on='location_id', how='left')\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')",
    "Clean up\ndf_script = df_script.dropna()",
    "Let's see how the script lines dataframe look like.",
    " Look at the data",
    " display the first few rows of the script dataset\ndf_script.head()",
    "# Show first 5 entries of 'simpsons_characters.csv'\ndf_characters.head()",
    "Preview the first few lines of each table to understand what we are dealing with\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check the first rows of the dataset `df_script` (to identify common columns and column names)",
    "Checking if the dataframes are loaded correctly",
    "Drop completely empty columns\ndf_script = df_script.dropna(axis=1, how='all')",
    "Create output directory if it does not exist\noutput_dir = 'output'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)",
    "Inspect the contents of the characters DataFrame.",
    "Limit the rows for the script dataframe",
    "Split the script into Story and coaching content.",
    "Filter out lines which are not spoken by characters\ndf_script = df_script.loc[df_script['speaking_line'] == True]",
    "Remove script lines without character, location, or raw text\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'raw_text']).reset_index(inplace=False, drop=True)",
    " display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "merged_df = df_script.merge(df_characters, on='raw_character_text', how = 'left')\nmerged_df = merged_df.merge(df_locations, on='raw_location_text', how = 'left')",
    "Loading the data into dataframes",
    "We will load and explore the data to get a first impression of the datasets.",
    " Data files\nos.listdir('data')",
    "Inspect the structure of the datasets",
    "Check missing values and df size",
    " Merge df_script with df_episodes to add more context to the lines of dialogue\ndf = pd.merge(df_script, df_episodes, on='episode_id', how='left')",
    "Let's clean the Script data first.",
    "Data Preparation",
    "Visualizing and understanding the data",
    "Declare the NLP pipeline\nnlp = spacy.load('en_core_web_sm')",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    " Display the first few rows of the table\nprint(df_script.head())",
    " Filter out non-speaking lines from df_script\ndf_script = df_script[df_script.speaking_line].reset_index(drop=True)",
    "View basic info about the dataframes\nprint(df_characters.head())",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "Explore the characters dataset\ndf_characters.head()",
    "Using driver function to parse the datasets for us\ndf_tuples = (\"Characters\", df_characters), (\"Locations\", df_locations), (\"Script\", df_script), (\"Episodes\", df_episodes)\nfor name, df in df_tuples:\n    print(name)\n    print(df.head())\n    print('\\n')",
    "Filter the lines with locations",
    "Inspecting first few entries of `df_characters` DataFrame",
    "Let's print the tables on the notebook to inspect them.",
    "Limit the number of rows displayed for the dataframes to a maximum of 5\npd.set_option('max_rows', 5)",
    "Extract genders for characters_forename column\ndf_characters[['forename', 'gender']].sample(10)",
    "Pandas default display options\npd.options.display.max_columns = None\npd.options.display.max_rows = None",
    "Print the shape and column names of the loaded data\nprint(\"Characters\")\nprint(df_characters.shape, df_characters.columns)\nprint('--'*24)\nprint(\"Locations\")\nprint(df_locations.shape, df_locations.columns)\nprint('--'*24)\nprint(\"Script\")\nprint(df_script.shape, df_script.columns)\nprint('--'*24)\nprint(\"Episodes\")\nprint(df_episodes.shape, df_episodes.columns)\nprint('--'*24)",
    "Merge all datasets on 'episode_id'\ndf = df_script.merge(df_episodes, on='episode_id')\ndf = df.merge(df_locations, on='location_id')\ndf = df.merge(df_characters, on='character_id')",
    "First, we import the necessary libraries and then read the CSV files into pandas dataframes.",
    "Let's have a look at the data.",
    "Add the following code to display the first few rows of the characters dataframe:\nprint(df_characters.head())",
    "Inspect data frames",
    "Check content of dataframe with confirmed deduplication",
    "Display the first 5 rows of the dataframes to inspect them\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "\"\n# Set the global parameters\nglobal_params = {\n    'REPLACE_NAME': 'Nat',\n    'REPLACE_LOCATION': 'Boston',\n    'DEFAULT_SUB': 'PERSON',\n    'PLOT_FILENAME': 'nat_cloud.png',\n    'NLP_MODEL': 'en_core_web_sm',\n    'NLP_REGEX_RULE_PREFIX': '-',\n    'NLP_REGEX_RULE_INFIX': '@',\n    'POS_NAMES': ['NOUN', 'PROPN', 'ADJ']\n}",
    "Display the first rows of the table containing the simpsons scripts.",
    "Set up working directory\nos.chdir('C:/Users/novir/github/simpsons_analysis')",
    "Select the key elements and only a subset of columns in the script table",
    "Remove bad characters and extra white spaces from the character names\ndf_script.raw_character_text = df_script.raw_character_text.str.strip()\ndf_characters.character_name = df_characters.character_name.str.strip()",
    "Browse files in the data directory\nos.listdir('data')",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    "Display the first few rows of the dataframe to understand the structure of the data.",
    " Merge the script lines with episode and characters data\ndf_script_lines = df_script.merge(df_episodes, on='episode_id')\ndf_script_lines = df_script_lines.merge(df_characters, left_on='character_id', right_on='id')\ndf_script_lines.rename(columns={'name': 'character_name'}, inplace=True)\ndf_script_lines = df_script_lines[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms',\n                                   'season', 'episode_name', 'character_id', 'character_name',\n                                   'location_id', 'spoken_words']]\ndf_script_lines = df_script_lines.merge(df_locations, left_on='location_id', right_on='id')\ndf_script_lines.rename(columns={'name': 'location_name'}, inplace=True)\ndf_script_lines = df_script_lines[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms',\n                                   'season', 'episode_name', 'character_id', 'character_name',\n                                   'location_id', 'location_name',\n                                   'spoken_words']]",
    "Merge the tables to have more information in one table",
    "print('Script dataframe: -' + str(len(df_script)) + \"- entries, \"+ str(len(df_script['episode_id'].unique())) + \" unique episodes.\" )",
    "Print the first few rows of each of the dataframes to understand the data better\nprint(\"Characters Data:\")\ndisplay(df_characters.head())\nprint(\"\\nLocations Data:\")\ndisplay(df_locations.head())\nprint(\"\\nScript Data:\")\ndisplay(df_script.head())\nprint(\"\\nEpisodes Data:\")\ndisplay(df_episodes.head())",
    "Global variables\nSEED = 42",
    "Check first 5 rows of `df_script`",
    "Check the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Harmonize character locations\ndf_harmonized = df_script.merge(df_characters, left_on=\"character_id\", right_on=\"id\", suffixes=('_script', '_character'))\ndf_harmonized = df_harmonized.merge(df_locations, left_on=\"location_id\", right_on=\"id\", suffixes=('_character', '_location'))",
    "Set some pandas defaults for nicer printing\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)",
    " Display script lines dataframe\ndf_script.head()",
    "Merge episodes with their corresponding scripts\ndf_episodes_with_scripts = pd.merge(\n    df_script, \n    df_episodes, \n    how='inner', \n    left_on='episode_id', \n    right_on='id'\n).drop(columns=['id_y']).rename(columns={'id_x': 'script_id'})\n\n# Merge characters to non-location scripts\ndf_episodes_with_scripts_and_characters = pd.merge(\n    df_episodes_with_scripts, \n    df_characters, \n    how='inner', \n    left_on='character_id', \n    right_on='id'\n).drop(columns='id').rename(columns={'name': 'character_name'})\n\n# Sanitize the location data\nlocation_alias_map = {\n    r'(Moe\\'s|moes)': 'MOE_S_TAVERN',\n    r'(Simpson House|the house|simpson home|our house|their house)': 'SIMPSON_HOME',\n    r'(elementary|school|detention|principal|lunchlady)': 'SPRINGFIELD_ELEMENTARY_SCHOOL',\n}",
    "Set and display the top level directory for data assets",
    "Check the contents and sizes of each dataframe\nprint(\"Characters\")\nprint(df_characters.head())\nprint(df_characters.shape)\n\nprint(\"Locations\")\nprint(df_locations.head())\nprint(df_locations.shape)\n\nprint(\"Script\")\nprint(df_script.head())\nprint(df_script.shape)\n\nprint(\"Episodes\")\nprint(df_episodes.head())\nprint(df_episodes.shape)",
    "Fix dates\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], errors='coerce')\ndf_episodes.moveToFirstAirenDate = pd.to_datetime(df_episodes.moveToFirstAirenDate, errors='coerce')",
    "Define the main characters, seasons, and locations for the analysis.",
    " quick look to our datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Outputs first 5 rows of each dataset\nprint(\"Characters dataset\")\nprint(df_characters.head())\nprint(\"\\n\")\n\nprint(\"Locations dataset\")\nprint(df_locations.head())\nprint(\"\\n\")\n\nprint(\"Script dataset\")\nprint(df_script.head())\nprint(\"\\n\")\n\nprint(\"Episodes dataset\")\nprint(df_episodes.head())",
    "Filter out the rows in df_script that do not contain a character_id in df_characters.",
    "Display the column names for each dataframe\nprint(\"Characters data:\\n\", df_characters.columns)\nprint(\"\\nLocations data:\\n\", df_locations.columns)\nprint(\"\\nScript data:\\n\", df_script.columns)\nprint(\"\\nEpisodes data:\\n\", df_episodes.columns)",
    " Checking all DataFrames",
    "to run the language model.",
    "Set the pandas display options for long strings, so they are properly displayed\npd.set_option('display.max_colwidth', None)",
    "Objectives\n# Extract script lines where at least 2 of the characters are in the same location\n# Perform NER for each line by using Spacy\n# Calculate the entity frequency for the dataframe\n# Calculate the named entity frequency for each location that is shared between the characters\n# Analyze the results and visualize them",
    "Ignore SettingWithCopyWarning\npd.options.mode.chained_assignment = None",
    "Set seed for reproducibility\nnp.random.seed(0)",
    "Remove useless df_script columns\ndf_script = df_script.drop(columns=[\n    'id',  # id is useless\n    'norm_id',  # not sure what this is\n    'episode_id',  # seems to be irrelevant as it corresponds to the index\n    'number',  # seems to be the same than index without 1\n    'raw_text',  # is already in text and speaking_line\n    'timestamp_in_ms',  # not interested in time\n    'speaking_line',  # we don't want to keep 1 because simpsons always have speaking lines\n    'character_id',  # not interested in the ID\n    'location_id',  # not interested in the ID\n    'raw_text',  # is already in text and speaking_line\n    'spoken_words',  # not interested in having the actual text._pla\n    'word_count'  # we will calculate it ourselves\n])",
    "Connect to SQL Database",
    "Visualize the percentage of lines spoken by each character\nlines_spoken = df_script['raw_character_text'].value_counts(normalize=True) * 100\nlines_spoken = lines_spoken[df_characters['character_id'].values]\nlines_spoken = lines_spoken.sort_values(ascending=True)\n\nplt.figure(figsize=(10, 25))\nplt.barh(lines_spoken.index, lines_spoken.values, color='skyblue')",
    " Show the first rows of the dataframe to understand the structure of the data\ndf_script.head()",
    "Display the first 5 rows of each dataframe\ndfs = [df_characters, df_locations, df_script, df_episodes]\nfor df in dfs:\n    display(df.head())",
    "Extract the first 100,000 script lines and limit them to the first 50 episodes only",
    "#Select the required columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'speaking_line', 'character_id']]\n\n# Informationen zu der Tabelle\nprint(df_script.info())",
    "Let's take a look at each of the datasets and determine if any preprocessing is necessary.",
    "df_script.shape",
    " Let's preview the first few entries of each dataframe to understand the data better.",
    " Set up spacy\nnlp = spacy.load('en_core_web_sm')",
    " Display the first few rows of the dataframe to understand its structure\ndf_script.head()",
    "Show the first rows of the characters dataframe\ndf_characters.head()",
    "Reduce the script data for a character-centric analysis\nmain_characters = ['marge', 'homer', 'bart', 'lisa', 'maggie', 'skinner', 'patty', 'selma', 'ned', 'krabappel', 'burns', 'milhouse']\nscript_idx = (df_script.raw_character_text.str.lower().isin(main_characters)) | (df_script.raw_character_text.isna())\ndf_script = df_script[script_idx]\n\n# Parse the data for a character-centric analyis\ndf_script.reset_index(drop=True, inplace=True)",
    "We open the datasets containing the Simpsons script lines, characters, locations, and episodes using pandas, and reset the index.",
    " Show the first 5 rows of the script dataframe\ndf_script.head()",
    "Merge episodes and script\ndf_script_episodes = df_script.merge(df_episodes,\n                how='inner',\n                left_on='episode_id',\n                right_on='id',\n                suffixes=('_script', '_episode'))\n\n# Random look at the dataset\ndf_script_episodes.sample(10)",
    " Select only the lines for the 8 main characters\nmain_characters = [\n    'marge simpson',\n    'homer simpson',\n    'bart simpson',\n    'lisa simpson',\n    'maggie simpson',\n    'ned flanders',\n    'seymour skinner',\n    'milhouse van houten'\n]",
    "Quick look at the first rows of each DataFrame\ndf_characters.head()",
    "For the sake of simplicity, we will remove unncessary columns from specific tables and save them into a new CSV which we will inport later on.",
    " Access local library\nimport sys",
    " Check the data types of each column\ndf_script.dtypes",
    "Check the first few lines of the characters dataframe.",
    " Check the first few rows of each table\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Check the folder structure and contents to see if data sets have been loaded successfully\nos.listdir('data')",
    "Clean quotes\ndf_script['raw_character_text'] = df_script['raw_character_text'].apply(lambda x: \"\".join(i for i in x if ord(i)<128))",
    "Inspect the dataframes",
    " Set index of episodes to be the same as in the other two files",
    "A function to retrieve the character information from the character_id.",
    "# Merging dataFrames in a unique one\ndf = df_script.copy()\ndf['character_id'] = df['character_id'].fillna(-1).astype(int)",
    "Ensure consistent character naming across dataframes\ndf_script['raw_character_text'] = df_script['raw_character_text'].replace({\n    'lenny': 'Lenny',\n    'carl': 'Carl',\n    'moe_szyslak': 'Moe Szyslak',\n    'charles_montgomery_burns': 'Mr. Burns',\n    'chief_wiggum': 'Chief Wiggum',\n    'homer_simpson': 'Homer Simpson',\n    'kent_brockman': 'Kent Brockman',\n    'marge_simpson': 'Marge Simpson',\n    'bart_simpson': 'Bart Simpson',\n    'lisa_simpson': 'Lisa Simpson',\n    'krusty_the_clown': 'Krusty the Clown',\n    'edna_krabappel': 'Edna Krabappel',\n    'nelson_muntz': 'Nelson Muntz',\n    'apu_nahasapeemapetilon': 'Apu Nahasapeemapetilon',\n    'seymour_skinner': 'Seymour Skinner',\n    'milhouse_van_houten': 'Milhouse Van Houten',\n    'maggie_simpson': 'Maggie Simpson',\n    'scratchy': 'Scratchy',\n    'barney_gumble': 'Barney Gumble',\n    'moe_szyslak': 'Moe Szyslak',\n    'rainier_wolfcastle': 'Rainier Wolfcastle',\n    'waylon_smithers': 'Waylon Smithers',\n    'ned_flanders': 'Ned Flanders',\n    'fat_tony': 'Fat Tony'\n})",
    "Merge the dataframes to get a comprehensive view of the Simpsons dataset",
    "# Print the first 5 lines of the dataframe to ensure it was properly imported\nprint(df_script.head())",
    "Check if main dataframe loads correctly",
    " Now concatenate all individual episode dataframes into one dataframe for easier access and management.",
    "Inspect the head of the characters dataframe\ndf_characters.head()",
    "Define the location of the pretrained model and load it",
    " Check for nulls\nprint(df_script.isnull().sum())",
    "\n# Display the first 5 records of each dataframe to get an initial feel for the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "def load_simpsons_datasets():\n    # Load datasets\n    df_characters = pd.read_csv('data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\n    df_locations = pd.read_csv('data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\n    df_script = pd.read_csv('data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\n    df_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)\n\n    return df_characters, df_locations, df_script, df_episodes",
    " Display the first few rows of the character dataframe\ndf_characters.head()",
    " Visualise first few entries in characters database\ndf_characters.head()",
    "Data cleaning and preparation",
    "Text preprocessing: removing useless characters and reducing words to their root form.",
    "# # Exploratory Data Analysis (EDA)",
    "Inspect the scripts DataFrame\ns = [i / len(df_script) for i in range(len(df_script))]\nsample = df_script.sample(frac=0.1)\nseries = sample.groupby('episode_id').count()['id']",
    "We can glimpse at each dataset to understand the structure and the information that it contains.",
    " Displaying the head of the Characters dataframe to understand the data",
    "Display top 5 rows of each dataset to understand the data",
    "Visualizing The Most Common Words with WordClouds",
    "Inspect the contents of the scriptlines DataFrame to understand its structure and the kind of data it contains.\ndf_script.head()",
    " Display expanded rows and columns when displaying DataFrames\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 150)",
    "Check if the dataframes were propertly loaded\ndf_characters.head()",
    "Quick analysis of the input datasets",
    "Visualizing the Simpsons script: A wordcloud of the most popular words in the script",
    "Inspecting the first 5 rows of all datasets to understand their structure\nprint(\"Characters Data:\")\nprint(df_characters.head())\nprint(\"\\nLocations Data:\")\nprint(df_locations.head())\nprint(\"\\nScript Data:\")\nprint(df_script.head())\nprint(\"\\nEpisodes Data:\")\nprint(df_episodes.head())",
    " Show the head of the data\ndf_script.head()",
    "Uncomment and run the following lines to display part of the content in each dataframe\n# df_episodes.head(3)\n# df_locations.head(3)\n# df_characters.head(3)\n# df_script.head(3)",
    "Merge the dataframes\ndf_merged = df_script.merge(df_episodes, on='episode_id', suffixes=('', '_episode'))",
    " Create a column for character names in the script dataframe\ndf_script = df_script[df_script['speaking_line'] == True]  # Keep only rows with a speaking line\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('','_original'))  # Join the character names",
    "Remove common words that are called \"stop words\", such as 'the', 'a', 'an', 'in', etc.",
    " Display the first few entries of the script data frame\ndisplay(df_script.head())",
    "Inspect the characters dataframe\ndf_characters.head()",
    "Filtering the data for better modelling",
    "Checking the data shape and head of each dataframe",
    " Character to gender mapping\ndf_gender = df_characters[['raw_character_text', 'gender']].groupby('raw_character_text').agg(lambda x: x.value_counts().index[0])",
    "Function to remove irrelevant script information",
    " Let's first inspect the structure of these dataframes.",
    "Display the first few rows of the script dataframe\ndf_script.head()",
    "Creating a series of episodes with their lines",
    "Display some basic information about the datasets\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script lines:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    " Filter lines with a specific character_id\ndf_character_1 = df_script[df_script['character_id'] == 1]\ndf_character_1.head()",
    " Display the first few rows of the dataframe containing the characters.",
    "Ensure the correct encoding for each dataframe",
    "# What are the names of the columns in the script Dataframe?\nprint(df_script.columns.tolist())",
    "Select main cast (based on how many sentences they have)",
    "Load data and display overview",
    " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "# Correctly identify the index column\ndf_characters = df_characters.set_index('id')\ndf_locations = df_locations.set_index('id')\ndf_script = df_script.set_index('id')\ndf_episodes = df_episodes.set_index('id')",
    "Visualisations related imports",
    "Checkpoint: All data is loaded and looks fine",
    " Display the first few rows of the dataframe containing the characters.",
    "df_script.head()",
    " Check out the first few rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "This script will focus on analyzing the script data.",
    " Display the first entries of the dataframe containing the script of the Simpson series\ndf_script.head()",
    "Display the first 10 rows of the characters dataframe\ndf_characters.head(10)",
    "Reading the data into pandas dataframes",
    "Make previews of each dataset",
    "Remove nonsense lines with length of less than 10 from the dataset",
    "Print the first 5 rows of the script dataset to understand its structure\ndf_script.head()",
    "Merge data frames to simplify the code and remove duplicate ids",
    "Checking the first few rows.",
    "Checking the data and cleaning it",
    "Converts 'raw_location_text' into a column of entity name\ndf_script['location_entity'] = df_script['raw_location_text'].apply(lambda x: [i['text'] for i in sp(x).ents if i.label_ == 'GPE'])",
    "Display the number of rows and columns in each dataframe\nprint(\"Characters:\")\nprint(df_characters.shape)\nprint(df_characters.columns)\nprint(\"\\nLocations:\")\nprint(df_locations.shape)\nprint(df_locations.columns)\nprint(\"\\nScript:\")\nprint(df_script.shape)\nprint(df_script.columns)\nprint(\"\\nEpisodes:\")\nprint(df_episodes.shape)\nprint(df_episodes.columns)",
    "Check the loaded dataframes",
    " Now it would be a good time to look into the data to see how it is structured and what kind of data is actually stored inside.",
    "Function to load pre-trained English NER model from spacy and apply it to a string",
    "Check the shape of each DataFrame\nprint(\"Characters shape:\", df_characters.shape)\nprint(\"Locations shape:\", df_locations.shape)\nprint(\"Script shape:\", df_script.shape)\nprint(\"Episodes shape:\", df_episodes.shape)",
    "Print some basic information about the datasets\nprint(f'Characters: {len(df_characters)}')\nprint(f'Locations: {len(df_locations)}')\nprint(f'Script lines: {len(df_script)}')\nprint(f'Episodes: {len(df_episodes)}')",
    "Generate new column that concatenates raw_text and normalized_text\ndf_script['raw_and_normalized_text'] = df_script['raw_text'] + ' ' + df_script['normalized_text']",
    "Check the dataset is correctly loaded",
    "Inspect the characters dataframe",
    "Let's explore the content of these datasets.",
    "# Merge all the datasets\ndf_merged = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_episode'))\ndf_merged = df_merged.merge(df_characters, on='character_id', suffixes=('_merged', '_character'))\ndf_merged = df_merged.merge(df_locations, on='location_id', suffixes=('_merged', '_location'))\n\n# Rename some columns for clarity\ndf_merged = df_merged.rename(columns={'normalized_text': 'spoken_words', 'name_merged': 'character_name', 'name_location': 'location_name'})",
    " Set option to display all columns in dfs\npd.set_option('display.max_columns', None)",
    "Create a summary statistics of the episodes data\ndf_episodes.describe()",
    "Create a small sample of the script for performances",
    "Let's print some basic information to start with.",
    "Create a smaller dataframe, capturing only the season 1, episode 1 rows.",
    "Get top 10 characters with the most lines\ntop_characters = df_script['character_id'].value_counts().head(10)\n\n# Get top 10 locations with the most lines\ntop_locations = df_script['location_id'].value_counts().head(10)",
    " Preview the characters dataframe\ndf_characters.head()",
    "Remove erroneous information on Lisa having the most lines ever",
    "Create the NLP model\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])",
    "Create a copy of the script data to work with\nscript_lines_copy = df_script.copy()",
    "Extract the characters who appear in each simpsons episode and create a new DataFrame",
    " visualize\nfrom spacy import displacy",
    " Display data from the scripts\ndf_script.head()",
    "# Create ./plots directory if it does not exist\nif not os.path.exists('./plots'):\n    os.makedirs('./plots')",
    "Merge characters, locations and episodes in the scripts dataset for better analyzis",
    "Load Spacy model\nnlp = spacy.load('en_core_web_sm')",
    "Limit rows\ndf_script = df_script.sample(100000, random_state=42)\n\n# Issue with characters and locations\ndf_script.loc[df_script.raw_character_text.str.contains('explosion', case=False, na=False, regex=False), 'raw_character_text'] = 'explosion'\ndf_script.loc[df_script.raw_location_text.str.contains('explosion', case=False, na=False, regex=False), 'raw_location_text'] = 'explosion'",
    "Check dataframes structure\nprint(df_characters.head(5))",
    "View dataframe shapes\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
    " Set up the figure and axis\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))",
    "Create a dataframe with the necessary information to work (only the characters with speaking lines)\ndf_script.loc[df_script['speaking_line'] == 'true'].reset_index(inplace=True, drop=True)",
    "quick check and shape of dataframe",
    "Explore the contents of the dataset\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Build a mapping between character_id and character_name for easier lookup\ncharacter_id_to_name = df_characters.set_index('character_id')['character_name'].to_dict()",
    "Remove unneeded rows\ndf_script = df_script[\n    (df_script['character_id'] != 2) & (df_script['character_id'] != 3)\n].reset_index(inplace=False, drop=True)",
    "Displaying the first few rows of each data set\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Path to save results\nresults_path = \"results\"",
    "# Display the first rows of the characters dataframe\ndf_characters.head()",
    "Check the data structure\ndf_script.head()",
    "Inspect and clean data",
    "Displaying the first lines of the script dataframe\ndf_script.head()",
    " Create an empty DataFrame to store the statistics of each character\ndf_characters_statistics = pd.DataFrame(columns=['id', 'word_count'])",
    "Split rows in 'simpsons_script_lines' by newlines in 'normalized_text'\ndf_script = df_script.assign(normalized_text=df_script['normalized_text'].str.split('\\n')).explode('normalized_text')\n\n# Remove ':' from speaker names\ndf_script = df_script.assign(speaker=df_script['speaker'].str.replace(':', ''))\n\n# Keep only 'spoken_words' and speaker name\ndf_script = df_script.assign(normalized_text=df_script['normalized_text'].str.split(':')).explode('normalized_text')\n\n# Remove leading/trailing whitespaces from 'normalized_text'\ndf_script = df_script.assign(normalized_text=df_script['normalized_text'].str.strip())\n\n# Remove rows with 'normalized_text' == ''\ndf_script = df_script[df_script['normalized_text'] != '']",
    "Let's start by taking a look at the data we have available.",
    "\n# Setting up Spacy\nnlp = spacy.load(\"en_core_web_sm\")",
    " Merge the dataframes",
    "Test out the dataframes",
    "def load_data():\n    #  Load data\n    df_characters = pd.read_csv('data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\n    df_locations = pd.read_csv('data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\n    df_script = pd.read_csv('data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\n    df_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)\n    \n    return df_characters, df_locations, df_script, df_episodes",
    "Check out the contents of each of the dataframes",
    "Display first few rows of the dataframe\ndf_script.head()",
    "Let's take a quick look at the various datasets.",
    "Inspect the dataframes",
    "Quick 'n dirty peek at the script dataframe\ndf_script.head()",
    "A quick preview of the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Look at the head of the lines DataFrame",
    "Inspect the first few rows of each DataFrame to understand its structure and contents.",
    "Join dataset to have episodes info in script dataset\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')",
    "Checking the imported datasets",
    "Display the first 5 rows of each dataframe\ndisplay(df_characters.head(), df_locations.head(), df_script.head(), df_episodes.head())",
    "Inspecting the first rows of each dataframe\nprint(\"_\"*80)\n\nprint(\"\\nCharacters data frame\")\ndisplay(df_characters.head())\n\nprint(\"_\"*80)\n\nprint(\"\\nLocations data frame\")\ndisplay(df_locations.head())\n\nprint(\"_\"*80)\n\nprint(\"\\nScript data frame\")\ndisplay(df_script.head())\n\nprint(\"_\"*80)\n\nprint(\"\\nEpisodes data frame\")\ndisplay(df_episodes.head())",
    " Join the dataframes on the episode_id",
    " Look at the first few rows of the characters dataframe\ndf_characters.head()",
    "Check that the imports worked\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Merge lines and episodes\ndf_merged = df_script.merge(df_episodes, how='left', on='episode_id')",
    "# Visualize the number of lines per character\nline_counts = df_script['character_id'].value_counts()\n\nplt.hist(line_counts, bins=100, range=(1, 100))\nplt.yscale('log')\nplt.title('Number of Lines per Character')\nplt.xlabel('Number of Lines')\nplt.ylabel('Number of Characters')\nplt.show()",
    " Merge the script lines with the characters, locations, and episodes datasets\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\ndf_script = df_script.merge(df_locations, on='location_id', how='left')\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')",
    "Explore the content of the datasets",
    "Extract quotes from script\nquotes = df_script[df_script['speaking_line'] == True][['character_id','raw_text']]\n\n# Extract quotes from script\ncharacters = df_characters['name']\n\n# Extract locations from dataset",
    "Set up environment for spaCy and Word Clouds",
    "Check what we are loading from the script csv file",
    "Setting up Spacy\nnlp = spacy.load('en_core_web_sm')",
    "Data prep: lowercase, remove punctuation, remove stop words",
    "Some initial configurations\npd.options.display.max_columns = None  # Shows all columns when printing the dataframe",
    "Check the first few lines of the characters dataframe\ndf_characters.head()",
    "begin by reading the data from csv files into pandas dataframes.",
    "Set the random seed for reproducibility\nnp.random.seed(0)",
    "Check the dataframes shape\nprint(\"Characters dataframe shape:\", df_characters.shape)\nprint(\"Locations dataframe shape:\", df_locations.shape)\nprint(\"Script dataframe shape:\", df_script.shape)\nprint(\"Episodes dataframe shape:\", df_episodes.shape)",
    "Inspect the first few rows of the characters dataset\ndf_characters.head()",
    "Check the first 5 lines of the content for each table",
    "# Ensure the scripts are in order\ndf_script.sort_values(['episode_id', 'timestamp_in_ms'], inplace=True)",
    "Displaying the first rows of the DataFrame to get a sense of the data distribution \ndf_episodes.head()",
    " Visualize the top 20 most common words in the script lines.",
    "Defining some functions",
    "Ensure matplotlib is correctly enabled in Jupyter notebooks\nmatplotlib.rcParams['figure.figsize'] = [10, 5]",
    "Inspect the dataframes to understand their structure and contents",
    " Add extra data to stopwords. These words will be ignored in the analysis.",
    "View first 5 rows of each dataset\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display the first few rows of each table to get an idea of the data",
    "We are importing pandas, numpy, spacy, matplotlib, WordCloud, and other required libraries for our data analysis and visualization. We are also importing custom libraries such as tqdm, Counter, etc. Then we are reading the data from CSV files into pandas dataframes.",
    "Check the first 5 rows of the characters dataframe.",
    " Visualise data\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.hist(df_script.speaking_line)\nplt.title('Speaking lines', fontsize=15)\nplt.xlabel('')\n\nplt.subplot(1, 2, 2)\nplt.hist(df_script.character_id.value_counts(), bins=50)\nplt.title('Number of lines per character', fontsize=15)\nplt.xlabel('Number of lines')\nplt.show()",
    "Check for missing values in the script data\ndf_script.isnull().sum()",
    " Displaying basic information from each dataframe",
    "Display the dataset samples\ndf_characters.sample(5)",
    "Select right episodes and keep only right columns",
    "Inspect the dataframes to understand the data",
    " Let's take a look at the first few rows of each dataframe to understand the data better.\nprint(\"Characters:\")\nprint(df_characters.head())\n\nprint(\"\\nLocations:\")\nprint(df_locations.head())\n\nprint(\"\\nScript:\")\nprint(df_script.head())\n\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
    "Merge the episodes and scripts dataframe on the column 'episode_id'\ndf_episodes_scripts = df_episodes.merge(\n    df_script, \n    how='inner', \n    left_on='id', \n    right_on='episode_id',\n    suffixes=('_episodes', '_scripts')\n)",
    " Show the first 5 rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Display the first few rows of the characters DataFrame\ndf_characters.head()",
    "Set up spacy model\nnlp = spacy.load('en_core_web_md')",
    "\n# Set up environment\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])",
    "Remove rows with empty \"spoken_words\" in the script\ndf_script = df_script.dropna(subset=['spoken_words'])",
    "Display the first 5 rows of each dataframe\ndf_script.head()",
    "Show the first few rows of characters dataframe\ndf_characters.head()",
    "View the first 5 rows of the characters dataset\ndf_characters.head()",
    "# Join tables script and episodes\ndf_script_episodes = df_script.merge(df_episodes, on='episode_id', how='left')\ndf_script_episodes.head()",
    "Count the number of transcript lines per episode",
    "Displaying the number of entries in each dataset",
    "Check if all datasets have been loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check files have been correctly loaded\ndf_characters.head()",
    "Merge character data\ndf_characters = df_characters.rename(columns={'id':'character_id'})\ndf_script = df_script.merge(df_characters, on='character_id')",
    " Join structures",
    "Some more exploratory data analysis ...\n# Filter out non-episode, non-dialogue script lines\ndf_script = df_script[\n    (df_script['episode_id'] != -1) & \n    (df_script['character_id'] != -1)\n].reset_index(inplace=False, drop=True)",
    "change this line if the script should be executed in Jupyter\nsns.set()",
    "Define directory path for wordcloud output\nwordcloud_dir = \"wordclouds\"",
    "# Show a bit of the df_characters dataframe\ndf_characters.head()",
    "\ndf_script = df_script[df_script[\"episode_id\"].notna()]",
    "Exploring the data\ndf_script.head()",
    "Join locations, script, and characters dataframes on the episode id",
    "Keep only data from the first 15 seasons (last season included = 15)",
    "# Number of characters\ndf_characters.shape[0]",
    "Filter valid episode scripts\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]",
    " check the datasets\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
    "Set this option to characteristic_size so as to show at most the characteristic number of relevant columns.",
    "Displaying one of the datasets to observe its structure\ndf_script.head()",
    "Exploring columns types and some of the data",
    "Remove duplicate values from characters, locations and episodes dataframes\n# We need to do this before merging to avoid duplication issues",
    " Selecting the season from \"df_episodes\" dataframe.",
    "Let's take a look at the data to understand its structure and content.",
    "Basic EDA\n# Show the first entries for the characters dataframe\ndf_characters.head()",
    "\n# Display the first rows of the table 'Episodes'\ndf_episodes.head()",
    "Let's take a quick look at the shapes of the dataframes to have an understanding of the size of each dataset.\n\nprint(\"Characters shape:\", df_characters.shape)\nprint(\"Locations shape:\", df_locations.shape)\nprint(\"Script shape:\", df_script.shape)\nprint(\"Episodes shape:\", df_episodes.shape)",
    "Creating a basic dataframe of episodes data\ndf_episodes.head()",
    "Disable SettingWithCopyWarning\npd.options.mode.chained_assignment = None  # default='warn'",
    " optional: run seaborn theme set\nimport seaborn as sns\nsns.set()",
    "Convert the episode air date to datetime object\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])\n\n# Show first 5 characters in the characters dataset\ndf_characters.head()",
    "Inspect content of scripts and extract relevant metadata",
    " Collecting personal stopwords, frequent mispellings, common words referring to the simpsons, and imperatives",
    "Inspect the first few rows of each dataframe to understand their structure and contents.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "\ndf_script.head()",
    "# Function converting categorical columns to category type\ndef convert_categorical(df, cols):\n    for col in cols:\n        df[col] = df[col].astype('category')",
    " Display the first few characters of the dataframes\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Set the index on the de-serialized dataframes",
    "Confirming the data has been loaded correctly\ndf_characters.head()",
    "Preview of Simpsons Characters data\ndf_characters.head()",
    "Check a sample of the data for each dataframe",
    "Inspect dataframes",
    " Display first few rows of characters data\ndf_characters.head()",
    "Preview the data\nprint('Characters:')\nprint(df_characters.head(3))\nprint('\\nLocations:')\nprint(df_locations.head(3))\nprint('\\nEpisodes:')\nprint(df_episodes.head(3))\nprint('\\nLines:')\nprint(df_script.head(3))",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Inspect the characters DataFrame\ndf_characters.head()",
    "Inspect the dataframes",
    "Print the first rows of the episodes DataFrame\ndf_episodes.head()",
    "Combining script lines with metadata",
    "Check for missing values\ndf_script.isna().sum()",
    "Limiting the database to only 5,000 lines",
    "Display the first few rows of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "You can also check the first couple of lines of each dataframe to have an idea of what kind of data they contain:",
    "Tokenize using spacy",
    "The lines in the original script are randomly ordered. Let's first sort them by episode id and index.",
    " Remove unwanted columns, convert columns types, etc.",
    "Inspecting the first dataset - characters",
    " Viewing memory usage of each dataframe\nprint(\"Memory usage of each dataframe:\")\nprint(df_characters.memory_usage().sum())\nprint(df_locations.memory_usage().sum())\nprint(df_script.memory_usage().sum())\nprint(df_episodes.memory_usage().sum())",
    "Check if the dataframe is loaded correctly\ndf_episodes.head()",
    "Download `en` model from spacy if not already in cache\ntry:\n    _ = spacy.load('en')\nexcept OSError:\n    _ = spacy.cli.download('en')",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "View the first few rows of each dataframe to understand the data",
    "!python -m spacy download en_core_web_sm",
    " Check the content of the first DataFrame",
    "Make sure ObjectId is of type int\ndf_script['episode_id'] = df_script['episode_id'].astype(int)",
    " Display first 5 records of each dataframe\nprint(\"Characters dataframe\")\ndisplay(df_characters.head())\n\nprint(\"Locations dataframe\")\ndisplay(df_locations.head())\n\nprint(\"Script dataframe\")\ndisplay(df_script.head())\n\nprint(\"Episodes dataframe\")\ndisplay(df_episodes.head())",
    "Check that everything was loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Check the loaded data",
    "Inspect first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Print the first few lines of each dataframe to understand its structure\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Print the size of the datasets\nprint(\"Characters: \", df_characters.shape)\nprint(\"Locations: \", df_locations.shape)\nprint(\"Script: \", df_script.shape)\nprint(\"Episodes: \", df_episodes.shape)",
    "Join the dataframes",
    "Inspect data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Clean text and add a column with the lengths of the sequences\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\r', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\n', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('<b>', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('</b>', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('<i>', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('</i>', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('<u>', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('</u>', ' ')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('<br />', ' ')",
    "Set the LIMIT constant\nLIMIT = 10000",
    "merge episodes\ndf_script_ep = pd.merge(df_script, \n                        df_episodes, \n                        on='episode_id', \n                        how='left')",
    "Set OS encoding to UTF-8",
    "Check the content of the characters dataframe\ndf_characters.head()",
    "Get the head of the characters dataframe",
    " Required if you get errors that the 'en' model was not found\n# !python -m spacy download en",
    "Let's see the first lines of those dataframes",
    " Rename ID columns\ndf_characters = df_characters.rename(columns={'id': 'character_id'})\ndf_locations = df_locations.rename(columns={'id': 'location_id'})",
    "Map the episode names to each script line\ndf_script['episode_name'] = df_script['episode_id'].map(df_episodes.set_index('id')['title'])\n\n# Remove the \\r formatting used in the script\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\r', '')",
    "Dataframe columns header correction\ndf_episodes.columns.tolist()",
    "We have completed the general imports and have loaded the datasets into pandas dataframes.",
    "Rename the raw columns from the script dataframe for readability and binary gender\n# 0 for male, 1 for female in the gender column",
    "Data Preprocessing\n# Show the first 5 records of the characters dataframe\ndf_characters.head()",
    "Inspect dataset 1: Characters",
    " This dataset especially is quite spicy and is full of joint operations between different data sources!",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Purpose of this code is to read the CSV files and store them in pandas dataframes for further processing and analysis.",
    "Preview data\ndf_script.head()",
    "View first 5 records of df_script\ndf_script.head(5)",
    "Configuro los estilos de los grficos\nmatplotlib.style.use('seaborn-bright')",
    "Display the first few rows of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Merge the datasets to include all relevant information in one dataframe.",
    "Set index of DataFrames for optimization",
    " Function to merge and filter the DataFrames",
    "Assuming you have the following workspace\ndata\n simpsons_characters.csv\n simpsons_episodes.csv\n simpson_locations.csv\n simpsons_script_lines.csv",
    "start by preliminary analysis of the dataset, let's get an overview of the data.",
    "Checking the format of the data for characters",
    " Merge locations with script\ndf_loc_script = pd.merge(\n    df_script,\n    df_locations,\n    how=\"left\",\n    left_on=\"location_id\",\n    right_on=\"id\",\n    suffixes=(\"-script\", \"-location\"),\n)\n\nprint(f\"We lost {df_loc_script['id-location'].isnull().sum()} records that weren't in the locations dataframe\")",
    " Let's take a look at the first few rows of the characters dataframe.",
    " Integration of data related to 'the simpsons' such as character, location, script lines and episodes into the notebook.",
    "Function to display dataframes in Jupyter notebooks with a cleaner format\ndef display_df(df):\n    return df.style.hide_index()",
    " Unnest the raw script, as largely used by DrQA's datasets and readers\ndf_script_unnested = (df_script['raw_character_text']\n .str.split(';', expand=True)\n .stack()\n .reset_index(level=0)\n .set_index('level_0')\n .rename(columns={0:'raw_character_text'})\n)\ndf_script_unnested.index.name = 'index'\ndf_script_unnested['raw_character_text'] = df_script_unnested['raw_character_text'].str.strip()",
    "Quick look at the character data",
    "Subset the script dataframe to only include the first 10 episodes.",
    " Check the structure of the dataframe containing the script lines.",
    " Use the same data in data/simpsons_script_lines.csv as used before\ndf_script.head()",
    "Print the number of script lines in the dataset\nprint(f\"Number of script lines: {df_script.shape[0]}\")",
    "Visualization functions",
    "Merge the episodes, locations, and script data into the characters dataframe and save it.",
    "Replace NaN values in episode_id with -1\ndf_script['episode_id'].fillna(-1, inplace=True)",
    "Check the data in one of the dataframes, e.g. df_script\nprint(df_script.head())",
    "Filter characters that appear in at least 100 episodes\ncharacter_ep_counts = df_script['raw_character_text'].value_counts()\nfrequent_characters = character_ep_counts[character_ep_counts > 100].index.to_list()\ndf_script = df_script[df_script['raw_character_text'].isin(frequent_characters)]",
    "View all datasets\ndisplay(df_characters.head(3))\ndisplay(df_locations.head(3))\ndisplay(df_script.head(3))\ndisplay(df_episodes.head(3))",
    " Display the first few lines of each dataframe to understand better their structure\ndf_characters.head()",
    "Print the columns of the characters, lines, and episodes DataFrames to understand their structure\nprint(df_characters.columns)\nprint(df_script.columns)\nprint(df_episodes.columns)",
    "Exploring the dataset.",
    "View dataframe info\ndf_script.info()",
    "Uncomment following line in case you are unable to see the plots\n# %matplotlib inline",
    " First we tokenize the script into words.",
    "Create a shallow copy\ndf_script_work = df_script.copy()",
    "Display plots inline in Jupyter notebook",
    "Join all on 'episode_id' and 'id' to get a full dataframe",
    "OK, now that we have loaded the data, let's take a look at the first few rows of each dataframe to understand its structure and the kind of data we're working with.",
    "hint: use the first few rows of the dataframe again to refresh your memory\ndf_characters.head()",
    "Set max column width to see more of the conversation\npd.set_option('max_colwidth', 150)",
    "Print the number of elements in the dataset\nprint(f\"Number of characters: {len(df_characters)}\")\nprint(f\"Number of locations: {len(df_locations)}\")\nprint(f\"Number of script lines: {len(df_script)}\")\nprint(f\"Number of episodes: {len(df_episodes)}\")",
    "Setting important variables",
    "Show the first five rows of df_locations\ndf_locations.head()",
    " Display the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Preview the first 5 records of each dataset\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
    "Display the first 5 records of the characters DataFrame\ndf_characters.head()",
    " Print the head of the characters dataframe\ndf_characters.head()",
    "Dropping the scriptid column, and indexing by this column",
    "Show version information for reproducibility\nprint(\"Pandas version: \", pd.__version__)\nprint(\"Matplotlib version: \", matplotlib.__version__)\nprint(\"Numpy version: \", np.__version__)",
    " Show first lines of characters dataframe\ndf_characters.head()",
    " Join characters with script\ndf_characters_script = df_script.merge(df_characters, left_on='character_id', right_on='id').drop(columns=['id', 'normalized_name'])\ndf_characters_script.head()",
    " For this analysis, we'll focus on the script dataset.",
    "We have successfully loaded the datasets into Pandas dataframes.",
    " Show first 5 entries of df_characters dataframe\ndf_characters.head()",
    "Set figure size\nplt.rcParams[\"figure.figsize\"] = [15, 6]",
    "Take a look at the content of each dataframe\nprint(\"Characters dataframe:\")\nprint(df_characters.head())\nprint(\"\\nLocations dataframe:\")\nprint(df_locations.head())\nprint(\"\\nScript dataframe:\")\nprint(df_script.head())\nprint(\"\\nEpisodes dataframe:\")\nprint(df_episodes.head())",
    "Visualizing data",
    "Convert non-numeric values to NaN\ndf_script['spoken_words'] = df_script['spoken_words'].apply(lambda x: np.nan if isinstance(x, str) and not x.isdigit() else x)",
    "Display settings for dataframes\npd.set_option('display.max_columns', None)",
    "Visualise the frequency of each character in the script dataset\nchar_distribution = dict(df_script['raw_character_text'].value_counts())\ntop_10_char, top_10_count = list(char_distribution.keys())[:10], list(char_distribution.values())[:10]\n\nfig, ax = plt.subplots(figsize=(16, 8))\nax.bar(np.arange(len(top_10_char)), top_10_count, color='purple')\nax.set_xlabel('Top 10 Characters', fontsize=24)\nax.set_ylabel('Frequency', fontsize=24)\nax.set_title('Top 10 Characters by Frequency', fontsize=36)\nax.set_xticks(np.arange(len(top_10_char)))\nax.set_xticklabels(top_10_char, rotation=45, ha='right', fontsize=16)\nax.set_yticklabels(np.arange(0, max(top_10_count)+10, 10), fontsize=16)\nplt.show()",
    "Check how the dataframes look\ndf_characters.head()",
    "Show first data in each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Implement more general imports to work with the data",
    "reduce memory usage\ndf_script['id'] = pd.to_numeric(df_script['id'], downcast='integer')\ndf_script['episode_id'] = pd.to_numeric(df_script['episode_id'], downcast='integer')\ndf_script['number'] = pd.to_numeric(df_script['number'], downcast='integer')\ndf_script['raw_text'] = df_script['raw_text'].astype('string')\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], downcast='integer')\ndf_script['speaking_line'] = df_script['speaking_line'].astype('boolean')\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], downcast='integer')\ndf_script['location_id'] = pd.to_numeric(df_script['location_id'], downcast='integer')\ndf_script['raw_text'] = df_script['raw_text'].astype('string')\n\ndf_episodes['id'] = pd.to_numeric(df_episodes['id'], downcast='integer')\ndf_episodes['viewers'] = pd.to_numeric(df_episodes['viewers'], downcast='integer')\n\ndf_characters['id'] = pd.to_numeric(df_characters['id'], downcast='integer')\ndf_characters['name'] = df_characters['name'].astype('string')\ndf_characters['normalized_name'] = df_characters['normalized_name'].astype('string')\ndf_characters['gender'] = df_characters['gender'].astype('string')\ndf_characters['description'] = df_characters['description'].astype('string')\ndf_characters['color'] = df_characters['color'].astype('string')\n\ndf_locations['id'] = pd.to_numeric(df_locations['id'], downcast='integer')\ndf_locations['name'] = df_locations['name'].astype('string')\ndf_locations['normalized_name'] = df_locations['normalized_name'].astype('string')\ndf_locations['image_url'] = df_locations['image_url'].astype('string')",
    "Check the size of each dataset\nprint('Characters dataset shape:', df_characters.shape)\nprint('Locations dataset shape:', df_locations.shape)\nprint('Script dataset shape:', df_script.shape)\nprint('Episodes dataset shape:', df_episodes.shape)",
    " Let's echo the last rows of the datasets.",
    " Function to display large dataframes in a more human friendly way.\ndef display_df(df, n_lines = 5):\n    pd.set_option('display.max_colwidth', 200)\n    if (len(df) > n_lines*2):\n        display(df[:n_lines])\n        print('...')\n        display(df[-n_lines:])\n    else:\n        display(df)\n    pd.reset_option('display.max_colwidth')",
    "Calculate the number of spoken words per gender\nspoken_words_per_gender = df_script.groupby(['spoken_by', 'gender']).agg({'word_count': 'sum'}).reset_index()\nspoken_words_per_gender['spoken_by'] = spoken_words_per_gender['spoken_by'].str.lower()\n\n# Speeches of the 4 main characters\nspoken_words_per_gender[spoken_words_per_gender['spoken_by'].str.contains('homer|marge|bart|lisa')]",
    "Initiate the spaCy model for natural language processing.",
    "Compute the count of words in each line of dialog\ndf_script['word_count'] = df_script['normalized_text'].apply(lambda x: len(x.split()))",
    "Get preview of the data in each of the DataFrames",
    "Let's take a look at the first few rows of the df_characters dataframe to understand its structure and contents.\ndf_characters.head()",
    "print(f\"Script size: {df_script.shape}, Characters size:  {df_characters.shape}, Locations size: {df_locations.shape},  Episodes size: {df_episodes.shape}\")",
    "Iterate through all including folders and files",
    "Quick look at the characters dataframe",
    "Since 'simpsons_script_lines.csv' is very large, we're going to use the first 100000 rows for the initial analysis\ndf_script = df_script[:100000]",
    " Set pandas to use 'id' as the index for all DataFrames\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "Remove all invalid schedule\ndf_episodes = df_episods.dropna(subset=['original_air_date'])",
    "Print the characters, locations, and script DataFrames\nprint('Characters DataFrame')\ndisplay(df_characters.head())\n\nprint('Locations DataFrame')\ndisplay(df_locations.head())\n\nprint('Script DataFrame')\ndisplay(df_script.head())\n\nprint('Episodes DataFrame')\ndisplay(df_episodes.head())",
    " Set output to display all columns in a dataframe\npd.set_option('display.max_columns', None)",
    "Let's take a look at the characters dataframe.",
    "Check the dataset\ndf_script.head()",
    " Set of stopwords found in Spacy for english language\nspacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS",
    "\ndf_script.head()",
    "Extract first `n` records from each dataframe",
    "Data investigation",
    " Create an object for counting the words\nword_freq = Counter()\n\n# Loop through the script to count the words\nfor _, row in tqdm(df_script.iterrows(), total=len(df_script)):\n    \n    # Get the lowercase version of the line\n    line = row['raw_text']\n    line = line.lower()\n    \n    # Tokenize the line\n    doc = nlp(line)\n    \n    # Update the word counter\n    word_freq.update([token.text for token in doc if token.is_alpha])",
    " Enable the Levenshtein's measure for Bratko-Klic's algorithm\n# Note: Requires installing the jellyfish package\nos.system('pip install jellyfish')\nimport jellyfish",
    " Convert the date and time attribute to datetime\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])",
    "Tokenize the text data of each script line using SpaCy.",
    "# Ensure the script dataframe is not holding a lot of memory.\ndf_script.drop(['norm_text', 'timestamp_in_ms', 'speaking_line'], axis=1, inplace=True)",
    " Display options\npd.set_option('display.width', 1000)\npd.set_option('display.max_columns', 25)",
    "Let's take a peek at the script data!",
    " Display the first few records of the dataframe\ndf_script.head()",
    "Set index for fast row selection and filtering\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)",
    "Ensure that the paths to the data files are correct\nfor df in [df_characters, df_locations, df_script, df_episodes]:\n    print(os.path.exists(df))",
    "Some basic data exploration",
    " Explore the characters DataFrame",
    "Visualise the first rows of the characters, locations, script and epidoses tables",
    "Spacy model\nnlp = spacy.load(\"en_core_web_md\")",
    "Displays the first few rows of the dataframe to understand the structure of the dataframe.",
    " Merge these dataframes into a single one",
    "Let's take a look at the data.",
    "Merge dialog with character information\ndf_dialog = (\n    df_script\n    .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('','_character'))\n    .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('','_location'))\n    .merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('','_episode'))\n)",
    "Load Spacy large library on disk\nnlp = spacy.load('en_core_web_lg', disable=['ner', 'parser'])",
    "Create a directory for saving plots if it does not exist",
    "Preview the first five rows of the characters dataframe\ndf_characters.head()",
    " Display the first few rows of the dataframe 'df_script'.\ndf_script.head()",
    "select the fields important for this analysis",
    " We need to \"reset_index(inplace=False, drop=True)\" to remove the new index that pandas creates automatically.",
    "Filter the columns jedi_order and species",
    "Installation TIP - if you don't have wordcloud installed, you might need to run !pip install wordcloud in a notebook cell.",
    "Drop unnecessary columns from characters dataframe\ndf_characters = df_characters.drop(columns=['Unnamed: 0'])",
    "Combine the script data with the character and location information to determine where each character is mentioned.",
    "Check all the datasets\nprint(\"df_characters\\n\")\ndisplay(df_characters.head(5))\nprint(\"\\n\\n\")\n\nprint(\"df_locations\\n\")\ndisplay(df_locations.head(5))\nprint(\"\\n\\n\")\n\nprint(\"df_script\\n\")\ndisplay(df_script.head(5))\nprint(\"\\n\\n\")\n\nprint(\"df_episodes\\n\")\ndisplay(df_episodes.head(5))",
    "Our dataset consists of four DataFrames:\n\n#   df_characters: information about the characters in The Simpsons\n#   df_locations: information about the locations in The Simpsons\n#   df_script: the script of each line in The Simpsons\n#   df_episodes: information about the episodes in The Simpsons",
    "Lets take a sneak peak at the data.",
    "Create a column representing the full names of the characters in the script dataframe.",
    "Extract information\nseasons = df_episodes['season'].unique()",
    "Looking at the first few records of each dataframe",
    "Checking the first few rows of the characters dataframe",
    "SEt default display parameters for pandas\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 1000)",
    "Display all columns in dataframe\npd.set_option('display.max_columns', None)",
    "#Overview of the data\ndf_episodes.head()",
    " Review the merged dataframe\ndf_script.head()",
    "We will only use the following columns from df_script DataFrame:\ndf_script = df_script[['episode_id', 'raw_text', 'character_id', 'location_id']]\n",
    " Define the database file\ndb_file = \"simpsons.sqlite\"",
    "Function that takes a list of spaCy tokens and returns a list of lemmatized strings\ndef lemmatize(token_list):\n    return [token.lemma_ for token in token_list]",
    "Check the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Display available data",
    "Inspect items\ndf_script['raw_character_text'].value_counts()",
    "Create dataframe with important informations \ndf_episodes_clean = pd.read_csv('data/cleaned_episodes.csv').reset_index(inplace=False, drop=True)",
    "# Filter the lines that have a location\ndf_script_location = df_script[df_script['raw_location_text'].notnull()]",
    "Preview of the characters data file\ndf_characters.head()",
    "Display the first few entries of each dataframe to get an understanding of the data.",
    "Visualize number of lines per character",
    "Preview data\ndf_characters.head()",
    "Check the dataframes to see that everything is as expected\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
    " Let's begin by taking a closer look at the data.",
    "View data\ndf_script.head()",
    "We'll first take a look at how the data is structured and what it looks like.",
    "Select only the normalized text column from the script dataframe\ndf_script = df_script['normalized_text']",
    " Check the first few rows of the characters dataframe",
    "# Display the number of missing values in the script DataFrame\nprint(df_script.isnull().sum())",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Previously, we imported necessary libraries and datasets for our analysis.",
    "Check the schema of the characters DataFrame\ndf_characters.head()",
    " Quick exploration of the tables to understand the structure of the data\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "set up the random state for replication of results\nnp.random.seed(42)",
    "Let's take a look at the data first.",
    "Helper function configparser\ndef get_project_path():\n    # Get the path to the main project folder\n    dir_path = os.path.dirname(os.path.realpath(__file__))\n    return os.path.abspath(os.path.join(dir_path, os.pardir))",
    "ensuring a random seed for notebook reproducibility\nnp.random.seed(21)",
    " Merge all available data into one large DataFrame\ndf = df_script.merge(df_episodes, on='episode_id')",
    " The scripts are very large, so the loading will take some time\ndf_script['word_count'] = df_script['raw_text'].apply(lambda x: len(x.split()))",
    " Extract only the first and second part of each script\ndf_script['part'] = df_script.apply(lambda x: x['raw_text'].split(' | ')[0], axis=1)",
    "Change the index of each dataframe to the index of the respective dataframe",
    "Extract main characters\nmain_characters = df_characters[df_characters['normalized_name'].notnull()].copy()\nmain_characters = main_characters['normalized_name'].str.lower().values.tolist()",
    "Replace missing gender\ndf_characters.gender.replace({'non-specific': np.nan}, inplace=True)",
    "Clean the script data\ndf_script_cleaned = df_script[(df_script['speaking_line'] == True) & (df_script['character_id'] != 0)]\n\n# Join character information\ndf_script_cleaned = df_script_cleaned.merge(df_characters, how='left', on='character_id')\n\n# Join location information\ndf_script_cleaned = df_script_cleaned.merge(df_locations, how='left', on='location_id')\n\n# Join episode information\ndf_script_cleaned = df_script_cleaned.merge(df_episodes, how='left', on='episode_id')\n\n# Display the first few rows of the cleaned script data\ndf_script_cleaned.head()",
    " Set the display options for the dataframes to print all the columns and to show the max number of rows",
    "Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Set basic configurations for visualization\nmatplotlib.rcParams['figure.figsize'] = [12, 8]\nmatplotlib.rcParams['font.size'] = 12",
    "To show the top few rows and understand the data's structure for each dataframe, we will use the head function for each dataframe.",
    "Drop rows containing NaN values\ndf_character_nonull = df_script[df_script.speaking_line == True][['id', 'episode_id', 'number', 'raw_character_text']].dropna()\ndf_location_nonull = df_script[df_script.speaking_line == True][['id', 'episode_id', 'number', 'raw_location_text']].dropna()\ndf_script_nonull = df_script[df_script.speaking_line == True][['id', 'episode_id', 'number', 'raw_text']].dropna()\n# clean_short_lowertnl\ndf_episode_nonull = df_episodes.dropna()",
    "Optional: Use this line of code to check the content of a dataframe to get a look at the data organization\n#df_script.head()",
    " Check if shape has changed\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    " Visualize the first few rows of the characters dataframe\ndf_characters.head()",
    "Create a sample of the dataset for performance reasons\ndf_script_sample = df_script.sample(5000, random_state=42).reset_index(drop=True)",
    "Drop columns with over 50% missing data\ndf_script = df_script.drop(columns=['normalized_text', 'word_count'])",
    "Display the head of the dataframes\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()",
    "Declare the language model\nnlp = spacy.load('en_core_web_sm')",
    "Checking the first five rows of each DataFrame",
    " Sample the script data\ndf_script.head()",
    "Display script dataframe\ndf_script.head()",
    "Check the character id 2.",
    "# Clean line\ndf_script = df_script[df_script[\"normalized_text\"] != \"\"].dropna()\n\n# Display some statistics\nprint(\"Number of episodes:\", df_episodes.shape[0])\nprint(\"Number of characters:\", df_characters.shape[0])\nprint(\"Number of locations:\", df_locations.shape[0])\nprint(\"Number of lines:\", df_script.shape[0])",
    "Check the result\ndf_characters",
    "Check import\nprint(df_characters.head())",
    "Imports and loading of dataframes",
    "Merge script and character data\ndf_lines_characters = pd.merge(df_script, df_characters, how='inner', left_on='character_id', right_on='id').drop(columns=['id'])",
    "The below code snippet shows how we load the preprocessed models from the cache directory.",
    "Display basic info of df_characters\ndf_characters.info()",
    " Checking how many script lines contain the word \"d'oh\"",
    "View the first 5 characters DataFrame rows.",
    "Join the necessary DataFrames to get a single DataFrame with the following columns: episode_id, raw_text, character_name, location_id, name.",
    "Setting index on the episodes dataframe",
    "Print the top 5 rows of the characters dataframe\ndf_characters.head()",
    "Check everything is ok.\ndf_script.head()",
    " Turn NaN values into empty strings\ndf_script = df_script.fillna('')",
    " Names of the columns in the dataframe of characters",
    "View script head\ndf_script.head()",
    "The .csv files will now be loaded into dataframes so that they can be further inspected and processed.",
    "Initializing spacy\nnlp = spacy.load(\"en_core_web_sm\")",
    "Functions to make the text easier to process",
    "More local imports\nfrom scripts.features import *\nfrom scripts.cleaning import *",
    "Check the files have been loaded correctly\nprint(\"Characters: \\t\", df_characters.shape)\nprint(\"Locations: \\t\", df_locations.shape)\nprint(\"Script: \\t\", df_script.shape)\nprint(\"Episodes: \\t\", df_episodes.shape)",
    "Merge the data to combine fields and for better visualization.",
    "Let's take a look at the first few lines of each dataframe to understand their structure and contents.",
    "# Fix errors and clean character names\ndf_characters['name'] = df_characters['name'].apply(lambda x: x.strip().replace('-', ' ').replace('_', ' '))\ndf_script['normalized_text'] = df_script['normalized_text'].apply(lambda x: x.strip().replace('-', ' ').replace('_', ' '))",
    "Inspecting the data\ndf_script.head()",
    "Check the shapes of the datasets\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Check the first few lines of each table",
    "Check the contents of the characters dataframe\ndf_characters.head()",
    "Check the data format\nprint(df_script.head(5))",
    "Join df_script with df_episodes to add episode information to df_script\ndf_joined = df_script.set_index('episode_id').join(df_episodes.set_index('id'), rsuffix='_episode')",
    "Drop broken entries\ndf_script = df_script.drop(df_script[df_script[\"id\"] == 17837].index)\ndf_script = df_script.drop(df_script[df_script[\"id\"] == 53270].index)",
    "Display the first few lines of each dataset\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Define functions to clean the data",
    "It is common to import multiple libraries and modules before beginning any data analysis or machine learning tasks in Python. In this example, we are importing pandas, numpy, spacy, matplotlib, wordcloud, tqdm, and collections. We also set up matplotlib to work correctly in a Jupyter notebook with the `%matplotlib inline` command. Additionally, we are reading in several CSV files using pandas to create dataframes for analysis.",
    "Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Let's first get a feel for our datasets by taking a look at the first few lines.",
    "Create random forest classifier",
    "# Code continues...",
    "Let's take a look at the first few rows of each dataset to understand the data better.",
    "The first 5 scripts in the dataset\ndf_script.head()",
    "Show the first few rows of the characters DataFrame\ndf_characters.head()",
    " Merge character information\ndf_episodes_characters = (\n    df_episodes.merge(df_script, how='left', on='episode_id')\n    .merge(df_characters, how='left', on='character_id', suffixes=['_ep', '_ch'])\n    .sort_values(by=['id_ep', 'timestamp_in_ms'])\n)",
    " Add episode titles to script lines table\ndf_script['title'] = df_script.apply(lambda row: df_episodes[df_episodes['id'] == row['episode_id']]['title'].values[0], axis=1)",
    " Group the script by episodes and join the lines for each speaker",
    " Join locations and episodes information to script data\ndf_script = pd.merge(df_script, df_episodes, on='episode_id', how='left')\ndf_script = pd.merge(df_script, df_locations, on='location_id', how='left')",
    "Configure TQDM for pandas\ntqdm.pandas()",
    " Additional customization - Ensure pandas displays column info fully\npd.set_option('display.max_colwidth', None)",
    "Define character name either KILLER (The murderer or being killed) or VICTIM (The person being killed or the victim of the murderer).",
    "Join the script dataframe with the rest of the dataframes\n# This way we can get the right character, location and episode ids for each line of the scripts\ndf_script = df_script\\\n    .join(df_characters, on='character_id', rsuffix='_character')\\\n    .join(df_locations, on='location_id', rsuffix='_location')\\\n    .join(df_episodes, on='episode_id', rsuffix='_episode')",
    "Auxiliary functions to simplify and clean the code below.",
    " To integrate plotly with matplotlib, we need to install another library.",
    " Let's preview the datasets.",
    "Remove rows with missing values in the script and characters DataFrames\ndf_script.dropna(inplace=True)\ndf_characters.dropna(inplace=True)",
    "Merge dataframes to have all in one dataframe",
    " Replace nans in spoken_words with \"\"\ndf_script['raw_character_text'] = df_script['raw_character_text'].fillna(\"\")\ndf_script['spoken_words'] = df_script['spoken_words'].fillna(\"\")",
    " Set the script Unique Id as index\ndf_script.set_index('id', inplace=True)",
    "Merge script lines with episode data\ndf_merged = pd.merge(\n    df_script, \n    df_episodes, \n    how='left',\n    on='episode_id',\n    suffixes=('', '_ep')\n)",
    "Fix line_break and initial spaces at the beginning and end of spoken words",
    "Start by cleaning the script lines data by removing any 'nan' values.",
    "Exctract the content of the `raw_text` column and make it the variable `raw_text`",
    "Display the first few rows of the characters DataFrame\ndf_characters.head()",
    "Let's take a look at the characters, locations, script and episodes DataFrames.",
    "Clean text",
    "View DataFrame info\ndf_characters.info()",
    "Filter out wrong sources",
    "Create additional column for line length\ndf_script['line_length'] = df_script['raw_text'].str.len()",
    "Proranpdopting for NLP for both character and location names to handle misspellings and sense\nnlp = spacy.load(\"en_core_web_md\")",
    "Check contents of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect the dataset\ndf_script.head()",
    " Data exploration",
    "Check the first 5 rows of the characters DataFrame\ndf_characters.head()",
    "Filter out bad data from the dataset",
    " Ensure that pandas will display at least 500 characters in a column\npd.set_option('display.max_colwidth', 500)",
    " Calculate the number of lines that contain the lines spoken by each character\nlines_per_character = df_script.groupby('character_id').size()\nlines_per_character = lines_per_character.sort_values(ascending=False)",
    "Creating the model.",
    "Clean and pre-process the data\n# Eliminate the rows with any nan values\ndf_script = df_script.dropna()\n\n# Keep only the required columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'speaking_line', 'character_id', 'location_id']]",
    "Explore the data\ndf_script.head()",
    "Checking what the data looks like",
    "Consultando los primeros registros del dataset df_characters.",
    "Start by exploring the first few rows of each dataframe.",
    "View the first few rows of the characters DataFrame\ndf_characters.head()",
    " Show first elements of df_characters\ndf_characters.head()",
    "Check imported DataFrames\ndf_characters.head()",
    "Visualize the distribution of characters' genders in the dataset",
    "Merge the datasets\ndf_characters = pd.merge(df_characters, df_script, left_on='id', right_on='character_id')\ndf_characters = pd.merge(df_characters, df_episodes, left_on='episode_id', right_on='id')\ndf_characters = pd.merge(df_characters, df_locations, left_on='location_id', right_on='id')",
    "Sanity-check dataframe objects\ndf_episodes",
    " Perform a naive join between script and characters, this will allow us to include the character information with each row in the dataframe.",
    "Set the random seed for numpy to have the same results for multiple runs\nnp.random.seed(0)",
    "check the data extracted from the characters dataset\ndf_characters.head()",
    "Checking top 5 records to understand data better\ndf_characters.head()",
    "Format dataframe columns and values",
    "Visualize the first few rows of the characters DataFrame\ndf_characters.head()",
    "Print basic information on the characters dataset\ncharacters_info = df_characters.info()",
    "Show all columns and the first few rows of each DataFrame to understand what data is available",
    "Replace all NaN values with an empty string\ndf_script.fillna('', inplace=True)",
    "\n# Character interactions\ninteractions = df_script.groupby(['character_id', 'utterance_id']).size().groupby('character_id').size()\n\n# Now we have to map the characters in interactions to their real names\ninteractions = interactions.to_frame().join(df_characters.set_index('character_id'))\n\n# Sort the interactions\ninteractions.sort_values(by=0, ascending=False, inplace=True)",
    "drop the location quote, raw_location_text, raw_character_text\n# drop normalized text\n# drop has spoken\n# drop timestamp_in_ms\n# drop starts_with_quote\ndf_script.drop(columns=['location_quote', 'raw_location_text', 'raw_character_text', \n                        'normalized_text', 'spoken_words', \n                        'timestamp_in_ms', 'start_with_quote'], inplace=True)",
    "Check data has been read correctly\ndf_characters.head()",
    "Let's explore the first few rows of each dataframe to get an idea of what the data looks like.",
    "Stat helper functions",
    "Filter the dataset to keep only the standard episodes (Simpsons TV show)",
    " Display the first few rows of the script dataset\ndf_script.head()",
    "df_script.head()",
    "View first 5 rows of the characters dataframe\ndf_characters.head()",
    "Merge dataframes to simplify the analysis of the data",
    "reate a directory to save text data\ndirectory = 'data/text_data'\nif not os.path.exists(directory):\n    os.makedirs(directory)",
    "View the first 5 rows of each dataframe\nprint('Characters')\ndisplay(df_characters.head())\nprint('Locations')\ndisplay(df_locations.head())\nprint('Script')\ndisplay(df_script.head())\nprint('Episodes')\ndisplay(df_episodes.head())",
    "# Language model for extracting Named Entities\nnlp = spacy.load(\"en_core_web_sm\")",
    "# Run this cell to verify if pandas module is imported or not within the current environment\n\"pandas\" in locals()",
    "Check the contents of df_characters dataframe\ndf_characters.head()",
    " Merge the script and episode DataFrames\ndf = df_script.merge(df_episodes, on='episode_id')",
    "del df_characters['Unnamed: 0']\ndel df_locations['Unnamed: 0']\ndel df_script['Unnamed: 0']\ndel df_episodes['Unnamed: 0']",
    "Count the frequency of each character in the script\ncount_char = Counter(df_script['character_id'])\ntop_10_char = count_char.most_common(10)",
    "We can now start to take a look at the data with a simple head of each dataframe.",
    " Set this locally\ncsv_exist_local = False",
    "Sanity check\ndf_script.head()",
    "First, let's take a look at the first few rows of each DataFrame to understand their structure.",
    "Load spacy model\nnlp = spacy.load('en')",
    "Display the first few rows of the dataframe\ndf_script.head()",
    "Inspect the characters dataframe.",
    "The lines and their structure is in df_script dataset. Let's add a column to it that has the text, each line was referencing, added and then we can do the same thing as above.",
    "Merge the datasets on episode_id\ndf = pd.merge(df_script, df_episodes, on='episode_id').merge(df_characters, on='character_id').merge(df_locations, on='location_id')",
    "Show the first 5 records of each dataframe to understand the structure and content of the data.",
    "# Set random state\nSEED = 42",
    "Limiting the amount of information for brevity\ndf_script = df_script.iloc[:300000]",
    "Display the first few records of the characters dataframe\ndf_characters.head()",
    "D(**df_characters.head(2))\n# display(df_locations.head(2))\n# display(df_script.head(2))\n# display(df_episodes.head(2))",
    "Display settings\npd.set_option('display.max_columns', None)",
    "Well start by analyzing the script data. Lets take a look at the first few rows.",
    "Preview the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "We merge dialogues from the scripts and the respective speakers by using left join on character_id field and index field, we finally consider only\nthose episode whose script is complete.",
    " Display top 5 rows of characters dataframe",
    " Display the first few lines of each dataframe to understand the data better.",
    " check the content of the CSVs",
    "Set up matplotlib parameters to make the plots look better\nmatplotlib.rcParams['figure.figsize'] = (15, 10)\nmatplotlib.rcParams['font.size'] = 10\nmatplotlib.rcParams['figure.facecolor'] = '#00000000'",
    " Check that the data was loaded correctly",
    " Additional custom imports for natural language processing (NLP)",
    "Inspecting Data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Just checking the content of the file\ndf_script.head()",
    " Set decimal precision for pandas dataframes\npd.set_option('display.float_format', lambda x: '%.3f' % x)",
    "We'll first take a look at the structure and the first few rows of these datasets.",
    " Plotting the number of locations per episode",
    "Display first 5 rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "# Display the number of lines and the first few rows of the df_script dataframe\nprint(df_script.shape)\ndf_script.head()",
    "Show what the Simpsons characters data looks like",
    " Display the dataframes' shapes\nprint(df_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape)",
    "Drop rows with missing data from the df_script dataframe\ndf_script.dropna(inplace=True)",
    " Extracting the main characters and locations\nmain_characters = [\n    'marge', 'homer', 'bart', 'lisa', 'maggie',\n    'ned', 'flanders', 'moe', 'krusty', 'milhouse',\n    'chief', 'edna', 'selma', 'patty', 'lenny',\n    'carl', 'cletus', 'professor', 'snake', 'apu',\n    'rainier', 'seymour', 'waylon', 'nelson', 'ralph',\n    'barney', 'patty', 'martin', 'hans'\n]\n\nmain_locations = [\n    'Simpson House', 'Springfield Elementary School', 'Springfield Nuclear Power Plant',\n    'Kwik-E-Mart', 'Moe\\'s Tavern', 'Springfield Retirement Castle', 'Springfield',\n    '742 Evergreen Terrace', 'Springfield Town Hall', 'Burns Manor', 'Ned Flanders\\' House'\n]",
    "Check the first few rows of the dataframe\ndf_script.head()",
    " Intialize spaCy model\nnlp = spacy.load(\"en_core_web_sm\")",
    "Show all columns explicitly\npd.set_option('display.max_columns', None)",
    " Viewing the first 5 rows of the characters dataframe\ndf_characters.head(5)",
    "Read JSon conversion table from local storage\njcn = pd.read_csv('data/JsonConversion.csv')",
    "inspect the first few rows of each dataframe\nprint(df_characters.head())",
    "Inspect the first few rows of each dataframe to understand the data better.",
    " View the structure of the script data\ndf_script.head()",
    "display(df_characters.head(3))",
    "Check the first few rows of the characters dataframe\ndf_characters.head()",
    "Inspect dataframe shapes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "Let's check what the characters dataframe looks like.",
    "Take a look at the characters dataframe\ndf_characters.head()",
    "Let's take a look at the characters data.",
    "View the characters dataframe",
    "View the first 5 rows of the characters DataFrame\ndf_characters.head()",
    " Display how the datasets look",
    "ndata_folders = ['data_copy', 'data_clean']",
    "Show the first few rows of the 'df_characters' DataFrame\ndf_characters.head()",
    "Joining the dataframe to get the full data",
    "Check all the columns in the script dataframe\nprint(df_script.columns)",
    "Check the content of all DataFrames\nprint(\"Characters:\")\nprint(df_characters.head())\nprint(\"\\n\\nLocations:\")\nprint(df_locations.head())\nprint(\"\\n\\nScript:\")\nprint(df_script.head())\nprint(\"\\n\\nEpisodes:\")\nprint(df_episodes.head())",
    "Sample the dataframes to visualize their structure\ndf_characters.head(3)",
    "Print the header of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Check content of one of the dataframes\ndf_script.head(10)",
    " Merge episodes and locations dataframes\ndf_episodes_locations = df_episodes.merge(df_locations, left_on='id', right_on='episode_id').drop('episode_id', axis=1)",
    " Set text cleaning settings\nnlp = spacy.load(\"en_core_web_md\", disable=[\"parser\", \"ner\"])\n\n# Constants\nwhite_list_chars = [\n    \"bart\", \"homer\", \"marge\", \"maggie\", \"lisa\", \"krusty\", \"burns\",\n    \"millhouse\", \"apu\", \"moe\", \"ned\", \"edna\", \"skinner\", \"ralph\",\n    \"barney\", \"todd\", \"rod\", \"hans\", \"troy\", \"citizen\", \"abraham\",\n    \"lenny\", \"carl\", \"lionel\", \"selma\", \"patty\", \"milhouse\", \"montgomery\",\n    \"clancy\", \"waylon\", \"apu_nahasapeemapetilon\"\n]\n\n# Function to preprocess texts\ndef clean_text(text: str) -> str:\n    # Convert to lowercase\n    text = text.lower()\n    \n    # Remove punctuation, digits and special characters\n    text = \" \".join(token.lemma_ for token in nlp(text) if token.is_alpha)\n    \n    return text",
    "Let's display first rows of `df_characters` DataFrame.",
    "Create counting dictionaries",
    " Show tables\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Split text lines into tokens using spaCy\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])",
    " Text processing tools\nnlp = spacy.load('en', disable=['parser', 'ner'])",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "Display the first few rows of the dataframes to get an understanding of the data",
    "Merge the characters and locations dataframes with the script dataframe\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id')\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id')\n\n# Reorder columns\ndf_script = df_script[['id_x', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', \n                       'character_id', 'name_x', 'normalized_text_y', 'location_id', 'name_y', 'image_url', \n                       'normalized_text_x', 'wikipedia_url', 'number_y', 'normalized_text']]",
    "Preview the first 5 rows of the characters dataset\ndf_characters.head()",
    " Now let's take a look at the first few rows of each dataframe to understand their structure and contents.",
    "Set paths for easier importing",
    "Clean the script data\ndf_script_cleaned = df_script[\n    (df_script['springfield_id'] <= df_locations.shape[0]) &\n    (df_script['id'] < 200000) &\n    (df_script['location_id'] <= df_locations.shape[0]) &\n    (df_script['normalized_text'].apply(lambda x: isinstance(x, str))) &\n    (df_script['character_id'] <= df_characters.shape[0])\n]",
    "Let's have a look at a snapshot of one of the datasets to understand its structure.",
    "Inspect the character data first\ndf_characters.head()",
    "Check duplicates and missing data in each dataframe",
    "Let's take a look at the dataframes we have to understand how we can use them.",
    "# A bit of visualization\ndf = df_script[['episode_id', 'character_id']].groupby('episode_id').count().reset_index(inplace=False)\ndf = pd.merge(df, df_episodes[['id', 'original_air_date']], left_on='episode_id', right_on='id', how='inner')\ndf['original_air_date'] = pd.to_datetime(df['original_air_date'])\ndf = df.rename(columns={'character_id': 'line_count'})\ndf[['episode_id', 'line_count']].sort_values(by='line_count', ascending=False)[:10]",
    "Look at the data",
    "Separate each sentence into a list of words",
    "Create an instance of the English spacy model",
    "Show info/\ndf_script.info()",
    "Displays all the dataframes\ndisplay(df_characters.head(3))\ndisplay(df_locations.head(3))\ndisplay(df_script.head(3))\ndisplay(df_episodes.head(3))",
    "Visualize the first few rows of each dataframe to understand the data",
    "Evaluating the dimensions of the imported dataframes to ensure data has been loaded successfully.",
    "Merge script with episodes, characters and locations\ndf_episodes = df_episodes.rename(columns={'id':'episode_id'})\n\ndf = df_script.merge(\n    df_episodes[['episode_id', 'title', 'original_air_date']],\n    on='episode_id',\n    how='inner'\n    )",
    "Check the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Join script, characters and locations\ndf_script_full = df_script\\\n    .merge(\n        df_characters,\n        how='left',\n        left_on='character_id',\n        right_on='id'\n    )\\\n    .merge(\n        df_locations,\n        how='left',\n        left_on='location_id',\n        right_on='id'\n    )",
    "Create an instance of the English class of the spacy load.",
    "Let's take a look at the structure of the datasets.",
    " Display first 5 rows of the characters DataFrame\ndf_characters.head()",
    ".concat([df_characters, df_locations, df_script, df_episodes], keys=['characters', 'locations', 'script', 'episodes'], axis=1)",
    "Inspect the first few rows of each dataframe to understand the data",
    "Optional; restart the kernels to be sure that changes are picked up when the notebook is re-run.",
    "Display first lines of scripts dataframe\ndf_script.head()",
    "Displaying the first few rows of the characters DataFrame to understand its structure\ndf_characters.head()",
    " Merge the dataframes",
    "Let's create a simple word cloud for the Simpsons script lines.",
    "# Only interested in characters with a known location\ndf_characters = df_characters[df_characters['location_id'].notnull()]",
    "setup spacy\nnlp = spacy.load('en')",
    "Inspect the first few rows of the characters data\ndf_characters.head()",
    "Looking at the first few rows of each dataframe to understand the data",
    "Merge all dataframes into a single one",
    "Inspecting first rows of the dataset\ndf_characters.head()",
    " Explore the structure and contents of the script dataframe\nprint(f\"Number of rows {df_script.shape[0]} and columns {df_script.shape[1]}\")\ndf_script.head()",
    "Select only the first 20 lines from the script dataset to avoid memory errors",
    " We will use `spacy` library for text pre-processing, which is large and may take a little while to download.",
    "Setting up a spacy pipeline with the English model.",
    "Applying Title to each columns",
    "Create a new dataframe with the episode title, character speaking, and spoken text.",
    "Let's display the first 5 rows of each dataframe to understand better the data structure.",
    " Display the first 5 rows of each dataframe to get a quick look at the data",
    "np.random.seed(0)",
    "I misunderstood the purpose of this script. The goal is to interact with the CSV files and create visualizations, so I will remove the unnecessary imports and invalid code.",
    "Characters and locations involve different entries for different versions or spellings.",
    " Display the first few rows of the dataframe\ndf_episodes.head()",
    " from wordcloud import WordCloud",
    "Merge datasets to have conversations with Chris on the same DataFrame",
    "function to display character lines\ndef display_lines(df, character_name, lines_to_display=10):\n    display(df[df['raw_character_text'] == character_name].head(lines_to_display))",
    "Quick look on the data\nprint(df_script.head())",
    "Inspect dataframe shapes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "Merge the dialogues with the characters and episodes",
    " Show head of dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Merge script with character info and its location\ndf_script = df_script.merge(df_characters, how='inner', on='character_id')\ndf_script = df_script.merge(df_locations, how='inner', on='location_id')",
    "Examine the first few rows of the characters dataframe\ndf_characters.head()",
    "Joining character and location names to the main script dataframe",
    " Display the first few rows of each dataframe to understand the data better\ndf_characters.head()",
    "How many unique characters are there in the dataset?\ndf_script['character_id'].nunique()",
    "What steps should I take to clean the data in the script dataframe?",
    "Load dataset and reset index",
    "Organize each data frame by their IDs as shown below",
    "# Room for checking the contents of the dataframes",
    "Set seed for numpy\nnp.random.seed(0)",
    " Check if null values exist in the datasets\nprint(\"The number of null values in df_characters is:\", df_characters.isnull().sum().sum())\nprint(\"The number of null values in df_locations is:\", df_locations.isnull().sum().sum())\nprint(\"The number of null values in df_script is:\", df_script.isnull().sum().sum())\nprint(\"The number of null values in df_episodes is:\", df_episodes.isnull().sum().sum())",
    "In the above code, we are importing various libraries such as pandas, numpy, spacy, matplotlib, wordcloud, etc. We are also importing custom libraries like tqdm and Counter. Then we are reading CSV files into pandas dataframes using pd.read_csv().",
    "Check the head of the dataframe to ensure information was imported correctly\ndf_characters.head()",
    "We will start by inspecting the unique values contained in these dataframes.",
    " Display the first five rows of the characters dataframe\ndf_characters.head()",
    "Check the data in each dataframe\nprint('Characters')\nprint(df_characters.info())\nprint(df_characters.head())\n\nprint('Locations')\nprint(df_locations.info())\nprint(df_locations.head())\n\nprint('Script')\nprint(df_script.info())\nprint(df_script.head())\n\nprint('Episodes')\nprint(df_episodes.info())\nprint(df_episodes.head())",
    "check loaded csvs\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect each DataFrame and their respective columns",
    "Setting seed for reproducibility\nnp.random.seed(0)",
    "Clean the script dataframe\ndf_script_cleaned = df_script[['episode_id', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_text']].copy()\ndf_script_cleaned['episode_id'] = df_script_cleaned['episode_id'].astype(int)\ndf_script_cleaned['timestamp_in_ms'] = df_script_cleaned['timestamp_in_ms'].astype(int)\ndf_script_cleaned['character_id'] = df_script_cleaned['character_id'].astype(int)\ndf_script_cleaned['location_id'] = df_script_cleaned['location_id'].astype(int)\ndf_script_cleaned.head()",
    "Merge episodes and script dataframes",
    " Set seed for reproducibility\nnp.random.seed(10)",
    "Check the data\nprint(\"The characters:\")\ndisplay(df_characters.head())\nprint(\"The locations:\")\ndisplay(df_locations.head())\nprint(\"The script:\")\ndisplay(df_script.head())\nprint(\"The episodes:\")\ndisplay(df_episodes.head())",
    "Convert information gain to mutual information",
    "Inspect the first 5 rows of df_characters\ndf_characters.head()",
    " Display first 5 rows of characters\ndf_characters.head()",
    "Don't truncate text fields in the DataFrame display",
    "View the first few rows of the characters DataFrame\ndf_characters.head()",
    "Note: in the following dataframe printouts, instead of providing the full row, only the first \n# five items are printed.",
    "Create dataset of main character lines and locations from the script data",
    "Change size of the `script` column.\n\ndf_script['raw_text'] = df_script['raw_text'].astype('string')",
    "View the data\ndf_episodes.head()",
    " View the characters dataframe\ndf_characters.head()",
    "\ndf_script.head()",
    "Display the head of each dataframe to quickly check if the import was successful",
    "Check the dataframes shape\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "Add your data directory to the path\ndata_path = './data'",
    "Quick look at the data types and null values",
    "Merge characters in script\ndf_script_characters = (\n    df_script\n    .loc[df_script['speaking_line']]\n    .merge(\n        df_characters,\n        how='left',\n        left_on='raw_character_text',\n        right_on='character'\n    )\n)",
    "Build a lookup table for characters and their gender.",
    " Set series limits to view more data\npd.set_option('display.max_rows', 300)\npd.set_option('display.max_colwidth', 300)",
    "Extract the first few elements of the dataframe to get an understanding of the data",
    "Visualizing Data\n# Setting up themes\nplt.style.use('seaborn-whitegrid')",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Merge scripts with character names and locations\ndf_merged = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character'))",
    "Inspect the first few rows of each dataframe to understand the data",
    "Inspect data\ndf_script.head()",
    "Displaying the content of the new dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "# Check the structure of the dataframes\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
    "Print the first 5 rows of the script dataframe\ndf_script.head()",
    "Check the content of the dataframe of the characters",
    "Check for the presence of the 'data' directory",
    "Explore the content of each table to understand what they contain.",
    "Create a single dataframe's column with the whole script",
    "Exploratory Data Analysis",
    "# Extract scripts by characters\nlisa_lines = df_script[(df_script['normalized_name'] == 'lisa simpson') & (df_script['spoken_words'].notnull())]['spoken_words'].values\nmarge_lines = df_script[(df_script['normalized_name'] == 'marge simpson') & (df_script['spoken_words'].notnull())]['spoken_words'].values\nhomer_lines = df_script[(df_script['normalized_name'] == 'homer simpson') & (df_script['spoken_words'].notnull())]['spoken_words'].values\nbart_lines = df_script[(df_script['normalized_name'] == 'bart simpson') & (df_script['spoken_words'].notnull())]['spoken_words'].values",
    "Importing all necessary packages and setting up the dataframes for further analysis.",
    " Prints the top rows of the dataset to understand its structure",
    "## Take a look at the data\nprint('Characters')\nprint(df_characters.head())\nprint('\\nLocations')\nprint(df_locations.head())\nprint('\\nScript')\nprint(df_script.head())\nprint('\\nEpisodes')\nprint(df_episodes.head())",
    "Check the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Visualize the most common words in the script lines",
    "# Set some display parameters for pandas\npd.set_option('display.max_columns', None)",
    " Let's take a look at the first few lines of each dataset to understand its structure.",
    "# merge tables to have access to all the information contained in the different files\ndf_script_location = pd.merge(df_script, df_locations, left_on='location_id', right_on='id')\ndf_script_location_character = pd.merge(df_script_location, df_characters, left_on='character_id', right_on='id')\ndf_script_location_character_episode = pd.merge(df_script_location_character, df_episodes, left_on='episode_id', right_on='id')\n\n# remove rows with missing lines\ndf_script_location_character_episode = df_script_location_character_episode.dropna(subset=['normalized_text'])\n\n# Sort lines by original air date\ndf_script_location_character_episode['original_air_date'] = pd.to_datetime(df_script_location_character_episode['original_air_date'])\ndf_script_location_character_episode = df_script_location_character_episode.sort_values('original_air_date')\n\n# Print the first few rows\ndf_script_location_character_episode.head()",
    " Filter to keep only characters with more than 300 lines",
    "# Show first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect the data types and missing values for each dataframe\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
    " Check first few rows of 'df_characters' DataFrame",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "```",
    " Join all DataFrames together on episode_id",
    "Set default fontsize for better readability of charts\nmatplotlib.rcParams.update({'font.size': 14})",
    "Color for the different characters\ncolors = ['hsl('+str(h)+',50%'+',50%)' for h in np.linspace(0, 360, df_characters.shape[0])]",
    "This data consists of four tables: characters, locations, script lines, and episodes.",
    " Quick look at each dataframe\nprint('Characters')\nprint(df_characters.info())\nprint(df_characters.head(2))\n\nprint('Locations')\nprint(df_locations.info())\nprint(df_locations.head(2))",
    "Check the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Optional: Display first few rows of the datasets\ndf_characters.head()",
    " Display the first 5 characters of the characters DataFrame\ndf_characters.head()",
    "\n# Preprocess script lines\n# Remove unwanted columns\ndf_script = df_script.drop(['id', 'image_url'], axis=1)",
    "Show the first few rows of each DataFrame to understand its structure and information.",
    "Merge information for characters and locations with the script dataframe",
    "Limit the number of cast members on one-off roles\ndf1 = df_script[df_script['normalized_text'].isin(df_characters[df_characters['n_lines'] > 100]['raw_character_text'])]\ndf1.head()",
    "Display the first 5 rows of each dataframe to understand the data better\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "# Check for missing data\ndf_script.isnull().sum()",
    " Measure total spoken lines per character\nlines_per_character = df_script.character_id.value_counts().reset_index()\nlines_per_character.columns = ['character_id', 'number_of_lines']\nlines_per_character = lines_per_character.merge(df_characters, on='character_id')\nlines_per_character = lines_per_character.sort_values(by='number_of_lines', ascending=False)\n\n# Show data\nlines_per_character.head()",
    "Print the first few lines of each dataframe to get an overview of the data.",
    "A 2-minute version of the cleaning procedure is initiated.",
    "Print the first 5 rows of the characters, locations, script, and episodes DataFrames\nprint(\"Characters DataFrame:\")\nprint(df_characters.head())\nprint(\"\\nLocations DataFrame:\")\nprint(df_locations.head())\nprint(\"\\nScript DataFrame:\")\nprint(df_script.head())\nprint(\"\\nEpisodes DataFrame:\")\nprint(df_episodes.head())",
    "Combine script lines and episodes data into a single dataframe",
    "Let's display the first few lines of each dataframe to understand their structure.",
    "# show the first 5 lines of the dataframe\ndf_script.head()",
    "Sanity check for first rows of df_characters\ndf_characters.head()",
    " Display the first 5 rows of each dataframe\nprint(\"\\ncharacters\")\nprint(df_characters.head())\n\nprint(\"\\nlocations\")\nprint(df_locations.head())\n\nprint(\"\\nscript\")\nprint(df_script.head())\n\nprint(\"\\nepisodes\")\nprint(df_episodes.head())",
    " Display the first 5 rows of each DataFrame\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()",
    " Filter nulls from location and characters dataframes\ndf_characters = df_characters.dropna(subset=['normalized_name']).reset_index(inplace=False, drop=True)",
    "Optional: Display the first 5 entries for each dataframe to validate the import",
    "change columns to lower case and replace ' ' by '_'\ndf_characters.columns = [col.lower().replace(' ', '_') for col in df_characters.columns]\ndf_locations.columns = [col.lower().replace(' ', '_') for col in df_locations.columns]\ndf_script.columns = [col.lower().replace(' ', '_') for col in df_script.columns]\ndf_episodes.columns = [col.lower().replace(' ', '_') for col in df_episodes.columns]",
    " Show the first lines of the characters dataframe\ndf_characters.head()",
    "# Show first few rows of the characters dataframe\ndf_characters.head()",
    " Load the pre-trained Spacy model\nnlp = spacy.load('en_core_web_sm')",
    "A quick look at what the script df looks like",
    "# Fix timestamps\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].replace('Timestamp(\\'', '').str.replace('\\')','').astype(int)",
    " Check data head\ndf_script.head()",
    "Filter characters whose names contain last_name or first_name\nmain_characters = [name for name in df_characters.character_name.unique() if ((last_name in name) or (first_name in name))]",
    "Check for null values in the characters dataframe\nprint(df_characters.isnull().sum())",
    "Select relevant columns for each dataframe\ndf_characters = df_characters[['id', 'name', 'normalized_name', 'gender', 'normalized_gender']]\ndf_locations = df_locations[['id', 'name', 'normalized_name']]\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id']].copy()\ndf_episodes = df_episodes[['id', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season', 'number_in_series']].copy()",
    "Let's get a glimpse of the data we have imported.",
    "Display limitations\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 50)\npd.set_option('display.min_rows', 150)\npd.set_option('display.max_colwidth', 200)",
    "Merge the script with the characters and the episodes dataframes to have all the relevant info in one place.",
    " Check dimensions of the datasets\nprint(\"Characters: \", df_characters.shape)\nprint(\"Locations: \", df_locations.shape)\nprint(\"Script: \", df_script.shape)\nprint(\"Episodes: \", df_episodes.shape)",
    "Loading datasets",
    "Explore column names\nprint('Characters:', df_characters.columns.tolist())\nprint('Locations:', df_locations.columns.tolist())\nprint('Script lines:', df_script.columns.tolist())\nprint('Episodes:', df_episodes.columns.tolist())",
    "Inspect the structure of the dataframes",
    "Display data information\nprint(\"\\n\\nDimensions and columns of each dataset:\")\nprint(\"Characters: \", df_characters.shape, df_characters.columns)\nprint(\"Locations: \", df_locations.shape, df_locations.columns)\nprint(\"Script: \", df_script.shape, df_script.columns)\nprint(\"Episodes: \", df_episodes.shape, df_episodes.columns)",
    "Check the first few entries for each of the dataframes to understand the structure of the data",
    "\n# Light cleaning of the lines dataframe to keep only relevant columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]",
    "Create a new column to keep track of the total length of each line of dialogue.\ndf_script['raw_character_text'].str.len()",
    "Previewing the first 5 lines of the dataframe containing the characters and the first 5 lines of the dataframe containing the locations",
    "Merge character details and script lines\ndf_characters_script = pd.merge(df_characters, df_script, left_on='id', right_on='character_id')",
    "Initial data overview",
    " Select features of interest from the script dataset\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]\n\n# Convert episode number from float to int\ndf_script['number'] = df_script['number'].fillna(0).astype(int)",
    "Inspect the first 5 rows of each dataset to understand its structure and content",
    "Merge script and episodes on episode_id\ndf_script_episodes = df_script.merge(df_episodes, on='episode_id')",
    "Define a function to load the SpaCy model for named entity recognition (NER) and attach it to the pandas dataframe.",
    "Merge the datasets",
    "Setting 'UNKNOWN' for NaN values, to avoid surprises later\ndf_script['raw_character_text'] = df_script['raw_character_text'].fillna('UNKNOWN')\ndf_script['raw_location_text'] = df_script['raw_location_text'].fillna('UNKNOWN')",
    " Create a directory for storing the plots\nif not os.path.exists('plots'):\n    os.makedirs('plots')",
    "df_script.head()",
    "Inspect the dataframes",
    "Check how the script dataframe looks like\ndf_script.head()",
    "Load the data into pandas DataFrames",
    " Display several columns to see the data\ndf_script.head()",
    "Check dataframes head\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Set the seed for reproducibility",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Check dataframes are loaded successfully\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "Combine script lines with corresponding character and episode information\ndf = df_script.merge(df_characters, on='id_number', how='inner')\ndf = df.merge(df_episodes, on='episode_id', how='inner')",
    "Inspect first 5 rows of the characters dataframe",
    "def read_data():\n    # characters, locations, script lines, and episodes\n    df_characters = pd.read_csv('data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\n    df_locations = pd.read_csv('data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\n    df_script = pd.read_csv('data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\n    df_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)\n    return df_characters, df_locations, df_script, df_episodes",
    "# THESE LINES MIGHT NEED TO BE UNCOMMENTED IF THEY THROW AN ERROR.\n# df_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].astype(float).astype(int)",
    "Check for null values in the dataframe",
    "Set this option to see all rows\npd.set_option('display.max_rows', 500)",
    "# Display the first 5 rows of the character dataset\ndf_characters.head()",
    " Display first 5 rows of the data\nprint(\"Characters:\")\ndisplay(df_characters.head())\nprint(\"\\nLocations:\")\ndisplay(df_locations.head())\nprint(\"\\nScript:\")\ndisplay(df_script.head())\nprint(\"\\nEpisodes:\")\ndisplay(df_episodes.head())",
    "Display the first few rows of the dataframe containing script lines",
    " Check that location_id and episode_id are meaningful indices\nprint(df_locations.index)\nprint(df_episodes.index)",
    "Let's take a look at the first 5 rows of the characters dataframe.",
    "First, we import the necessary libraries and modules to set up our environment and load the data. Then, we read the CSV files into DataFrames using pandas.",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Create an instance of the WordCloud class",
    "# Define the evaluating function\ndef evaluate_representation(text_data, representation):\n    \"\"\"\n    Args:\n        text_data (string, pd.Series): The input text data\n        representation (spacy.tokens.doc.Doc): The representation we want to compare with the data\n    Returns:\n        pandas.core.series.Series: The similarity score for each data point\n    \"\"\"\n    return text_data.apply(lambda x: representation.similarity(nlp(str(x))))",
    "Check the first rows for each dataframe",
    "\ndf_script.head()",
    "Print the first 5 rows of the characters DataFrame\ndf_characters.head()",
    " Look at data format, read a few lines",
    "Check the structure of the dataset\ndf_script.head()",
    "Merge the datasets on foreign keys",
    "Merge multiple dataframes into one by episode number\ndf_full = df_script.merge(df_episodes, how='left', on='episode_id')\ndf_full = df_full.merge(df_characters, how='left', on='character_id')\ndf_full = df_full.merge(df_locations, how='left', on='location_id')\n\n# Create a DataFrame 'df_dialogue' to store the relevant columns\ndf_dialogue = df_full[['episode_id', 'number', 'raw_text', 'name', 'normalized_name', 'us_president', 'location', 'normalized_location']]\ndf_dialogue.rename(columns={'number': 'episode_number', 'raw_text': 'dialogue', 'name': 'character_name', 'normalized_name': 'character_id', 'us_president': 'president'}, inplace=True)",
    "Ignore pandas warnings\npd.options.mode.chained_assignment = None",
    "Create a directory to store visualizations if not present",
    " Load model\nnlp = spacy.load('en_core_web_md')",
    " Display the first few lines of the characters dataframe\ndf_characters.head()",
    "Display the first few rows of the character dataframe\ndf_characters.head()",
    "Inspect the first few rows of each dataframe to understand the data",
    "Inspect the first 5 rows of the characters DataFrame\ndf_characters.head()",
    "Display column names\nprint(\"Columns in character dataframe:\")\nprint(df_characters.columns)\nprint(\"\\nColumns in location dataframe:\")\nprint(df_locations.columns)\nprint(\"\\nColumns in script dataframe:\")\nprint(df_script.columns)\nprint(\"\\nColumns in episodes dataframe:\")\nprint(df_episodes.columns)",
    "Let's take a look at the first few rows of each dataframe",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Check what's inside df_script\ndf_script.head()",
    "A_D = {'she': 'Marge', 'her': 'Marge', \"he\": \"Homer\", \"him\": \"Homer\"}",
    " Integrating the data: combine the information from the different dataframes into a single dataframe.",
    "Preview the characters data\ndf_characters.head()",
    " Helper for production side\ndef load_all():\n    \"\"\"\n    Load datasets from the input file\n    \"\"\"\n    global df_characters, df_locations, df_script, df_episodes\n    df_characters = pd.read_csv('data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\n    df_locations = pd.read_csv('data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\n    df_script = pd.read_csv('data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\n    df_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)",
    " Let's take a look at each table to understand its structure and content.",
    "Check the number of null values in each dataframe\nprint(df_characters.isnull().sum())\nprint(df_locations.isnull().sum())\nprint(df_script.isnull().sum())\nprint(df_episodes.isnull().sum())",
    " Let's take a look at the structure and contents of each data type.",
    "General analysis on the datasets.",
    "Inspecting the Characters data frame.",
    "Import necessary modules and read in the CSV files into pandas dataframes.",
    " We'll also set the appropriate data types for each of the columns and perform other necessary data cleaning steps.",
    " Helper function to visualize a word cloud\ndef plot_wordcloud(wordcloud):\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")",
    "Part 1: Data preprocessing",
    " Remove all the \"bad\" lines (i.e. duplicate, not indiced, without a raw_text)\ndf_script = df_script[df_script[\"raw_text\"].notna()]",
    "Merge with characters and drop nans for speaking_character_id\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id').dropna(subset=['speaking_character_id'])",
    "Check the first 5 rows of the script dataframe",
    "Merge tables",
    "Set seed for reproducibility\nnp.random.seed(0)",
    "[\"added\", \"chapter\", \"overview\", \"front\"]",
    "Creating a new DataFrame containing only the raw text of the script lines, and the character that spoke them.\ndf_conversations = df_script[['raw_text', 'character_id']]\ndf_conversations = df_conversations.dropna()\ndf_conversations.reset_index(inplace=True, drop=True)\n\n# The character_id is of float type; converting it to int for compatibility with spacy's EntityRuler\ndf_conversations['character_id'] = df_conversations['character_id'].astype('int')",
    " Convert timestamps to datetime\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].apply(pd.to_datetime)",
    "Next, let's see how many unique characters, locations, and episodes are present in the dataset.",
    "Display the first 5 rows of each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display multiples output at once.\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"",
    "Set GPU usage to 30% to limit the resources used\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'",
    " Display the first few rows of the dataframe\ndf_script.head()",
    " Optionally set explore_mode to retrieve smaller random sample instead\nexplore_mode = False",
    "Building a word cloud for the entire Simpsons script\nscript = \" \".join(df_script['raw_text'])",
    " Look at the dimension of dataframes",
    "display the dataframes to observe the structure",
    " Display the first few lines of the script dataframe to understand its structure\ndf_script.head()",
    "inspect the first few records of the dataframe\ndf_characters.head()",
    "We need to fix the episode title - some of the titles from the script data frame have additional information about the season and episode numbers. We need to remove this information.",
    "Merge the data for characters, locations, and script lines using the episode ID as the common key.",
    "Add missing value to data\ndf_script.fillna('')",
    "Display sizes of the dataframes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "We'll start by taking a look at the first few rows of the script lines dataframe to understand its structure and the kind of data it contains.",
    " Join script lines and get an example episode\ndf_script = df_script.merge(df_episodes, on='episode_id')",
    "Choose a subset of the data to speed up the computation",
    "Display the first 5 records for the characters dataframe\ndf_characters.head()",
    "Let's first check out the data to see what we're working with.",
    " to show the first few rows of the dataframe, which can be helpful in understanding the data.",
    "Check the content of one of the DataFrames\ndf_script.head()",
    "Tagging the variables that we will be using to create the corpus.",
    "Remove potentially problematic rows",
    " Remove bad data points\ndf_script = df_script[df_script.sentence.str.len() > 1]",
    "spacy.load('en_core_web_md')\nnlp = spacy.load('en')",
    " Check the content of the dataframes",
    "Define the label to merge by\nlabel = ['season', 'number_in_season']\n\n# Join the datasets on the common label\ndf_merged = df_script.merge(df_episodes, on=label)",
    "Check that everythong is working as intended\nprint('Characters:')\ndisplay(df_characters.head())\nprint('Locations:')\ndisplay(df_locations.head())\nprint('Script:')\ndisplay(df_script.head())\nprint('Episodes:')\ndisplay(df_episodes.head())",
    "Following code will rename the column 'id' to 'episode_id'.",
    "\nprint(\"The file simpsons_script_lines.csv has loads of columns: \", *df_script.columns, \"\\n\")",
    "Inspect script dataframe",
    "Check if there are any NULL or empty rows in the script data\nprint(df_script.isnull().sum())",
    "Load the serialized version of the SpaCy pre-trained model 'en_core_web_md'\nnlp = spacy.load('en_core_web_md')",
    "Inspect top rows of df_characters\ndf_characters.head()",
    "The first step is to load the data into DataFrames using pandas. We then reset the index of each DataFrame to ensure everything is properly aligned.",
    "Visualizing the data",
    " filter to keep only one character_location\ndf_filtered_locations = df_locations[df_locations['raw_location_text'].str.lower().isin(df_script['raw_location_text'].str.lower().unique())].copy()",
    "Select the relevant columns in the characters dataframe\ndf_characters = df_characters[['id', 'name']]\n\n# Display the first few rows of the dataframe\ndf_characters.head()",
    "Display all rows and columns\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)",
    "Set plot size\nmatplotlib.rcParams['figure.figsize'] = [10, 7]",
    "preprocessing\ndf_script = df_script.dropna(subset=['character_id', 'location_id'])",
    "Get it to the right encoding\ndf_script = df_script.astype({\"index\": int, \"id\": int, \"number\": pd.Int64Dtype(),\n                              \"raw_text\": str, \"timestamp_in_ms\": pd.Int64Dtype(), \"speaking_line\": bool, \"character_id\": pd.Int64Dtype(),\n                              \"location_id\": pd.Int64Dtype(), \"raw_character_text\": str, \"raw_location_text\": str,\n                              \"spoken_words\": str, \"normalized_text\": str, \"word_count\": pd.Int64Dtype()})",
    "Inspect the first few rows of the characters data frame\ndf_characters.head()",
    "Check a few columns in the script data, as well as extract the character having the most lines and the location in which these lines were delivered",
    "# Cleaning Strings\ndf_characters = df_characters.dropna(subset=['name', 'normalized_name'])\ndf_locations = df_locations.dropna(subset=['name', 'normalized_name'])\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'raw_text'])\ndf_episodes = df_episodes.dropna(subset=['title'])",
    "Check if files are present\nos.listdir(\"data\")",
    "Checking size of the dataframes\ndf_episodes.shape, df_script.shape, df_characters.shape, df_locations.shape",
    " Display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Merge the script with characters and locations\ndf_script_chars_locations = pd.merge(df_script, df_characters, left_on='raw_character_text', right_on='character_name', how='left')\n\ndf_script_chars_locations = pd.merge(df_script_chars_locations, df_locations, left_on='raw_location_text', right_on='raw_location_text', how='left')\n\n# Verify the result\ndf_script_chars_locations.head()",
    "Inspect the first few rows of the characters DataFrame\ndf_characters.head()",
    "Checking loading of data done correctly",
    "nlp = spacy.load(\"en_core_web_sm\")\n\n# Path to where the wordcloud images will be saved\nWORDCLOUD_DIR = \"wordclouds\"\n\n# Create output directory if it does not exist\nos.makedirs(WORDCLOUD_DIR, exist_ok=True)",
    "Since the filenames for the datasets are 'simpsons_characters.csv', 'simpsons_locations.csv', 'simpsons_script_lines.csv', and 'simpsons_episodes.csv' it can be inferred that the datasets contain information about characters, locations, script lines, and episodes from the show \"The Simpsons.\"",
    "Display the number of characters, locations, script lines, and episodes\nlen(df_characters), len(df_locations), len(df_script), len(df_episodes)",
    "Inspect DataSource",
    "df_script_episode = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id')\ndf_script_character = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')\ndf_script_location = pd.merge(df_script, df_locations, left_on='location_id', right_on='id')",
    "View the characters dataframe\ndf_characters.head()",
    "Display for DataFrame\npd.options.display.max_columns = None",
    "Combine the tables to form one large dataset to work with",
    "Quick look at individual datasframes\ndf_characters.head()",
    " A famous collection of stopwords\nfrom nltk.corpus import stopwords",
    " Settings for visualization\nfont = {'size': 60}\nmatplotlib.rc('font', **font)",
    " Merge script data with corresponding character and location data\ndf_script_character = df_script.merge(df_characters, on='character_id', how='left')\ndf_script_location = df_script.merge(df_locations, on='location_id', how='left')",
    "Create new columns with episode title and writer names\ndf_script['episode_title'] = df_script['episode_id'].map(df_episodes.set_index('id')['title'])\ndf_script['writers'] = df_script['episode_id'].map(df_episodes.set_index('id')['writers'])",
    "Check result for each DataFrame\ndf_characters.head()",
    "It would be helpful to display the first few rows of each dataframe to get an idea of the data.",
    "Create a meta DataFrame with all the characters in the script, and the total number of spoken words for each character.",
    "Check the first 5 rows of each of the dataframes.",
    "Visualize the table's structure\ndf_episodes.head()",
    " Rest of the code is not provided.",
    "Load the required models from spacy module",
    "Convert date attributes to datetime\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])",
    " Show the first 10 rows of the character dataset\ndf_characters.head(10)",
    " Segment neighborhoods as different episodes.",
    " Show at least the beginning of each dataframe to understand the data",
    "Display available CSVs through their dataframes\ndf_script.columns",
    "All four dataframes have an 'id' attribute that we can use to make joins work better.",
    "Check data read correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "an inspection of the first few rows of df_characters\ndf_characters.head()",
    "Fixing name of the columns with right index numbers in dataframe and discarding unwanted columns",
    "Print out the first two rows of each of the dataset.",
    " Remove all lines with missing values in the following columns\ncolumns_to_clean = ['episode_id', 'number', 'raw_text']\n\ndf_script = df_script.dropna(subset=columns_to_clean)",
    "This will raise an error because the CSV files are not available, so let's remove it.",
    " Set the default style for plots",
    "Inspect the characters dataframe",
    "Setting spacy configuration with English model",
    " Split the `raw_character_text` column into a list of characters, regexing to remove ambiguities",
    "Compatibility with new pandas versions\nif pd.__version__>='1.0.0':\n    df_characters.rename(columns={'id': 'char_id'}, inplace=True)\n    df_locations.rename(columns={'id': 'loc_id'}, inplace=True)\n    df_script.rename(columns={'id': 'line_id', 'episode_id': 'ep_id', 'character_id': 'char_id', 'location_id': 'loc_id'}, inplace=True)\n    df_episodes.rename(columns={'id': 'ep_id'}, inplace=True)",
    " Check the first 5 rows of the characters dataframe.",
    "View the shape of these dataframe",
    "Explore the characters dataframe\ndf_characters.head()",
    "Set the `index` of each DataFrame to the `id` column\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    " Let's analyze the structure of the dataframe characters.",
    "Display all columns to be able to choose\npd.options.display.max_columns = None",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])",
    "View the dataset headers and the first five records in the dataframes.\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()",
    "Let's check the contents of the characters dataframe.",
    " Display the dataframe to understand its structure\ndf_script.head()",
    "Display the first five rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Display the first few rows of each dataframe to understand their structure and contents.",
    " Set up spaCy\nnlp = spacy.load(\"en_core_web_sm\")",
    " Display general information about the datasets\nprint(\"Characters Data:\")\ndisplay(df_characters.info())\ndisplay(df_characters.head(3))\n\nprint(\"\\nLocations Data:\")\ndisplay(df_locations.info())\ndisplay(df_locations.head(3))\n\nprint(\"\\nScript Data:\")\ndisplay(df_script.info())\ndisplay(df_script.head(3))\n\nprint(\"\\nEpisodes Data:\")\ndisplay(df_episodes.info())\ndisplay(df_episodes.head(3))",
    "Extract and display characters, locations, episodes and script data\nprint(\"\\n-- Characters --\")\nprint(df_characters.head())\n\nprint(\"\\n-- Locations --\")\nprint(df_locations.head())\n\nprint(\"\\n-- Episodes --\")\nprint(df_episodes.head())\n\nprint(\"\\n-- Script Lines --\")\nprint(df_script.head())",
    " Check the first 5 rows of the script DataFrame",
    "Set global plot styles and settings for consistent looks across all visualizations\nmatplotlib.rc_file_defaults()",
    "Show the dataframes to gain an overview of the columns and data types.",
    "Inspect the content of the loaded DataFrames",
    "Setting a seed for reproducibility\nnp.random.seed(123)",
    "Display the first few rows to ensure everything is loaded correctly\ndf_script.head()",
    "We are reading multiple CSV files into pandas dataframes for further analysis and processing.",
    "Check if all dataframes have been imported correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display sample rows for Simpsons characters\ndf_characters.head()",
    " Looking at the first few lines of each dataset to understand the structure and the type of data present",
    " Remove newlines and leading/trailing whitespaces from character_short column\ndf_script['character_short'] = df_script['character_short'].str.strip().str.replace(r'\\n', '')",
    "Clean dataframe \"df_script\" from NaN and duplicated data",
    "Explore the data\nprint('Characters\\n', df_characters.head(), '\\n')\nprint('Locations\\n', df_locations.head(), '\\n')\nprint('Script\\n', df_script.head(), '\\n')\nprint('Episodes\\n', df_episodes.head())",
    "Create syntax highlighting across all text and not just strings\nmatplotlib.rcParams['syntax.note_color']='#AA0000'",
    " Merge datasets\n# Merge characters and script\ndf_chars_script = pd.merge(df_characters, df_script, on='character_id')\n\n# Merge episodes and locations\ndf_ep_locs = pd.merge(df_episodes, df_locations, on='location_id')\n\n# Merge the previous result with characters and script\ndf_ep_locs_chars_script = pd.merge(df_ep_locs, df_chars_script, on='episode_id')",
    "collapse multi-line pandas DataFrames to a single line\nprint(f\"{len(df_characters)} characters, {len(df_locations)} locations, {len(df_script)} script lines, {len(df_episodes)} episodes\")",
    "display(df_characters.head())\n#display(df_locations.head())\n#display(df_script.head())\n#display(df_episodes.head())",
    "First, let's take a look at the character dataset.",
    "Test that we have loaded the data correctly\ndf_script.head()",
    " Display the dataframe containing the script\ndf_script",
    "Filters irrelevant columns from the characters dataframe",
    "Displays the first 3 rows from the characters dataframe\ndf_characters.head(3)",
    "needed in the EDA portion of the assignment",
    "Explore the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Show the first few characters of the main datasets\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Setup matplotlib style\nplt.style.use('fivethirtyeight')",
    "Init spacy\nnlp = spacy.load('en')",
    "Simple regularization\ndf_script = df_script[['episode_id', 'raw_text']].groupby('episode_id').agg(lambda x: ' '.join(x)).reset_index()",
    "Select only The Simpsons family member\nmain_characters = [\n    'marge', 'homer', 'bart', 'lisa', 'maggie', \n    'abraham', 'patty', 'selma', 'krusty'\n]\n\n# Scraped from URL\nplayable_characters = [\n    'ned', 'apu', 'moe', 'skinner', 'flanders',\n    'barney', 'lenny', 'carl', 'duffman', \n    'snake', 'otto', 'manjula', 'bont', 'herman', \n    'jasper', 'hibbert', 'milhouse', 'ralph', \n    'wiggum', 'frink', 'edna', 'lovejoy', 'nelson', \n    'carlson', 'quimby', 'stampy', 'krabappel', \n    'snake', 'willie'\n]\n\n# Combine the two lists of characters\ncharacters = main_characters + playable_characters\n",
    "Add character name to script lines dataframe",
    " Set up a nice background for the wordcloud\nbackground = np.array(Image.open('data/homer.png'))",
    "Enable or download spacy English language model\n# !python -m spacy download en ",
    "Check if dataframe have been sorted correctly\ndf_script.head()",
    " Set the default figure size for matplotlib plots\nmatplotlib.rcParams['figure.figsize'] = (15, 10)",
    "Split text into words using SpaCy's English tokenizer.",
    "first, let's cleanup the data.",
    "Extract the file_name and line_text columns\ndf_script = df_script[['file_name', 'normalized_text']]",
    "View data tables\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Discover and display some basic informations about the data",
    "Merge the script data with the episode data\ndf_merged = df_script.merge(df_episodes, on='episode_id')\n\n# Filter out the bad rows and columns\ndf_merged = df_merged[(df_merged.notnull().all(axis=1)) & (df_merged['word_count'].notnull())]\ndf_merged = df_merged.query('word_count > 0')\n\n# Filter out rows where the character is not a Simpson\ndf_merged = df_merged[df_merged['raw_character_text'].map(lambda x: 'simpson' in x.lower())]",
    "Display the top 5 records of each dataframe\ndf_characters.head()",
    " Let's take a look at the first few rows of each dataframe.",
    "Set plot style\nmatplotlib.style.use('fivethirtyeight')",
    " Checking out the characters DataFrame\ndf_characters.head()",
    "Display the first few rows of each dataframe to understand their structure and content\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Add custom named entities to spaCy\nnlp = spacy.load('en_core_web_sm')\n\n# Function to add custom named entities to spaCy\ndef add_custom_named_entities(nlp, labeled_data):\n    for entry in labeled_data:\n        for token in entry[0].split(' '):\n            nlp.tokenizer.add_special_case(token, [{'ORTH': token}])\n    return nlp",
    "Print first 5 rows of the script dataset\nscript_dataset = df_script\nprint(script_dataset.head())",
    " Merge datasets\ndf_script_episodes = df_script.merge(df_episodes, on='episode_id', how='left')\ndf_script_episodes_characters = df_script_episodes.merge(df_characters, left_on='character_id', right_on='id', how='left', suffixes=['_script', '_character'])\ndf_script_episodes_characters_locations = df_script_episodes_characters.merge(df_locations, left_on='location_id', right_on='id', how='left', suffixes=['_character', '_location'])\n\n# Now we have a single dataframe containing all the information.",
    "Check dataframes\ndf_characters.head()",
    " A small hack as PySpark expects the file to end in \".parquet\" while pandas saves it just with \".gzip\".\nfilename = 'data/simpsons_script_lines.csv.gzip'\nif not os.path.isfile(filename):\n    import shutil\n    shutil.copy('data/simpsons_script_lines.csv.gzip_temp', filename)",
    " Let's take a look at heads of each dataframe",
    "Checking df_characters dataframe",
    " Remove unclosed parentheses in the code and join it together with backslashes",
    "Make the models deterministic\nspacy.util.fix_random_seed(0)\nnp.random.seed(0)",
    "# Display the head of the dataframe to have a first look at its content\ndf_script.head()",
    "Create a new column containing the normalized lemmatized version of the spoken lines\ndf_script['spoken_lemmatized'] = df_script['normalized_text'].progress_apply(spacy_lemmatize)",
    "Preview of the characters dataframe\ndf_characters.head()",
    "# Let's take a look at the characters data\ndf_characters.head()",
    "Count the number of words spoken by each character\ndf_character_word_count = df_script.groupby('character_id')['word_count'].sum().reset_index()\n\n# Merge with characters and limit the top 20\ndf_character_word_count = (pd\n    .merge(df_characters, df_character_word_count, how='inner', left_on='id', right_on='character_id')\n    .sort_values('word_count', ascending=False)\n    .head(20))\n\n# Plot\nfig, ax = plt.subplots(figsize=(10,8))\nplt.barh(np.arange(len(df_character_word_count)), df_character_word_count['word_count'])\nplt.yticks(np.arange(len(df_character_word_count)), df_character_word_count['name'], rotation=0, ha='right')\nplt.xlabel('Word count')\nplt.title('Number of words spoken by character')\nplt.gca().invert_yaxis()",
    "Build a Panda Script using Dataframes",
    "check info in the imported data files\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
    " Displaying the first few entries for each of our datasets",
    " Set the max display of rows in pandas display to 10",
    "Displaying the first few entries of the characters dataframe\ndf_characters.head()",
    "limiting number of rows is generally a good practice in data exploration\npd.options.display.max_rows = 10",
    "Let's explore the data by displaying information about the characters, locations, episodes, and script lines.",
    "hood_character(e.g. Homer Simpson, Marge Simpson, Mr. Burns), name of the characterhood_location(e.g. Street Name, House of Ned Flanders), name of the location, dialogue(Text by character), timestamp_in_ms(Millisecond of dialogue)",
    "Display settings\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    "Check the characters DataFrame\ndf_characters.head()",
    "Setting the \"include\" parameter of the read_csv function call to \"all\" will force pandas to read all columns, \n # even if they have mixed dtypes. Use at your own risk - it's 5-10x slower.",
    "Create a subset of the script lines dataframe containing only the spoken lines",
    "We will start by exploring the data to understand its structure, contents, and how everything relates together.",
    "Load pre-trained spacy model\nnlp = spacy.load(\"en_core_web_sm\")",
    "Display top 10 rows of each dataframe to understand structure and information.",
    "Get only a few columns for the purpose of this analysis",
    "Exploring the first few rows of the dataframe\ndf_characters.head()",
    "Merge the datasets to create one single dataframe",
    "Check that the file in each DataFrame are ordered in the same way as the corresponding IDs",
    "Display the dataframe and data types of each column\ndf_script.info()",
    "Check if rows in script DF contain either characters or locations\ncharacter_names = list(df_characters['character_name'].values)\nlocation_names = list(df_locations['raw_location_text'].values)",
    "Set the dataframe display option to show all columns for visibility\npd.set_option('display.max_columns', None)",
    "View the first few rows of the characters data\ndf_characters.head()",
    " Show first 5 rows of the dataframe\ndf_script.head()",
    "Merge the dataset to get all the information in a single dataframe",
    "Display the data to better understand its structure and the available features\ndf_characters.head()",
    "As the dataset is too large for this course, a subset will be used instead.",
    " Setuptools' entry point\ndef main():\n    \"\"\"\n    Main function\n    \"\"\"",
    "Preview the loaded data\ndf_characters.head()",
    " Display the top 5 rows of the characters dataframe\ndf_characters.head()",
    " Check the imported data\nprint(df_characters.head())",
    "Some of the character names are in lowercase in the script, while they are in uppercase in the characters DataFrame. Let's convert all names to lowercase for consistency.",
    " Set the script dataset index\ndf_script.set_index('id', inplace=True)",
    " Check the character dataframe for NaN values\nprint(df_characters.isna().sum())",
    "%reload_ext autoreload\n%autoreload 2",
    " Display first rows of all DataFrames related to the Simpsons dataset\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display in Jupyter notebook the top 5 rows of the Simpsons characters dataset\ndf_characters.head()",
    " Set option to display dataframe in Jupyter\npd.set_option('display.max_columns', None)",
    " drop duplicate values from the script dataframe\ndf_script.drop_duplicates(subset=['raw_text'], keep='first', inplace=True)",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Looks like the code reads data from CSV files into pandas dataframes.",
    " Visualization function to plot word clouds",
    "cos when print statements appear in the middle of my sentence I can think of nothing better so say.",
    "Check missing values\nprint(\"NaN Values in characters: \",df_characters[df_characters.isna().any(axis=1)].shape[0])\nprint(\"NaN Values in locations: \",df_locations[df_locations.isna().any(axis=1)].shape[0])\nprint(\"NaN Values in script: \",df_script[df_script.isna().any(axis=1)].shape[0])\nprint(\"NaN Values in episodes: \",df_episodes[df_episodes.isna().any(axis=1)].shape[0])",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Check if the data loaded properly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())",
    "Inspecting the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Display the first few rows of the dataframe\ndf_script.head()",
    " Combining all the different datasets",
    "filter out script entries that dont have an associated location or character",
    "Check loaded dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "# Display all dataframe columns\npd.set_option('display.max_columns', None)",
    "Check the shape of each DataFrame\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "# Set the maximum number of rows and columns displayed when printing a DataFrame\npd.set_option('display.max_rows', 300)\npd.set_option('display.max_columns', 300)",
    "A quick view of the characters dataset\ndf_characters.head()",
    "clean the character lines by dropping duplicate lines and removing special chars\ndf_script = df_script.drop_duplicates('raw_text').reset_index(inplace=False, drop=True)",
    "Remove unused columns for the script and characters dataframe\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'spoken_words', 'character_id', 'location_id', 'timestamp_in_ms']]\ndf_characters = df_characters[['id', 'name', 'normalized_name']]\ndf_locations = df_locations[['id', 'name']]",
    "Check the data correctness\ndf_script.head()",
    "The next section replaces speaker's names, locations, and special expressions by\n# VALUE_NOT_USED. We also store each replacement in separate csv files.\n\nfrom preprocess import *",
    "Display settings\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('max_colwidth', None)",
    "Declare the file path to the stopwords file\nstopwords_file = \"stopwords.txt\"",
    "Let's take a look at each dataframe.",
    "Visualize the data",
    " Remove nas\ndf_script = df_script.dropna(subset=['normalized_text'])",
    "Display the head of the characters dataframe to understand its structure\ndf_characters.head()",
    "Combining the data from simpsons_script_lines with the text data to make the analysis easier.",
    "Setup Matplotlib\nmatplotlib.rcParams['figure.figsize'] = (10, 6)  # Use bigger plots",
    " Create a column containing the length of each line of dialogue\ndf_script['length'] = df_script['raw_character_text'].str.len()",
    "WARNING: It is bad practice to use inplace=True and assigning to the same variable, as this might lead to unexpected behavior.",
    " Let's have a look at the data.",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Inspect the structure of each dataframe\ndf_characters.head()",
    "Let's display the first few rows of each of the datasets to understand their structure and contents.",
    "\n# Display the first few rows of the dataframe\ndf_characters.head()",
    " Preview each loaded dataset",
    "Print first 5 rows of characters, locations, script lines and episodes dataframes",
    "df_script.head()",
    "Check the first rows of the first dataset (the script)\ndf_script.head()",
    "df_script.head()",
    "rename the columns in the DataFrames to make them more legible.\ndf_characters.columns = ['character_id', 'name']\ndf_locations.columns = ['location_id', 'name']\ndf_script.columns = ['index', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text', 'word_count']\ndf_episodes.columns = ['id', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season', 'number_in_series', 'us_viewers_in_millions', 'views', 'imdb_rating', 'imdb_votes', 'image_url', 'video_url']",
    "Remove `Unnamed: 0` column from `df_characters`\ndf_characters.drop(columns='Unnamed: 0', inplace=True)",
    "Checking the simpons dataframe data.",
    "Filter script lines to eliminate bad data",
    " Display some basic information about our datasets\nprint(\"Characters:\")\nprint(df_characters.info())\nprint(df_characters.head())\nprint()\nprint(\"Locations:\")\nprint(df_locations.info())\nprint(df_locations.head())\nprint()\nprint(\"Script:\")\nprint(df_script.info())\nprint(df_script.head())\nprint()\nprint(\"Episodes:\")\nprint(df_episodes.info())\nprint(df_episodes.head())",
    "Load it as read access to avoid writing permissions",
    "Check the head of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check some sample data for each file",
    " Set logging level\nimport logging\nlogging.getLogger().setLevel(logging.CRITICAL)",
    "Create an instance of the WordCloud class and model the word cloud using the script data",
    "Print the number of rows in each table\nprint(f\"The characters table has {len(df_characters)} rows.\")\nprint(f\"The locations table has {len(df_locations)} rows.\")\nprint(f\"The script table has {len(df_script)} rows.\")\nprint(f\"The episodes table has {len(df_episodes)} rows.\")",
    "Inspect character dataframe\ndf_characters.head()",
    "display(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Inspecting the first 5 rows of each dataframe to understand the structure of the data.",
    "Let's get an overview of these datasets.",
    "Preview df_characters\ndf_characters.head()",
    " View the first few rows of the characters dataframe\ndf_characters.head()",
    "Print the head of each DataFrame to inspect them\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Finding episode titles for each id in the dialogs dataset.",
    "Merge the dataframes\ndf_joined = df_script.merge(df_episodes, how='left', on='episode_id')\ndf_joined = df_joined.merge(df_characters, how='left', left_on='character_id', right_on='id')\ndf_joined = df_joined.merge(df_locations, how='left', left_on='raw_location_text', right_on='raw_location_text')",
    " Print the first few entries of the characters DataFrame\nprint(f\"The shape of the Simpsons characters DataFrame is: {df_characters.shape}\")",
    "Inspect information of each dataframe\nprint('Characters dataframe')\ndisplay(df_characters.info())\ndisplay(df_characters.head())",
    "Project settings\nimport warnings\nwarnings.filterwarnings(\"ignore\")",
    "Merge script lines with relevant information about episodes, characters, and locations\ndf_merged = df_script.merge(df_episodes, on='episode_id', how='left')\ndf_merged = df_merged.merge(df_characters, on='character_id', how='left')\ndf_merged = df_merged.merge(df_locations, on='location_id', how='left')",
    " WordCloud requires text data to generate word clouds. We will use the Simpsons script lines as our text data to generate word clouds for each character's dialogues.",
    " Define stop words and punctuation to remove from the script\nstop_words = spacy.lang.en.stop_words.STOP_WORDS\npunctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n\n# Load the language model and parse the dialog\nnlp = spacy.load('en_core_web_sm')\ndialogue = ' '.join(df_script['raw_text'].values)\nparsed_dialogue = nlp(dialogue)",
    "Preprocess data\n# Simpsons script data\n# 1. Merge script and episodes data\ndf_script_episodes = pd.merge(df_script, df_episodes, how='left', on='episode_id')",
    "Display all tables\npd.set_option('display.max_columns', None)",
    "define a helper function to print the first few rows of a dataframe",
    "Dropping lines that have not been assigned to an episode\ndf_script = df_script.dropna(subset=['episode_id'])",
    "Filtering the dataset to only include data from the first 10 seasons",
    "Clean text data and remove special characters, punctuation, etc.",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Filter the data to only include the lines from the 10 main characters.",
    "merging the data to have all pertinent information in one dataframe",
    "Select only the parts of the script with at least two words.",
    " Check the content and the type of each of the DataFrames\nprint(\"Characters DataFrame\")\nprint(df_characters.head())\nprint(\"\\nLocations DataFrame\")\nprint(df_locations.head())\nprint(\"\\nScript DataFrame\")\nprint(df_script.head())\nprint(\"\\nEpisodes DataFrame\")\nprint(df_episodes.head())",
    "Merge episode, character and location names into the main script dataframe\ndf_script = df_script.merge(df_episodes[['id', 'title', 'original_air_date', 'production_code']], \n                            left_on='episode_id', right_on='id', how='left')\ndf_script = df_script.merge(df_characters[['id', 'normalized_name']], \n                            left_on='character_id', right_on='id', how='left')\ndf_script = df_script.merge(df_locations[['id', 'normalized_name']], \n                            left_on='location_id', right_on='id', how='left')",
    "Drop null columns and trim whitespaces",
    "Load the custom NLP pipeline\nnlp = spacy.load('simpsons')",
    "Inspect the first 5 rows of the characters DataFrame\ndf_characters.head()",
    "jupyter notebook compatible code\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"",
    "Display the first few rows of the dataframe\ndf_script.head()",
    "# Show head of characters data\ndf_characters.head()",
    "Remove non-text columns\ndf_script = df_script[['episode_id', 'number', 'raw_text']]",
    " Use pandas to see what's inside the first loaded dataset\ndf_characters.head()",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    "Visual Representation of the Data\n# Show the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Displaying the first 5 rows of each dataset\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Limit the maximal number of columns displayed to 50\npd.set_option('display.max_columns', 50)",
    "define language model\nnlp = spacy.load('en_core_web_sm')",
    "# Debug information\nprint(f'Total characters in dataset {len(df_characters)}')\nprint(f'Total unique characters in dataset {df_characters.character.nunique()}')\nprint(f'Total locations in dataset {len(df_locations)}')\nprint(f'Total unique locations in dataset {df_locations.location.nunique()}')\nprint(f'Total script lines in dataset {len(df_script)}')\nprint(f'Total unique episodes in dataset {df_script.episode_id.nunique()}')\nprint(f'Total episodes in dataset {len(df_episodes)}')",
    "Check the dataframe\ndf_characters.head()",
    " Create a sub-dataframe using only the lines\ndf_lines = df_script[['episode_id', 'number', 'raw_text']]",
    " Display the first few rows of the characters DataFrame to understand its structure.\ndf_characters.head()",
    " Display information about the script dataset\ndf_script.info()",
    "Let's check how the characters dataframe looks like.",
    "Check the data type and print as the number of missing values in each column\nprint(f'df_characters: {df_characters.shape}')\nprint(df_characters.dtypes, end='\\n\\n')\nprint(df_characters.isna().sum(), end='\\n\\n')\n\nprint(f'df_locations: {df_locations.shape}')\nprint(df_locations.dtypes, end='\\n\\n')\nprint(df_locations.isna().sum(), end='\\n\\n')\n\nprint(f'df_episodes: {df_episodes.shape}')\nprint(df_episodes.dtypes, end='\\n\\n')\nprint(df_episodes.isna().sum(), end='\\n\\n')\n\nprint(f'df_script: {df_script.shape}')\nprint(df_script.dtypes, end='\\n\\n')\nprint(df_script.isna().sum(), end='\\n\\n')",
    ".*.",
    "Create a table with the title and the number of lines for each episode.",
    "Check first rows of the characters dataframe\ndf_characters.head()",
    "Display a preview of the dataframes",
    "Inspect the structure of the data:",
    " Let's start by looking at what's in the dataframes",
    "Create some directories to store graphs and data",
    "First we will need to do a bit of cleanup of the dataset in order to work with it.",
    "Check if all files are properly loaded\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Let's take a look at the dataframes",
    "Clean the script (remove noisy data and keep only dialogues)",
    "define UTC dates and reset index for simpsons_episodes if not done previously",
    "Add the Simpsons script in case the CSV is not available.",
    "Load the provided csv files into pandas dataframes.",
    " For simplicity, only keep the data we'll need for this analysis.",
    " Check the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "The simpsons script is a flattened version of the episodes where each line is a new entry in the table.",
    ".against general memory issues\nprint(\"Characters:\", df_characters.memory_usage().sum() / 1024**2, \"MB\")\nprint(\"Locations:\", df_locations.memory_usage().sum() / 1024**2, \"MB\")\nprint(\"Script lines:\", df_script.memory_usage().sum() / 1024**2, \"MB\")\nprint(\"Episodes:\", df_episodes.memory_usage().sum() / 1024**2, \"MB\")",
    "Ensure all scripts are in the same format (remove leading/trailing whitespace, convert to lowercase, remove brackets and their contents)\n\ndf_script['raw_text'] = df_script['raw_text'].str.strip()\ndf_script['raw_text'] = df_script['raw_text'].str.lower()\ndf_script['raw_text'] = df_script['raw_text'].str.replace(r\"\\(.*\\)\", \"\")",
    "Display first few rows of the characters dataframe\ndf_characters.head()",
    "Looking at the dimensions of the tables\nprint('Dimensions of characters table:', df_characters.shape)\nprint('Dimensions of locations table:', df_locations.shape)\nprint('Dimensions of script table:', df_script.shape)\nprint('Dimensions of episodes table:', df_episodes.shape)",
    "Display a node like: 'Number of rows & columns in each table'",
    "Declare variable for working with the lemma of the words",
    "Browse the first few rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Smaller dataframes with the essential columns only",
    "pd.set_option('display.max_columns', None)",
    "Set seed for reproducibility\nnp.random.seed(0)",
    "Check the imported dataframes",
    " Displaying the word cloud for the most common words in The Simpsons script lines",
    "Merge the datasets",
    "Display first rows of DataFrame\ndf_script.head()",
    " View the first few lines of the dataframe\nprint(df_script.head())",
    "View the first 5 rows of the character dataframe\ndf_characters.head()",
    "Check for missing values in the characters dataframe\ndf_characters.isnull().sum()",
    "Merge episodes with locations\ndf_episodes_locations = df_episodes.merge(\n    df_locations, left_on='id', right_on='episode_id')\n\n# Count how many times each location was used\nlocation_counts = df_episodes_locations.location_id.value_counts()\n\n# Merge episodes with characters\ndf_episodes_characters = df_episodes.merge(\n    df_characters, left_on='id', right_on='episode_id')\n\n# Count how many times each character was used\ncharacter_counts = df_episodes_characters.character_id.value_counts()\n\n# Create a location count plot\nlocation_counts.plot(kind='bar', figsize=(15, 5))\nplt.title('Number of times each location was used')\nplt.ylabel('Count')\nplt.xlabel('Location')\nplt.show()\n\n# Create a character count plot\ncharacter_counts.plot(kind='bar', figsize=(15, 5))\nplt.title('Number of times each character was used')\nplt.ylabel('Count')\nplt.xlabel('Character')\nplt.show()",
    "# create a column for every episode/character combination and populate it with line_index\nep_char_comb = pd.merge(df_script[['episode_id', 'character_id','line_index']],\n                        pd.crosstab(df_script['line_index'], df_script['character_id'])\n                                .reset_index(inplace=False),\n                        on='line_index',\n                        how='left')",
    "source: https://www.kaggle.com/pierremegret/dialogue-lines-of-the-simpsons?select=simpsons_script.csv",
    "Merge script with episodes\ndf = df_script.merge(df_episodes, on='episode_id')\n# Create a date field\ndf['date'] = pd.to_datetime(df['original_air_date'])\n# BeautifulSoup is cleaner\ndf['raw_text_clean'] = df['raw_text'].str.replace('<.*>', '')",
    "Data Cleaning and Processing",
    "df_script.head()",
    "Display the first few lines of each dataframe to understand its structure and contents.",
    "Define a seed for reproducibility.",
    "visualize wordcloud of Simpson script data",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "display the columns and first 5 rows of the characters dataframe\ndf_characters.head()",
    "Let's take a look at the character data:",
    "Print the shape of the datasets\nprint(df_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape)",
    "Print the first 3 rows of the characters dataset\nprint(df_characters.head(3))",
    "Data description:\n# - df_characters: information about the characters in the Simpsons series\n# - df_locations: information about the locations where the series takes place\n# - df_script: the script lines for each episode\n# - df_episodes: information about each episode",
    "Let's start!",
    "Set the 'id' column as the index for each DataFrame\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)",
    "Inspect the contents of the Character dataset\ndf_characters.head()",
    "Let's have a look at the content of each of these datasets.",
    "Setting some pandas display options for better readability of dataframes",
    " Viewing the first few rows of each dataframe to get an understanding of the data",
    "Verify the script dataframe\ndf_script.head()",
    "Inspecting the first few rows of the characters dataset\ndf_characters.head()",
    "Inspect data\ndf_script.head()",
    " Extract all the sentences in the script and column to a list\nsentences = df_script['raw_text'].tolist()",
    " Check the first few rows of the characters dataframe to understand its structure\ndf_characters.head()",
    "Checking the dataframes",
    "View the first 5 rows of the script dataframe\ndf_script.head()",
    " Set the seed for reproducibility\nnp.random.seed(0)",
    "Check to make sure everything was read in properly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Visualizing the distribution of character genders.",
    "Inspect content of the `df_characters` dataframe by displaying its first few rows",
    " Select first 10k\ndf_script = df_script.iloc[:10000]",
    "Checking Python version for compatibility",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    " Extract script for requested episode\nepisode_id = 12\ndf_episode_script = df_script[df_script['episode_id'] == episode_id]",
    "*Note: If you're using a Jupyter notebook, make sure to run the `%matplotlib inline` command to display the visualization within the notebook.*",
    "Display all columns of the dataframe\npd.set_option('display.max_columns', None)",
    " Set max column width for dataframes to 1000\npd.set_option('display.max_colwidth', 1000)",
    "Rename the 'id' column to 'script_id' in df_script DataFrame\ndf_script.rename(columns={'id': 'script_id'}, inplace=True)",
    "Merge script lines with episode data\ndf_script_full = df_script.merge(df_episodes,\n                                 on='episode_id',\n                                 how='left')",
    " Show first rows of the characters DataFrame\ndf_characters.head()",
    "Summary statistics of the characters dataset\ndf_characters.head()",
    "Set scripts to lower case\ndf_script['raw_text_lc'] = df_script.raw_text.str.lower()",
    "Enable f-strings in python 3.5, 3.6, and 3.7",
    "Remove punctuation from the script lines and lowercase the text.",
    "CORRECT INCORRECT COLUMNS IN script LINES DATAFRAME",
    "Check DataFrame contents to ensure they're correctly loaded\ndf_script.head()",
    "Check segments of the dataframes to understand their contents\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Show how one line of dialogue is structured\ndf_script.head(1)",
    "Merge dataframes",
    "Look at a statististical summary of the dataframes",
    "Reset index for consistency",
    "Inspect the first few rows of each dataframe to understand their structure and contents.",
    "Check dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Let's take a look at the data to understand its structure and content.",
    " Merge character names and script lines on character_id\ndf = df_script.merge(df_characters, on=\"character_id\", how=\"left\")",
    "Display set-up for pandas dataframe\npd.set_option('display.max_columns', None)",
    "Check the data and its structure before performing any analysis",
    " Display basic informations about the dataframes",
    " We'll start by cleaning the dataset.",
    "let's look at the schema of the data from each of these dataframes",
    "Display the first few records of the characters dataset\ndf_characters.head()",
    "Prepare sklearn vectorier with the correct tensor shape\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer()",
    "Filter for only the Simpsons family members, remove stage directions, and only include the speaking lines",
    " Display the first five rows of the characters dataframe\ndf_characters.head()",
    "Setting up variables needed for pre-processing",
    "def get_info(df: pd.DataFrame, info: str):\n    \"\"\"\n    Prints the shape, the columns names and the first 5 rows of a DataFrame.\n\n    :param df: The DataFrame to get information from.\n    :param info: The name of the DataFrame.\n    \"\"\"\n    print(f'{info} shape:', df.shape, '\\n\\n')\n    print(f'{info} columns:', df.columns, '\\n\\n')\n    print(f'{info}:', df.head(), '\\n\\n')",
    "Display the first lines of the script dataframe\ndf_script.head()",
    "Let's take a quick look at the structure of these tables",
    "Merge dataframes and remove rows in which there are at least one NaN value",
    "Checking if the data is loaded correctly",
    "Display the first few rows of each dataframe to understand the data",
    "Create an index for each episode\ndf_episodes.set_index('id', inplace=True)",
    "Display settings\npd.set_option('display.max_columns', None)",
    "Check the contents of the characters dataset\nprint('Number of characters:', len(df_characters))\ndf_characters.head()",
    "Show some statistics about the datasets\nprint(\"Number of characters:\", len(df_characters))\nprint(\"Number of locations:\", len(df_locations))\nprint(\"Number of script lines:\", len(df_script))\nprint(\"Number of episodes:\", len(df_episodes))",
    "Let us begin by displaying the first few lines of each data frame.",
    " function to get the script lines for a certain episode",
    "Setting the 'character_id' column in 'episode' dataframe to match 'id' in 'character' dataframe.",
    " Let's first examine the structure of the data.",
    "Join the datasets on episode_id and create one big dataframe",
    "Check whether data has been split correctly\nprint(df_script.head())\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_episodes.head())",
    "to check if the profane words are in the script out of curiosity.\nprofane_words = set([\"ass\", \"asshole\", \"bastard\", \"bitch\", \"crap\", \"damn\", \"dick\", \"douche\", \"fag\", \"fuck\"])\nscript_profanity = []\n\nfor i in tqdm(range(len(df_script))):\n    text = df_script.loc[i, 'raw_text']\n    words = set([word.lower().strip() for word in text.split()])\n    profane = bool(words & profane_words)\n    script_profanity.append(profane)\n\ndf_script['profane'] = script_profanity",
    " Show the first few rows of the characters dataframe\ndf_characters.head()",
    "to make this last import work without error\nmatplotlib use the tkinter Agg backend\nmatplotlib.use('Agg')",
    "Filtering the script dataset to only keep the lines spoken by the main characters",
    "Importing the required datasets from csv files into pandas dataframes.",
    "Create lowercase 'raw_text' column in df_script\ndf_script['raw_text'] = df_script['raw_text'].apply(lambda x: x.lower())",
    "We'll also use the following configuration in this notebook:",
    "Disabling non-used pandas warning\npd.options.mode.chained_assignment = None",
    "Get a list of all the regular characters in the show.",
    " Puts everything to lower case\ndf_script_normalized = df_script\ndf_script_normalized['raw_character_text'] = df_script_normalized['raw_character_text'].str.lower()\ndf_script_normalized['raw_location_text'] = df_script_normalized['raw_location_text'].str.lower()\ndf_script_normalized['spoken_words'] = df_script_normalized['spoken_words'].str.lower()",
    "This will display the first 5 rows of each dataframe with their names.",
    "This script uses the `WordCloud` package to visualize the most common words found in the Simpsons script.",
    "Check the first few rows of the characters dataframe\ndf_characters.head()",
    "Combine the script with the character names and locations\ndf_script_ext = (\n    df_script\n    .merge(df_characters.rename(columns={\"id\": \"character_id\"}), on=\"character_id\")\n    .merge(df_locations.rename(columns={\"id\": \"location_id\"}), on=\"location_id\")\n)",
    "Merge script with character & location infos\ndf_script_char = pd.merge(df_script, df_characters, how='inner', left_on=['character_id'], right_on=['id']).rename(columns={'name': 'character_name'}).drop(columns=['id'])\ndf_script_char_loc = pd.merge(df_script_char, df_locations, how='left', left_on=['location_id'], right_on=['id']).rename(columns={'name': 'location_name'}).drop(columns=['id'])",
    "Remove characters that do not have any speaking lines",
    "For this tutorial, we focus on the script data only.",
    "Display records for Simpsons character data\ndf_characters.head()",
    "Quick peek at the character dataset\ndf_characters.head()",
    "Join episodes data to script data\ndf_episodes = df_episodes.rename({'id':'episode_id'}, axis=1)",
    " Rerun the similar code and use the head and tail commands to check the data of each dataframe individually\ndf_characters.head()",
    " Take a look at the first few rows of each table",
    "# Stopwords in the English language\nimport nltk\nnltk.download('stopwords')",
    "Quick overlook of the data",
    " Set index of dataframe to id column\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    " Quick look at the dataset\ndf_script.head()",
    "Character level analysis\n# Let's try to identify who talks the most\n\n# Count characters\ndf_script['character_id'].value_counts().head(10)",
    "Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Explore the dataset\n# Display all the dataframes in a user friendly manner\nprint(\"Characters\")\ndisplay(df_characters.head(5))\nprint(\"Locations\")\ndisplay(df_locations.head(5))\nprint(\"Script\")\ndisplay(df_script.head(5))\nprint(\"Episodes\")\ndisplay(df_episodes.head(5))",
    " Filter only \"spoken_lines\"\ndf_script = df_script[df_script[\"speaking_line\"] == \"true\"].reset_index(inplace=False, drop=True)",
    "Get an overview of the dataset\nprint('>>> DataFrame Characters')\ndisplay(df_characters.head())\nprint('\\n')\nprint('>>> DataFrame Locations')\ndisplay(df_locations.head())\nprint('\\n')\nprint('>>> DataFrame Script')\ndisplay(df_script.head())\nprint('\\n')\nprint('>>> DataFrame Episodes')\ndisplay(df_episodes.head())",
    "Other imports and settings",
    "Visually inspect the characters dataframe\ndf_characters.head()",
    "Check the content of these datasets",
    "Dropping rows with missing values on 'raw_character_text' column\ndf_script.dropna(subset=['raw_character_text'], inplace=True)",
    "Create a single dataframe that contains all the information we need.",
    "Inspecting the data",
    "Set max display rows and increase display width\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_colwidth', 400)",
    " Display the top 5 rows of the script dataframe\ndf_script.head()",
    "Display the first few rows of the dataframe\ndf_script.head()",
    "Inspect the dataframes to understand the structure and content of the data.",
    "Check the first 5 rows of the characters dataframe.\ndf_characters.head()",
    "Filter leading and trailing white spaces from character and location names\ndf_characters['character'] = df_characters['character'].str.strip()\ndf_locations['raw_location_text'] = df_locations['raw_location_text'].str.strip()",
    "Preview datasets structure\nprint('Characters')\nprint(\"shape:\", df_characters.shape)\nprint(df_characters.head())\nprint('---------------------------------------')\n\nprint('Locations')\nprint(\"shape:\", df_locations.shape)\nprint(df_locations.head())\nprint('---------------------------------------')\n\nprint('Episodes')\nprint(\"shape:\", df_episodes.shape)\nprint(df_episodes.head())\nprint('---------------------------------------')\n\nprint('Script lines')\nprint(\"shape:\", df_script.shape)\nprint(df_script.head())",
    "Let's see what's inside each data table.",
    " Each dataset contains:",
    "Explore the structure of the datasets\ndf_characters.head()",
    "# Time idx's\ntime_since_release = pd.to_datetime(df_episodes.timestamp, unit='s') - pd.to_datetime(df_episodes.timestamp, unit='s').min()\nyears_since_release = time_since_release.dt.days / 365.25",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "Let's take a look at the structure of these datasets.",
    "Make sure that the csv files are in a folder named data",
    "Merge the datasets to get all the information in a single dataframe",
    " Print dataframe shapes\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
    " Merge script and episodes\ndf_script_episodes = pd.merge(df_script, df_episodes, how='left', on='episode_id')\n\n# Clean\ndf_script_episodes_clean = df_script_episodes[\n    (df_script_episodes.raw_location_text != '')\n    & (df_script_episodes.raw_character_text != '')\n    & (df_script_episodes.spoken_words != '')\n].copy()",
    "check the resulting DataFrames\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Print dimensions of DataFrames\nprint('Characters:\\t', df_characters.shape)\nprint('Locations:\\t', df_locations.shape)\nprint('Script:\\t\\t', df_script.shape)\nprint('Episodes:\\t', df_episodes.shape)",
    "Let's first take a look at the data.",
    "Check the number of characters and locations\nprint(\"Number of characters:\", df_characters.shape[0])\nprint(\"Number of locations:\", df_locations.shape[0])",
    " Display the first few rows of the table to understand its structure\ndf_script.head()",
    "Setting up Spacy",
    "Check the script data",
    "Data Overview\ndf_characters.head(3)",
    " Show the first few rows of the characters dataframe\ndf_characters.head()",
    "Reloading Franky's functions correctly.\nimport sys\nsys.path.append('..')\n\nfrom nlpFunctions import *",
    "Check data samples\nprint(\"Characters:\")\ndisplay(df_characters.sample(5))\n\nprint(\"Locations:\")\ndisplay(df_locations.sample(5))\n\nprint(\"Script lines:\")\ndisplay(df_script.sample(5))\n\nprint(\"Episodes:\")\ndisplay(df_episodes.sample(5))",
    "Quick display of the character dataframe\ndf_characters.head()",
    "Set NaN values to empty strings in character_name, raw_location_text, and spoken_words.\ndf_script['character_name'] = df_script['character_name'].fillna('')\ndf_script['raw_location_text'] = df_script['raw_location_text'].fillna('')\ndf_script['spoken_words'] = df_script['spoken_words'].fillna('')",
    "# Text preprocessing\nnlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n\ndef preprocess_text(text):\n    # Parsing with Spacy\n    doc = nlp(text.lower())",
    "Set some display options for better readability of DataFrames in Jupyter notebooks\npd.set_option('display.max_columns', 60)",
    " Look at several random rows in the characters DataFrame\nprint(df_characters.sample(5))",
    "Visualization of the class distribution\nplt.figure(figsize=(12,5))\nax = df_script['raw_character_text'].value_counts().plot(kind='bar',\n                                    color=list(plt.rcParams['axes.prop_cycle'].by_key()['color']),\n                                    title='Distribution of the character speaking')\n\nax.set_xlabel(\"Character name\")\nax.set_ylabel(\"Frequency\")\nplt.show()",
    "\n# Display the first few rows of the character dataframe\ndf_characters.head()",
    "Uncomment this line to see the column names\n# df_script.columns",
    "Download 'en_core_web_md' before starting\nspacy.cli.download(\"en_core_web_md\")",
    "Remove speech lines that do not contain any actual text in them.\ndf_script = df_script[df_script.raw_text.str.replace(' ', '') != '']\ndf_script = df_script[df_script.raw_text.str.replace(' ', '') != '...']",
    "View the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Format date\ndf_episodes.is_airing = pd.to_datetime(df_episodes.is_airing, errors='coerce')\ndf_episodes.production_code = pd.to_numeric(df_episodes.production_code, errors='coerce')",
    "Check the imported dataframes\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"Locations\")\nprint(df_locations.head())\nprint(\"Script\")\nprint(df_script.head())\nprint(\"Episodes\")\nprint(df_episodes.head())",
    "Only keep dialog\ndf_script = df_script[df_script['speaking_line'] == True]\n\ndf_script.head()",
    "Familiarize ourselves with one of the dataset.",
    "Display the first 5 rows of each dataframe\ndfs = [df_characters, df_locations, df_script, df_episodes]\nfor df in dfs:\n    display(df.head())",
    "Inspect the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Exploring the data",
    " Look at the dataframes to understand their structures\ndf_characters.head()",
    "Merge characters, locations and script together\ndf_script = df_script.merge(df_characters, how='left', on='character_id')\ndf_script = df_script.merge(df_locations, how='left', on='location_id')",
    "Explore the first few rows of each dataframe to understand the data.",
    " Visualize some of the data\ndf_characters.head()",
    "pd.set_option(\"display.max_columns\", None)",
    "We'll begin by examining the first few rows of each dataframe using the `head()` function.",
    "Load spaCy model\nnlp = spacy.load(\"en_core_web_sm\")",
    " View the first rows of the characters dataframe\ndf_characters.head()",
    "Basic overview of datasets",
    "Preview the characters dataframe\ndf_characters.head()",
    " Show the first 3 rows of all datasets\ndisplay(df_characters.head(3))\ndisplay(df_locations.head(3))\ndisplay(df_script.head(3))\ndisplay(df_episodes.head(3))",
    "Inspect dataframe\ndf_script.head()",
    "# Connect to local PostgreSQL database\nfrom sqlalchemy import create_engine\nengine = create_engine('postgresql://localhost/simpsons')\nconn = engine.connect()",
    "Set options for pandas\npd.set_option('display.max_columns', None)",
    "Visualizao do tamanho dos dataframes\nprint(\"df_characters.shape\", df_characters.shape)\nprint(\"df_locations.shape\", df_locations.shape)\nprint(\"df_script.shape\", df_script.shape)\nprint(\"df_episodes.shape\", df_episodes.shape)",
    "Print something in a random cell",
    "df_script.info()",
    "Seeing that the function was removed, I can only assume it was some form of data exploration or manipulation. If you have a specific function in mind, feel free to ask for its inclusion.",
    "Filter out bad data\ndf_script = df_script[\n    (df_script.speaking_line == True) & \n    (df_script.character_id != 2) & \n    (df_script.character_id != 1)\n]",
    "# Create a column with the name of the episode based on the id\ndf_script['name_of_episode'] = df_script['episode_id'].apply(lambda x: df_episodes[df_episodes['id'] == x].iloc[0]['title'])",
    "Show matplotlib plots\nmatplotlib.rcParams['figure.figsize'] = (12, 12)",
    "Check if these work correctly",
    " Display the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Check that the script dataframe has the correct colums    dataframe.",
    "We'll merge the two datasets to get the episode for each script line.",
    "Filter out transcriptions that doesn't have the characters' name.",
    "Visualize number of lines per season",
    "Pandas option for column width\npd.set_option('display.max_colwidth', -1)",
    " Add a setting to allow pandas to display the right number of columns\npd.set_option('display.max_columns', 8)",
    "Format script data\ndf_script = df_script[df_script['episode_id'] != 'special']\ndf_script['raw_character_text'] = df_script['raw_character_text'].astype(str)\ndf_script['spoken_words'] = df_script['spoken_words'].astype(str)\ndf_script = df_script.dropna(subset=['raw_character_text'])\ndf_script = df_script.dropna(subset=['spoken_words'])",
    "Auxiliary functions",
    "Preview the first 5 lines of the episodes DataFrame\ndf_episodes.head()",
    "Checking out the first 5 characters dataframe",
    "we want to reset the index of the returned DataFrame",
    "Let's take a look at the first couple of rows in each dataframe to understand the structure and content.",
    "Ensure some required columns have the appropriate types",
    "First, read the provided CSV files into pandas DataFrames.",
    "Display the first few records of each dataframe to understand the data",
    "Check the available data columns\nprint(df_script.columns)",
    "Visualization Functions",
    "Building the graph of the characters relationships.",
    "View first few rows of the Simpsons script DataFrame\ndf_script.head()",
    "Check the first few rows of each dataframe in the dataset\nprint(\"Character dataset\")\nprint(df_characters.head())\nprint(\"\")\nprint(\"Locations dataset\")\nprint(df_locations.head())\nprint(\"\")\nprint(\"Script lines dataset\")\nprint(df_script.head())\nprint(\"\")\nprint(\"Episodes dataset\")\nprint(df_episodes.head())",
    "Reduce the size of the dataset for the purpose of this lecture\ndf_script = df_script[df_script['episode_id'] < 150]",
    "Set visualization style\nmatplotlib.style.use('ggplot')",
    " Create a cast dict\ncast_dict = {}\nfor index, character in df_characters.iterrows():\n    cast_dict[character['id']] = character['name']\n\n# Create a location dict\nlocation_dict = {}\nfor index, location in df_locations.iterrows():\n    location_dict[location['id']] = location['name']",
    "Ensure script line data types are correct\ndf_script['character_id'] = df_script['character_id'].astype('Int64')\ndf_script['location_id'] = df_script['location_id'].astype('Int64')\ndf_script['raw_text'] = df_script['raw_text'].astype(str)",
    "Inspect the first few rows of the characters dataframe\nprint(df_characters.head())",
    "Check the types of the loaded dataframes",
    "Create a new directory called \"visualizations\" to store the visualizations we will create",
    "A quick look at the characters data\ndf_characters.head()",
    "Display the dataframes for inspection\ndf_characters.head()",
    "Enable validation as one validation raised unstable results\npd.options.mode.chained_assignment = None",
    "Quick overview of the characters dataset\ndf_characters.head()",
    "Inspect the content of the dataframes",
    "Create the NLP object and add vectors for the entity linking model\nnlp = spacy.load('en_core_web_sm')\nlinker = nlp.get_pipe('entity_linker')\nfor i, row in df_characters.iterrows():\n    linker.add_Entity(entity=row['raw_name'], freq=0, entity_vector=nlp(row['raw_name']).vector)\nfor i, row in df_locations.iterrows():\n    linker.add_Entity(entity=row['raw_location'], freq=0, entity_vector=nlp(row['raw_location']).vector)",
    "Set plot style\nplt.style.use('fivethirtyeight')",
    "TODO: Add content here",
    "# Let's take a look at the script data\ndf_script.head()",
    "# Set seed for reproducibility\nnp.random.seed(1)",
    "Filtering for just the title and ID of each episode.",
    "# Manually add matplot lib to available styles\nplt.style.use('ggplot')",
    "Checking the top 5 rows of the characters dataframe.",
    "Inspect the contents of the characters dataframe for any obvious issues\ndf_characters.head()",
    "Join the datasets on the numeric column.",
    "Explore the datasets to understand their structure and the information they contain.",
    "Inspecting the first few rows of each DataFrame",
    "Drop the index from the DataFrames\ndf_characters.reset_index(inplace=True, drop=True)\ndf_locations.reset_index(inplace=True, drop=True)\ndf_script.reset_index(inplace=True, drop=True)\ndf_episodes.reset_index(inplace=True, drop=True)",
    " Checking dataframe shapes",
    "limit the number of lines being displayed\npd.options.display.max_rows = 10",
    "Potential dataframe for results then and there.",
    "Setting to display all columns in Jupyter\npd.set_option('display.max_columns', None)",
    "Combining both the script data with character metadata and episode metadata.",
    "Create a list for each episode containing all its lines\nepisode_2_lines = []\nfor episode in df_episodes[df_episodes['id']==3]['episode_id']:\n    episode_lines = df_script[df_script['episode_id']==episode]\n    episode_2_lines.append(' '.join(episode_lines['raw_text']))",
    "Detect which episode each line of the script is from\nepisodes_list = []\n\nfor index, row in tqdm(df_script.iterrows()):\n    mask = df_episodes['id'] == row['episode_id']\n    episode = df_episodes[mask]\n    episode = episode.to_dict(orient='records')[0]\n    episodes_list.append(episode)",
    "The last line of code imports the data from CSV files into pandas dataframes.",
    "Check the content of each DataFrame",
    "This line of code reads various CSV files containing Simpsons data and stores them in separate dataframes for characters, locations, script lines, and episodes.",
    "Let's take a look at the first few rows of each dataset.",
    "Merge characters information\ndf_episodes = pd.merge(df_episodes, df_characters, left_on='character_id', right_on='id', how='left', suffixes=('', '_character'))\ndf_episodes.rename(columns={'name': 'character_name', 'normalized_name': 'character_normalized_name'}, inplace=True)",
    " Check for any null values and drop if any\ndf_characters = df_characters.dropna()\ndf_locations = df_locations.dropna()\ndf_script = df_script.dropna()\ndf_episodes = df_episodes.dropna()",
    " Optionally, ensure compatibility with spaCy by disabling components that we don't need\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])",
    "Kernel -> Restart & Run All to refresh DataFrame shapes\n# New episode shapes\nprint(f\"df_episodes shape: {df_episodes.shape}\")\n\n# New script shapes\nprint(f\"df_script shape: {df_script.shape}\")",
    " Let's start by taking a look at the first few rows of each of these DataFrames.",
    "Display the first 5 rows of the characters DataFrame\ndf_characters.head()",
    "Checking for missing values in the datasets\nprint(df_characters.isnull().sum())\nprint(df_locations.isnull().sum())\nprint(df_script.isnull().sum())\nprint(df_episodes.isnull().sum())",
    "Filter out the non-dialogue lines",
    " Check the loaded data\nprint(\"\\n\\n============ Checking Characters data head ============\\n\\n\")\nprint(df_characters.head(5))\n\nprint(\"\\n\\n============ Checking Locations data head ============\\n\\n\")\nprint(df_locations.head(5))\n\nprint(\"\\n\\n============ Checking Script data head ============\\n\\n\")\nprint(df_script.head(5))\n\nprint(\"\\n\\n============ Checking Episodes data head ============\\n\\n\")\nprint(df_episodes.head(5))",
    "Print basic info on each dataframe\nprint(\"Characters\")\nprint(df_characters.info())\nprint(\"Locations\")\nprint(df_locations.info())\nprint(\"Script Lines\")\nprint(df_script.info())\nprint(\"Episodes\")\nprint(df_episodes.info())",
    "Display the first few rows of the dataframe\ndf_script.head()",
    "Clean the texts of NaN values\ndf_script.cleaned_text = df_script.cleaned_text.fillna('')",
    "Check if the data files have been read correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Hide warnings (this is usually a bad idea, but just for this exercise)",
    "Display the first few rows of the script DataFrame\ndf_script.head()",
    " Show first rows of the dataframe 'df_characters'\ndf_characters.head()",
    "Display first few rows of each dataframe to understand the data",
    "Check the first few rows of each table",
    "Concatenate the location, character and speaking turn from the script to the episodes.",
    " Display the first few lines of each dataset to understand the data",
    " Show the main datasets to understand the structure and content",
    "Let's check the content of the dataset",
    "Create a directory to save the output figures\nif not os.path.exists('output'):\n    os.makedirs('output')",
    "Enable f-strings in Python 3.6 and 3.7\nfrom __future__ import annotations",
    "Setting up Spacy models",
    "It is a good practice to reset the index of DataFrames after reading them from CSV files, as it will avoid potential issues with index misalignment.",
    "counts number of lines each character has\nlines_per_character = df_script\n    .groupby('raw_character_text')['id']\n    .count()",
    "Set seed for reproducibility\nnp.random.seed(0)",
    "Inspect the first few rows of the script data\ndf_script.head()",
    " Display the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "define MAIN_DIR\nMAIN_DIR = 'data'",
    "Some settings for all the dataframe display\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    " Check the loaded data\ndf_characters.head()",
    "Function to display and store word cloud",
    "Let's start by taking a look at the structure of each dataframe.",
    " Merge scripts with corresponding episode data\ndf = df_script.join(df_episodes, on='episode_id', rsuffix='_ep')\ndf = df.join(df_characters, on='character_id', rsuffix='_ch')\ndf = df.join(df_locations, on='location_id', rsuffix='_loc')\n\n# Preview the dataset\ndf.head()",
    "Merge the script with the relevant locations and characters\ndf_script_loc_char = df_script.merge(df_locations[['location_id', 'name', 'normalized_name']], on='location_id', how='left')\\\n.merge(df_characters[['character_id', 'name', 'normalized_name']], on='character_id', how='left')",
    "Let us take a look at each dataframe to better understand the kind of data we have.",
    "Create a column for the episode's season and convert the date to a datetime type\ndf_episodes['season'] = df_episodes['production_code'].str.slice(2, 4)\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], infer_datetime_format=True)",
    "Merge the episodes and the script dataframes on the id column\ndf_data = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id', suffixes=('', '_episode'))",
    "Display the first few rows of the dataframe\ndf_script.head()",
    "join lines to attach the episode's title to the episode number",
    "Inspecting datasets",
    "Optional: View the columns and first few rows of one of the dataframes\nprint(df_script.columns)\ndf_script.head()",
    "Visualisation of the data",
    "List the first 5 records of the specific data set",
    "Check for a correct import by visualizing the head of the characters dataframe\ndf_characters.head()",
    "Merge data frames",
    "Exploring the obtained datasets",
    "Check if the script contains lines of dialog_physically painful",
    "Consider loading only a subset of the data for performance reasons if the dataset is large.",
    "Optional exploration - SysCall\nos.system(\"/bin/ls -lh\")",
    "Downloading the spacy model for English",
    "Let's start by taking a quick look at the structure of our datasets.",
    " Preview datasets\ndf_characters.head()",
    " La structure des donnes est  prsent charge.",
    " Check the first few lines of the characters dataframe\ndf_characters.head()",
    "Creating a good memory management function in order to reduce the memory usage of the dataset.",
    "1. Load Data and get an overview",
    "fromutils import *",
    "df_script.head()",
    "Fill in the NaN values in the raw script data with empty strings to avoid issues with the text processing later on\ndf_script = df_script.fillna('')",
    "Display dataframe info\ndf_characters.info()",
    "Limit the number of script lines for now\n# df_script = df_script[:50000]",
    "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Merge the datasets to include all relevant information in one dataframe.",
    "Take a look at the first couple of lines in each of the dataframe to see what kind of data we'll be working with\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Calculating number of missing values in each DataFrame\nnull_characters = df_characters.isnull().sum().sum()\nnull_locations = df_locations.isnull().sum().sum()\nnull_episodes = df_episodes.isnull().sum().sum()\nnull_script = df_script.isnull().sum().sum()",
    "Discard unnecessary columns from df_episodes\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]",
    "Keep short only the ones that are useful to avoid cluttering when making predictions from the script\nshort_cols = ['id', 'character_id', 'location_id', 'episode_id', 'raw_text']\n\n# Keep only the useful columns\ndf_script = df_script[short_cols]\n\n# Add episode related data\ndf_script = df_script.merge(df_episodes,\n                            how='left',\n                            on='episode_id')",
    "Visualizing the script data",
    "Explore the datasets\ndf_episodes.head()",
    "Data overview",
    "display complete dataframe for a quick look\ndf_script",
    "Display the dimensions of each dataframe\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script lines:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
    "Preview the dataframe with the script\nprint(df_script.head())",
    " Look at the shape of the dataframes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Check the info of df_characters\ndf_characters.info()",
    " Set max display of rows and columns for pandas dataframes\npd.set_option('display.max_rows', 10)\npd.set_option('display.max_columns', 10)",
    " Let's take a quick look at the Simpsons script data.",
    "View the first 5 records of characters dataset\ndf_characters.head()",
    "View the first 5 lines of the characters dataframe\ndf_characters.head()",
    "# Outputs first n rows of a dataframe\ndef firstn(df, n=5):\n    return df.head(n)",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "Discover the script dataset:",
    " Let's display some basic information about the dataframes.",
    "Look at the few first rows of the first dataframe\ndf_characters.head()",
    "anya all the tables to dictionaries",
    "Inspecting the dataframe shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Check that the dataframes were loaded successfully\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check the shape of all datasets\nprint(f'Shape of df_characters: {df_characters.shape}')\nprint(f'Shape of df_locations: {df_locations.shape}')\nprint(f'Shape of df_script: {df_script.shape}')\nprint(f'Shape of df_episodes: {df_episodes.shape}')",
    "Data overview",
    "Display head of the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "For more details, check the documentation folder within the project folder.",
    "Merge scripts with characters and locations\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('','_char'), validate=\"many_to_one\")\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id', suffixes=('','_loc'), validate=\"many_to_one\")\n\n# Shorten the character and location dataframes for merging\ndf_characters = df_characters[['id', 'name']]\ndf_locations = df_locations[['id', 'name']]\n\n# Merge into one dataframe\n# df_episodes[df_episodes.id==30] # Example of how to extract a specific id\ndf = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('','_ep'), validate=\"many_to_one\")",
    "Inspect first rows of characters dataframe\ndf_characters.head()",
    " We set word clouds parameters\nmatplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\nmatplotlib.style.use('ggplot')",
    "Check that the datasets have been loaded correctly\ndf_characters.head()",
    "Define the path of the data directory",
    " Display the first 5 entries of the 'simpsons_characters.csv' file\ndf_characters.head()",
    " Display the first few rows of the characters dataset\ndf_characters.head()",
    "Counting lines of each script to measure which characters play an important role in The Simpsons series and plot a word cloud",
    "Some more data preprocessing: remove rows with missing data and keep only the script lines from the first 10 seasons",
    "Preview the 'simpsons_characters.csv' dataset\ndf_characters.head()",
    "Set random seed for reproducibility\nnp.random.seed(13)",
    "Merge characters in script\ndf_script_characters = df_script.merge(df_characters, how='left', on='id', suffixes=('_script', '_character'))\n\n# Merge locations in script\ndf_script_locations = df_script_characters.merge(df_locations, how='left', left_on='raw_location_text', right_on='raw_location_text', suffixes=('', '_location'))",
    " Combine df_script with df_episodes and filter out non-Simpsons lines",
    " Optional: set seed for reproducibility\nseed = 42",
    " Display the first few rows of the dataframe\ndf_characters.head()",
    "Displaying all columns in the dataframe\npd.set_option('display.max_columns', None)",
    "also drop and reorder the columns in the script dataframe\ndf_script = df_script.drop(['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms'], axis=1)\ndf_script = df_script[['episode_id', 'character_id', 'location_id', 'spoken_words']]",
    "function to load large data files using dask (for parallelism)\ndef load_large_csv(file):\n    return dd.read_csv(file, blocksize=int(1e6))",
    " Replace original_na values with Python's NaN valuemarker\ndf_characters.replace([r'\\N'], np.nan, inplace=True)\ndf_locations.replace([r'\\N'], np.nan, inplace=True)\ndf_script.replace([r'\\N'], np.nan, inplace=True)\ndf_episodes.replace([r'\\N'], np.nan, inplace=True)",
    "Display first 5 records of all the dataframes",
    "If you have a different file path, please modify it accordingly.",
    "This code snippet imports necessary libraries and reads in data from CSV files using pandas. The data includes information about characters, locations, script lines, and episodes from The Simpsons TV show.",
    "Setting with copy error\npd.options.mode.chained_assignment = None  # default='warn'",
    " Visual inspection of the first 5 rows of the `df_characters` dataframe\ndf_characters.head()",
    "Inspect the characters data\ndf_characters.head()",
    " Display the first 5 rows of each DataFrame to verify they were loaded correctly\ndisplay(df_characters.head())\ndisplay(df_locations.head())",
    "Create smaller subsets for exploration and model building",
    "Check the first few rows of the episodes dataframe",
    "Let's take a quick look at the data to understand its structure.",
    "Clean df_characters\ndf_characters = df_characters.dropna()",
    " define a fixed value variable.",
    "Check the head to ensure that everything is working fine\ndf_script.head()",
    " Enforce typing for `df_script` for an `integer` index",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    " Display the first few rows of each dataframe to understand their structure and contents\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Create a dictionary that maps character names to their gender\nchar_gender_dict = df_characters.groupby('name').first().gender.to_dict()",
    "Show the first few lines of the table to get an idea of the data present.",
    "Exploratory data analysis and data preprocessing",
    " Optional (if you want visible changes in your word cloud)\nmatplotlib.rcParams['figure.figsize'] = [10, 8]",
    "ppend all the data into one single data frame\ndf_final = pd.merge(df_script, df_characters, how='left', on=['character_id'])\ndf_final = pd.merge(df_final, df_locations, how='left', on=['location_id'])\ndf_final = pd.merge(df_final, df_episodes, how='left', on=['episode_id'])",
    " Now that we have our dataframes loaded, let's take a look at the first few rows of each dataframe to familiarize ourselves with the data.",
    "Display the first few rows of the script dataframe\ndf_script.head()",
    "Create a spacy model for the English language and set a variable to files directory",
    "Drop any NaN values from the 'raw_text' column, as they don't provide any valuable information for our analysis\ndf_script = df_script.dropna(subset=['raw_text'])",
    "Check for null values in the dataframes\ndf_characters.isnull().sum()",
    "NOTE: The reset_index(inplace=False, drop=True) is necessary to prevent the automatic creation of a new index column.",
    "Clean the script data\ndf_script = df_script[pd.to_numeric(df_script['id'], errors='coerce').notnull()]\ndf_script['id'] = df_script['id'].astype(int)",
    "pd.set_option('display.max_columns', None)",
    "Make a copy of each dataframe",
    "Language-specific imports and variables\nimport en_core_web_sm\nnlp = en_core_web_sm.load()\n\n# Utility function\ndef flatten(l):\n    return [item for sublist in l for item in sublist]",
    "Fill \\'NA\\' values with empty strings\ndf_script = df_script.fillna('')",
    " Create a new column for episode titles in df_script\ndf_script['episode_title'] = df_script['episode_id'].map(df_episodes.set_index('id')['title'])",
    "Setting up the basic configuration for the spaCy library",
    " Show number of rows\nprint(f\"Number of characters: {len(df_characters)}\")\nprint(f\"Number of locations: {len(df_locations)}\")\nprint(f\"Number of script lines: {len(df_script)}\")\nprint(f\"Number of episodes: {len(df_episodes)}\")",
    "Display the basic information about datasets\nprint(\"\\n- Simpsons Episodes - \")\nprint(df_episodes.info())\nprint(\"\\n- Simpsons Characters - \")\nprint(df_characters.info())\nprint(\"\\n- Simpsons Locations - \")\nprint(df_locations.info())\nprint(\"\\n- Simpsons Scripts - \")\nprint(df_script.info())",
    "Leave the rest of the code as is",
    "Check what the dataframes look like",
    "Merge the script with the characters and locations\ndf_script_characters = pd.merge(df_script, df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_character')).drop(columns='id_character')\ndf_script_characters_locations = pd.merge(df_script_characters, df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_location')).drop(columns='id_location')",
    "Displays the first 5 entries for each table\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Set seed for reproducibility",
    "Let's take a look at the data first.",
    "Display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " preprocessing the script\ndf_script = df_script[(df_script['speaking_line'] == True)]",
    "Explore the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Filter the dataset to only consider speaking lines",
    "We'll filter only the lines from Lisa.",
    "Let's explore the data to see what it looks like.",
    "Check the contents of the Characters dataframe\ndf_characters.head()",
    "Set up the spaCy model and the function to properly clean sentences.",
    "Merge data\ndf_characters_script = df_script.merge(df_characters, how='left')\ndf_script_merged = df_characters_script.merge(df_episodes, how='left')",
    "Merge all into one\ndf_simpsons = (df_script\n                .merge(df_episodes, on='episode_id', how='inner')\n                .merge(df_characters, on='character_id', how='inner')\n                .merge(df_locations, on='location_id', how='inner'))",
    "Ensure the corpus is loaded.",
    "Merge datasets in order to get the character and location names for each line in the script\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]\ndf_script = df_script.merge(df_episodes, how='inner', left_on='episode_id', right_on='id')\n\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'title', 'original_air_date']]\ndf_script = df_script.rename(columns={'episode_id': 'episode_id', 'number': 'episode_number', 'raw_text': 'text',\n                                     'title': 'episode_title', 'original_air_date': 'air_date'})\n\n# Remove lines for which the character isn't specified\ndf_script = df_script.loc[df_script.character_id.notnull()]\n\ndf_script = df_script.merge(df_characters, how='inner', left_on='character_id', right_on='id')\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id')\n\ndf_script = df_script[['episode_id', 'episode_number', 'episode_title', 'text', 'air_date', 'name',\n                       'normalized_name', 'alignment_id', 'alignment', 'image_url', 'id_y',\n                       'name_y']]",
    "Displaying the script lines dataset\ndf_script.head()",
    " Display the first few rows of the dataset\ndf_script.head()",
    "Display the first records of characters dataframe to understand what we have in the dataframe",
    " Visualize episodes per season\ndf_episodes.groupby('season')['id'].count().plot(kind='bar', color='skyblue', figsize=(15, 7))",
    " remove index from csv imports",
    "Display the first 5 rows of each dataframe to ensure everything loaded correctly.",
    "Optional - Preview tables\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Ensure identical index for all the dataframes",
    "We can now have a look at the characters and locations dataframes.",
    "Preview the data to quickly gather the main information and have a general view of the structure and content.",
    "Print shapes of dataframes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
    " Merge the dataset based on the character_id, episode_id from the scripts data.",
    "Print the schema and first few rows of each table",
    "Text vectorization of the series names",
    "Select the main characters and the locations, which are those that have more than 500 lines spoken.",
    "First, let's take a look at the data to understand its structure and the type of information it contains.",
    "Merge characters, locations, script lines, and episodes data\ndf_episodes['id'] = df_episodes['id'].astype(str)  # Change type to string to merge\ndf_script['episode_id'] = df_script['episode_id'].astype(str)  # Change type to string to merge\ndf = df_script.merge(df_episodes, left_on='episode_id', right_on='id')  # Merge script lines and episodes\ndf['character_id'] = df['character_id'].astype(str)  # Change type to string to merge\ndf = df.merge(df_characters, left_on='character_id', right_on='id')  # Merge script lines and characters\ndf['location_id'] = df['location_id'].astype(str)  # Change type to string to merge\ndf = df.merge(df_locations, left_on='location_id', right_on='id')  # Merge script lines and locations",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Initial overview of the data\nprint(\"Characters dimension: {}\".format(df_characters.shape))\nprint(\"Locations dimension: {}\".format(df_locations.shape))\nprint(\"Script dimension: {}\".format(df_script.shape))\nprint(\"Episodes dimension: {}\".format(df_episodes.shape))",
    " Add index to script dataframe\ndf_script.reset_index(inplace=False, drop=True)",
    " Show first rows of \"script\" data\ndf_script.head()",
    "# Convert raw text into word frequency representation\ndef word_frequency(text):\n    words = [word.text.lower() for word in nlp(text) if word.is_alpha and not word.is_stop]\n    word_freq = Counter(words)\n    return word_freq",
    "Change episodes to its datetime column\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])",
    "Filter df_characters, df_locations and df_script to the main characters and locations",
    "import warnings",
    "Display all the columns of the dataframe\npd.set_option('display.max_columns', None)",
    "Preview the dataset\ndf_script.head()",
    " Check data\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script lines:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "Download spacy's transformer model \"en_core_web_trf\" to be able to tokenize words.",
    "Simplify episode titles\ndef clean_title(title):\n    return (\n        title.lower()\n        .replace(\"the simpsons\", \"\")\n        .replace(\": part \", \" \")\n        .replace(\":\", \" \")\n        .replace(\"(\", \"\")\n        .replace(\")\", \"\")\n        .strip()\n    )\n\ndf_episodes['clean_title'] = df_episodes['title'].apply(clean_title)",
    "Quick look at the data and its structure",
    "Check integrity of the datasets\nprint(\"Checking Characters DataFrame...\")\nprint(df_characters.isnull().sum())",
    " Display the first few rows of each dataframe to get an idea of what the data looks like\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Create identifiers to set index from 1",
    "\nprint(df_characters.head())",
    "Display multiple dataframe side-by-side\nfrom IPython.display import display_html\ndef display_side_by_side(*args):\n    html_str=''\n    for df in args:\n        html_str+=df.to_html()\n    display_html(html_str.replace('table','table style=\"display:inline\"'), raw=True)",
    "Let's start by examining the contents of each dataset.",
    "Display settings\npd.set_option('display.max_columns', None)  # Unlimited max columns\npd.set_option('display.max_colwidth', None)  # Unlimited max column width",
    "Set pandas display options for easier exploration\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)",
    "Merge the datasets to have all the information on the script lines",
    "Inspect the first few records of the characters dataframe\ndf_characters.head()",
    "Filtered script lines for performing text analysis",
    "Examine the data\ndf_script.head()",
    "Set pandas table display configurations to get a better look at the data\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.max_colwidth', None)",
    "Creating a new column with the number of words\ndf_script['number_of_words'] = df_script['spoken_words'].apply(lambda x: len(x.split()))",
    "Preview the datasets",
    "Data Preprocessing\n# First, let's get an idea of what our data looks like\nprint(f\"Characters Shape: {df_characters.shape}\")\nprint(f\"Locations Shape: {df_locations.shape}\")\nprint(f\"Script Shape: {df_script.shape}\")\nprint(f\"Episodes Shape: {df_episodes.shape}\")",
    "Filter out the bad data points from our data set and keep the examples that are actually usuable.",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "Explore data distributions and format before implementing nlp tools",
    "Display the first few rows of the characters DataFrame\ndf_characters.head()",
    " Display head of script dataframe\ndf_script.head()",
    "df_script.shape",
    "Remove episodes without a location\ndf_script = df_script[df_script['episode_id'].isin(df_locations['episode_id'])]",
    "Merge characters and script tables on character_id\ndf = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')\n\n# Get the main characters' names\nmain_characters = list(df['name'].value_counts().head(10).index)\n\n# Plot function\ndef plot_wordclouds(data, title):\n    # Instantiate wordcloud\n    wc = WordCloud(background_color='white', max_words=100)\n\n    # Generate word cloud\n    wc.generate_from_frequencies(data)\n\n    # Plot\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wc, interpolation='bilinear')\n    plt.axis('off')\n    plt.title(title)",
    "Transform plain text to a bag of words representation for each spring line",
    "Create character's and location's names maps",
    "# Ensure the Episode data is unique on id\ndf_episodes = df_episodes.drop_duplicates(subset=['id'])",
    "Show all the available pandas options",
    "View the script data\ndf_script.head()",
    "Remove weird columns without a name",
    " Set up variables for storing the required data\n# Characters\ncharacters = {}\nfor index, row in df_characters.iterrows():\n    char_id = row['id']\n    name = row['name']\n    characters[char_id] = name",
    "Filter the main characters of the Simpsons series",
    " Remove invalid IDs from script\nvalid_ids = set(df_episodes['id'].unique())\n\ndf_script = df_script[df_script['episode_id'].isin(valid_ids)].reset_index(inplace=False, drop=True)",
    "Select main characters identified by the community\nmain_characters = [\"bart\", \"homer\", \"marge\", \"lisa\", \"maggie\", \"krusty\", \"burns\", \"milhouse\", \"chief\", \"skinner\", \"n edna\", \"bob\", \"apu\", \"moe\", \"ned\"]",
    " Show first rows\ndf_characters.head()",
    "Merge the data into a single dataframe\ndf = (\n    df_script\n    .merge(df_episodes, on='episode_id', how='left')\n    .merge(df_characters, on='character_id', how='left')\n    .merge(df_locations, on='location_id', how='left')\n)",
    "Combine the script data with the character and location data per script line.\ndf_script = (\n    df_script\n    .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=(False, False))\n    .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=(False, False))\n)",
    " Display heads of all files to understand the data",
    "Functions",
    "Display the number of rows and columns for each dataframe\nfor name, df in zip(['Characters', 'Locations', 'Script', 'Episodes'], \n                    [df_characters, df_locations, df_script, df_episodes]):\n    print(f\"{name} has {df.shape[0]} rows and {df.shape[1]} columns\")",
    "Get the TV script of the episode with the most number of lines.",
    "View dimensions of dataframes\nprint('Characters :', df_characters.shape)\nprint('Locations :', df_locations.shape)\nprint('Lines :', df_script.shape)\nprint('Episodes :', df_episodes.shape)",
    "To reduce memory usage, we should convert some columns to categoricals.",
    "Remove the rows with no locations\ndf_script_dropped = df_script.dropna(subset=['raw_location_text'])\n\n# Split the data - to remove this step, replace dfs with df_script\ndfs = {\n    'simpsons_characters': df_characters,\n    'simpsons_locations': df_locations,\n    'simpsons_script_lines': df_script_dropped,\n    'simpsons_episodes': df_episodes\n}",
    "General settings\nplt.style.use('fivethirtyeight')\nnlp = spacy.load('en_core_web_sm')",
    "Checking the script dataframe",
    "Explore the first few rows of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Display the first few records of the script data to understand its structure\ndf_script.head()",
    "Show the first lines of the characters data\ndf_characters.head()",
    "Create a directory within the data directory\ndirectory = 'data/wordclouds/'\nif not os.path.exists(directory):\n    os.makedirs(directory)",
    "Conversion of the columns that contain json format to actual python objects\nimport json\n\ndf_characters['character_image_url'] = df_characters['character_image_url'].apply(lambda x: json.loads(x))\ndf_script['spoken_words'] = df_script['spoken_words'].apply(lambda x: json.loads(x))",
    "Print first few rows of `df_characters`\ndf_characters.head()",
    "Display the first 5 lines of each dataframe to understand the data better",
    " The next step is to preprocess and explore the data to gain insights.",
    "Ensure you're using the correct data types\ndf_characters.info()\ndf_locations.info()\ndf_script.info()\ndf_episodes.info()",
    " Remove the following dataframes since they are not used in this code snippet.\ndel df_characters, df_locations, df_episodes",
    "Quick overview of the data\nprint(\"DF Characters\")\nprint(df_characters.head())",
    " This is the first model to start early exploration of the dataset.",
    "Check the first 5 records of the characters dataframe\ndf_characters.head()",
    "Select season 2's data\nseason2_episode_ids = df_episodes[df_episodes.season == 2].index\nseason2_script = df_script[df_script['episode_id'].isin(season2_episode_ids)]",
    "Visualizing a word cloud for the script lines",
    "Get data types",
    " What is the structured data in the `simpsons_characters.csv`, `simpsons_locations.csv`, `simpsons_script_lines.csv`, and `simpsons_episodes.csv` files?",
    "The data is now loaded into dataframes, let's take a quick look at the structure of each dataframe.",
    "Load initial versions of datasets and reset index to ensure correct functionality",
    "Check the basic info of the datasets\nprint(\"Characters : \", df_characters.shape)\nprint(\"Locations : \", df_locations.shape)\nprint(\"Script : \", df_script.shape)\nprint(\"Episodes : \", df_episodes.shape)",
    "Set option to display all columns at any time",
    "Create a new column in df_script that corresponds to the length of each utterance.",
    "Check the first few entries in each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Add a 'word_count' column to the df_script dataframe\ndf_script['word_count'] = df_script['raw_text'].apply(lambda x: len(x.split()))",
    "Checking dimensions of each dataframe",
    "Enrich Data: Characters, Locations, and Scripts\n# Sort episodes by id\ndf_episodes = df_episodes.sort_values(by='id').reset_index(drop=True)\n\n# Filter the dataframes\ndf_script_en = df_script[df_script['raw_character_text'].notnull()]\ndf_script_en = df_script_en[df_script_en['raw_location_text'].notnull()]\n\n# Removing duplicates\ndf_script_en = df_script_en.drop_duplicates()\n\n# ensure `episode_id` column is integer\ndf_script_en['episode_id'] = df_script_en['episode_id'].astype(int)\n\n# merging the episode to the script\ndf_script_meta = df_script_en.merge(df_episodes[['id', 'title', 'original_air_date', 'production_code']], left_on='episode_id', right_on='id', how='right')\n\n# remove when `episode_id` is null\ndf_script_meta = df_script_meta[~df_script_meta['episode_id'].isnull()]\ndf_script_meta = df_script_meta.drop(['id', 'number', 'timestamp_in_ms'], axis=1)\ndf_script_meta = df_script_meta.sort_values(by=['episode_id', 'id']).reset_index(drop=True)\n\n# install spacy model\n!python -m spacy download en_core_web_sm",
    "Check the 5 characters in the df_characters dataframe",
    "We do this to avoid retyping these lines every time we make a change to our python scripts.",
    "Display the first few rows of the dataframe \"df_characters\"\ndf_characters.head()",
    "Let's check how the character dataset looks like",
    "Cleaning the data\ndf_script = df_script.dropna(subset=['normalized_text', 'character_id']).reset_index(inplace=False, drop=True)",
    "Check the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Let's start by displaying the first few lines of each dataframe to get a sense of how the data is structured.",
    " Let's take a quick look at the first few rows of each dataframe.",
    "Let's inspect the data.",
    "Display the first few rows of each dataframe to inspect the data.",
    " Inicializa spaCy\nnlp = spacy.load('en')",
    "Don't worry about the lines below, as they're only effecting how the backend works and nothing for you to worry about.\npd.options.display.max_columns = None  # Make sure we can see all of the columns",
    " Look for data with NaNs in the episode data\ndf_script[df_script['episode_id'].isna()]",
    "Select characters gender and distinct genders\ngenders = df_characters[['gender', 'name']].drop_duplicates().dropna()",
    "Show the first 5 rows of each dataset to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "In this section, we will explore the data in the script dataset.",
    "Load the data and display the different DataFrames.",
    " Reset character and location names to lowercase for easier matching\ndf_characters['name'] = df_characters['name'].str.lower()\ndf_locations['name'] = df_locations['name'].str.lower()",
    " Remove rare characters from the data\ncharacter_counts = df_script.raw_character_text.value_counts()\nmask = (character_counts >= 50)\ncharacter_list = character_counts.index[mask].tolist()\ndf_script = df_script[df_script['raw_character_text'].isin(character_list)]",
    "Remove unwanted columns\ndf_script = df_script.drop(columns=['id', 'episode_id'])",
    "Set display options for pandas dataframes to ensure rows and columns are not truncated\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)",
    "Merge all the dataframes with based on the episode id to have a clear dataframe with all the information.",
    "Declare the plot style and color palette",
    "View first few records of characters DataFrame\ndf_characters.head()",
    "Let's see how the data looks like",
    "Display first 5 lines of df_characters\ndf_characters.head(5)",
    " Check the data sample\ndf_script.head()",
    "Merge the dataframes that contain the scripts with the dataframes containing the characters and locations as well as the episodes.",
    "Extracting the names of the main characters from the table's names_eps variable.",
    "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    "The first dataframe (df_characters) holds all the characters and their metadata.",
    "To start off, let's take a look at the first few rows of each dataframe to understand what kind of data we are working with.",
    "pd.set_option('display.max_columns', None)",
    "To harmonize the location names supplementary gathered from the internet, I'll ensure these strings either appear in lower case or are capitalized.",
    " Look at the first few rows of the characters dataframe\ndf_characters.head()",
    "Visualization and styling parameters\ncolors = {\n    'background': '#111111',\n    'text': '#7FDBFF',\n    'data': '#FF851B',\n    'title': '#FF4136'\n}\n\n# Display settings\npd.set_option('display.max_colwidth', 120)",
    "Ensure dataframes work correctly with Jupyter\ntqdm.pandas()",
    "Check the first few lines of the dataframe to understand its structure\ndf_script.head()",
    " Display the first dataframe to understand the structure of the data.",
    "Check the first rows of the characters dataframe\ndf_characters.head()",
    " Add decade to episodes dataframe\ndf_episodes['decade_id'] = np.floor(df_episodes['original_air_year'] / 10) * 10",
    "Print the script from the first episode",
    "Ignore certain warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
    " Set a pre-defined random state for reproducibility",
    "Explicitly load in the required spacy model.\nnlp = spacy.load(\"en_core_web_sm\")",
    "Display the first few records in each dataframe to understand the data",
    "Create a copy of the \"simpsons_script_lines\" dataframe and drop the \"id\" and \"episode_id\" columns\ndf = df_script.copy()\ndf.drop(columns=['id', 'episode_id'], inplace=True)",
    " Defines characters as main characters only",
    "Expanding the script lines to show Episode title and character name instead of their ids.",
    "Set IPython indentation mode to always indent after line breaks\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'",
    "Setting random seed to 42 to determine the topic modeling outcome\nnp.random.seed(42)",
    "Load the data from the CSV files",
    "display general information about the datasets",
    "Show head of characters dataframe\ndf_characters.head()",
    "Inspect dataframes",
    "Check top few rows of the dataframe of simpsons_characters",
    "Display basic information for each DataFrame\nprint(\"Characters DataFrame\")\ndf_characters.info()\nprint(\"Locations DataFrame\")\ndf_locations.info()\nprint(\"Script DataFrame\")\ndf_script.info()\nprint(\"Episodes DataFrame\")\ndf_episodes.info()",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Data Preprocessing",
    "Merge the script lines with episode data\ndf_script['episode_id'] = df_script['episode_id'].astype('int64')\ndf_merged = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id', suffixes=('_script', ''))",
    "#   Changing path to be in the script_files directory to use functions from the .py files\nos.chdir(\"script_files\")",
    "Display the first rows of the characters DataFrame\ndf_characters.head()",
    "check the data\nprint(df_script.head())\n",
    "quick look at the dataframes\nprint(\"Characters: \\n\", df_characters.head())\nprint(\"\\nLocations: \\n\", df_locations.head())\nprint(\"\\nScript: \\n\", df_script.head())\nprint(\"\\nEpisodes: \\n\", df_episodes.head())",
    "Display the first rows of the episodes dataframe\ndf_episodes.head()",
    "We will start by loading the datasets we'll use for the analysis.",
    "Define the string keyword for the characters we want to consider.",
    " Data preprocess\ndf_script = df_script.rename(columns={'id': 'id_script'})\ndf_script = df_script.drop_duplicates(subset='raw_text')",
    "Remove unnecessary columns and fill NaN values with empty strings\ndf_script = df_script[['episode_id', 'id', 'character_id', 'location_id', 'raw_text']]\ndf_script = df_script.fillna('')",
    "Create character roles\nmain_characters = [\n    \"marge_simpsons\", \"homer_simpsons\", \"bart_simpson\",\n    \"lisa_simpson\", \"maggie_simpson\", \"abraham_grampa_simpson\",\n    \"ned_flanders\", \"moe_szyslak\", \"krusty_the_clown\",\n    \"chief_wiggum\", \"charles_montgomery_burns\", \"milhouse_van_houten\",\n    \"seymour_skinner\", \"nelson_muntz\", \"edna_krabappel\",\n    \"lenny_leonard\", \"carl_carlson\", \"waylon_smithers\", \"kent_brockman\"\n]\n\nsupporting_characters = [\n    \"apu_nahasapeemapetilon\", \"comic_book_guy\", \"ralph_wiggum\",\n    \"english\", \"snake_jailbird\", \"kent_brockman\", \"mayor_quimby\",\n    \"barney_gumble\", \"selma_bouvier\", \"patty_bouvier\",\n    \"martin_prince\", \"troy_mcclure\", \"lionel_hutz\", \"groundskeeper_willie\",\n    \"fat_tony\", \"professor_john_frink\", \"dr_julius_hibbert\",\n    \"cletus_spuckler\", \"otto_mann\"\n]\n\n# This role list is not exhaustive\nminor_characters = [\n    \"apu_nahasapeemapetilon\", \"milhouse_van_houten\",\n    \"comic_book_guy\", \"snake_jailbird\", \"troy_mcclure\",\n    \"kent_brockman\", \"martin_prince\", \"ralph_wiggum\",\n    \"mayor_quimby\", \"edna_krabappel\"\n]",
    "Load spacy core\nnlp = spacy.load(\"en_core_web_sm\")",
    "Remove the entries with no spoken line and lines than have no character associated",
    "Inspect data frames\ndf_characters.head()",
    "Use the NLTK library to download the stopwords data\nimport nltk\nnltk.download('stopwords')",
    "Set up spacy\nnlp = spacy.load('en_core_web_sm')",
    "Reduce the size of the datasets for testing, not required for final use\ndf_script = df_script.head(10000)\ndf_episodes = df_episodes.head(1000)",
    "Display output of all the lines in the dataframe\npd.set_option('display.max_rows', None)",
    " Merging data into one dataframe",
    "Clean the script dataframe",
    "Filter and remove rows with information unvailable in any df",
    " Remove special characters from raw lines in script\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.replace(r'\\r+|\\n+|\\t+','', regex=True)",
    "Check how the dataframes look like\ndf_characters.head(3)",
    "Check data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Set text column width to see whole text\npd.set_option('display.max_colwidth', None)",
    "Check the count of lines and characters",
    "Filter for a specific episode, e.g., episode \"1\", and display the first 5 lines",
    " Display general information about the datasets\ndf_characters.info()\ndf_locations.info()\ndf_script.info()\ndf_episodes.info()",
    "Join the data together\ndf = (df_script\n      .merge(df_episodes, on='episode_id', suffixes=('_script', 'ep'))\n      .merge(df_characters, on='character_id', suffixes=('_ep', 'char'))\n      .merge(df_locations, on='location_id', suffixes=('_char', 'loc'))\n     )",
    "Let's start by taking a look at the data.",
    "Let's print the shape of the all dataset and the head of the script dataset.",
    " Setting the index to line_id for simplicity\ndf_script.set_index('id', inplace=True)",
    "Let's take a look at the contents of these DataFrames.",
    "Load the script and episodes dataframe\ndf_script_id = df_script.join(df_episodes, on='episode_id', rsuffix='_ep')",
    "Create a new column in df_script with the number of words in the utterance.",
    "# Display first few rows of the dataset\ndf_script.head()",
    "Select columns for analysis",
    "First, let's start by looking at some general information about the datasets.",
    "to be continued...",
    "Create copies of these dataframes",
    "Let's take a look at the data.",
    "Initial data observation\ndf_script.head()",
    "Check all of the databases have been correctly loaded",
    "Check if the episodes' raw data is complete.",
    "Build an inverted index by character and by location using the script lines data.",
    "Check the content of the characters dataframe.",
    "Let's take a look at the structure of each of these DataFrames and their first few rows.",
    "Display first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Remove lines without any text in them.\ndf_script = df_script.dropna(subset=['normalized_text'])",
    "Drop duplicates from all tables\ndf_characters.drop_duplicates(subset='character_id', inplace=True)\ndf_locations.drop_duplicates(subset='location_id', inplace=True)\ndf_script.drop_duplicates(subset='line_id', inplace=True)\ndf_episodes.drop_duplicates(subset='episode_id', inplace=True)",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Remove unwanted column from the dataframes",
    "Local imports",
    "Check the structure of the characters DataFrame\ndf_characters.head()",
    "Check the first three rows of the script data to see what it looks like\ndf_script.head(3)",
    "Convert string representations of lists to actual lists\nimport ast\n\ndf_script['raw_character_text'] = df_script['raw_character_text'].apply(ast.literal_eval)\ndf_script['spoken_words'] = df_script['spoken_words'].apply(ast.literal_eval)",
    "Merge datasets to get one big dataset",
    "Check if data has been loaded successfully\ndf_characters.head()",
    "Remove unwanted rows and leave only those, which have the same length of 'normalized_text' and 'word_count'",
    "Preview the characters dataframe\ndf_characters.head()",
    "Data exploration",
    "Inspect the data files",
    "Install textual analysis library and the the language model for English\n!python -m spacy download en",
    "Check data import\ndf_script.head()",
    "Remove all lines with NaN values, and all values that are the empty string",
    " Reformat the script data to include only the information that is relevant to our project",
    "Check content of the script data\ndf_script.head()",
    "Print first 5 lines of first data file\nprint(df_characters.head())",
    "With `inplace=False` we reset the index of the dataframe, and we avoid creating a new dataframe.",
    " Load Spacy model for English language\nnlp = spacy.load('en_core_web_sm')",
    "Print the first 5 rows of each dataframe to understand the data",
    " Set the script to use the 'fivethirtyeight' matplotlib style\nplt.style.use('fivethirtyeight')",
    "Quick look at the dataframes",
    " For more details about the dataset, read 'description.txt'",
    "Remove invalid script lines and merge tables",
    "Set up Spacy\nnlp = spacy.load(\"en_core_web_sm\")",
    "Filter the script to only keep the lines with characters and locations available in their respective datasets",
    "View the first few rows of the characters dataframe\ndf_characters.head()",
    "Check the first few rows of the characters dataframe\ndf_characters.head()",
    "Split date into year, month and day, to make it easier to aggregate later on",
    "# First look at the data\nprint('First look at the data')\nprint(df_episodes.head(), '\\n\\n', df_episodes.info())\nprint(df_characters.head(), '\\n\\n', df_characters.info())\nprint(df_locations.head(), '\\n\\n', df_locations.info())\nprint(df_script.head(), '\\n\\n', df_script.info())",
    "Extract data\ndf_char_ep_count = df_script[['character_id','episode_id']].groupby('character_id').episode_id.nunique().reset_index(name='episode_count')\ndf_char_ep_count = df_char_ep_count[df_char_ep_count.episode_count >= 20]\ndf_char_ep_count = df_char_ep_count.merge(df_characters, left_on='character_id', right_on='id').sort_values('episode_count', ascending=False)",
    "Define ufoc\nUFOC = spacy.blank('en')",
    "Check the first few rows of the characters dataframe\ndf_characters.head()",
    "# Spokane_County_Animation_Corpus_General\ndf_script.head()",
    "Inspect the data for each table",
    "Set default style for plotting",
    "Renaming user columns",
    "Merge script with episodes\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id')",
    "Show the first few rows of the characters DataFrame",
    "dsfd",
    "Set the paths to the datasets\nEPISODES_DATASET_PATH = \"data/simpsons_episodes.csv\"\nSCRIPT_DATASET_PATH = \"data/simpsons_script_lines.csv\"\nCHARACTERS_DATASET_PATH = \"data/simpsons_characters.csv\"\nLOCATIONS_DATASET_PATH = \"data/simpsons_locations.csv\"",
    "Let's take a look at the data first.",
    "Start by looking at the first few rows of the characters DataFrame.",
    "Create the word cloud function using the WordCloud package.",
    "merge script, characters and locations tables\ndf_script_char = pd.merge(df_script, df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_char')).drop(columns='id')\ndf_script_char_loc = pd.merge(df_script_char, df_locations, left_on='location_id', right_on='id', suffixes=('', '_loc')).drop(columns='id')",
    "Preview first 5 entries of df_characters\ndf_characters.head()",
    "List first 5 rows\ndf_characters.head(5)",
    "Check the first episodes record to see what data is available\ndf_episodes.iloc[0]",
    "Check the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Merge the script lines with the characters and locations information\ndf_script_full = df_script.merge(df_characters, how='left', on='character_id')\ndf_script_full = df_script_full.merge(df_locations, how='left', on='location_id')",
    "Ensure all NaN values are replaced with an empty string\ndf_script = df_script.fillna('')",
    " Display the first few rows of the script DataFrame\ndf_script.head()",
    "List first 5 script lines.",
    " Display the first 5 rows of each dataframe",
    "Merge episodes with the script lines\ndf_episodes_and_script = df_script.merge(df_episodes, on='episode_id')",
    "Display a preview of the dataframe pertaining to script data\ndf_script.head()",
    "Display some basic information about each dataframe",
    "Display the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display the first 5 rows of the script dataframe\ndf_script.head()",
    "Get the first 5 rows of each DataFrame for a quick look at the data",
    "Preview the first 5 rows of 'df_characters' DataFrame\ndf_characters.head()",
    "Data Inspection",
    "Display the first 5 rows of each dataframe\ndf_script.head(), df_characters.head(), df_locations.head(), df_episodes.head()",
    "Filter seasons before COVID-19",
    "# Checking the first lines of the dataframe\nprint(\"\\nData: Characters\")\nprint(df_characters)\nprint(\"\\nData: Locations\")\nprint(df_locations)\nprint(\"\\nData: Script\")\nprint(df_script)\nprint(\"\\nData: Episodes\")\nprint(df_episodes)",
    "Check first 5 rows of each dataset\nprint(\"Characters\\n\", df_characters.head(), \"\\n\\n\")\nprint(\"Locations\\n\", df_locations.head(), \"\\n\\n\")\nprint(\"Script\\n\", df_script.head(), \"\\n\\n\")\nprint(\"Episodes\\n\", df_episodes.head(), \"\\n\\n\")",
    "Check if the data loaded correctly\nprint(f'Characters: {len(df_characters)}')\nprint(f'Locations: {len(df_locations)}')\nprint(f'Script lines: {len(df_script)}')\nprint(f'Episodes: {len(df_episodes)}')",
    "View the script lines dataframe\ndf_script.head()",
    "Merge 'simpsons_script_lines.csv' with 'simpsons_characters.csv' based on `character_id`\ndf = df_script.merge(df_characters, on='character_id', how='left')",
    "Remove rows with NaN valued spoken_words (empty spoken_words)\ndf_script = df_script.dropna(subset=['spoken_words'])",
    "Visualize The Word Frequency In The Script Lines",
    "Check we can join the relevant tables on the episode ID",
    " To achieve this, we'll use the `merge` function provided by Pandas to join our datasets together.",
    "\n# Merge main data into a single dataframe\ndf_merged = (\n    df_script\n    .merge(df_episodes, on='episode_id', suffixes=('_script', ''))\n    .merge(df_characters, on='character_id', suffixes=('_script', '_character'))\n    .merge(df_locations, on='location_id', suffixes=('_script', '_location'))\n)",
    " View the first few lines of the characters dataframe\ndf_characters.head()",
    "In case of small datasets, pandas is smart enough to infer the correct data type of each column, however, it's best to be explicit to avoid ambiguity and noisy type warnings in case of larger datasets.",
    " Display the progress bar by setting the pandas options\ntqdm.pandas()",
    "Display first 5 records of script lines (caption, raw_text, spoken_words)\ndf_script.head()",
    "Merge episodes with script in order to obtain episode data at every line's level.",
    "select only necessary columns\ndf_script = df_script[['episode_id', 'id', 'character_id', 'location_id', 'raw_text']]",
    " Data quality\n# df_script contains the raw text\n\n# Ensure we have all the needed data\nrequired_cols = ['episode_id', 'character_id', 'location_id', 'raw_text', 'timestamp_in_ms']\nfor col in required_cols:\n    assert col in df_script.columns, f\"Column '{col}' not found in df_script\"\n\nprint(\"All required columns found in df_script\")",
    "Create the nlp object\nnlp = spacy.load('en_core_web_sm')",
    "Set parameters for dataframe pretty print\npd.set_option('display.max_columns', None)",
    "Merge script and episode datasets\ndf = pd.merge(df_script, df_episodes, on='episode_id', how='inner')",
    "Recommended: set a fixed seed for reproducibility in pyspark.",
    "Process data.frames and set index if necessary",
    "Merge all data together by their foreign keys.",
    " Display first 5 rows of df_characters\ndf_characters.head()",
    "View the first 5 rows of the characters dataframe",
    "df_script.info()",
    "Display\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"\\nLocations\")\nprint(df_locations.head())\nprint(\"\\nScript\")\nprint(df_script.head())\nprint(\"\\nEpisodes\")\nprint(df_episodes.head())",
    " from datetime import datetime",
    "Filtering raw dataframe",
    "check missing data\ndf_script.isnull().sum()",
    "Check for missing values\ndf_script.isnull().sum()",
    "Drop duplicate lines and NaN values from the script\ndf_script.drop_duplicates(subset=['id', 'episode_id'], inplace=True)\ndf_script.dropna(subset=['raw_text', 'normalized_text'], inplace=True)",
    "Merge the dataframes to simplify analysis.\ndf = df_script.merge(df_episodes, on='episode_id')\ndf = df.merge(df_characters, on='character_id', suffixes=['_script', '_character'])\ndf = df.merge(df_locations, on='location_id')",
    "function to tokenize a script line and remove stopwords",
    "Tokenize the script lines to run some analysis on it\nnlp = spacy.load(\"en_core_web_sm\")",
    " Look at the first few rows of the characters DataFrame\ndf_characters.head()",
    "Join characters, locations, and scripts into a single dataframe for simplicity",
    " Let's take a peek at the first few lines of each dataframe to get an idea of what we are working with.",
    " Let's start by exploring the data and visualizing some interesting statistics.",
    "A sample of the 'simpsons_script_lines' dataset\ndf_script.sample(5)",
    " drop first column (Unnamed: 0) of all DataFrames\ndf_characters.drop(columns=['Unnamed: 0'], inplace=True)\ndf_locations.drop(columns=['Unnamed: 0'], inplace=True)\ndf_script.drop(columns=['Unnamed: 0'], inplace=True)\ndf_episodes.drop(columns=['Unnamed: 0'], inplace=True)",
    "Show the first 5 rows of the df_characters dataframe\ndf_characters.head()",
    "Display a preview of the characters DataFrame\ndf_characters.head()",
    "Let's start by taking a look at the first few rows of the characters dataframe.",
    "View data structure\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Display main datasets\ndf_episodes.head()",
    "# Visualizing the first few rows of the characters dataframe\ndf_characters.head()",
    "Explore the data\ndf_script.head()",
    "Filtering Data for Analysis\n# ",
    "Extract the gender and the line\ndf_script_lines = df_script[['character_id', 'location_id', 'gender', 'normalized_text']]",
    "# Selection of information useful for this task\ndata = df_script[['episode_id', 'character_id', 'raw_text']]\ndata = data.dropna()  # Remove missing (NaN) data\n\n# Database with relations between characters and locations\nrelations = pd.read_csv('data/simpsons_locations.csv', usecols=['location_id', 'name'])",
    "# Display the first 5 rows of the episodes dataframe\ndf_episodes.head()",
    "Get data from users_dicussion of all characters.",
    "Set the configuration for the Spacy language model.",
    "Check the head of each dataframe to understand the available data.",
    "Explorating the first 5 rows of the characters dataset\ndf_characters.head(5)",
    "Let's look at the first few rows of each of these dataframes to understand their structure better.",
    "Find the most common professions of characters in The Simpsons",
    "Selecting relevant columns and renaming index column",
    "Let's take a look at the first few rows (and columns) of our data.",
    " Create directory for figures if it doesn't exist\nif not os.path.exists('figures'):\n    os.makedirs('figures')",
    "Inspect the first 5 records of the characters dataframe",
    "Checking the dataframes\ndf_characters.head()",
    "Let's print a single script line.",
    "Inspect the structure of the datasets\nprint(f'Characters: {len(df_characters)}')\ndf_characters.head()",
    "Get the episodes for each character",
    "To avoid truncating the display of DataFrames, we're going to tell pandas to display up to 100 columns and 100 rows.\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)",
    "checks the right columns have been loaded\ndf_characters.head()",
    " Generate a sample of each data frame to understand its structure\nprint(\"Characters dataset\")\ndisplay(df_characters.sample(5))\n\nprint(\"\\nLocations dataset\")\ndisplay(df_locations.sample(5))\n\nprint(\"\\nScript dataset\")\ndisplay(df_script.sample(5))\n\nprint(\"\\nEpisodes dataset\")\ndisplay(df_episodes.sample(5))",
    "# Print the first 5 rows of the characters dataframe\ndf_characters.head()",
    " Take a look at the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Checking the first few rows",
    "Print the first three elements for each dataframe\nprint(\"Characters\")\nprint(df_characters.head(3), '\\n')\n\nprint(\"Locations\")\nprint(df_locations.head(3), '\\n')\n\nprint(\"Script\")\nprint(df_script.head(3), '\\n')\n\nprint(\"Episodes\")\nprint(df_episodes.head(3))",
    "We start with the import statements, importing necessary libraries like pandas, numpy, spacy, matplotlib, and others. We also import the custom libraries like tqdm, Counter, and the WordCloud module from the wordcloud library. Then we read the CSV files using pandas, creating dataframes for characters, locations, script lines, and episodes.",
    "Check dataframe shape\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Make a directory to save the figures\nif not os.path.exists('figures'):\n    os.makedirs('figures')",
    "Transforming the script dataframe to include more useful information\ndf_script['episode_id'] = df_script.apply(lambda row: int(row['raw_text'].split('\\t')[1]), axis=1)\ndf_script['character'] = df_script.apply(lambda row: row['raw_text'].split('\\t')[2] if len(row['raw_text'].split('\\t')) > 2 else '', axis=1)\ndf_script['text'] = df_script.apply(lambda row: row['raw_text'].split('\\t')[-1], axis=1)\ndf_script = df_script.merge(df_episodes[['id', 'season', 'number', 'air_date', 'title']], how='left', left_on='episode_id', right_on='id')",
    "Inspect df_characters\ndf_characters.head()",
    "# Elasticsearch imports\nfrom elasticsearch import Elasticsearch, helpers",
    "Let's start by taking a look at the first few lines of each dataframe.",
    "Preview the characters dataframe\ndf_characters.head()",
    " Load previously saved data from these pickles. Uncomment if you have ran the cells above and have pickled before\n\n# df_characters = pd.read_pickle('data/pickles/characters.pkl')\n# df_locations = pd.read_pickle('data/pickles/locations.pkl')\n# df_script = pd.read_pickle('data/pickles/script.pkl')",
    " Set the style\nmatplotlib.style.use('ggplot')",
    "Data cleaning and processing",
    "Let's peek into the data to understand what we are working with.",
    "Set filepath here\nfilepath = \"data/episodes\"",
    "Quick overview of the data\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"\\nLocations\")\nprint(df_locations.head())\nprint(\"\\nScript\")\nprint(df_script.head())\nprint(\"\\nEpisodes\")\nprint(df_episodes.head())",
    "Checking the first few entries of the characters dataframe",
    " Merge names with main characters and locations\ndf_script = pd.merge(df_script, df_characters,\n                    how='left', left_on='character_id', right_on='id')",
    "Let's look at the character dataset first.",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    " Set index Episode and Processed text for df_script",
    "Display the first 5 rows of each dataframe\ndfs = {'Characters': df_characters, 'Locations': df_locations, 'Script': df_script, 'Episodes': df_episodes}\nfor name, df in dfs.items():\n    print(name)\n    print(df.head())\n    print('\\n')",
    "Set the index of the dataframes to match the ID of the columns in the dataset",
    "Understand the structure of the datasets",
    "Show first rows of the characters dataframe\ndf_characters.head()",
    "# Investigate the data\nprint(\"Characters:\")\nprint(df_characters.head())\nprint(\"\\nLocations:\")\nprint(df_locations.head())\nprint(\"\\nScript:\")\nprint(df_script.head())\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
    " Print first rows of the dataframe to understand the data structure\nprint(df_characters.head())",
    "Merge dataframes to have all relevant information in one place",
    "Inspect the first few rows of each dataframe to understand the data",
    "Define helper function to join script snippets",
    "Merging the script with the character information",
    "Inspecting the character dataset\ndf_characters.head()",
    "Replace NaN with an empty string\ndf_script = df_script.replace(np.nan, '', regex=True)",
    " Quick peek at the characters\ndf_characters.head()",
    "The head method shows the first few rows of a DataFrame.",
    "Load and preprocess data",
    "Set the pandas options to visualize the dataset\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)",
    "Filtering the script data for the episode number and the episode name",
    "Joining the datasets based on the available keys in the dataframes",
    "Separate script lines dataframe into lines by character, and save lines as text files",
    " Checking the first few rows of each DataFrame to understand the data",
    "Display available columns\ndf_script.columns",
    "Remove bad data in script, episodes and characters\ndf_characters = df_characters[(df_characters['name'] != '?') & (df_characters['normalized_name'] != '')].reset_index(inplace=False, drop=True)\ndf_locations = df_locations[(df_locations['name'] != '?') & (df_locations['normalized_name'] != '')].reset_index(inplace=False, drop=True)\ndf_episodes = df_episodes[(df_episodes['title'] != '?')].reset_index(inplace=False, drop=True)\ndf_script = df_script[df_script['character_id'].isin(df_characters['id'])]\ndf_script = df_script[df_script['location_id'].isin(df_locations['id'])]\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]",
    "Analyzing the character lines and building word clouds",
    "Inspect the dataframes",
    "Drop columns that are not necessary for this particular analysis:\ndf_episodes.drop(['original_air_year', 'production_code', 'thumbnail_address', 'video_address'], axis=1, inplace=True)\ndf_script.drop(['number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_image_url', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text'], axis=1, inplace=True)\ndf_locations.drop(['number', 'image_url', 'modification_date', 'special'], axis=1, inplace=True)\ndf_characters.drop(['number', 'image_url', 'gender', 'hair', 'modification_date', 'imdb_url'], axis=1, inplace=True)",
    "Check that the data has been loaded correctly\nprint(df_characters.sample(5))\nprint(df_locations.sample(5))\nprint(df_script.sample(5))\nprint(df_episodes.sample(5))",
    "df_script['raw_character_text'].value_counts()",
    " Dataframe that combines script lines and episode information\ndf_script_episodes = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_episode'))\ndf_script_episodes",
    " Show the first 5 lines of the script dataframe\ndf_script.head()",
    "Checking the head for df_characters",
    "Display the first five rows of the characters dataframe\ndf_characters.head()",
    "# Note - please ensure that the files have been placed in the correct path as mentioned in the code for the imports to work",
    " Show first lines of each dataframe to understand their content\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Remove useless data\ndf_script = df_script[['episode_id', 'raw_text']]",
    "Checking a few stats about the datasets",
    " Display the first few rows of the dataframe\ndf_characters.head()",
    "Limiting to the lines with valid character and location ids\ndf_script = df_script[df_script.character_id.isin(df_characters.id) & \n                      df_script.location_id.isin(df_locations.id)]",
    "Df2nlp_class.py\n# Custom class for the following\n# - Load\n# - Preprocess\n# - Tokenize\n# - Build Corpus\n# - Embedding representation\n# - Helper functions\n#      - txt to segments\n#      - txt to sequences\n# Import file",
    "Check the content of the characters file",
    "Create and init default wordcloud configuration\nwc_default_config = {\n    \"max_words\": 100,\n    \"width\" : 800,\n    \"height\" : 400,\n    \"collocations\" : False #\"False colocations\" are a pair or more of words that are commonly co-located in a text. In general, they tend to appear together more than would be expected by chance\n}",
    "Merge the episodes and the script dataframes using the common 'episode_id' column.\ndf_merged = df_script.merge(df_episodes, on='episode_id')",
    "uer_import",
    "Lets see what the contents look like",
    " Show the top entries of each DataFrame\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Load the saved variables",
    "Check if dataframes were imported correctly\ndf_characters.head()",
    "Check if data loaded correctly\ndf_characters.head()",
    "Remove unwanted columns\ndf_script = df_script.drop(columns=['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_character_text', 'raw_location_text', 'normalized_text'])",
    "Inspect first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Visualizations\n# Wordcloud of the most common words of the script\nall_words = ' '.join(df_script['normalized_text'].values)\nwordcloud = WordCloud(width = 1000, height = 500).generate(all_words)\n\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')",
    "View data in the different csv files\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Display the first few rows of the dataframe containing the characters.",
    "Exploring the datasets\ndf_characters.head()",
    "Merge the script lines with the corresponding characters and locations",
    "Inspecting the first few rows of the characters dataframe\ndf_characters.head()",
    "\nprint('Characters dataset size:', df_characters.shape)\nprint('Locations dataset size:', df_locations.shape)\nprint('Script dataset size:', df_script.shape)\nprint('Episodes dataset size:', df_episodes.shape)",
    "nitialize spaCy model\nnlp = spacy.load('en_core_web_sm')",
    "Checking the head of the dataframe to make sure all the data was imported correctly.",
    "Set up figure size\nmatplotlib.rcParams['figure.figsize'] = (10, 10)",
    "Ensure proper file separator for both Windows and Unix-based systems\nfile_separator = os.sep",
    "Check out the first few lines of dataframes\nprint(\"First few lines of df_characters\")\nprint(df_characters.head(3))\nprint(\"\\n\\n\")\n\nprint(\"First few lines of df_locations\")\nprint(df_locations.head(3))\nprint(\"\\n\\n\")\n\nprint(\"First few lines of df_script\")\nprint(df_script.head(3))\nprint(\"\\n\\n\")\n\nprint(\"First few lines of df_episodes\")\nprint(df_episodes.head(3))",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Create folder to save images",
    "Display first 5 records of the dataframe\ndf_characters.head()",
    "Build lookup tables for characters, locations, and episodes",
    "Displaying dataset samples\ndf_script.sample(10)",
    "Data overview",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Drop lines without any character or dialogue\ndf_script = df_script.dropna(subset=['character_id', 'raw_text'])",
    "Inspect the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Let's take a look at the first few rows of each dataframe to understand the data structure.",
    "View dataframes headers",
    "Viewing the structure of the characters dataset",
    " Look at the first 5 rows of the script dataframe\ndf_script.head()",
    " Generate a list of dialogue for each character",
    "# Settings\npd.set_option('display.max_columns', None)",
    "Remove the data folder and create a clean data folder",
    "Combine name and normalized_text columns\ndf_script['speaking'] = df_script['raw_text']\ndf_script['speaking'] = df_script['speaking'].fillna(df_script['normalized_text'])\n\n# Get first words of each script and lowercase them\ndf_script['first_word'] = df_script['speaking'].apply(lambda x: x.strip().lower().split(' ')[0])",
    "Explore the data and generate statistics",
    "# To create the wordclouds we will need the large language model \n# and some additional utility code from the course NLP repository\n!wget https://github.com/SDS-AAU/SDS-master/raw/master/M3/nlp/nlp.py -O nlp/nlp.py\n!wget https://github.com/SDS-AAU/SDS-master/raw/master/M3/nlp/sdsai_ofehome.py -O nlp/sdsai_ofehome.py",
    "check character count and header",
    "Remove column \"id\" as it is unnecessary\ndf_script.drop(columns=['id'], inplace=True)",
    "Optional (this script is designed to select a sub-dataset to reduce memory consumption.\n# scripts for visualizations)",
    "interactively display plots\n%matplotlib notebook",
    "check for missing values\ndf_script.isnull().sum()",
    "More imports",
    "Merge dataframes to have all the data in one place\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id')\ndf_merged = pd.merge(df_merged, df_characters, on='character_id', how='inner')\ndf_merged = pd.merge(df_merged, df_locations, on='location_id', how='inner')",
    "def print_full(x):\n    pd.set_option('display.max_rows', len(x))\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.width', 2000)\n    pd.set_option('display.float_format', '{:20,.2f}'.format)\n    pd.set_option('display.max_colwidth', None)\n    print(x)\n    pd.reset_option('display.max_rows')\n    pd.reset_option('display.max_columns')\n    pd.reset_option('display.width')\n    pd.reset_option('display.float_format')\n    pd.reset_option('display.max_colwidth')",
    "Join episodes to the script on the 'episode_id' field\n# (two dataframes, episodes and script)\ndf = df_episodes.set_index('id').join(\n    df_script.set_index('episode_id')\n).reset_index()\n\n# Join the resulting dataframe to the characters and locations tables.\n# (characters/locations and episodes/script now)\ndf = df.set_index('character_id').join(\n    df_characters.set_index('id')\n).reset_index().set_index('location_id').join(\n    df_locations.set_index('id')\n).reset_index()",
    "Visualising the occurences of character names with wordclouds",
    "df_script_subset = df_script[df_script['episode_id'].isin(df_episodes['id'])]",
    "Joining the datasets on the common columns to be able to analyze the text based on other columns is an important step in this data pre-processing.",
    "Filter out script lines that have not been assigned to any character\ndf_script = df_script[df_script['character_id'].isin(df_characters['id'])]\n\n# Counting the number of lines spoken by each character\nlines_per_character = df_script['character_id'].value_counts().reset_index()\nlines_per_character.columns = ['id', 'num_lines']\n\n# Merging this information into the characters dataframe\ndf_characters = pd.merge(df_characters, lines_per_character, on='id', how='left')",
    "Checkin some dataframes basic info\ndf_characters.info(), df_locations.info(), df_script.info(), df_episodes.info()",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    " Show first 5 rows of script_lines DataFrame\ndf_script.head()",
    "We then specify where data will be saved\nsave_dir = 'image_outputs'\n\n# Make the directory if it doesn't exist\nos.makedirs(save_dir, exist_ok=True)",
    " Sample the script, characters, and locations DataFrames\ndf_characters.head(), df_locations.head(), df_script.head()",
    "Let's try to see what each dataframe looks like.",
    "Check for missing values in the datasets\nprint(df_characters.isnull().sum())",
    "Set the default figure size for matplotlib to (14,7)\nmatplotlib.rcParams['figure.figsize'] = (14, 7)",
    "Check the number of data points \nprint(\"Number of data points: \", df_script.shape[0])",
    "Set display options for pandas dataframes, so that we'll be able to see the entire content.",
    "Merge the scripts with the character metadata\ndf_scripts_characters = pd.merge(df_script, df_characters, on='character_id', how='inner')",
    "Check the first 5 lines of each dataframe to understand the data",
    "Let make sure we join the datasets correctly:",
    "Remove duplicates in the datasets",
    "Modify episode id to be zero-indexed in order to facilitate join operations\ndf_episodes['id'] = df_episodes['id'] - 1",
    " Merge with the location data to get the locations mentioned per line\ndf_lines_with_locations = pd.merge(df_script, df_locations, how='left', left_on='location_id', right_on='id')",
    "Cleaning the data",
    "Join Dfs",
    "Display the number of rows and columns for each dataset\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
    "Plot settings\nmatplotlib.rcParams['axes.labelsize'] = 14\nmatplotlib.rcParams['xtick.labelsize'] = 12\nmatplotlib.rcParams['ytick.labelsize'] = 12\nmatplotlib.rcParams['text.color'] = 'k'",
    "merging the datasets and looking at some examples",
    "Display all columns in the dataframes\npd.set_option('display.max_columns', None)",
    "Set maximum row and column display\npd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 1000)",
    "Load the pre-processed data from the Pickle files",
    "Display basic information about the datasets\nprint('Characters')\ndisplay(df_characters.head())\nprint('Locations')\ndisplay(df_locations.head())\nprint('Script')\ndisplay(df_script.head())\nprint('Episodes')\ndisplay(df_episodes.head())",
    "Load spacy model\nnlp = spacy.load('en')",
    "Show the first 5 rows of \"df_characters\" dataframe\ndf_characters.head()",
    "Inspect the datasets to understand their structure and contents.",
    "View some of the data in `df_characters`\ndf_characters.head(3)",
    "Check column names",
    "Start an analysis session using pandas and matplotlib",
    " Display basic information for all DataFrames",
    "View top few rows of character dataset\ndf_characters.head()",
    "Set the global seed for reproducibility",
    "Visualize the top 10 characters with the most lines in the script\ntop_10_characters = df_script['character_id'].value_counts().head(10)\ntop_10_characters_names = [df_characters[df_characters['id'] == character_id]['name'].values[0] for character_id in top_10_characters.index]\n\nplt.figure(figsize=(20,10))\nplt.bar(top_10_characters_names, top_10_characters.values)\nplt.title('Top 10 characters with the most lines in the script')\nplt.xlabel('Character')\nplt.ylabel('Number of lines')\nplt.xticks(rotation=45)\nplt.show()",
    "Set the max row display\npd.set_option('display.max_row', 1000)",
    "Keep only Homer speaking lines\nhomer_utterances = df_script[(df_script['character_id'] == df_characters[df_characters['raw_character_text'] == 'Homer Simpson'].iloc[0]['id'])]",
    "Remove non-essential columns\ndf_script = df_script.drop(columns=['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms'])",
    "Print the top 5 rows of the characters dataframe\ndf_characters.head()",
    " The script contains four dataframes, each corresponding to a table in the original database.",
    "Preview the first 5 rows of the main dataframe (for Simpsons script lines)\ndf_script.head()",
    "Create directory for generated output\noutput_dir = 'output'\nos.makedirs(output_dir, exist_ok=True)",
    "Visualize the distribution of the most common words in the script lines.",
    "Remove recurring spaces and drop duplicates\ndf_script['normalized_text'] = df_script.raw_text.str.lower().str.replace(r\"\\s+\", \" \").str.strip()\ndf_script = df_script.drop_duplicates('normalized_text')",
    "Build a single dataset containing all the character lines and metadata",
    "Inspect the dataframes",
    "Word cloud visualization for the entire Simpsons script\nscript_texts = ' '.join([str(x) for x in df_script['normalized_text'].values])\nwordcloud = WordCloud(width = 2000, height = 1000, random_state=21, max_font_size=200).generate(script_texts)\nplt.figure(figsize=(20, 10))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')",
    "# Filter non-spoken lines and reset index\ndf_script = df_script[df_script['speaking_line'] == True].reset_index(drop=True)",
    "Let's take a look at the characters dataset.",
    "Change the dataframe name for clarity\ndf_episodes_copy = df_episodes.copy()",
    " Visualize the number of lines per character\n# Number of dialog lines per character (in descending order)\nlines_per_character = df_script['character_id'].value_counts()\n\n# Only keep the 20 most frequent characters\ntop_20_characters = lines_per_character.head(20)\ntop_20_characters_list = top_20_characters.index.tolist()\n\n# Data frame containing only the top 20 characters\ntop_20_characters_df = df_script[df_script['character_id'].isin(top_20_characters_list)]\n\n# Count the number of lines per character\nlines_per_character = top_20_characters_df['character_id'].value_counts()\n\n# Create a barplot of the number of lines per character\nplt.figure(figsize=(20,10))\nplt.bar(lines_per_character.index, lines_per_character.values)\nplt.xticks(rotation=90)\nplt.xlabel('Character')\nplt.ylabel('Number of lines')\nplt.title('Number of dialog lines per character')\nplt.show()",
    " Display maximum 5 rows and columns of a data frame\npd.set_option('display.max_columns', 5)\npd.set_option('display.max_rows', 5)",
    "Define the characters' speech as the features, and the characters as the target.",
    "# Set up Spacy\nnlp = spacy.load('en_core_web_sm')",
    "Set pandas display options for easier viewing\npd.set_option('max_columns', 50)\npd.set_option('max_colwidth', 100)",
    "Let's take a look at the data by displaying the first few rows of each DataFrame.",
    "Merge the dataframes to add character information to the script lines\ndf_script = df_script.merge(df_characters, on='character_id', suffixes=('', '_orig'))\n# Merge the dataframes to add location information to the script lines\ndf_script = df_script.merge(df_locations, on='location_id', suffixes=('', '_orig'))",
    "Checking that the data was in fact loaded\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Sets up dataframe display\npd.set_option('display.max_columns', 500)",
    "View the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display full dataframe info\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', -1)",
    "Inspect the table schema",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "inspect first few rows of the dataframe\ndf_characters.head()",
    "# Display first few records of df_chars\ndf_characters.head()",
    " Set `np.NaN` untuk string kosong\ndf_script.replace('', np.NaN, inplace=True)",
    "Remove rows with missing script data\ndf_script = df_script.dropna(subset=['normalized_text'])",
    "Ensure that we only use 1/4 of every element of the dataset as a temporary measure.",
    "\n# Merge dataframes to create a unified dataframe for analysis\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id', how='inner')\ndf_merged = pd.merge(df_merged, df_characters, on='character_id', how='inner')\ndf_merged = pd.merge(df_merged, df_locations, on='location_id', how='inner')\n\n# Output the first few rows of the merged dataframe\ndf_merged.head()",
    " Sample the characters dataframe\ndf_characters.sample(10)",
    " Verify data loading",
    "It is not clear what the next steps are in the code, as the provided code seems to be incomplete.",
    "Merge datasets to have episode, character and location information in one DataFrame\ndf_merged = pd.merge(df_script, df_episodes, how='left', on='episode_id')\ndf_merged = pd.merge(df_merged, df_characters, how='left', left_on='character_id', right_on='id')\ndf_merged = pd.merge(df_merged, df_locations, how='left', left_on='location_id', right_on='id')\n\n# Show the first few rows of the DataFrame\ndf_merged.head()",
    " Set random seed for deterministic results\nnp.random.seed(0)",
    "Selecting all the lines spoken by Homer Simpson and the name of the episode the lines belong to",
    "Check for missing values in the datasets\nprint('Missing values for characters:')\nprint(df_characters.isnull().sum())\nprint('Missing values for locations:')\nprint(df_locations.isnull().sum())\nprint('Missing values for script:')\nprint(df_script.isnull().sum())\nprint('Missing values for episodes:')\nprint(df_episodes.isnull().sum())",
    "Remove the second index column that appeared from the file",
    "Set default style for plots",
    "Setting index on the dataframes",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Display the first few rows of the dataframe to understand its structure.\ndf_characters.head()",
    "Display the first few rows of the dataframe to understand its structure and content\ndf_characters.head()",
    "Let's print the first few rows of each Dataframe to understand their structure and available columns.",
    "Print head of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect loaded data\nprint('characters:', df_characters.shape)\nprint('locations:', df_locations.shape)\nprint('script_lines:', df_script.shape)\nprint('episodes:', df_episodes.shape)",
    "Create character-episode mapping dataframe\ndf_char_ep = df_script[['episode_id', 'character_id']].copy()\ndf_char_ep.dropna(inplace=True)\ndf_char_ep['character_id'] = df_char_ep['character_id'].astype(int)\ndf_ep_char_map = (df_episodes[['id', 'title']]\n                  .merge(df_char_ep, how='left', left_on='id', right_on='episode_id')\n                  .drop(columns=['id'])\n                  .rename(columns={'title': 'episode_title', 'episode_id': 'episode_id'})\n                  .groupby('character_id')['episode_title']\n                  .apply(list)\n                  .reset_index(name='episode_titles'))",
    " set random seed for consistency\nnp.random.seed(0)",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Examine the first few lines of the characters dataframe\ndf_characters.head()",
    "Show the dataframes shape\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "Check if the folder does not exists, create it",
    "Preview the first 5 rows of each dataframe to see what we are working with\nprint(\"Characters\")\ndisplay(df_characters.head())\n\nprint(\"Locations\")\ndisplay(df_locations.head())\n\nprint(\"Script\")\ndisplay(df_script.head())\n\nprint(\"Episodes\")\ndisplay(df_episodes.head())",
    "Create an output folder to store images",
    " Check the first lines of the \"Characters\" dataframe",
    "Merge character, location and episodes information into the main script dataframe\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=(False, False)).drop('id', axis=1)\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=(False, False)).drop('id', axis=1)\ndf_script = df_script.merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=(False, False)).drop('id', axis=1)",
    "Remove unwanted columns",
    " Merge lines with characters and locations\ndf_lines = df_script.merge(df_episodes, on=\"episode_id\")\ndf_lines = df_lines.merge(df_characters, on=\"character_id\", suffixes=('_line', '_character'))\ndf_lines = df_lines.merge(df_locations, on=\"location_id\", suffixes=('_line', '_location'))",
    " Explore the first few rows of the characters DataFrame\ndf_characters.head()",
    "Hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
    "Display the first few rows of each dataframe to understand its structure and contents.\ndf_characters.head()",
    "# Display first 5 rows of characters dataframe\ndf_characters.head()",
    "# Set up the spacy model for preprocessing\nnlp = spacy.load('en')",
    "check for null values",
    "Inspecting the content of the csv files",
    "Create a pandas dataframe containing the character, location and episode information\n\nloc_c = pd.DataFrame(pd.merge(df_script, df_characters, on='character_id', how='left'))\nloc_c_e = pd.DataFrame(pd.merge(loc_c, df_episodes, on='episode_id', how='left'))\nloc_c_e.url=loc_c_e.url.astype(str)\n\nloc_c_e.info()",
    "Define the parser for the names",
    "configure matplotlib style\nplt.style.use('ggplot')",
    "Check file imports",
    " Display the first few rows of each dataframe\n# print(\"\\n\\nFirst few rows of each dataframe:\")\n# print(df_characters.head())\n# print(df_locations.head())\n# print(df_script.head())\n# print(df_episodes.head())",
    "Create a new clean data frame ready for later processing.",
    "#global variables\nnlp = spacy.load(\"en_core_web_sm\")",
    " Show first 5 rows of the characters dataframe\ndf_characters.head()",
    "Check the loaded datasets\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Let's take a look at the characters data.",
    "Declare the global variables",
    "Checking the data types of each column",
    " The first five rows of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())",
    "Define the main directory path where the datasets are located",
    "Visualise the top characters in The Simpsons",
    "# various sources cite various names for the character \"moe\"\n# also drop characters that don't have any specific lines (i.e. only hears lines from others)\ndrop_chars = [\"mo\", \"Moe_Syszlak\", \"Carl_Carlson\", \"C._Montgomery_Burns\"]",
    "Checking out the content of the characters data",
    "# Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Checking the shapes of the data\nprint(f'Shapes Characters: {df_characters.shape}, Locations: {df_locations.shape}, '\n      f'Script: {df_script.shape}, Episodes: {df_episodes.shape}')",
    " Let's see what's in these datasets",
    "Check the shape and the first rows of each DataFrame",
    "Create a deep copy of df_script and drop duplicate rows based on 'id' column\ndf_script_unique = df_script.copy()\ndf_script_unique.drop_duplicates(subset='id', keep='last', inplace=True)",
    "Remove invalid entries from the dataset\ndf_script = df_script[df_script['timestamp_in_ms'].notna()]\ndf_script = df_script[df_script['character_id'].notna()]\ndf_script = df_script[df_script['location_id'].notna()]",
    "By resetting the index, we ensure that our DataFrames start with index 0 and increase by 1 for each row.",
    " The top 5 rows of the characters dataframe are:",
    "Preview data\ndf_characters.head()",
    "Check the character data set\ndf_characters.head()",
    " Display first 5 records from all dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Preview the first 5 lines of the characters dataframe\ndf_characters.head()",
    "Print some lines of the script\nfor i in range(5):\n    print(f'{df_script.iloc[i].character_id} ({df_characters[df_characters.id == df_script.iloc[i].character_id].name.values[0]]}): {df_script.iloc[i].raw_text}')",
    "Set to display all columns\npd.set_option('display.max_columns', None)",
    "View first few rows of the characters dataset\ndf_characters.head()",
    "# output the first 5 rows of the script dataframe\ndf_script.head()",
    "Remove some special features of the datasets",
    " Concatenate location name and normalized_text and split them with a space\ndf_script['location_text'] = df_script['raw_location_text'] + ' ' + df_script['normalized_text']\n\n# Normalizes text field\n# Converts string to lowercase and removes leading and trailing white spaces\ndf_script['location_text'] = df_script['location_text'].str.lower().str.strip()",
    "Let's take a look at the data.",
    " Display the first few lines of the characters dataframe\ndf_characters.head()",
    "Check the first 5 rows of the characters dataframe.",
    " Set random state for reproducibility\nnp.random.seed(0)",
    " Let's view the first few rows of each dataframe to understand their structure and contents.",
    " Let's take a look at the structure of the datasets.",
    "Display some records of each dataframe to understand the data",
    " Display the first few rows of the dataframe\ndf_characters.head()",
    "Option configuration for pandas",
    " Display the first 5 rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    " Display the first 5 rows of each dataframe to get a quick overview of the data",
    " Change the index of the dataframes",
    "Let's have a look at one of our datasets, `df_script`.",
    " Set the option to display all columns of the pandas dataframe\npd.set_option('display.max_columns', None)",
    " Let's start by exploring the data in each DataFrame to see what we're working with.",
    "We'll parse all relevant columns to string types so we can perform string operations.",
    "Drop rows where one element is NaN\ndf_script = df_script.dropna()",
    "Check a data sample for visual inspection\ndf_characters.head()",
    " I can help you on anything you want about the dataset after you load it.",
    "Let's have a quick overview of each dataset.",
    "Declare the path where the spacy model will be saved\nnlp_path = 'data/spacy_model'",
    "Remove all characters but keep the letters, make it lowercase and strip\ndef clean_line(line):\n    return ''.join(char for char in line if char.isalpha()).lower().strip()",
    "List of stopwords\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))",
    " Display a sample of the data in each dataframe to understand its structure and the kind of data it contains\nprint(\"Characters\")\nprint(df_characters.head(5))\nprint(\"Locations\")\nprint(df_locations.head(5))\nprint(\"Script\")\nprint(df_script.head(5))\nprint(\"Episodes\")\nprint(df_episodes.head(5))",
    " Display the first 5 rows of the characters DataFrame\ndf_characters.head()",
    " Check for missing data\ndf_characters.isnull().sum()",
    " We start by displaying the 5 first lines of each dataframe.",
    " Using the bounding box data to filter out only 4-sided boxes to be displayed",
    "Load the necessary data files for analysis and processing.",
    " View top rows of characters dataframe\ndf_characters.head()",
    "# Prints\ndf_script.head()",
    "Display number of rows for each dataframe\nprint('Number of rows:')\nprint(f'Characters : {len(df_characters)}')\nprint(f'Locations : {len(df_locations)}')\nprint(f'Script : {len(df_script)}')\nprint(f'Episodes : {len(df_episodes)}')",
    "Merge character and location info into script data\ndf_script = df_script.merge(df_characters, on='Character_ID', suffixes=('', '_y'))\ndf_script = df_script.merge(df_locations, on='Location_ID', suffixes=('', '_y'))",
    "df_characters.head()",
    "Normalize the data - make everything lowercase in the required columns",
    "Inspect the first 5 rows of the characters dataframe",
    "Show the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Display the first few rows of the characters DataFrame\ndf_characters.head()",
    "type(df_characters)",
    "Add relative path for SQL connections\nimport sys\nsys.path.append('..')",
    "Remove warning caused by unnamed index column in data files\npd.options.mode.chained_assignment = None",
    " Construct the (id -> name) mapping for the characters\nchar_id2name = df_characters.set_index('id')['name'].to_dict()\n\n# Construct the (id -> name) mapping for the locations\nloc_id2name = df_locations.set_index('id')['name'].to_dict()",
    " Convert the date from string to datetime\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])",
    "Display all dataframe columns\npd.set_option('display.max_columns', None)",
    "Split the `text` column into multiple columns: \ndf_script[['speaking_line', 'character_id', 'location_id', 'raw_text', 'timestamp_in_ms2', 'timestamp_in_ms', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text']] = pd.DataFrame(df_script['text'].str.split(',',10).tolist())",
    "Now that we have imported the required libraries and loaded the datasets, we can start exploring and analyzing the data to gain insights into \"The Simpsons\" TV show.",
    "Drop conversations with just a single speaker\ndf_script = df_script[df_script['number'] != 'unassigned']",
    " Preview data\ndf_script.head()",
    "# Define constants\nSEASON_COLORS = ['#56B4E9', '#009E73', '#E69F00', '#CC79A7', '#0072B2', '#D55E00']",
    " Set default font size for plots\nmatplotlib.rcParams.update({'font.size': 12})",
    "\n# print the number of rows and columns in each dataframe\nprint(\"Characters dataframe:\", df_characters.shape)\nprint(\"Locations dataframe:\", df_locations.shape)\nprint(\"Script dataframe:\", df_script.shape)\nprint(\"Episodes dataframe:\", df_episodes.shape)",
    "Set plot style\nmatplotlib.style.use('ggplot')",
    "\n# %%bash\n# head -n 3 simpsons_characters.csv",
    "Let's take a glance at what's inside each DataFrame by displaying the first few rows.",
    "Custom imports\nfrom utils import preprocess_text",
    "Create some global variables",
    " Display the first few rows of the characters DataFrame\ndf_characters.head()",
    "Display available columns per dataframe for reference when inspecting the data.",
    " Display a few lines of the characters dataframe\ndf_characters.head()",
    "Language model\nimport spacy\n\n# Download the language model\n!python -m spacy download en_core_web_sm",
    "Replace all newline characters with <br> and cache the pre-processed script\ndf_script.raw_text = df_script.raw_text.str.replace('\\n', '<br>')",
    " convert date from string to datetime in episodes data\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])",
    "Process CSV files",
    "Replace NaN values with empty strings\ndf_script['normalized_text'] = df_script['normalized_text'].fillna('')",
    "Assume we want to analyze the script data of the Simpsons. We can start by inspecting the first few rows of the dataset.",
    "cleaning NaN values\ndf_script = df_script[(df_script['episode_id'].notna()) & (df_script['character_id'].notna()) & (df_script['location_id'].notna())\n                     & (df_script['raw_text'].notna())]",
    " Display the first five rows of the script dataframe\ndf_script.head()",
    "Adds a few useful columns to df_script, such as \"spoken_words_count\", \"character_name\".",
    "Declare and intialize a new spacy model",
    "Display dataframe\ndf_script.head()",
    "The main principle of dividing data into different datasets is to make them more manageable and easier to work with. By loading the data of Simpsons characters, locations, script lines, and episodes into separate DataFrames, we can perform targeted analysis and explore specific relationships within the data. Additionally, it allows for modularity and reusability of these datasets, providing a more organized structure for data analysis and manipulation.",
    "nlp = spacy.load('en_core_web_sm')",
    "Preview the characters dataframe",
    " Preprocess script dataframe\ndf_script = df_script.dropna(subset=['normalized_text'])  # Keep only non-NA values in the dataframe\ndf_script = df_script[df_script.normalized_text != '']  # Keep only non-empty values in the dataframe",
    "Filter only the canonical ones\ndf_characters = df_characters[df_characters['is_canon']]\n\n# Convert the title of characters to lowercase\ndf_characters['normalized_name'] = df_characters['name'].str.lower()\n\n# Display the dataframe\ndf_characters.head()",
    "Print the first 10 rows of each DataFrame to have a quick look at their structure.\nprint('Characters:')\nprint(df_characters.head(5))\n\nprint('\\nLocations:')\nprint(df_locations.head(5))\n\nprint('\\nScript:')\nprint(df_script.head(5))\n\nprint('\\nEpisodes:')\nprint(df_episodes.head(5))",
    " Verify the size and structure of the DataFrames\nprint('Characters', df_characters.shape)\nprint('Locations', df_locations.shape)\nprint('Script', df_script.shape)\nprint('Episodes', df_episodes.shape)\n\ndf_characters.head()",
    "Get first rows of the character dataframe",
    "Do some cleanup on the original DataFrames and drop unnecesary columns",
    "Load the pre-trained spaCy NLP model\nnlp = spacy.load('en_core_web_sm')",
    "Display the first few rows of each dataframe to understand its structure and content\nprint('Characters')\ndisplay(df_characters.head())\nprint('Locations')\ndisplay(df_locations.head())\nprint('Script')\ndisplay(df_script.head())\nprint('Episodes')\ndisplay(df_episodes.head())",
    "Check for duplicate columns\nassert len(df_characters.columns.unique()) == len(df_characters.columns)\nassert len(df_locations.columns.unique()) == len(df_locations.columns)\nassert len(df_script.columns.unique()) == len(df_script.columns)\nassert len(df_episodes.columns.unique()) == len(df_episodes.columns)",
    "Rename character name in df_script to prepare for join",
    "Data understanding\n# Characters in the Simpsons\ndf_characters.head()",
    "df_script",
    "preprocessing the script data",
    "Hide warning messages\nimport warnings\nwarnings.filterwarnings('ignore')",
    "Combine the data of the episodes with their corresponding scripts.",
    "Initialize spacy\nnlp = spacy.load('en_core_web_sm')",
    "# Visualization function\ndef cloud(text):\n    # Create and generate a word cloud image:\n    wordcloud = WordCloud().generate(text)\n\n    # Display the generated image:\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.show()\n\n# Initialize spacy 'en' model, keeping only tagger component needed for lemmatization\nnlp = spacy.load('en', disable=['parser', 'ner'])",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "view the script dataframe to understand what information it contains\nprint(df_script.head())",
    "Check the size of each dataframe\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "Ensure all strings are actually strings.",
    "Check our datasets",
    "Check if characters have an alternative name",
    "Optional: Display the first few rows of the dataframe to get an overview of the data.",
    "Display the dataframe once more to ensure the data has been loaded correctly",
    "Check the content of these files.",
    "Code complete.",
    "Print the head of the characters dataframe\nprint(df_characters.head())",
    "# Output some metadata about the datasets\nprint('Characters count:', len(df_characters))\nprint('Locations count:', len(df_locations))\nprint('Episode count:', len(df_episodes))\nprint('Script lines count:', len(df_script))",
    "Merge the scripts with the characters and locations\ndf_merged = df_script.merge(df_episodes, on='episode_id')  # merge scripts with episodes\ndf_merged = df_merged.merge(df_characters, on='character_id')  # merge characters\ndf_merged = df_merged.merge(df_locations, on='location_id')  # merge locations",
    "Set a seed for reproducibility",
    "Check out the data\ndf_episodes.head()",
    "Load spacy\nnlp = spacy.load(\"en_core_web_md\")",
    "Delete the first column\ndf_characters = df_characters.iloc[:, 1:]\ndf_locations = df_locations.iloc[:, 1:]\ndf_script = df_script.iloc[:, 1:]\ndf_episodes = df_episodes.iloc[:, 1:]",
    "Check the overview of each dataset",
    "Merge df_script and df_episodes on episode_id, using a left join\ndf_merged = df_script.merge(df_episodes, on='episode_id', how='left')",
    "Check the import results\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "# Display first 5 rows of each dataframe to verify data has been loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Set the seed for reproducibility",
    "Code not available for this cell.",
    "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    " Check the data types and null values of the datasets\ndf_characters.info()",
    "Check the first few rows of the characters data frame",
    "Set index for faster filtering\ndf_episodes.set_index('id', inplace=True)\ndf_script.set_index('episode_id', inplace=True)",
    "Print first records of df_episodes dataframe\ndf_episodes.head()",
    "Check if the package is installed properly\npackage_name = 'spacy'\ntry:\n    __import__(package_name)\nexcept ImportError:\n    print(f'{package_name} is not installed properly. Please re-install the package and try again.')",
    "Create a directory to store the processed data if it does not exist\nif not os.path.exists('processed_data'):\n    os.mkdir('processed_data')",
    "Install the French model for spaCy if not present\nif 'fr_core_news_sm' not in spacy.util.get_installed_models():\n    !python -m spacy download fr_core_news_sm",
    "Combine script lines and episodes dataframes so we can use episode information to analyze the script lines data.",
    "Check the 5 first lines of the characters dataframe to understand its structure\ndf_characters.head()",
    "Create the list of scripts for each episode ID.",
    "Display most important columns\nprint(df_characters.info())",
    "Check characters info\ndf_characters.head()",
    "Inspect the first few lines of each dataframe to understand its structure and content\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "## Displaying the first rows of the characters dataset\ndf_characters.head()",
    "df_script.head()",
    "Show the first few rows of each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "We'll use strict lists for the values instead of DataFrames for quick retrieval times.",
    "Display all dataframe columns\npd.set_option('display.max_columns', None)\n\n# Show first rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "nlp = spacy.load(\"en_core_web_sm\")",
    " Joining the scripts with the episodes on the episode id",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "# Frequent regex replacements\ndf_script['raw_text'] = df_script['raw_text'].str.replace(r'-', ' ', regex=True)",
    "Check the head of the 4 dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check the first few rows of the characters dataframe\ndf_characters.head()",
    "# Helper function to display information in percentage\ndef percent(x, pos=0):\n    \"\"\"The two args are the value and tick position.\n    Label ticks with the percentage of the total\"\"\"\n    return '%1.1f%%' % (x * 100)",
    "Example of using the dataset.",
    "ne hot encoding to deal with the gender variable\ndf_characters['gender'] = pd.get_dummies(df_characters['gender'])\n\n# Replacing bad symbols in the raw text\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\n', ' ')",
    "Display series lists two column names.",
    "Filter characters and dialogues with more than 6 words\ndf_script['word_count'] = df_script['normalized_text'].str.split().apply(len)\ndf_script = df_script[df_script.word_count>=6]\ndf_script.head()",
    " Check the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Merging of Simpsons data into one single dataframe",
    "Get a feel of the data\nprint(df_script.head(3))\n\n# Plot the 10-most frequent characters\nplt.figure(figsize=(18, 6))\ntop_characters = df_script['raw_character_text'].value_counts().head(10)\ntop_characters.plot(kind='bar')\nplt.title('Top-10 most frequent characters')\nplt.show()",
    "Check the size & header of each data\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "Checking dataframes dimensions\nprint('Dimensions characters:', df_characters.shape)\nprint('Dimensions locations:', df_locations.shape)\nprint('Dimensions script:', df_script.shape)\nprint('Dimensions episodes:', df_episodes.shape)",
    "Display the first few rows of the characters dataset\ndf_characters.head()",
    "- Display the first rows of the characters dataframe\ndf_characters.head()",
    "Display the first few rows of the dataframe to understand its attributes and values\ndf_characters.head()",
    "Let's take a look at the first few lines of each of these DataFrames.",
    "Merge the script, episodes, characters and locations in one DataFrame",
    "Check if GPU is available\nimport tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))",
    "# Ensure that displayed column limit is sufficiently large\npd.set_option('display.max_colwidth', 200)",
    " Visualization on the number of lines for each character and location.\nchar_lines = df_script['character_id'].value_counts()\nchar_lines = char_lines[char_lines.index != 'nan']\nchar_lines = char_lines[char_lines.index != ''])\nloc_lines = df_script['location_id'].value_counts()\nloc_lines = loc_lines[loc_lines.index != 'nan']\nloc_lines = loc_lines[loc_lines.index != ''])",
    "Remove non-English lines from the script dataframe\n# English language detection\nnlp = spacy.load('en_core_web_sm')\n\ndef detect_english_nlp(text):\n    try:\n        doc = nlp(text)\n        # Consider a text in English if the stopwords are less than 60% of the total words\n        if (len(doc) > 0 and len(doc) / len(text) > 0.4):\n            return True\n        else:\n            return False\n    # If the text is too large spacy returns a value error\n    except:\n        return False\n\ntqdm.pandas()\ndf_script = df_script[df_script['raw_text'].progress_apply(detect_english_nlp)]",
    "Print the head of the characters dataframe\ndf_characters.head()",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Print the number of characters, locations, script lines and episodes\nprint('Number of characters:', len(df_characters))\nprint('Number of locations:', len(df_locations))\nprint('Number of script lines:', len(df_script))\nprint('Number of episodes:', len(df_episodes))",
    "Explore the first lines of the characters dataset\ndf_characters.head()",
    "Creating a spacy model and disabling the component we don't need",
    "Set index accordingly\ndf_characters.set_index('character_id', inplace=True)\ndf_locations.set_index('location_id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "Display the first few rows of each dataframe to understand its structure and the type of data it contains.",
    "Let's take a quick look at the first few rows in each DataFrame to understand the data better.",
    "Check first 5 lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display the characters dataframe\ndf_characters",
    "Checking the first few rows of the characters dataframe.",
    "\ndf_script.head()",
    "Checking the script data\nprint(\"We have\", len(df_script), \"script lines\")\ndf_script.head()",
    "Inspecting the first few characters of each table",
    "Create a dataframe `df_script_unique` with the column `spoken_words` containing unique `spoken_words` and the number of occurrences of these `spoken_words` under the column `count`",
    "df_script.head()",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "# Creating a connection\nfrom sqlalchemy import create_engine\nengine = create_engine('sqlite:///data/simpsons.db')",
    "Set interim sampling levels\nn = 10000\nfrac = n / len(df_script)",
    "Check top 5 rows",
    "Set up the script column map for easier retrieval of script lines",
    "Compute total number of words spoken by each character\ndf_characters_spoken_words = df_script.groupby('character_id')['spoken_words'].sum()\ndf_characters_spoken_words.sort_values(ascending=False, inplace=True)",
    "take a look at the available columns in the dataset\nprint(df_script.columns)",
    "Drop rows which do not have any lines or location\ndf_script = df_script.dropna(subset=['raw_location_text', 'spoken_words'])\n\n\n# How many different locations are there in the script\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.lower()\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.replace('springfield','')\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.replace('the simpson home','home')\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.replace('the simpson house','home')\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.replace(\"moe's tavern\",\"moes tavern\")\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.replace(\"moe's\",\"moes tavern\")\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.strip()\n\nlen(df_script['raw_location_text'].value_counts())",
    "Keep only the communication lines from the script dataframe\ndf_script_lines = df_script[df_script['speaking_line'] == True]\ndf_script_lines.reset_index(inplace=True, drop=True)",
    "Printing the first few lines of each dataframe to see what they look like\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " merge to get speaker/line/episode information\ndf_merged = df_script.merge(df_episodes, on='episode_id')\ndf_merged = df_merged.merge(df_characters, on='character_id')\ndf_merged = df_merged.merge(df_locations, on='location_id')",
    "Sanity check\nprint('Characters:', len(df_characters))\nprint('Locations:', len(df_locations))\nprint('Script:', len(df_script))\nprint('Episodes:', len(df_episodes))",
    "Setting the seed for reproducability",
    "filtering out bad data from each dataframe",
    "Print info about each dataframe\nprint('Characters:')\nprint(df_characters.info())\n\nprint('Locations:')\nprint(df_locations.info())\n\nprint('Script:')\nprint(df_script.info())\n\nprint('Episodes:')\nprint(df_episodes.info())",
    "Set a proper index for the episode DataFrame, as the plot will rely on it",
    "Inspect scripts data\ndf_script.head()",
    "# Add episode number to the original dataframe\ndf_script['episode'] = df_script.apply(lambda x: df_episodes[(df_episodes['original_air_year'] == x['year']) & \n                                                             (df_episodes['season']==x['season'])]['number'].values[0] if len(df_episodes[(df_episodes['original_air_year'] == x['year']) & \n                                                                                                                                    (df_episodes['season']==x['season'])]['number'].values) > 0 else -1, axis=1)",
    "Set seaborn style for matplotlib plots\nplt.style.use('seaborn')",
    "Removing unnecessary columns in df_script\ndf_script = df_script.drop(['date', 'timestamp_in_ms', 'speaking_line', 'raw_text', 'normalized_text', 'word_count'], axis=1)",
    "Check the first few rows of each dataframe\ndf_characters.head()",
    "List all data that exists in each dataframe\nprint(\"##################### COLUMNS NAMES #############################\")\nprint(\"Characters columns: \", df_characters.columns)\nprint()\nprint(\"Locations columns: \", df_locations.columns)\nprint()\nprint(\"Script lines columns: \", df_script.columns)\nprint()\nprint(\"Episodes columns: \", df_episodes.columns)",
    "Display the first 5 rows of each dataframe\nprint(\"Characters\")\ndisplay(df_characters.head(5))\nprint(\"Locations\")\ndisplay(df_locations.head(5))\nprint(\"Episodes\")\ndisplay(df_episodes.head(5))\nprint(\"Scripts\")\ndisplay(df_script.head(5))",
    "let's see how the scripts looks with all the cleaned text",
    "Merge the script lines with character and location information",
    "Set the random seed for numpy for reproducible results\nnp.random.seed(0)",
    "Set up the tokenization pipeline with spaCy",
    "peat word cloud code for character dialogues\nwordcloud = WordCloud(width = 1000, height = 500, max_font_size = 110, collocations = False).generate(characters_dialogues_text)\nplt.figure(figsize=(16, 8))\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')",
    "Display the first few entries of each table to understand its structure and content\ndf_characters.head()",
    "display first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Checking the first 5 rows of the \"simpsons_characters.csv\" file\ndf_characters.head()",
    "Exploratory Data Analysis (EDA)",
    "Fix the index of the episodes' dataframe after concatenating the test and training data.",
    "For this example, we will only use the 'name' column of the 'characters' Dataframe and the 'raw_text' column of the 'script' Dataframe.",
    "Check the contents of each dataframe",
    "Inspect a few entries in the characters dataset\ndf_characters.head()",
    "Display shape and info\nprint('Characters shape:', df_characters.shape)\nprint('Locations shape:', df_locations.shape)\nprint('Script shape:', df_script.shape)\nprint('Episodes shape:', df_episodes.shape)",
    "Display the first few rows of the characters DataFrame\ndf_characters.head()",
    " Let's start by taking a look at the structure and content of each of these dataframes.",
    " Clean 'speaking line' column in df_script\ndf_script = df_script.dropna(subset=['speaking_line'])",
    "\n# let's remind ourselves what's in the data.\nprint(df_characters.keys())",
    " View the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Set display options for pandas dataframes\npd.options.display.max_columns = None\npd.set_option('display.float_format', lambda x: '%.3f' % x)",
    "Merge the script lines with the episodes dataframe\ndf_script_full = pd.merge(df_script, df_episodes, on='episode_id')",
    "Display the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Display the first few rows of each dataframe to understand their structure and contents.",
    "Remove any possible duplicate rows in the dataframes\ndf_characters.drop_duplicates(subset =\"id\", keep = False, inplace = True)\ndf_locations.drop_duplicates(subset =\"id\", keep = False, inplace = True)\ndf_script.drop_duplicates(subset =\"id\", keep = False, inplace = True)\ndf_episodes.drop_duplicates(subset =\"id\", keep = False, inplace = True)",
    "Explore the data\ndf_episodes.head()",
    "\n# Sample data\ndf_script.head()",
    "Join episodes and locations\ndf_joined = df_episodes.merge(\n    df_locations,\n    how='left',\n    left_on='id',\n    right_on='episode_id'\n)",
    "Inspect the first 5 rows of the characters DataFrame\ndf_characters.head()",
    "Display the first few rows of each dataframe to get an idea of the data",
    " Let's display the head of each dataframe to get a sense of its structure.",
    "Merge necessary dataframes and columns",
    "Check the structure and dtypes of the character dataframe",
    "Check the size of the dataframes",
    "Check the first entries of each DataFrame\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "# Given a character, determining how many unique locations that character has been to.",
    " Visualisation of character's prevalence in the Simpson corpus",
    "Display the first few rows of the script data\nprint(df_script.head())",
    "plexico characters by the number of lines of speech\ncounts = df_script['raw_character_text'].value_counts()\n\nif 'simpsons' in counts.index:\n    counts.drop('simpsons', inplace=True)\n\n# Label\ncounts.index.name = 'character'\ncounts.name = 'lines'",
    "Select relevant columns and transforming id columns to ints\ndf_script = df_script[['episode_id','number','raw_text','character_id','location_id']]\ndf_script.character_id = df_script.character_id.astype('Int64')\ndf_script.location_id = df_script.location_id.astype('Int64')",
    "# Display the first few rows of the characters DataFrame\ndf_characters.head()",
    " #Install spaCy languages\n!python -m spacy download en_core_web_sm",
    "print(df_characters.head())",
    "Inspects the first few rows of the scripts dataframe\ndf_script.head()",
    "Remove duplicates from script dataframe\ndf_script.drop_duplicates(subset=['episode_id', 'number', 'raw_text'], inplace=True)",
    "Preview the characters data\ndf_characters.head()",
    "Create a simplified dataframe with only relevant information",
    "Display the scripts dataframe\ndf_script.head()",
    "Display the dataframe info to understand its structure and columns\ndf_script.info()",
    " Make the data directories if they do not exist\nos.makedirs('data', exist_ok=True)",
    "Check top 5 records of each dataset\ndf_characters.head()",
    " Display the first 10 rows of the \"df_script\" DataFrame\ndf_script.head(10)",
    " Inspect the structure of the dataframes",
    "Merge script with episodes and strip the data\ndf_episodes['id'] = df_episodes.id.astype(str)  # ensure alignment on merge\ndf_script_lines_with_episode = df_script.merge(\n    df_episodes,\n    left_on='episode_id',\n    right_on='id',\n    suffixes=('_script', '_episode')).copy()\n\n# simplify\ndf_script_lines_with_episode.drop(\n    ['id_episode','image_url','id_script','number_in_season','number_in_series','original_air_date','id_script',\n     'title', 'us_viewers_in_millions','views', 'imdb_votes', 'imdb_rating','video_url'],\n    axis=1,\n    inplace=True)",
    "Set the constants for matplotlib and spacy models.",
    "Setting up the Spacy NLP model\nnlp = spacy.load('en_core_web_sm')",
    "Data ingestion is complete, moving on to data exploration and analysis.",
    "We can display the first few rows of each dataset to get a sense of their structure.",
    "check the first row for each dataframe\nprint(df_characters.head(1))\nprint(df_locations.head(1))\nprint(df_script.head(1))\nprint(df_episodes.head(1))",
    "Checking the loaded datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Quick overview of each dataframe\nfor name, df in {'characters': df_characters, 'locations': df_locations, 'script': df_script, 'episodes': df_episodes}.items():\n    print(f'\\n{name.upper()}')\n    display(df.head(2))",
    "Remove episodes that have no information about writers, \n# directors or production codes, since this information is necessary for further steps\ndf_episodes.dropna(subset=['writer', 'director', 'production_code'], inplace=True)",
    "# Access the first 5 characters\ndf_characters.head()",
    " View the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Set the Style of the plots\nmatplotlib.style.use('ggplot')",
    "Check we have the data\ndf_characters.head()",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "\n# Let's start by checking which columns we have in each dataframe\nprint('Characters:', df_characters.columns)\nprint('Locations:', df_locations.columns)\nprint('Script:', df_script.columns)\nprint('Episodes:', df_episodes.columns)",
    "Let us examine our datasets to see what's inside and what can be interesting",
    "visualize the first few rows of each dataframe to understand the structure of the dataframes.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Data preparation",
    "Inspect the content of the script dataframe to understand its structure and content.",
    "Set custom options for pandas display and read the data.",
    " Merge df_script with df_episodes to attach episode info to each line\ndf_script_all_info = pd.merge(df_script, df_episodes,\n                              on=['episode_id', 'season', 'number_in_season', 'number_in_series'])",
    "check the data\ndf_characters.head()",
    "Setting correct data types",
    "Show the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect the structure of the dataframes",
    " Merge characters and script\ndf_charlines = df_script.merge(df_characters, on='character_id')",
    "Pandas default behavior is to do partial matches, so we need to be rigorous\n# about the columns we in order to avoid ambiguity.\ndf_characters = df_characters.filter(items=['index', 'real_name', 'real_name'])\ndf_locations = df_locations.filter(items=['index', 'name'])\ndf_episodes = df_episodes.filter(items=['id', 'title'])",
    " Merge the datasets together\ndf = df_script.merge(df_episodes, on='episode_id')",
    "Merge all dataframes into a single one for more convenience",
    " Filter out rows from df_script that don't contain any spoken lines (i.e. rows where the speaking_line column is False)\ndf_script = df_script[df_script[\"speaking_line\"] == True].reset_index(drop=True)",
    " Remove rows with empty script lines\ndf_script = df_script.dropna(subset=['raw_text']).reset_index(inplace=False, drop=True)",
    " Checking contents of the dataset",
    " Merge the datasets to include the names of the characters and locations in the script DataFrame for better analysis.",
    " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Join the location of each line using locations.csv and export to csv",
    "Settings\npd.set_option('display.max_columns', None)",
    "remove episode id = 1 as it contains no proper information i.e. script/season/episode name, etc\ndf_script = df_script[df_script['episode_id'] != 1]",
    "Representing text data as numbers with bag of words model\n# We are going to represent each document as a vector with the word frequencies\n# First, we need to tokenise the documents\n\n# Tokenising documents\n# Load the large model to get the vectors\nnlp = spacy.load('en_core_web_lg')\n\n# We have 158276 documents in the dataset which is quite a lot. \n# We can speed up this process and make it more efficient if we use the nlp.pipe for the tokenization.\n\n# Since the tokenisation takes some time, we can save the tokenized documents to a file, \n# such that we wont need to do the tokenisation again, in case we close the notebook or shut down the computer.",
    "# Display all columns\npd.set_option('display.max_columns', None)",
    "Code\n# Data exploration\nprint('Characteres:')\nprint(df_characters.info())\nprint(df_characters.describe())\nprint(df_characters.head())\nprint(df_characters.tail())",
    "To find the top characters according to number of mentions.\n# Getting only the lines of the script that are spoken by characters that exist in the characters dataframe.\ndf_script = df_script[df_script.raw_character_text.isin(df_characters.raw_character_text)]",
    " Show the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "# Custom imports\nfrom tqdm import tqdm\nfrom collections import Counter",
    "Inspect the first few rows of each dataframe to understand its structure and content.\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Changing column names for consistency with annotations",
    "Optional: Set options for pandas.",
    " Quick inspection of each data set",
    "Check for missing data\ndf_characters.isnull().sum()",
    "Inspect the structure of the data and look for inconsistencies and missing values.",
    "\nimport warnings\nwarnings.filterwarnings('ignore')",
    "# IPython-cache\n%load_ext jupyter_cache\n\n# Caching\n%cache df_characters df_locations df_script df_episodes",
    " Print some information about the obtained datasets\nprint(\"Characters:\")\nprint(df_characters.info())\nprint(\"\\n_________________________\\nLocations:\")\nprint(df_locations.info())\nprint(\"\\n_________________________\\nScript:\")\nprint(df_script.info())\nprint(\"\\n_________________________\\nEpisodes:\")\nprint(df_episodes.info())",
    "Display the first few rows of the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "View the content of the dataframes",
    "Remove unnecessary columns from dataframe",
    "Create new directory to save images if it doesn't exists\nimg_dir = 'images'\nif not os.path.exists(img_dir):\n    os.makedirs(img_dir)",
    " Display settings for Pandas dataframes\npd.set_option('display.max_columns', None)",
    "Display all columns to decide which ones I want\npd.set_option('display.max_columns', None)\n\ndisplay(df_episodes.head(5))\ndisplay(df_characters.head(5))\ndisplay(df_locations.head(5))\ndf_script.head(5)",
    "Merge the characters and script lines tables on the character_id key and reindex the resulting table.",
    "Clean up NaN values\ndf_script = df_script.dropna(subset=['raw_text'])",
    "Preview the data\ndf_episodes.head()",
    "Show the top 5 rows of the characters dataframe\ndf_characters.head()",
    "Since we are working with data from the Simpsons TV show, we are importing the required data from CSV files using pandas. This code snippet reads the data from CSV files and resets the index of each dataframe.",
    "Creating a backup of the script dataframe\ndf_script_original = df_script.copy()",
    "Obtain a high-level overview of the dataset\nprint(\"Characters dataset\")\nprint(df_characters.info())\n\nprint(\"Locations dataset\")\nprint(df_locations.info())\n\nprint(\"Script dataset\")\nprint(df_script.info())\n\nprint(\"Episodes dataset\")\nprint(df_episodes.info())",
    "To get a quick feel of the data in each of the DataFrames, we can display the first few rows of each DataFrame using the `head()` method.",
    "Changing the shape of all datasets\na = df_characters.shape\nb = df_locations.shape\nc = df_script.shape\nd = df_episodes.shape",
    "ast values to check the data loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Now, let's take a look at the structure and content of each of these dataframes.",
    "Setting \"Unnamed: 0\" as index for all dataframes\ndf_characters.index = df_characters['Unnamed: 0']\ndf_locations.index = df_locations['Unnamed: 0']\ndf_script.index = df_script['Unnamed: 0']\ndf_episodes.index = df_episodes['Unnamed: 0']",
    " Merge characters/locations to script (using joins)",
    "! python -m spacy download en_core_web_md",
    "Show the head of the script dataframe to better understand its structure\ndf_script.head()",
    "# Display the first few lines of the characters dataframe\ndf_characters.head()",
    "Explore the characters dataset\ndf_characters.head()",
    " Remove badly formatted rows from episodes and script tables",
    "Function to retrieve script for a specific episode",
    "Display settings\npd.set_option('display.max_columns', None)",
    "Check the first five rows of the characters dataframe\ndf_characters.head()",
    "Inspect the dataframe shapes.",
    " View the first rows of the characters dataframe\ndf_characters.head()",
    "Check a few attributes of our datasets\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "# Print the head of the characters dataframe\nprint(df_characters.head())",
    "Preview the characters dataframe\ndf_characters.head()",
    "Combine the lines into single sentences in the `raw_text` column\ndf_script_combined = df_script.groupby('episode_id')['raw_text'].apply(lambda x: ' '.join(x)).reset_index()\ndf_script_combined.head()",
    "Inspect the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Declare the path to the word embeddings from Spacy",
    "Display the first few rows of each dataframe to understand the data",
    "Let's check the first few rows of each dataframe to understand its structure.",
    " Visualize available datasets\nprint(\"Characters:\")\ndisplay(df_characters.head(3))\nprint(\"Locations:\")\ndisplay(df_locations.head(3))\nprint(\"Script:\")\ndisplay(df_script.head(3))\nprint(\"Episodes:\")\ndisplay(df_episodes.head(3))",
    " Visualize top characters",
    "Looking at the first 5 rows of each dataframe.",
    " Display the first few rows of the dataset\ndf_script.head()",
    "Check the script dataframe",
    "Set font for entire script\nmatplotlib.rcParams['font.family'] = 'DejaVu Sans'",
    " Explore the first few rows of the characters dataframe\ndf_characters.head()",
    " These will be the sources of data we will be working with.",
    "Exploring the script data",
    "Explore the content of each dataframe",
    "We  will now display the first 5 rows of the characters dataframe.",
    "set up the plotting style\nmatplotlib.style.use('fivethirtyeight')",
    "characters and locations dimensions\nprint('Dimension of characters data:', df_characters.shape)\nprint('Dimension of locations data:', df_locations.shape)",
    "Merge the dataframes",
    " Display top 5 rows of characters dataframe\ndf_characters.head()",
    "Use the variable to see that the CSVs have been read correctly\ndf_script.head()",
    " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Test the import of the data\nprint(\"Characters:\")\nprint(df_characters.head(5))\nprint(\"\\nLocations:\")\nprint(df_locations.head(5))\nprint(\"\\nScript:\")\nprint(df_script.head(5))\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head(5))",
    "Optional: choose the tallest characters and include others that have the same height, then inspect the names and heights",
    "Load the spacy model\nnlp = spacy.load('en_core_web_sm')",
    "Let's first inspect the first lines for each of these dataframes.",
    " Preprocessing the script dataset by keeping only the spoken lines, and normalizing the character names and locations for consistency.",
    "Display the first few rows of the characters dataset\ndf_characters.head()",
    "Check data and datatypes\ndf_script.head()",
    "TODO: Make sure the dataframe indexes are reset.",
    "Exploring the structure of our data.",
    "Merge the datasets in order to have a unified dataframe containing all necessary information.",
    "Show first few rows of the characters dataframe",
    "Sample the dataframe to understand its structure\ndf_script.sample(10)",
    "Remove very beginning of date from date column in df_episodes\ndf_episodes['date'] = df_episodes['date'].apply(lambda x: str(x)[10:] if pd.notnull(x) else x)",
    " Get the first 5 rows of the script dataframe\ndf_script.head()",
    "A quick view at both characters and locations dataframe",
    "Print the first few rows of the df script\ndf_script.head()",
    "Print the first 5 rows of each dataframe to understand the data",
    " GloVe word vectors\n!pip install -U gensim\n\nimport gensim.downloader as api\n\nword_vectors = api.load(\"glove-wiki-gigaword-100\")",
    "Set shorthands for character and location names",
    "Inspect the first 5 rows of each dataframe to understand its structure and data.",
    " View available data\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"Locations\")\nprint(df_locations.head())\nprint(\"Script\")\nprint(df_script.head())\nprint(\"Episodes\")\nprint(df_episodes.head())",
    " Checking the first few rows of the script dataframe",
    " Create a new dataframe with only the parts of the script that are spoken by a character (not scene headings, etc.)\ndf_script_lines = df_script[df_script.raw_text.str.contains(\"[A-Za-z0-9]+:\")]\ndf_script_lines.reset_index(drop=True, inplace=True)",
    "Load the pre-trained spacy model\nnlp = spacy.load('en_core_web_md')",
    "Ensure that the dataframe the correct dtypes\ndf_episodes['original_air_year'] = pd.to_numeric(df_episodes['original_air_year'], errors='coerce')\ndf_episodes['production_code'] = pd.to_numeric(df_episodes['production_code'], errors='coerce')\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], errors='coerce')",
    "Let's display the first few elements of the following DataFrames to understand what data we are working with:\n# - df_characters\n# - df_locations\n# - df_script\n# - df_episodes",
    "Remove all unnecessary columns from the dataframe",
    " Merge the datasets to get all the relevant info in one dataframe",
    "Checking the first entry of each dataframe",
    " Quick overview of the data",
    "Import stop words from NLTK",
    "Filter columns from dataset",
    "Displaying the first lines of the episodes dataframe",
    "\n# Filter non-English lines\ndf_script_en = df_script[df_script['raw_character_text'].notnull()\n                        & df_script['raw_location_text'].notnull()\n                        & df_script['spoken_words'].notnull()  \n                       ].copy()\n\n# keep only lines by English-speaking characters in English locations\nlocation_en = df_locations[df_locations['normalized_name'].str.contains('[A-Za-z]', na=False)].copy()\ncharacters_en = df_characters[df_characters['normalized_name'].str.contains('[A-Za-z]', na=False)].copy()",
    "\n# To look into the dataframes, we just run the cell\n# Characters DataFrame\ndf_characters.head()",
    "Check information of the script dataset\nprint(df_script.head())\nprint(df_script.info())",
    "Setting the index to use for the DataFrames",
    " Now, let's take a look at the first few rows of each of these DataFrames to understand their structure and the kind of data they contain.",
    "# Showing the first few rows of the dataframes\ndf_characters.head()",
    "Let's start by having an overview of the data.",
    "# Add episode title to script dataframe\ndf_script = df_script.join(df_episodes.set_index('id'), on='episode_id')",
    "Preview the dataframes\ndf_characters.head()",
    " Remove rows where the episode id, character id, or location id are empty/null\ndf_script = df_script[df_script['episode_id'].notna()]\ndf_script = df_script[df_script['character_id'].notna()]\ndf_script = df_script[df_script['location_id'].notna()]",
    "Display the shape of each dataframe to understand the dataset.",
    "View dataframe info\ndf_script.info()",
    "Inspect the first few rows of each dataframe to understand their structure and the type of data stored in them.",
    "df_script.head()",
    "Options for pandas\npd.set_option('display.max_rows', 200)\npd.set_option('display.max_columns', 200)",
    "df_script.rename(columns={\"episode_id\": \"id\"}, inplace=True)",
    "Out-of-the-box excerpted from the summary\n# These scripts are licenced by simpsons_dataset, grouped by season. It contains up to 27 seasons,\n# dated to november 2015, which stands for the 596th episode of this dataset. The author tries to \n# keep contrack for the future.",
    "Display the first few rows of the episodes data\ndf_episodes.head()",
    "Let's take a look at the first few rows of each dataframe to understand the data better.",
    "Let's check out the structure of the data.",
    "Displaying the first few rows of the script dataframe to understand its structure\ndf_script.head()",
    "# Download and load the spacy model\n!python -m spacy download en_core_web_sm",
    "Top 10 most popular characters\ntop_characters = df_script['character_id'].value_counts().head(10)\n# Change character numeric ID to character name\ntop_characters = pd.DataFrame(top_characters).merge(df_characters, left_index=True, right_on='id').set_index('id')\ntop_characters.columns = ['count', 'character_name']",
    "Define stop words and punctuation to be excluded from analysis\nstop_words = spacy.lang.en.stop_words.STOP_WORDS\npunctuations = spacy.lang.en.punctuation.PUNCT_PREFIXES",
    "Preprocess script lines",
    " Drop the first data in the df_characters dataframe as it is just a row of NaN values.",
    " Merge the script with the characters and locations\ndf_script_char = df_script.merge(df_characters[['id', 'normalized_name']], \n                                how='left', \n                                left_on='character_id', \n                                right_on='id').rename(columns={'normalized_name' : 'character'})\ndf_script_char_loc = df_script_char.merge(df_locations, \n                                          how='left', \n                                          left_on='raw_location_id', \n                                          right_on='normalized_name').rename(columns={'normalized_name' : 'location'})\n\n# Select only the important columns\ndf_script_char_loc = df_script_char_loc[['episode_id', 'id', 'number', 'raw_character_text', 'raw_location_text',\n                                         'speaking_line', 'character_id', 'location_id', 'character', 'location']]",
    "Quick look at the data\ndf_characters.head()",
    " Show head of characters dataframe\ndf_characters.head()",
    "fixes a bug on the simpsons script which causes an index column to be loaded.",
    " Check the number of existing episodes.",
    "As an AI model, I don't have access to the local files on your machine. However, it seems like this code snippet is reading data from CSV files into pandas DataFrames. The code is using the 'read_csv' function of pandas to read from files called 'simpsons_characters.csv', 'simpsons_locations.csv', 'simpsons_script_lines.csv', and 'simpsons_episodes.csv'. These DataFrames are then reset to have a new index.",
    "Preview the characters dataset\ndf_characters.head()",
    "Merging character names into the script DataFrame\ndf_script = pd.merge(df_script, df_characters, how='inner', left_on='character_id', right_on='id', suffixes=('_script', '_character'))",
    "View some data from the locations DataFrame\ndf_locations.head()",
    "# Load the English model\nnlp = spacy.load('en_core_web_sm')",
    "Set maximum columns/rows to display for dataframes\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)",
    "Preview and reset index of all dataframes",
    "# Set local environment to use VADER\nos.environ['VADER_COMPOUND'] = '1'",
    "Let's take a look at the first few rows of each dataset.",
    "ensure data/simpsons folder exists\nif not os.path.exists('data/simpsons'):\n    print('Creating directory data/simpsons')\n    os.makedirs('data/simpsons')",
    "Check the first five rows of the characters DataFrame\ndf_characters.head()",
    "Display first few lines of the dataframe\ndf_script.head()",
    "View the first 3 rows of the script dataframe\ndf_script.head(3)",
    "Filter out incorrect rows in df_episodes",
    "Check the shape of the datasets",
    " Check the first few rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Print the first few rows of the dataset for sanity check\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " The head of the episode dataframe\ndf_episodes.head()",
    " Grabs a random sample from the dataframe\nsample_line = df_script.sample()",
    "A quick look at the data shows that it needs a bit of cleaning up before it'll be very useful to us.",
    "Create a joining table between the episodes and script lines DataFrame\ndf_episodes['id'] = df_episodes['id'].astype(str)\ndf_script['episode_id'] = df_script['episode_id'].astype(str)\n\ndf_episodes_script = df_episodes.set_index('id').join(\n    df_script.set_index('episode_id'),\n    rsuffix='_episode',\n    how='right'\n)",
    " Strip leading whitespace characters",
    "Remove the rows which have no dialogue, and remove the unuseful columns",
    "Print info of the characters dataframe\nprint(df_characters.info())",
    "Examine the data\ndf_characters.head()",
    "Print file shapes\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_characters.shape)\nprint('Script:', df_characters.shape)\nprint('Episodes:', df_characters.shape)",
    "Remove the unamed column from dataframes",
    "# Split dataset into train, validation and test datasets\ntrain_dataset = dataset.sample(frac=0.6, random_state=0).reset_index(drop=True)\nvalid_dataset = dataset.drop(train_dataset.index).reset_index(drop=True)\ntest_dataset = valid_dataset.sample(frac=0.5, random_state=0).reset_index(drop=True)\nvalid_dataset = valid_dataset.drop(test_dataset.index).reset_index(drop=True)",
    " Display first 5 rows of each dataframe\ndfs = {'characters': df_characters, 'locations': df_locations, 'script': df_script, 'episodes': df_episodes}\nfor name, dframe in dfs.items():\n    print('\\n' + name.upper())\n    print(dframe.head())",
    " Let's start by having a look at a few rows of each of our dataframes.",
    "Filter out boring Simpsons characters",
    "Creating a character-level dataset for each character in the list",
    " Check that directories exists or create them\ntry:\n    for directory in ['images', 'vocabulary', 'dataframes']:\n        os.makedirs(directory)\nexcept FileExistsError:\n    print(\"Directories already exist\")",
    "Filtering datasets.",
    "Create a new column 'raw_character_text' in the df_script dataframe to store the raw text from the Simpsons script.",
    "Load spacy model to get word embeddings",
    "Display first 5 rows of Simpsons characters dataframe\ndf_characters.head()",
    "Check the content of Simpsons characters dataset",
    "Extract the 'raw_text' from 'df_script' DataFrame and convert it to a list",
    " Set up spacy\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\n\n# Setup pandas\npd.set_option('display.max_columns', None)",
    "Limit the number of rows to 5000 to speed up computations\ndf_script = df_script.head(5000)",
    "Check shape of the DataFrames\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Select the character names and the raw lines from the script data frame and join with the characters data frame to get the characters' gender.",
    "Load language model\nnlp = spacy.load('en_core_web_sm')",
    "Check data samples",
    "Merge the episode and script dataframes on the episode_id column\ndf = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id', suffixes=('_script', '_episode')).drop('id', axis=1)",
    "Check the first five rows of the characters dataframe.",
    "Merge the scripts, characters, and locations in a single dataframe.",
    "Define the base directory where the NLP model is saved\nnlp_base_dir = \"C:/nlp_model\"",
    "Show first rows of characters df\ndf_characters.head()",
    "Removing all non speaking_lines\nspeaking_lines = df_script[df_script.speaking_line]\nspeaking_lines_idxs = speaking_lines.line_id\n\n#cleaning the strings for speakers and raw_texts\nspeaking_lines.raw_text = speaking_lines.raw_text.str.replace('\\r', ' ')\nspeaking_lines.raw_text = speaking_lines.raw_text.str.replace('\\n', ' ')\nspeaking_lines.character_id = speaking_lines.character_id.str.replace('^\\s+', '', regex=True)",
    "Merge with characters and locations names\ndf_script = df_script.merge(df_characters[['id', 'name']], how='left', left_on='character_id', right_on='id', suffixes=('', '_c')).drop('id', axis=1)\ndf_script = df_script.merge(df_locations[['id', 'name']], how='left', left_on='location_id', right_on='id', suffixes=('', '_l')).drop('id', axis=1)",
    "Display some lines from the main dataframe\nwith pd.option_context(\"display.max_rows\", 3, \"display.max_columns\", 6):\n    display(df_script.head(2))",
    "merge script with character and location data\ndf_characters.rename(columns={'id': 'character_id'}, inplace=True)\ndf_locations.rename(columns={'id': 'location_id'}, inplace=True)\ndf_episodes.rename(columns={'id': 'episode_id'}, inplace=True)\n\ndf_script = pd.merge(df_script,\n                     df_characters[['character_id', 'name']],\n                     on='character_id')\ndf_script = pd.merge(df_script,\n                     df_locations[['location_id', 'name']],\n                     on='location_id')\ndf_script = pd.merge(df_script,\n                     df_episodes[['episode_id', 'title']],\n                     on='episode_id')",
    "Preview the first 5 rows of each dataframe",
    "Display the basic information of characters dataset\ndf_characters.info()",
    "Checking the heads of the datasets to better understand their structure.",
    "# Display the first few rows of the dataframe\ndf_script.head()",
    "Check for NaN in each dataframe\nprint(df_characters.isna().sum())\nprint(df_locations.isna().sum())\nprint(df_script.isna().sum())\nprint(df_episodes.isna().sum())",
    "View the content of each file",
    "Let's take a brief look at the structure of the datasets.",
    " Start by getting an overview of the data",
    " Check the first 5 characters of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Let's take a look at the structure of the datasets.",
    "Remove rows with missing 'spoken_words' and 'raw_text' values\ndf_script = df_script.dropna(subset=['spoken_words', 'raw_text'])",
    "Display max rows and columns\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)",
    "Checking the data in df_characters dataframe.",
    "Remove lines where the speaking character id is not in the characters dataframe",
    "Set seed for reproducibility of the results\nnp.random.seed(0)",
    "This will allow us to see how many unique and major characters, episodes, and locations we are working with.",
    "Define spacy model and stop words",
    "Quick overview of the dataset\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    " Set up statistics for the characters.",
    "Remove episodes with missing data\ndf_episodes = df_episodes.dropna(subset=['original_air_date'])",
    "# Define a function to display full dataframes\ndef display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000):\n        display(df)",
    "Drop all the na entries from the script, characters and location dataframes",
    "Characters and Locations CSVs are already preprocessed. Let's display some examples to understand the data better.",
    "Quick overview of the script dataframe\ndf_script.head()",
    "Check, that everything went right \nprint('Number of characters: ', df_characters.shape[0])\nprint('Number of locations: ', df_locations.shape[0])\nprint('Number of episodes: ', df_episodes.shape[0])\nprint('Number of lines: ', df_script.shape[0])",
    "Inspect the structure of the characters data frame",
    "We need to load the spaCy model that we will use for natural language processing.",
    "Preview first 5 rows of each dataframe\nprint(\"--- Characters ---\")\ndisplay(df_characters.head())\n\nprint(\"--- Locations ---\")\ndisplay(df_locations.head())\n\nprint(\"--- Script ---\")\ndisplay(df_script.head())\n\nprint(\"--- Episodes ---\")\ndisplay(df_episodes.head())",
    "Display the first few rows of each dataframe to understand the data",
    " Visualize the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    "# Set seaborn aesthetic parameters to defaults\nsns.set()",
    " We will preprocess the data to remove missing values and merge the relevant columns.",
    "Let's preview each table to understand the data we're working with.",
    "Check the content of `df_script`",
    "Set display options for Pandas to display nicely\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', -1)",
    "Join the datasets\ndf_script = (\n    df_script\n    .merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('', '_episode'))\n    .merge(df_characters, left_on='character_id', right_on='id', suffixes=('', '_character'))\n    .merge(df_locations, left_on='location_id', right_on='id', suffixes=('', '_location'))\n)",
    " Display the first few rows of the dataframe for inspection\ndf_script.head()",
    " Transform raw data before feature creation",
    " Use tqdm to visualize progression of pandas apply\ntqdm.pandas()",
    "# Extracting the main script from the data and dropping the columns not needed\ndf_main = df_script[['episode_id', 'number', 'raw_text', 'timestamp_in_ms']]\ndf_main.sort_values(['episode_id', 'number'], inplace=True)\ndf_main = df_main[df_main['timestamp_in_ms'] > 0]",
    "Character lines dataset\nline_data = pd.merge(df_script, df_episodes, on='episode_id', how='inner')",
    "Check the shape and sample of the dataset\ndf_script.shape",
    "Preview the characters dataset\ndf_characters.head()",
    "Check DataFrame structure for each dataset",
    "Merge characters and locations to get character_speech\ndf_char_loc = pd.merge(df_script, df_characters, how='left', left_on='raw_character_text', right_on='character_text')\ndf_char_loc.rename(columns={'character_id': 'raw_character_id', 'name': 'raw_character_name'}, inplace=True)\ndf_char_loc = pd.merge(df_char_loc, df_locations, how='left', left_on='raw_location_text', right_on='location_text')\ndf_char_loc.rename(columns={'location_id': 'raw_location_id', 'name': 'raw_location_name'}, inplace=True)",
    "Show the first 5 records of the characters dataframe\ndf_characters.head()",
    "Create new column with the script's length for each character and unite the data into a single DataFrame",
    "Clean the characters dataframe.\ndf_characters.head()",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Quick look at the scripts dataframe\ndf_script.head()",
    "Check the first few rows of each dataframe",
    "Some basic info of the datasets",
    "Show the first few rows of the characters dataframe\ndf_characters.head()",
    "Data visualization and exploration",
    "Reading the datasets from CSV files and resetting the index of each DataFrame.",
    " Merge all datasets into a single dataframe\ndf = (df_script\n      .merge(df_episodes, on='episode_id')\n      .merge(df_characters, on='character_id', how='left')\n      .merge(df_locations, on='location_id', how='left'))",
    " Some configurations for displaying datasets in an easily readable way\npd.set_option('display.max_columns', None)",
    "Create a connection to a database",
    "Visualize missing values",
    "\n# Display the first 5 script lines\ndf_script.head()",
    "Word clouds are a popular way to visualize word frequencies in a corpus of text. Let's create a word cloud for the Simpsons script lines to see which words are most common.",
    "Check out the first few rows of the characters dataframe\ndf_characters.head()",
    "Check the dataframes' dimensions",
    " Set the display options for large DataFrames\npd.set_option('display.max_columns', None)",
    " Characters Avatar\ndf_characters['raw_character_text']",
    "For the rest of the article, we'll focus only on the `df_script` DataFrame.",
    " Display the first few rows of the dataframe\ndf_characters.head()",
    "Word cloud function\ndef plot_wordcloud(words, title, save_as=None):\n    word_cloud = WordCloud(width = 1000, height = 500, background_color='black', stopwords=STOPWORDS).generate(words)\n\n    plt.figure(figsize=(15,8))\n    plt.imshow(word_cloud)\n    plt.title(title, fontdict={'size':20})\n    plt.axis('off')\n\n    if save_as:\n        plt.savefig(save_as, format='png')\n        plt.close()\n    else:\n        plt.show()",
    "\n# Import the required modules for processing data and creating visualizations",
    "Checking the data shapes",
    "Em primeira instancia vamos fazer uma analise nos caracteres, depois analisaremos os locais e finalmente os scripts, por isto vou\n# separar cada uma em sua propria variavel para cada uma das analises.",
    "Before continuing, let's take a look at the first few rows of each dataframe to understand their structure and contents.",
    "Display available data\nprint(\"Characters\")\ndisplay(df_characters.head(5))\nprint(\"Locations\")\ndisplay(df_locations.head(5))\nprint(\"Script\")\ndisplay(df_script.head(5))\nprint(\"Episodes\")\ndisplay(df_episodes.head(5))",
    "Let's take a look at the structure of our dataframes.",
    "Let's see the content of each table.",
    "Display the first 5 rows of the \"script\" dataframe to understand its structure and content\ndf_script.head()",
    "Let's display the first couple of rows of each of our dataframes to see what they look like:\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check data load success\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Viewing the first few rows of the character data\ndf_characters.head()",
    "import spacy\n\n# Load the large English NLP model\nnlp = spacy.load('en_core_web_lg')",
    "Inspect the dataframes",
    "pd.set_option('display.max_columns', None)",
    "Check the first row of the dataframe to ensure it loaded correctly\ndf_script.head(1)",
    "Show the first 5 rows of the script dataframe\ndf_script.head()",
    " Display first 5 rows of df_characters\ndf_characters.head()",
    "Visualize the number of episodes in the dataset\nepisodes_per_season = df_episodes['season'].value_counts().sort_index()\n\nplt.figure(figsize=(10, 6))\nplt.bar(episodes_per_season.index, episodes_per_season.values, color='skyblue')\nplt.title('Number of episodes per season')\nplt.xlabel('Season')\nplt.ylabel('Number of episodes')\nplt.show()",
    "Drop NaN values in 'raw_text' and 'character_id' columns\ndf_script = df_script.dropna(subset=['raw_text', 'character_id'])",
    "Filtering the data to remove unnecessary columns and NaN values",
    "Show sample lines from the script\ndf_script.head()",
    "Exploring the dataset",
    "Start by using the describe method to get a sense of the statistics for each variable.",
    "Display the first few rows of the characters DataFrame\ndf_characters.head()",
    "show some statistics for easy reference\nprint(f'Characters dataframe has {len(df_characters)} rows and '\n      f'{len(df_characters.columns)} columns.')\nprint(f'Locations dataframe has {len(df_locations)} rows and '\n      f'{len(df_locations.columns)} columns.')\nprint(f'Script dataframe has {len(df_script)} rows and '\n      f'{len(df_script.columns)} columns.')\nprint(f'Episodes dataframe has {len(df_episodes)} rows and '\n      f'{len(df_episodes.columns)} columns.')",
    " Display the first few rows of the dataframe\ndf_script.head()",
    " clean script df\ndf_script_clean = df_script.dropna(subset=['raw_text'])  # Remove rows with NaN in 'raw_text' column",
    "Using the `head` function to display the first few rows of the dataframe.",
    "Show all script lines\npd.set_option('display.max_colwidth', -1)\ndf_script.head()",
    "# Setup spacy\nnlp = spacy.load('en_core_web_sm')",
    " Show the initial records from the dataframe.",
    "Check the first few lines of the characters dataframe\ndf_characters.head()",
    "Inspecting the first entries of the dataset",
    "Let's take a quick look at the structure of the datasets.",
    " Set the maximum column width to avoid output or data representation issues",
    " Checking dataframes dimensions",
    "First, let's perform some basic exploratory data analysis (EDA) to get a feel for the data.",
    "Inspect the characters dataframe\ndf_characters.head()",
    "Path to Spacy model\nnlp = spacy.load('en_core_web_sm')",
    "Explore the characters dataframe\ndf_characters.head()",
    "Define the font to use for plots\nplt.rcParams['font.family'] = 'DejaVu Sans'",
    "Explore the data\ndf_characters.head()",
    "Display a sample of each dataframe to know the data features",
    "Concatenate CSVs to a single dataframe",
    "Display the number of rows and columns for each dataframe\nprint(f\"Characters dataframe shape: {df_characters.shape}\")\nprint(f\"Locations dataframe shape: {df_locations.shape}\")\nprint(f\"Script dataframe shape: {df_script.shape}\")\nprint(f\"Episodes dataframe shape: {df_episodes.shape}\")",
    "View DataFrame information\ndf_script.info()",
    "Print the first 5 rows of each of the imported DataFrames\nprint('\\nCharacters DataFrame:')\nprint(df_characters.head(5))\n\nprint('\\nLocations DataFrame:')\nprint(df_locations.head(5))\n\nprint('\\nScript DataFrame:')\nprint(df_script.head(5))\n\nprint('\\nEpisodes DataFrame:')\nprint(df_episodes.head(5))",
    "merge script and location on\n#location_id\ndf_merged = pd.merge(df_script, df_locations, how='inner', on='location_id')",
    "Check dataframes structure\ndf_characters.head()",
    "Spacy's nlp pipeline, thanks to this pipeline we can have access to the entities recognized.",
    "Inspect some sample data\ndf_script.head()",
    "Exploratory Data Analysis (EDA)",
    "Preview the first three rows of the characters data\ndf_characters.head(3)",
    "Most of the data:\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "Display the columns of the script dataframe\ndf_script.columns",
    "Remove duplicated episode titles and join tables",
    "Hide all warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
    "Display some information about the datasets\nprint(\"Characters info:\")\nprint(df_characters.info())\nprint(\"\\nLocations info:\")\nprint(df_locations.info())\nprint(\"\\nScript info:\")\nprint(df_script.info())\nprint(\"\\nEpisodes info:\")\nprint(df_episodes.info())",
    " Check that the data is correctly loaded\ndf_script.head()",
    "Set character_id as index for fast sclicing\ndf_characters.set_index('id', inplace=True)\n\n# Setup Spacy\nnlp = spacy.load(\"en_core_web_sm\")",
    "Checking out the first few rows of each dataframe",
    "Remove rows with missing data\ndf_script = df_script.dropna(subset=['normalized_text'])",
    "Because we're going to be doing some text processing notebooks, we will load in the natural language processing model from `spaCy`.",
    "We'll see the structure of the main datasets",
    "Preview the characters dataframe\ndf_characters.head()",
    "Let's take a look at the data.",
    " save the script data to disk\nscript_file = 'data/simpsons_script.csv'\n\nif not os.path.isfile(script_file):\n    print(f\"Saving script data to {script_file}\")\n    df_script.to_csv(script_file, index=False)",
    "Declare print function for head of tables\ndef print_head(df, n=5):\n    print(df.shape)\n    display(df.head(n))",
    "Let's take a look at the dataframes to see what we're working with.",
    "Inspect the dataframes to understand their structure and contents",
    "Get some info of datas\nprint(df_characters.info())\nprint(df_locations.info())",
    "Optional: Display the first few rows of each dataframe to understand their structure and contents.",
    "# Shows the first entries of the characters dataframe\ndf_characters.head()",
    "DataFrame's info\ndf_characters.info()",
    "Display the first few rows of each dataframe to understand the data",
    "Remove punctuation and format text data",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Set the display options to properly display dataframes",
    "Check the first few rows of each dataframe to get an understanding of the data",
    " Check if the following fields will have null values:\n# 'character_id': always filled / integer\n# 'episode_id': always filled / integer\n# 'location_id': always filled / integer\n# 'id': always filled / integer\n# 'text': always filled / string",
    "# Set the max width of the columns for better visibility\npd.options.display.max_colwidth = 100",
    "Merge episode, character and location data into script data\ndf_script = df_script.merge(df_episodes, on='episode_id')\ndf_script = df_script.merge(df_characters, on='character_id', suffixes=('', '_character'))\ndf_script = df_script.merge(df_locations, on='location_id', suffixes=('', '_location'))",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "check what the dataframes look like\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "First we are importing typical Python libraries such as os, pandas, numpy, spacy, matplotlib, etc. Then we are importing some specific functions and libraries we will use in the script. After the imports, we are reading CSV files using pandas and creating DataFrames for characters, locations, script lines, and episodes from The Simpsons dataset.",
    "Add column with text length in words\ndf_script['word_count'] = df_script['normalized_text'].str.split().apply(len)",
    "Converting 'raw_text' column into string type",
    "Create new dataframe with a fraction of the script lines for testing\ndf_script_test = df_script.sample(frac=0.1, replace=True, random_state=1)\n\n# Save \"name\" and \"line\" columns to separate variables for testing\ntest_names = df_script_test.name.values\ntest_lines = df_script_test.raw_text.values",
    " Set pandas options to not truncate columns when printing\npd.set_option('display.max_colwidth', -1)",
    "Optional print dataframes for a quick overview\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Load scripts since some characters don't appear in the provided script (about 500MB)\nif os.path.isfile('data/simpsons_script_lines_sc.csv'):\n    df_script_sc = pd.read_csv('data/simpsons_script_lines_sc.csv').reset_index(inplace=False, drop=True)\nelse:\n    df_script_sc = pd.read_csv('data/simpsons_script_lines.csv').sample(frac=0.25).reset_index(drop=True)\n    df_script_sc.to_csv('data/simpsons_script_lines_sc.csv')",
    "Show how the script data looks like\ndf_script.head()",
    " Load locations and main characters CSV files\ndf_locations = pd.read_csv('data/simpsons_locations.csv')\ndf_characters = pd.read_csv('data/simpsons_characters.csv')",
    "Separate lines into dialogues from the same scene and speaker.",
    " Select the 4000 most common words in the dataset",
    "Inspect the characters table",
    " Display snippets of each dataframe\nprint(\"\\nSimpsons characters dataframe\")\ndisplay(df_characters.head())\nprint(\"\\nSimpsons locations dataframe\")\ndisplay(df_locations.head())\nprint(\"\\nSimpsons script dataframe\")\ndisplay(df_script.head())\nprint(\"\\nSimpsons episodes dataframe\")\ndisplay(df_episodes.head())",
    "  - Remove invalid entries",
    "SOME_DISPLAY = 5",
    "Create a directory to store the images if it does not exist\nif not os.path.exists('images'):\n    os.makedirs('images')",
    "Filter out non-speaking lines",
    "Checking the general structure of the datasets",
    " Print dfs to see sample data and how they look",
    " remove unwanted white spaces form `simpson_characters.csv`\ndf_characters = df_characters.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)",
    "Display the dimensions and the head of the dataframes",
    " Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Create a DataFrame that retrieves the main details about each script line as well as the character and location names.",
    "Setting the settings\npd.set_option('display.max_columns', None)",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "display only the first 5 records of df_characters\ndf_characters.head()",
    "Remove any duplicate rows\ndf_script.drop_duplicates(inplace=True)",
    "Display the number of records of each dataset\nprint('Number of records in characters dataset:', len(df_characters))\nprint('Number of records in locations dataset:', len(df_locations))\nprint('Number of records in script dataset:', len(df_script))\nprint('Number of records in episodes dataset:', len(df_episodes))",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Let's explore the dataset one by one.",
    " Clean character names\ndf_characters.character_id = df_characters.character_id.apply(str)\ndf_script.character_id = df_script.character_id.apply(str)",
    "Some basic visualisations to understand our datasets better.",
    " Check data\ndf_characters.head()",
    "Let's take a first look at the data.",
    " For simplicity, let's concatenate all the lines in the script together, segmenting them by episode.",
    "Converts date attributes to Python date objects\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])\n\n# Drop unnecessary columns and rename others\ndf_episodes.drop(['id', 'image_url', 'video_url'], axis=1, inplace=True)\ndf_episodes.rename(columns={'id_s': 'episode_id', 'id': 'character_id', 'name': 'character_name'}, inplace=True)",
    "We'll start by loading the data into pandas dataframes.",
    "merge location and episodes dataframes",
    " Custom header\nfrom jupyterthemes import jtplot\njtplot.style(theme='chesterish', context='notebook', ticks=True, grid=False)",
    "Check our datasets\ndf_characters.head()",
    "Display general information about the script dataset\nprint(df_script.shape)\nprint(df_script.dtypes)",
    "Merge episodes and scripts\ndf = pd.merge(df_script, df_episodes, on='episode_id')",
    "Let's take a look at the first few rows of each dataframe to understand the data better.",
    "Check the number of lines of each csv file\nprint(\"Number of characters: \", len(df_characters))\nprint(\"Number of locations: \", len(df_locations))\nprint(\"Number of lines scripts: \", len(df_script))\nprint(\"Number of episodes: \", len(df_episodes))",
    "Let's take a look at the first few rows of each of these DataFrames.",
    " Display the first few columns of the dataframe\ndf_script.head()",
    "Show the first 5 rows of the characters dataframe\ndf_characters.head()",
    " Tokenization ",
    "Display the first few rows of the dataframe\ndf_script.head()",
    "# Remove rows with empty character names\ndf_script = df_script.dropna(subset=['raw_character_text'])",
    "Check what we have in each DataFrame\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
    "Checking the data in the datasets",
    "Merge all available data into one dataframe.",
    "The first line of code imports the data from CSV files into pandas dataframes.",
    "Remove unnecessary columns\ndf_script = df_script.drop(columns=['id', 'number', 'raw_text', 'timestamp_in_ms'])",
    "# Ensure the script is correctly imported\ndf_script.head()",
    "Merge characters and script dataframes\ndf_characters_and_script = pd.merge(df_script,\n                                    df_characters,\n                                    left_on='character_id',\n                                    right_on='id',\n                                    suffixes=(False, False))",
    "Read one example of each table",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Checking shapes of dataframes",
    "Explore the data\ndf_characters.head()",
    " Data preview\ndf_characters.head()",
    "Rows to display\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    "# Let's take a quick look at the datasets\ndf_characters.head()",
    "Check how the data looks like",
    " Display the dataframes to understand their structure and contents\ndf_characters",
    "df_script.head()",
    " I'm not sure where this code is going or what its purpose is, but it appears to be loading data from CSV files into Pandas DataFrames.",
    " Load the pre-built NLP model - spacy.load('en')",
    "Extract the data path\ndata_path = 'data/'",
    "Overview of characters DataFrame\nprint(df_characters.shape)\nprint(df_characters.head())",
    "Show more columns\npd.set_option('display.max_columns', None)",
    " View the first 5 rows of the characters dataframe\ndf_characters.head()",
    " Display of loaded datasets",
    "Setup\nnlp = spacy.load(\"en_core_web_sm\")",
    "Load the data from the CSV files into pandas DataFrames.",
    "For now, drop the seven episodes that do not have any line associated with them",
    "For plotting\nfont = {'family' : 'normal',\n        'weight' : 'bold',\n        'size'   : 22}\n\nmatplotlib.rc('font', **font)",
    "Print the dataset shapes\nprint(f'Characters: {df_characters.shape}')\nprint(f'Locations: {df_locations.shape}')\nprint(f'Script lines: {df_script.shape}')\nprint(f'Episodes: {df_episodes.shape}')",
    "Display the first five rows of the characters dataframe\ndf_characters.head()",
    "# Set up\nnlp = spacy.load('en_core_web_sm')\n\n# Only consider named entities that are characters or locations\ndf_script_filtered = df_script[(df_script['raw_character_text'].notnull()) | (df_script['raw_location_text'].notnull())]\n# Replace nans with empty strings\ndf_script_filtered = df_script_filtered.fillna('')\n\n# Lemmatization mapping\nlemmatization_df = pd.read_csv('data/lemmatization.csv', index_col=0, squeeze=True).to_dict()",
    "Display the data\ndf_script",
    "Check the first rows of the characters dataframe.",
    "Limit the number of script lines for this example\ndf_script = df_script.head(10000)",
    "Select only these characters with known locations:\nknown_characters = df_characters[df_characters['location_id'].notnull()]['character_id'].values\n\n# Filter the lines only to those spoken by known characters\ndf_script_known = df_script[df_script['character_id'].isin(known_characters)]\n\nprint(f'The dataset contains {len(df_script_known)} lines of {len(known_characters)} characters with known locations')",
    "Show the head of each loaded dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Remove any blank/NaN/Null values in the raw script data",
    "View first 5 rows of the characters dataframe\ndf_characters.head()",
    "Create a pandas series with the top characters and create a word cloud.",
    "# Display the last 5 rows of the character DataFrame\ndf_characters.tail(5)",
    "Display some simple informatoin basic infomraiton about the DataFrames\nprint(f'Characters dataframe shape: {df_characters.shape}')\nprint(f'Locations dataframe shape:  {df_locations.shape}')\nprint(f'Script dataframe shape:      {df_script.shape}')\nprint(f'Episodes dataframe shape:    {df_episodes.shape}')",
    "Check the shape and the first 5 rows of each DataFrame",
    "Merge script with locations and characters\ndf_script = df_script.merge(df_episodes[['id', 'season', 'number_in_season', 'number_in_series']], on='id')\n\ndf_script = df_script.merge(df_characters, on='character_id')\n\ndf_script = df_script.merge(df_locations, on='location_id')",
    " Data cleaning",
    "We will start by taking a look at the data to understand its structure and content.",
    " Let's start by taking a look at the first few rows of each DataFrame.",
    "# Smaller dataset with male and female\ndf_script_small = df_script[(df_script['gender'] == 'm') | (df_script['gender'] == 'f')]\ndf_script_small = df_script_small.sample(10000, random_state=42)\n\n# \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n# \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n# Get word counter for each character\n",
    " To be continued...",
    "# Dress dataset",
    "Show first few rows\ndf_script.head()",
    "Add a column for the number of words in each script line",
    "Join datasets\n# Merge the datasets to have all the information in the same DataFrame\ndf = df_script.merge(df_episodes, on='episode_id')\ndf = df.merge(df_characters, on='character_id', suffixes=('', '_from'))\ndf = df.merge(df_locations, on='location_id', suffixes=('', '_from'))",
    " Merge characters and script dataframes\ndf_characters_script = pd.merge(df_characters, df_script, left_on='id', right_on='character_id')\ndf_characters_script.head()",
    "Join the DataFrames",
    "Check dataframes\ndf_characters.head()",
    "Get a preview of the characters data\ndf_characters.head()",
    "Check the contents of the character dataframe\ndf_characters.head()",
    "\n# Display the first 5 rows of the Characters dataframe\ndf_characters.head()",
    " display dataframe\ndf_characters.head()",
    " Display the first few rows of the character dataframe\ndf_characters.head()",
    "Replace NaN values with empty strings\ndf_script = df_script.fillna('')",
    "Set the global parameters for the notebook.",
    " Display the first few rows of the dataframe\ndf_characters.head()",
    "Dude, select the specific character we are  gonna be using\ncharacter_name = \"Bart Simpson\"",
    "Set the following configurations to avoid truncating DataFrame display (optional)\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    "Let's take a quick look at the dataframes to understand their structure.",
    "Checking first rows for each dataset\ndf_characters.head()",
    "Setting the figure sizes\nmatplotlib.rcParams['figure.figsize'] = (20, 15)",
    "Basic exploration of 'Simpsons' dataset",
    "Display first 5 records of each dataframe to understand its structure\nprint(\"Characters\")\ndisplay(df_characters.head())\n\nprint(\"Locations\")\ndisplay(df_locations.head())\n\nprint(\"Script\")\ndisplay(df_script.head())\n\nprint(\"Episodes\")\ndisplay(df_episodes.head())",
    "Merge script with characters and keep only necessary columns\ndf_lines = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('', '_char'))\ndf_lines = df_lines[['id', 'season', 'episode_id', 'number', 'raw_text', 'name']]\n\n# ",
    "change the password to your student's ID number\npassword = 123456789",
    "Display first 5 lines of characters dataset\ndf_characters.head()",
    "Merge with character information\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('','_character')).drop(labels='id_character', axis=1)\n\n# Merge with location information\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id', suffixes=('','_location')).drop(labels='id_location', axis=1)\n\n# Merge with episode information\ndf_script = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('','_episode')).drop(labels='id_episode', axis=1)\n\n# Display the resulting dataframe\ndf_script.head()",
    " Display the first 5 rows of each dataframe\nprint('Characters:')\nprint(df_characters.head())\nprint('\\n\\nLocations:')\nprint(df_locations.head())\nprint('\\n\\nScript:')\nprint(df_script.head())\nprint('\\n\\nEpisodes:')\nprint(df_episodes.head())",
    "Remove any rows that have NaN values for the character speaking or the dialogue.",
    " Check file integrity\nlen(df_episodes)",
    " Lowercase character names in the characters dataframe\ndf_characters['name'] = df_characters['name'].str.lower()",
    "Inspect the data frames",
    "Inspect the first few lines of each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Display first rows of the characters dataframe\ndf_characters.head()",
    "Explore the content of the characters file\ndf_characters.head()",
    "Checking the general structure of each dataframe",
    "Preview the characters data\ndf_characters.head()",
    "Limiting script to the first character's line",
    " Check the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Display the first few rows of each table to understand its structure and the information it contains.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect the header of the characters DataFrame\ndf_characters.head()",
    "Merge characters and script\ndf_script = df_script[df_script.raw_character_text != \"\"]\ndf_script = pd.merge(df_script, df_characters, how=\"left\", on=[\"raw_character_text\"])",
    "Inspect the first few rows of the characters DataFrame\ndf_characters.head()",
    " Set the size of the graphs\nmatplotlib.rcParams['figure.figsize'] = (10, 5)",
    " Display the first 5 rows of each dataframe to get an idea of the data",
    "Set pandas to show all the columns in the dataframe\npd.set_option('display.max_columns', None)",
    "Remove all non speaking_lines from script\ndf_script = df_script[df_script['speaking_line'] == True]",
    "df_script.head()",
    "Filter some locations which contain non-ASCII characters\ndf_locations_filtered = df_locations[df_locations['name'].apply(lambda x: x.isascii())].copy()\n\n# Extract character names\ncharacters = df_characters['name'].tolist()\n",
    "General information about the character dataset\nprint(df_characters.shape)\nprint(df_characters.columns)\nprint(df_characters.dtypes)",
    "Preview the dataframes\nprint('Characters:')\ndisplay(df_characters.head(5))\nprint('Locations:')\ndisplay(df_locations.head(5))\nprint('Script:')\ndisplay(df_script.head(5))\nprint('Episodes:')\ndisplay(df_episodes.head(5))",
    "Quick peek at the data",
    " Display the first few rows of the characters dataset\ndf_characters.head()",
    "# Count the number of lines spoken by each character\nlines_per_character = df_script['character_id'].value_counts()\n\n# Count the number of locations where each character appears\nlocations_per_character = df_script.drop_duplicates(subset=['location_id', 'character_id'])['character_id'].value_counts()",
    "\n# Convert character_id to int\ndf_script['character_id'] = df_script['character_id'].astype('Int64')\n\n# Create a column containing only the year of the episode\ndf_episodes['year'] = df_episodes['original_air_date'].str[:4]",
    "remove rows with empty \"normalized_text\" column\ndf_script = df_script.dropna(subset=['normalized_text'])",
    "Examine the structure of the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Apply `Contract` and `df_script` dataframes",
    "Check the content of the episodes.csv file",
    "Set the seed for reproducing the results",
    "Merge dataframes",
    "Visualize the top 30 characters by number of appearances\ntop_30_characters = df_script.speaking_line_id.value_counts()[:30]\n\nfig, ax = plt.subplots(figsize=(20, 10))\nax.bar(top_30_characters.index, top_30_characters.values, color='b')\n\nax.set(title='Top 30 characters by number of appearances', xlabel='Character id', ylabel='Number of appearances')\nax.grid(True)\nplt.xticks(rotation=90)",
    "Let's see what the data looks like.",
    " Let's take a look at the first 5 rows of our character dataframe to see what it looks like.\ndf_characters.head()",
    "let's take a look at the content of the first 5 lines (5 rows and all columns) of the lines dataset.\ndf_script.head()",
    " Show the head of the dataframe to understand better what kind of data we are dealing with\ndf_script.head()",
    "Parser to extract entities in a consistent manner.\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'textcat'])",
    "Combine script lines, characters, locations, and episodes into one dataframe.",
    "Setting up matplotlib styles\nplt.style.use('fivethirtyeight')",
    "Explore the first lines of each dataframe",
    "']]['raw_text'] = df_script['raw_text'].str.replace('[^\\w\\s]','')",
    "Limit the number of script lines to 5,000 for speed reasons\ndf_script = df_script[:5000]",
    " Split the 'raw_text' speech into a list of quotes of parts of 7 types.",
    "Load Spacy\nnlp = spacy.load('en_core_web_sm')",
    "Merge dataframes together",
    "Set the seed for reproducibility",
    " Let's check the structure of the character dataframe.",
    "Display the first few rows of the characters dataframe to understand its structure\ndf_characters.head()",
    "Set up wordcloud\nfont_path = '/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf'\nwordcloud = WordCloud(\n    width = 900,\n    height = 500,\n    background_color = 'black',\n    stopwords = STOPWORDS,\n    contour_width = 0.5,\n    contour_color = 'steelblue',\n    collocations = False,\n    colormap = 'viridis',\n    font_path = font_path\n)",
    "Inspecting first few lines of 'characters' dataframe\ndf_characters.head()",
    "Check to see the loaded datasets look like.",
    "Display the first 5 rows of each DataFrame\nprint(\"Characters\")\ndisplay(df_characters.head())\nprint(\"\\nLocations\")\ndisplay(df_locations.head())\nprint(\"\\nScript\")\ndisplay(df_script.head())\nprint(\"\\nEpisodes\")\ndisplay(df_episodes.head())",
    "check the first 5 rows of one of the dataframes\ndf_characters.head()",
    "Set up the WordCloud with the parameters specified in the task",
    "Look at first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "# ensure all dataset load correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Creating a new column containing the tokenized version of the 'spoken_words' column.",
    " Let's take a look at the data.",
    " Let's take a look at the first few rows from each dataframe to understand the data better.",
    "We'll use the 'episode_id' field as index for every dataframe\ndf_characters.set_index('episode_id', inplace=True)\ndf_locations.set_index('episode_id', inplace=True)\ndf_script.set_index('episode_id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "Create an instance of the English class in spaCy.",
    "Visualizing the dataset by printing out the first few rows",
    "print('Script shape:', df_script.shape)\nprint('Character shape:', df_characters.shape)\nprint('Location shape:', df_locations.shape)\nprint('Episodes shape:', df_episodes.shape)",
    "Increase the max number of columns to display for the PD dataframes, as follows",
    "\n# Add the content of the script to the corresponding characters and locations\n",
    "Let's start by looking at the first few entries of each DataFrame.",
    " Display first rows of df_characters\ndf_characters.head()",
    "Data Dimensions\nprint('Dimensions of the Data')\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "# Merge script, characters, locations and episodes files\ndf_script['character_id'] = df_script['character_id'].astype('Int64')\ndf_script['location_id'] = df_script['location_id'].astype('Int64')\ndf_script = df_script \\\n        .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character')) \\\n        .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('_script', '_location')) \\\n        .merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('_script', '_episode'))\n\n# Sort the df_script to always have the episodes in order\ndf_script = df_script.sort_values(by=['imdb_rating', 'original_air_date', 'season', 'number_in_season', 'number_in_series'])\n\n# We don't need the same information twice or ids\ndf_script.drop(['id_script', 'id_character', 'id_location', 'id_episode'], axis=1, inplace=True)",
    "Let's look at the shape and content of these DataFrames",
    "Set the episode_id for: df_script, df_characters, df_locations",
    "# Print DataFrame characteristics\nprint_characters(df_characters)\nprint_locations(df_locations)\nprint_script(df_script)\nprint_episodes(df_episodes)",
    "Let's explore the datasets first to see their structure and data types.",
    "Remove the script lines mentioned prior to the first episode of The Simpsons",
    " Filter columns and merge the 4 datasets",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Create a series with the lines of the script\ns_script_lines = df_script[['id', 'raw_text']].set_index('id').squeeze()",
    "Visualize the episode count distribution by season",
    "Display first 5 rows of each DataFrame to understand their structure\nprint(\"Characters data:\")\ndisplay(df_characters.head())\n\nprint(\"Locations data:\")\ndisplay(df_locations.head())\n\nprint(\"Script data:\")\ndisplay(df_script.head())\n\nprint(\"Episodes data:\")\ndisplay(df_episodes.head())",
    "Inspect the structure of the datasets.",
    " Applying reset_index(inplace=False, drop=True) to the pandas dataframes",
    "Visualize distribution of script line lengths",
    "Merge the data in a single dataframe and show the first few characters",
    "\ndf_script.sample(10)",
    "select main characters that have at least 1000 lines\nmain_characters = df_script.character.value_counts()\nmain_characters = main_characters[main_characters > 1000]",
    "Clean gender information\n# Convert empty strings in gender column to NaN\ndf_characters['gender'] = df_characters['gender'].apply(lambda x: np.NaN if x == '' else x)\n\n# Replace unknown genders with NaN\ndf_characters['gender'] = df_characters['gender'].replace('?', np.NaN)",
    "Display the first few rows of each dataframe to get an idea of their contents\nprint(\"characters.csv\")\ndisplay(df_characters.head())\n\nprint(\"\\nlocations.csv\")\ndisplay(df_locations.head())\n\nprint(\"\\nscript_lines.csv\")\ndisplay(df_script.head())\n\nprint(\"\\nepisodes.csv\")\ndisplay(df_episodes.head())",
    "Inspect the contents of the 'simpsons_characters.csv' file",
    "Inspect Dataframes",
    "Strip quotes around 'raw_location_text' and 'spoken_words' columns\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.strip('\\'')\ndf_script['spoken_words'] = df_script['spoken_words'].str.strip('\\'')",
    " Strip invalid characters from character names and location names\ndf_characters['name_stripped'] = df_characters['name'].str.replace('[^\\w\\s]', '')\ndf_locations['name_stripped'] = df_locations['name'].str.replace('[^\\w\\s]', '')",
    "Data overview",
    "Let's take a look at the structure of our datasets.",
    " Optionally, you can display the top 5 rows of all these DataFrames to see what they look like",
    "Merge the scripts and episodes datasets\ndf = df_script.merge(df_episodes, on='episode_id')",
    "Set max display columns and width\npd.set_option('display.max_columns', 30)\npd.set_option('display.width', 180)",
    "Display the first 5 rows of the characters data frame\ndf_characters.head()",
    "Show the first few rows of each dataframe",
    "In the root directory, create a `visualizations` directory if it does not exist.",
    "Remove string descriptions for scripts with non-alphanumeric IDs\ndf_script = df_script[df_script['id'].apply(lambda x: x.isnumeric())]",
    "pd.set_option('max_rows', 10)  # show at most 10 rows for each DataFrame in this notebook",
    "Checking the first rows for df_characters",
    "Disabling the SettingWithCopyWarning in pandas, as we are interested in modifying dataframes in place and not creating copies\npd.options.mode.chained_assignment = None",
    "Merge all datasets on `episode_id`\ndf_merged = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_ep'))\n# remove duplicate columns\ndf_merged = df_merged.loc[:, ~df_merged.columns.duplicated()]",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Set TreeTagger directory\nos.environ['TREETAGGER_HOME'] = '/usr/local/Cellar/treetagger/3.2.2/'",
    " Dictionary to store tokenized documents\ntokenized_documents = {}\n\n# Load spacy models\nnlp = spacy.load('en')",
    "# Display settings for pandas dataframes\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 1000)",
    "Merge episodes and scripts\ndf_episodes.rename(columns={'id':'episode_id'}, inplace=True)\ndf = pd.merge(df_script, df_episodes, on='episode_id')\n\n# Display the first rows of the dataframe\ndf.head()",
    "Check the imported data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Some preprocessing",
    "Inspect top 10 rows of each DataFrame\nprint('Characters')\ndisplay(df_characters.head())\n\nprint('Locations')\ndisplay(df_locations.head())\n\nprint('Script')\ndisplay(df_script.head())\n\nprint('Episodes')\ndisplay(df_episodes.head())",
    "# Load the spacy model (medium model is sufficient, small would be too small and big too large)\nnlp = spacy.load(\"en_core_web_md\")",
    " Checking the structure of the dataframes",
    "\n# Display the first 5 rows of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_episodes.head(), df_script.head()",
    "Join the dataframes on the common episode_id to create a master dataframe",
    "Ways to handle and format a list of fastText word vectors.",
    "Limit the number of script lines for this example\ndf_script = df_script.head(5000)",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "Print the shape and information of the datasets\nprint(f'Shape of characters dataset: {df_characters.shape}')\nprint(f'Shape of locations dataset: {df_locations.shape}')\nprint(f'Shape of script dataset: {df_script.shape}')\nprint(f'Shape of episodes dataset: {df_episodes.shape}')",
    "Create a text variable for the script\nscript = \" \".join(df_script.raw_text)",
    "Initialize a spaCy nlp pipeline for part of speech tagging, entity recognition and word vectors.",
    "Connect to Google Drive to save/load data\nfrom google.colab import drive\ndrive.mount('/content/drive')",
    "df_characters, df_locations, df_script, and df_episodes are DataFrames containing characters, locations, script lines, and episodes data from the Simpsons show.",
    "Look at first entries of the characters DataFrame\ndf_characters.head()",
    " inspect the structures of the dataframes",
    "Find out which scripts are in our dataframe",
    "function to convert string to lowercase and strip white space\ndef lowercase_and_strip(column):\n    return column.astype(str).str.lower().str.strip()",
    "Check that the data has been loaded correctly\ndf_script.head()",
    " Ensure reproducibility\nnp.random.seed(0)",
    "Check that the csv files have been correctly located and loaded.",
    "Display rich content\nfrom IPython.display import display",
    "Let's take a look at the dimensions of our dataframes.\nprint('Characters df shape:', df_characters.shape)\nprint('Locations df shape:', df_locations.shape)\nprint('Script df shape:', df_script.shape)\nprint('Episodes df shape:', df_episodes.shape)",
    " Quick overview of the characters dataset\nprint(df_characters.head())\n\n# Quick overview of the locations dataset\nprint(df_locations.head())\n\n# Quick overview of the script dataset\nprint(df_script.head())\n\n# Quick overview of the episodes dataset\nprint(df_episodes.head())",
    " Optional:\ndf_script = df_script.sample(frac=0.1)",
    "Display the dataframes\nprint(df_characters.head(10))\nprint(df_locations.head(10))\nprint(df_script.head(10))\nprint(df_episodes.head(10))",
    "Show first 5 rows of dataframe to ensure everything's been read correctly\ndf_script.head()",
    "print(df_script.head())",
    "check dataframe shape\ndf_characters.shape",
    "Preview the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Define the path to the data folder\nsimpsons_data_path = 'data/'",
    "Look at sample of episodes data\ndf_episodes.sample(5)",
    "Looking at the data structure of each to find how to merge the files and how to work with them.",
    "Check the first 5 rows of each of the datasets",
    "display the first rows of the df_characters dataframe\ndf_characters.head()",
    " Display the first five rows of each dataframe.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Preview of the data\nprint(df_script.head())\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_episodes.head())",
    "Display all columns (handy when dealing with large DataFrames)\npd.set_option('display.max_columns', None)",
    "Join dataframe to retrieve character's information",
    "Remove scripts that have invalid characters and locations\ndf_script_cleaned = df_script[df_script['character_id'].isin(df_characters['id'])]\ndf_script_cleaned = df_script_cleaned[df_script_cleaned['location_id'].isin(df_locations['id'])]",
    "# Disabling the tagger, parser and NER part of the pipeline. We just want to lemmatize\nnlp = spacy.load('en', disable=['tagger', 'parser', 'ner'])",
    "Show the number of data points in each dataset\nprint(len(df_characters), len(df_locations), len(df_script), len(df_episodes))",
    "data overview\nprint(\"\\n======== Characters =======\")\nprint(df_characters.head(3))\n\nprint(\"\\n======== Locations =======\")\nprint(df_locations.head(3))\n\nprint(\"\\n======== Script =======\")\nprint(df_script.head(3))\n\nprint(\"\\n======== Episodes =======\")\nprint(df_episodes.head(3))",
    " Take a look at the first few lines of the dataset\nprint(df_script.head())",
    "let's take a look at the data",
    "Preview the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "# Remove non-character lines from the script\ndf_script = df_script[df_script.normalized_text != ''].copy()\ndf_script.reset_index(inplace=True, drop=True)",
    "Let's first take a look at the schema of each dataset.",
    "Print the first rows of each dataframe to better understand the data structure\n\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Display the first few lines of the characters dataframe\ndf_characters.head()",
    "Explore the data\ndf_characters.head()",
    "Display the first 5 rows of each dataframe to better understand the data",
    "Later we will need to group the script lines by episode, so we precompute this for later usage.",
    "left join location, episode to script \ndf_merged = df_script.join(df_episodes.set_index('id'), on='episode_id') \ndf_merged = df_merged.join(df_locations.set_index('id'), on='location_id')",
    "Display options\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
    "Clean up the scripts dataframe\n# Remove unwanted columns\ndf_script.drop(['id', 'episode_id', 'number', 'raw_text'], axis=1, inplace=True)\n\n# Missing dialogues\ndf_script.dropna(subset=['character_id', 'location_id'], how='all', inplace=True)\n\n# Convert character_id and location_id to int\ndf_script['character_id'] = df_script['character_id'].astype('Int64')\ndf_script['location_id'] = df_script['location_id'].astype('Int64')\n\n# Reorder columns\ndf_script = df_script[['character_id', 'location_id', 'timestamp_in_ms', 'speaking_line', 'spoken_words']]",
    "Resize the amount of data we are going to work with. For this version, our machine learning model will be trained with 20,000 lines of dialogue.",
    "Setting plot space to be for Jupyter notebook specifically",
    " Check Files Size in MB",
    "settings\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
    " Show the first few rows of the script dataset\ndf_script.head()",
    "Show the first 5 lines of the characters dataframe\ndf_characters.head()",
    " Display the first few rows of the dataframe\ndf_script.head()",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "print('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "Selecting only the lines in which the characters and locations exist\ndf_script = df_script[df_script[\"normalized_text\"].notna()]\ndf_script = df_script[df_script[\"location_id\"].notna()]\n\n# Left joining the script dataset with the character names and location names\ndf_script = pd.merge(df_script, df_characters['name'], how='left', left_on=df_script['character_id'], right_index=True)\ndf_script = df_script.rename(columns={'name': 'character_name'})\n\ndf_script = pd.merge(df_script, df_locations['name'], how='left', left_on=df_script['location_id'], right_index=True)\ndf_script = df_script.rename(columns={'name': 'location_name'})\n\n# Dropping the location_id and character_id columns\ndf_script = df_script.drop(columns=['location_id', 'character_id'])",
    "Print the shape of the dfs\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "# Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Merge script lines and episodes\ndf_script_episodes = df_script.merge(df_episodes, on='episode_id', how='left')",
    " Check if the script is loaded correctly\ndf_script.head()",
    "Show top 10 rows of Simpsons character dataframe\ndf_characters.head(10)",
    "Check the first few rows of the characters DataFrame.",
    "Let's take a brief look at the some sample data.",
    "Display dataframe\ndf_script",
    "Display the first 5 rows of the characters dataset\ndf_characters.head()",
    "Remove useless columns in some dataframes",
    "Inspect the first rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Work directory\nprint(\"Current working directory\", os.getcwd())",
    "Display the first few rows of the character dataset\ndf_characters.head()",
    " Displaying the head of the tables to understand the data",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Caching the Word Embeddings to quickly iterate on the same computations.",
    "Looking at the data",
    "Check the number of rows of each DataFrame",
    "Define the most likely episode length in minutes from 15 to 30 minutes",
    " Set maximum column width when displaying dataframes\npd.set_option('display.max_colwidth', 80)",
    "We first take a look at the available data.",
    "Merge all datasets",
    "Create a dictionary to map character IDs to character names.\ncharacters = dict(zip(df_characters['id'], df_characters['name']))\nlocations = dict(zip(df_locations['id'], df_locations['name']))",
    "Get a random script line",
    "\n# Define helper functions and objects\nnlp = spacy.load('en_core_web_sm')",
    "Check the CSV files have been read correctly, view them, and if needed, drop columns indices with inplace = True and reset column indices.",
    "Displaying the data.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Visualize the data\ndf_characters.head()",
    "View the head of the characters data\ndf_characters.head()",
    "Display the first 10 rows of each dataframe to get a sense of the data",
    " define data path\ndata_path = 'data'",
    " Check that everything worked by printing a snippet of each DataFrame",
    "Check the first few rows of the dataframe to verify that the data was loaded properly\ndf_characters.head()",
    "Display the loaded pandas dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Display the first few records of the characters dataset\ndf_characters.head()",
    "Create an object of class 'spacy.lang.en.English' and name it 'nlp'.",
    "Discard data before 1989 because the data is too sparse and Springfield hasn't been revealed yet",
    " Keep only \"spoken_words\" and \"raw_text\" columns\ndf_script = df_script[[\"spoken_words\", \"raw_text\"]]",
    "Quick look at the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Inspect the first 3 lines of the dataframe containing the script lines.",
    "\"\"\"Look at the data.\"\"\"",
    "Filter the script for only the episodes 1 to 3 of season 1.",
    "Display first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Print first 5 rows of the data\ndf_characters.head()",
    "Overview of the characters dataset\nprint(df_characters.shape)\ndf_characters.head()",
    "We can set the index of each dataframe to the id for faster access.",
    " exploration\ndf_episodes.head()",
    "Display first 5 rows of each dataframe\ndf_list = [df_characters, df_locations, df_script, df_episodes]\ndf_names = ['Characters', 'Locations', 'Script', 'Episodes']\nfor i, df in enumerate(df_list):\n    print(f\"First 5 rows of {df_names[i]}\")\n    display(df.head())",
    "Set plotting style\nplt.style.use('fivethirtyeight')",
    "Filter out non-dialogue lines from the script data\ndf_script_dialogue = df_script[(df_script[\"speaking_line\"] == True) & (df_script[\"character_id\"].notnull())].reset_index(inplace=False, drop=True)",
    "Check if GPU is there and the available RAM",
    "Merge the datasets.",
    "Remove apostrophes\ndf_script_normalized = df_script\ndf_script_normalized['normalized_text'] = df_script_normalized['normalized_text'].str.replace(\"'\", \"\")",
    "Look into the first few records\nprint(\"Characters\")\nprint(df_characters.head(5))\n\nprint(\"Locations\")\nprint(df_locations.head(5))\n\nprint(\"Script\")\nprint(df_script.head(5))\n\nprint(\"Episodes\")\nprint(df_episodes.head(5))",
    " Display scripts\ndf_script.head()",
    " Merge script lines with linking character and location information\ndf_script_location = df_script.copy()\ndf_script_location['character_id'] = df_script_location['character_id'].astype(str)",
    "Merge using \"merge\" method",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    "Extract all lines concerning Marge from the script dataframe",
    "Display the first few rows of each dataframe to understand its structure and what kind of data it contains",
    " Check the head of the characters dataframe",
    "Merge characters\ndf_characters_ep = df_characters.merge(df_script, left_on='id', right_on='character_id').merge(df_episodes, on='episode_id')",
    "Code to reset the index of the dataframes and drop the old index column",
    "Data exploration",
    "Check a few rows of characters dataframe",
    " Check if we have empty rows or NaN values",
    "Visualizamos la primeras lineas de cada dataframe",
    "Check basic dimensions\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Reduce the amount of memory used by the dataframes.",
    "Check the number of missing values in each column\ndf_script.isnull().sum()",
    "Create a \"debut\" column in df_characters containing the episode_id of the character's debut episode.",
    "# Quick look at the characters dataframe\nprint(df_characters.head())",
    "Let's start by taking a look at the first few rows of each of these DataFrames to understand their structure and contents.",
    "Define the name to ID mapping and ID to name mapping for characters and locations.",
    "Show first 5 rows of each dataframe\nprint('Characters:')\nprint(df_characters.head(5))\nprint('\\n\\nLocations:')\nprint(df_locations.head(5))\nprint('\\n\\nScript:')\nprint(df_script.head(5))\nprint('\\n\\nEpisodes:')\nprint(df_episodes.head(5))",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Check the head of each dataset\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "View dimensions of the various data frames\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    " Ensure data is loaded correctly\nprint(\"Characters:\")\nprint(df_characters.head())\n\nprint(\"\\nLocations:\")\nprint(df_locations.head())\n\nprint(\"\\nScript:\")\nprint(df_script.head())\n\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
    " Remove the newline and tab tokens from script\ndf_script['normalized_text'] = df_script['normalized_text'].str.replace('\\n', ' ')\ndf_script['normalized_text'] = df_script['normalized_text'].str.replace('  ', ' ')",
    "Create a set of all episode ids",
    " View the first 5 rows of the characters dataframe.\ndf_characters.head()",
    " Merge script and character data\ndf_script_full = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id')",
    "Display main dataframes dimensions\nprint(\"Characters df dimensions : {}\".format(df_characters.shape))\nprint(\"Locations df dimensions : {}\".format(df_locations.shape))\nprint(\"Script df dimensions: {}\".format(df_script.shape))\nprint(\"Episodes df dimensions: {}\".format(df_episodes.shape))",
    "fourth merge to create our final dataset: df\ndf = (\n    df_script\n    .merge(df_characters, how='inner', on='character_id')\n    .merge(df_episodes, how='inner', on='episode_id')\n    .merge(df_locations, how='inner', on='location_id')\n)",
    "Fix character names (for joins)",
    " Let's start by looking at the data.",
    "View dataframe structure\ndf_script.head()",
    "Deal with decimal type column\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].fillna(0.0).astype(np.int64)\n\n# Convert `timestamp_in_ms` to datetime\ndf_script['timestamp_in_ms'] = pd.to_datetime(df_script['timestamp_in_ms'], unit='ms').dt.time",
    "Let's take a first look at this dataframe.",
    "Combine characters, locations and episodes under a single dataframe",
    "Constants\nnlp = spacy.load('en_core_web_lg')\nstopwords = spacy.lang.en.STOP_WORDS",
    " Display the first few rows of each dataframe to understand its structure\nprint(\"Characters\")\ndisplay(df_characters.head())\n\nprint(\"Locations\")\ndisplay(df_locations.head())\n\nprint(\"Script\")\ndisplay(df_script.head())\n\nprint(\"Episodes\")\ndisplay(df_episodes.head())",
    "Use the default theme\nplt.style.use('seaborn')",
    "To display some basic information about the dataframes",
    "Show the df_characters first entries\ndf_characters.head()",
    "I have imported the data from the CSV files using pandas and stored them in dataframes for further processing.",
    "View available columns\ndf_script.columns",
    "Smaller samples for testing\ndf_characters = df_characters.sample(100).reset_index(drop=True)\ndf_locations = df_locations.sample(100).reset_index(drop=True)\ndf_script = df_script.sample(1000).reset_index(drop=True)\ndf_episodes = df_episodes.reset_index(drop=True)",
    "Display the first few rows of the script lines dataframe\ndf_script.head()",
    "Quick look at the \"Characters\" table\nprint(df_characters.head())",
    "Let's take a closer look at the data provided.",
    " Check the first few rows of each DataFrame",
    " Set pandas display options to better show long data\npd.set_option('display.max_columns', 500)",
    "Merge the related datasets into a single dataframe",
    "Displaying a few rows of the script data\ndf_script.head()",
    "Sort the columns to make the data easier to understand\ndf_script = df_script[[c for c in df_script.columns if c != 'word_count'] + ['word_count']]",
    "Data validation and some general statistics\nprint('Episodes Dataframe shape: ', df_episodes.shape)\nprint('Script Dataframe shape: ', df_script.shape)",
    " Remove the first 3 columns from df_script since they don't provide any value\ndf_script = df_script[['episode_id', 'id', 'character_id', 'location_id', 'raw_text']]",
    "Take a peek at the first 5 lines of the characters dataframe.",
    "Display the number of rows in each of the datasets\nprint(\"Number of rows in characters dataset: \", len(df_characters))\nprint(\"Number of rows in locations dataset: \", len(df_locations))\nprint(\"Number of rows in script lines dataset: \", len(df_script))",
    " Create a column with the raw tokenized text",
    "Filter episodes where the character interacts with a location.",
    "Define a class for preprocessing the script data, extracting the script for each episode, and tokenizing the text for natural language processing.",
    "Creates a dictionary to map character id to character name",
    " Let's start by looking at the first few rows of each dataset to understand their structure.",
    "Set pandas to display long text\npd.set_option('display.max_colwidth', -1)",
    "Merge the data on `episode_id`",
    " Check the first few rows of each dataframe",
    " Take a look at the content from the characters file\ndf_characters.head()",
    "Display the first record of each table to understand the data",
    " Show a preview of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Test and visualize data",
    " Profiling of data\nprint(\"Episodes\"); df_episodes.info()\nprint(\"\\nLocations\"); df_locations.info()\nprint(\"\\nCharacters\"); df_characters.info()\nprint(\"\\nScript\"); df_script.info()",
    "Merge the dataframe tables `df_script`, `df_locations`, `df_characters` and `df_episodes` on the common columns.",
    "Remove unwanted columns from the characters, locations and script DataFrames",
    " Merge script, characters, and locations\ndf_all = pd.merge(df_script, df_characters, on='raw_character_text', how='left')\ndf_all = pd.merge(df_all, df_locations, on='raw_location_text', how='left')",
    " Split each line into words and stem each word\nscript_stemmed = [nlp(line) for line in tqdm(df_script['raw_text'])]",
    "To get rid of some columns that we don't need in some dataframes",
    " Take a peek at the df_characters dataframe\ndf_characters.head()",
    "Set custom style form matplotlib\nplt.style.use('fivethirtyeight')",
    "Add an index to episodes dataframe",
    " Calculate how many occurrences of words there are in all the lines of the scripts",
    " Display the first few rows of each dataframe to understand the data",
    "Look at the first five rows of the characters dataframe\ndf_characters.head()",
    "Load the custom module for this problem set.",
    " Preprocess the text data and merge the relevant columns",
    " Check columns and example of some of the dataframes\nprint(df_characters.columns, df_characters.head())\nprint(df_locations.columns, df_locations.head())\nprint(df_script.columns, df_script.head())\nprint(df_episodes.columns, df_episodes.head())",
    "Check the head of each dataset to understand its structure\nprint(df_characters.head())\n\nprint(df_locations.head())\n\nprint(df_script.head())\n\nprint(df_episodes.head())",
    "Head displays the first 5 rows of the dataframe\ndf_characters.head()",
    "First, let's take a look at the first few rows of each of these dataframes to understand the kind of data we are dealing with.",
    "Read the datasets from CSV files into pandas DataFrames.",
    "Functions for feature engineering",
    " Show first 3 rows of the characters dataframe",
    "Setting path for the to be saved wordclouds for each episode, character and location\nwordcloud_path = os.path.dirname(os.path.realpath(__file__))+'/wordclouds/'",
    "Show the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Let's check the contents of these files.",
    "join transcript lines for each episode into single string\ndf_script_grouped = df_script.groupby(by='episode_id').agg({'normalized_text': lambda x: ' '.join(x)}).reset_index(inplace=False)\n\nnlp = spacy.load('en')",
    "Get the names of the characters in the Simpsons",
    " Merge the dataframes with the episode and character info",
    " Ensure reading worked correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Import of Dataframes successfully executed",
    "Data preprocessing tasks",
    "Display available columns for each dataset\nfor name, df in {\n    'characters': df_characters,\n    'locations': df_locations,\n    'script': df_script,\n    'episodes': df_episodes\n}.items():\n    print(f'{name}: {df.columns.values}\\n')",
    "Display the first few rows of the script dataframe\ndf_script.head()",
    " Load Spacy English \"Core Web\" Model\nnlp = spacy.load('en_core_web_sm')",
    "Create a directory to store images if it does not exist\nimg_dir = 'images'\nif not os.path.exists(img_dir):\n    os.makedirs(img_dir)",
    "Merge simpsons_characters.csv and simpsons_script_lines.csv on character_id\ndf_characters_script = pd.merge(df_characters, df_script, on='character_id', how='inner')",
    " Remove characters and locations not mentioned in script\nmentioned_chars = df_script_raw.name.str.lower().unique()\nmentioned_locs = df_script_raw.raw_location_text.str.lower().unique()\n\ndf_characters = df_characters[df_characters.normalized_name.str.lower().isin(mentioned_chars)]\ndf_locations = df_locations[df_locations.normalized_name.str.lower().isin(mentioned_locs)]",
    "Check the imported datasets\ndf_characters.head()",
    "Define a function to create a word cloud from a given text",
    "ipandas style-settings\npd.set_option('display.max_columns', None)",
    "We start by loading the datasets using pandas `read_csv` function. Then we reset the index using the `reset_index` method to have a fresh index.",
    "Define and load the model\nnlp = spacy.load('en_core_web_md')",
    "display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Let's use the head() method to display the first 5 rows of each DataFrame and understand how the data is structured.",
    " Create an index for quicker lookup\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "Merge script with episodes\ndf_script_full = df_script.merge(df_episodes, on='episode_id').merge(df_characters, on='character_id')\n\n# Display the first 5 rows and all columns of the resulting dataframe\npd.set_option('display.max_columns', None)\ndf_script_full.head()",
    "Preview the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Display basic info for each of the datasets",
    "Display settings for large data\npd.set_option('display.max_columns', None)",
    " Convert columns containing json data into dataframes\nimport json\nfrom pandas.io.json import json_normalize\n\n# convert to json\ndf_script[\"episode_id\"] = df_script[\"episode_id\"].apply(lambda x: json.loads(x.replace(\"'\", \"\\\"\")))\ndf_script[\"character_id\"] = df_script[\"character_id\"].apply(lambda x: json.loads(x.replace(\"'\", \"\\\"\")))\ndf_script[\"location_id\"] = df_script[\"location_id\"].apply(lambda x: json.loads(x.replace(\"'\", \"\\\"\")))\ndf_script[\"spoken_words\"] = df_script[\"spoken_words\"].apply(lambda x: json.loads(x.replace(\"'\", \"\\\"\")))\ndf_script[\"normalized_text\"] = df_script[\"normalized_text\"].apply(lambda x: json.loads(x.replace(\"'\", \"\\\"\")))\n\n# Transform json into individual lines\ndf_script_eid = df_script.explode('episode_id').reset_index(inplace=False, drop=True)\ndf_script_cid = df_script.explode('character_id').reset_index(inplace=False, drop=True)\ndf_script_lid = df_script.explode('location_id').reset_index(inplace=False, drop=True)\ndf_script_spoken = df_script.explode('spoken_words').reset_index(inplace=False, drop=True)\ndf_script_normalized = df_script.explode('normalized_text').reset_index(inplace=False, drop=True)",
    "Setting the episode_id as index for querying",
    "Displaying the first 5 records of each dataframe\nprint('Characters')\nprint(df_characters.head(5))\nprint('Locations')\nprint(df_locations.head(5))\nprint('Script')\nprint(df_script.head(5))\nprint('Episodes')\nprint(df_episodes.head(5))",
    "Check first few rows of df_characters\ndf_characters.head()",
    " Set the dataframe display option to show the full content of the cells\npd.set_option('display.max_colwidth', None)",
    "Create a spacy nlp object\nnlp = spacy.load('en_core_web_sm')",
    "Displaying the first five rows of the characters dataframe",
    "Join the datasets on the episode id",
    "Check import of data\ndf_script.head()",
    " Extract the first few lines of the script to get a feeling of the data structure\ndf_script.head()",
    "# Checking the first 5 rows of the characters dataframe\ndf_characters.head()",
    "def load_word_label_dictionary(filename):\n    result = {}\n    with open(filename, 'r') as file:\n        for line in file:\n            (key, val) = line.split()\n            result[key] = val\n    return result",
    "Set index after loading the csv files\ndf_script.set_index('id',inplace=True)\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id',inplace=True)\ndf_episodes.set_index('id',inplace=True)",
    "Create the master table by joining the other tables",
    "Set custom matplotlib configurations",
    "Let's take a look at the structure of our data.",
    "Display the first few rows of the dataframe\ndf_episodes.head()",
    "# Let's display some basic information from the dataset to get a better\n# understanding of the data. Let's start with all the datasets in general.",
    " Show the first few script lines\ndf_script.head()",
    "Merge episodes and scripts\ndf = df_episodes.merge(df_script, on='episode_id', how='left')",
    "data directories\nos.listdir(\"data/\")",
    "Check our datasets\nprint(\"Characters dataset shape\", df_characters.shape)\nprint(df_characters.head())\n\nprint(\"\\nLocations dataset shape\", df_locations.shape)\nprint(df_locations.head())\n\nprint(\"\\nScript dataset shape\", df_script.shape)\nprint(df_script.head())\n\nprint(\"\\nEpisodes dataset shape\", df_episodes.shape)\nprint(df_episodes.head())",
    "Create a Spacy NLP object",
    "Check if the lines have the `character_id`, `location_id` and `episode_id` (where available) that match the `id` in the characters, locations, and episodes tables.",
    " Check the first few rows of each dataframe\nprint(\"Characters:\")\ndisplay(df_characters.head())",
    "Inspect the data for any important details and initial data cleaning",
    "We define the data as \"raw\" since it has not been processed.\nraw_script = df_script.copy()",
    "Inspect the dataframes, check for missing values, etc.",
    "Print shapes of the dataframes to check if everything went okay\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations:  {df_locations.shape}\")\nprint(f\"Script:     {df_script.shape}\")\nprint(f\"Episodes:   {df_episodes.shape}\")",
    "Import the data from the CSV files into pandas dataframes.",
    "Ensure actors are consistently mapped with the same name\ndf_script[\"raw_character_text\"].replace({\"brad goodman\": \"brad goodman psychiatrist\"}, inplace=True)\ndf_script[\"raw_character_text\"].replace({\"brad goodman psychiatrist\": \"brad goodman\"}, inplace=True)",
    "Check the structure of the dataframes and display their first few rows\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"Locations\")\nprint(df_locations.head())\nprint(\"Script\")\nprint(df_script.head())\nprint(\"Episodes\")\nprint(df_episodes.head())",
    " Let's take a closer look at the structure of the DataFrames.",
    "Checking the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Check the first 5 rows for each dataset.",
    "Display the first few lines of each table to get an idea of the data",
    "Detectron2\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\n\nsetup_logger()\n\nimport numpy as np\nimport os, json, cv2, random\n\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog",
    " Let's display the first 10 rows of the characters dataframe.",
    "Merge the script with character, location and episode info\ndf_merged = df_script.merge(df_characters[['id', 'normalized_name']], left_on='character_id', right_on='id', how='left').rename(columns={'normalized_name': 'character'}).drop(columns='id')\ndf_merged = df_merged.merge(df_locations[['id', 'normalized_name']], left_on='location_id', right_on='id', how='left').rename(columns={'normalized_name': 'location'}).drop(columns='id')\ndf_merged = df_merged.merge(df_episodes[['id', 'title']], left_on='episode_id', right_on='id', how='left').rename(columns={'title': 'episode'}).drop(columns='id')\n\n# Drop rows with no episode info\ndf_merged = df_merged.dropna(subset=['episode'])\n\n# Reset index\ndf_merged = df_merged.reset_index(inplace=False, drop=True)",
    "Remove all the rows where at least one element is missing.\ndf_script = df_script.dropna()",
    " Visualize number of lines per character\nline_counts = df_script['character_id'].value_counts()\nline_counts = line_counts.reset_index()\nline_counts.columns=['character_id', 'count']\nline_counts = line_counts.merge(df_characters, on='character_id')\nline_counts = line_counts.sort_values(by='count', ascending=False)\n\nfig, ax = plt.subplots(1,1,figsize=(15,10))\nax.bar(line_counts['name'][:30], line_counts['count'][:30])\nax.set_xlabel('Character')\nax.set_ylabel('Number of lines')\nax.set_title('Number of lines per character')\nax.set_xticklabels(line_counts['name'][:30], rotation=90)\nplt.show()",
    "there are 27 tables, most related will be:\n#   (label, brightness, contrast, homogen_datatype)",
    "Inspecting the data for first rows\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display the characters dataframe\ndf_characters",
    "Inspect dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Display the first 5 rows of the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Explore data\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "Check for missing and null values\ndf_script.isnull().sum()",
    " Display the first 5 rows of the characters DataFrame\ndf_characters.head()",
    "df_script = df_script.sample(1000)  # Speed up computation",
    "Let's have a look at Character lines and Locations.",
    "Check the number of rows before merging\nprint(len(df_characters))\nprint(len(df_locations))\nprint(len(df_script))\nprint(len(df_episodes))",
    "creating index for the original dataframes",
    " filter only the conversation lines, we will need them for Named Entity Recognition (NER)ruption",
    "Examining the data\n# Display the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Data cleanup\n# Keep only non-empty lines\ndf_script = df_script[df_script['raw_text'].notna()]\n\n# Keep only lines related to an episode\ndf_script = df_script[df_script['episode_id'].notna()]\n\n# Set NaT values to the pandas NaT type\ndf_episodes['original_air_date'] = df_episodes['original_air_date'].apply(lambda x: pd.NaT if pd.isna(x) else pd.to_datetime(x))\n\n# Limit the number of rows for faster execution\nsample_size = 98000\ndf_script = df_script.loc[:sample_size]",
    "We should also set the random seed for reproducibility.",
    "Inspecting the character data\nprint(df_characters.head())",
    "Inspect the dataframes head\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Display option to show all columns when displaying dataframe\npd.set_option('display.max_columns', None)",
    " Display the first few rows of each dataframe to understand the data",
    "Selecting only lines from one specific episode",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Parameters\nseason_of_interest = 10",
    "# Ensure sqlite3 works in Jupyter\n%load_ext sql\n\n# Connect to the pre-loaded SQLite database\n%sql sqlite:///data/simpsons-database.db",
    "Visualisation for the jupyter notebook",
    "Filters",
    "Make the rows display up to 200 characters\npd.set_option('display.max_colwidth', 200)",
    "Setting and checking if the data is loaded correctly",
    "Let's first explore the data to see what fields we have and what kind of data is in them.",
    "# The 'df_script' dataframe contains all the script lines. Let's take a look at the first few rows.\ndf_script.head()",
    "Display the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "df_script.head()",
    "Apply slight transformation to each dataframe",
    "Merge the characters, locations, and episodes dataframes with the script dataframe\ndf_script = df_script.merge(df_episodes, how='left', left_on='episode_id', right_on='id',\n                            suffixes=('_script', '_episodes'))\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id',\n                            suffixes=('', '_characters'))\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id',\n                            suffixes=('_script', '_locations'))",
    "# Display options\npd.set_option('max_colwidth', 100)",
    "Check dimensions of the datasets to make sure nothing is misaligned\nprint(\n    \"Characters:\\t\", df_characters.shape,\n    \"\\nLocations:\\t\", df_locations.shape,\n    \"\\nScript:\\t\\t\", df_script.shape,\n    \"\\nEpisodes:\\t\",  df_episodes.shape\n)",
    "Display the first few lines of the characters dataframe\ndf_characters.head()",
    "Limiting and exploring the data",
    "View the top 5 rows of the characters DataFrame\ndf_characters.head()",
    "Display the data\ndf_script.head()",
    "# Let's print the head of each dataframe to better understand the structure of the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Test print of the first few lines of each imported dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Checking the data types for each dataframe",
    "Set the seed for reproducibility\nnp.random.seed(0)",
    " Show the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Split data into training and testing sets\ndf_script['split'] = np.random.randn(df_script.shape[0], 1)\n\n# 80% train, 20% test\nm = np.percentile(df_script['split'], 80)\ndf_train = df_script[df_script['split'] < m]\ndf_test = df_script[df_script['split'] >= m]",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Set the index of each dataframe to be the unique identifier",
    "Set pandas to display wide data\npd.set_option('display.max_colwidth', None)",
    " Showing the head of the episodes dataframe\ndf_episodes.head()",
    "Check the number of rows and columns for each dataframe\nprint(f'Characters: {df_characters.shape}')\nprint(f'Locations: {df_locations.shape}')\nprint(f'Script: {df_script.shape}')\nprint(f'Episodes: {df_episodes.shape}')",
    "Mixin external data into script data",
    "Setting random seed for reproducibility\nnp.random.seed(0)",
    "Set the seed for reproducibility.",
    "# Reset index for all df except df_script\ndf_characters = df_characters.reset_index(inplace=False, drop=True)\ndf_locations = df_locations.reset_index(inplace=False, drop=True)\ndf_episodes = df_episodes.reset_index(inplace=False, drop=True)",
    "Check character dataframe",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Let's take a quick look at each of the datasets.",
    "\n# Python code to create a CSV file\n# from a list\nimport csv\n\n# field names\nfields = ['Name', 'Branch', 'Year', 'CGPA']\n\n# data rows of csv file\nrows = [ ['Nikhil', 'COE', '2017', '9.0'],\n         ['Sanchit', 'COE', '2017', '9.1'],\n         ['Aditya', 'IT', '2017', '9.3'],\n         ['Sagar', 'SE', '2017', '9.5'],\n         ['Prateek', 'MCE', '2017', '9.1'],\n         ['Sahil', 'EP', '2017', '9.2']]\n\n# name of csv file\nfilename = \"university_records.csv\"\n\n# writing to csv file\nwith open(filename, 'w') as csvfile:\n    # creating a csv dict writer object\n    csvwriter = csv.writer(csvfile)\n    \n    # writing the fields\n    csvwriter.writerow(fields)\n    \n    # writing the data rows\n    csvwriter.writerows(rows)",
    "Simplify DataFrames for better this tutorial\ndf_script = df_script[[\"episode_id\", \"character_id\", \"location_id\", \"normalized_text\"]].dropna()",
    "# Display the first 5 rows of each table\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Exploratory data analysis",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Check our datasets\ndf_episodes.head()",
    "Let's inspect the first 5 records of the dataset containing the characters.",
    "Create a dictionary for characters and locations (from id to string)\ncharacters_dict = {}\nlocations_dict = {}",
    "Merge episodes and script datasets based on the episode id",
    "Ignore data necessary for testing during production\ndf_script = df_script[df_script[\"episode_id\"].isin(df_episodes[df_episodes[\"production_code\"] != \"\"].index)]\ndf_script = df_script[df_script[\"character_id\"].isin(df_characters[df_characters[\"name\"] != \"\"].index)]\ndf_script = df_script[df_script[\"location_id\"].isin(df_locations[df_locations[\"name\"] != \"\"].index)]",
    "Display the first few lines of each dataframe to understand their structure\nprint(\"Characters DataFrame:\")\nprint(df_characters.head())\nprint(\"\\nLocations DataFrame:\")\nprint(df_locations.head())\nprint(\"\\nScript DataFrame:\")\nprint(df_script.head())\nprint(\"\\nEpisodes DataFrame:\")\nprint(df_episodes.head())",
    "Check correct\ndf_script.head()",
    "Setting seed for reproducibility\nnp.random.seed(42)",
    "Checking that the content has been imported correctly",
    "# Names of the characters\ncharacters = df_characters.character_name.values\n\n# Names of the locations\nlocations = df_locations.location_name.values",
    "Let's look at an example to understand our data better.",
    "Extract data requirements for specific questions",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "This will allow the visuals to be displayed in the notebook.",
    " Display general information of each dataframe.\ndef display_df_info(df, name):\n    print(name)\n    print(df.info())\n    display(df.head(5))",
    "Preview the data.frames\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Preview characters dataset.",
    "Show dataframe\ndf_script.head()",
    "Check the data when it has been imported",
    "Display the 5 first rows of the dataframe containing the characters",
    "# Display the characters of the Simpsons series\ndf_characters.head()",
    "Create a list with episodes dates\nep_dates = df_episodes['original_air_date'].tolist()\nep_dates",
    "# Example data\nprint('Characters:')\nprint(df_characters.head(10))\nprint('\\nLocations:')\nprint(df_locations.head(10))\nprint('\\nScript:')\nprint(df_script.head(10))\nprint('\\nEpisodes:')\nprint(df_episodes.head(10))",
    "# Display the number of lines we have for each character\nlines_by_character = df_script['raw_character_text'].value_counts()\nlines_by_character",
    "What are the dtypes that each dataframe is storing?",
    "For a selected subset of characters, extract a subset of the scripts only containing dialogs of these characters",
    "Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check the content of each file.",
    "Create one big DataFrame containing all the informations needed for the following analysis:",
    "Print out the Characters dataframe, note that this will return a huge table that might be slow to render",
    "Merge the scripts dataframe with the character and location dataframes\ndf_script_char = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_char'))\ndf_script_char_loc = df_script_char.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_merge', '_loc'))",
    "Only use the top 300 episodes to avoid memory errors\ndf_script = df_script[df_script['episode_id'] <= 300]",
    "Reduce memory footprint by downcasting integers and replacing objects with categoricals.",
    "Merge locations and script\ndf_locations_script = pd.merge(\n    df_locations,\n    df_script,\n    left_on='id', \n    right_on='location_id',\n    suffixes=('_location', '_script')\n).drop(['id', 'location_id'], axis=1)",
    " Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Find the main characters for each episode",
    "replace NaN values with empty strings\ndf_script.fillna('', inplace=True)",
    "Check the shape of the datasets",
    "Checking data first.",
    " conda install -c conda-forge spacy",
    "Set notebook preferences",
    "I'm going to clean the script data.",
    "Set display options for pandas dataframes\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    "Explore the dataset\ndf_characters.head()",
    "Let's display them to see their structure\ndf_characters.head()",
    "Check the general structure of the dataframes\ndf_characters.head()",
    "Check the shape of the dataframes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    " Display the top 5 character lines in the dataset\ndf_script.head()",
    " Visualize the number of lines spoken by each character.",
    "Let's have a look at the characters dataframe.",
    "Let's start by displaying the first few rows of each dataframe to understand their structure and content.",
    "Optional - Explore a dataframe\ndf_script.head()",
    "Ensure all data was loaded successfully\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "Create a connection to the PostgreSQL database",
    "Filter main characters\nmain_characters = [\"Lisa\", \"Bart\", \"Homer\", \"Marge\", \"Maggie\", \"Mr. Burns\"]\n\ndf_script_main_characters = df_script[df_script.raw_character_text.isin(main_characters)]",
    "Display first 5 rows of characters dataframe\ndf_characters.head()",
    "Define the length of the dataset for the purpose of interactive exploration\ndata_length = len(df_script)",
    "Remove information about Simpsons' episode title and whether its dataset\n# Song does not have any meaningful information\ndf_script.pop('episode_title')\ndf_script.pop('number')",
    "Merge the dataset\ndf_name_only = df_characters.loc[:, ['name', 'normalized_name']]\ndf_total = pd.merge(df_script, df_name_only, how='left', left_on='raw_character_text', right_on='name')\n\ndf_total.dropna(subset=['normalized_name'], inplace=True)",
    "# General configuration\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_colwidth', 1000)\nmatplotlib.rcParams['figure.figsize'] = (10.0, 5.0)",
    " Explore the content of one of the dataframes\ndf_script.head()",
    "Allow pandas to display all columns, and provide autocomplete scoring based on column type\npd.set_option('display.max_columns', None)\npd.set_option('display.memory_usage', True)",
    "Display the first 5 rows of the dataframe containing the characters.",
    "Coding as per the companion's request.",
    "Set the style of the visualization\nmatplotlib.style.use('seaborn-muted')",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "# Merge characters and script\ndf_merged = df_script.merge(df_characters, on='id', suffixes=('_lines', '_characters'))",
    "# I realized that df_script is very large, so let's free up some memory\ndel df_script",
    "Check if datasets were loaded properly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check the data, its type and a few rows",
    "To use Google Colab's data from Google Drive\nfrom google.colab import drive\ndrive.mount('/content/drive')",
    "Data Preprocessing",
    "Checking the data shapes\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "Download spacy model\npython -m spacy download en_core_web_md",
    "Inspect data columns and types\nprint(df_characters.dtypes)",
    " View the dataframes' head\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " View the first few rows of the characters DataFrame\ndf_characters.head()",
    "Getting rid of the NaN values for both `location_id` and `normalized_text`",
    "Remove rows with null characters ID\ndf_script = df_script[df_script['character_id'].notnull()]",
    " Set maximum columns and rows to display\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    " Let's take a quick look at the data and understand its structure.",
    "Display the first 5 records of the characters data\ndf_characters.head()",
    " Check the size of each dataframe",
    "Display some sample data",
    "Set some options for Pandas to display data.frames\npd.set_option('display.max.columns', None)\npd.set_option('display.max_colwidth', None)",
    "Let's see the first few rows of each dataframe to understand the data better.",
    "Let's inspect the first few rows of each of these DataFrames to understand their structure and content.",
    "Print the first few rows of each dataframe to understand its structure\nprint(\"\\nCharacters:\")\nprint(df_characters.head())\nprint(\"\\nLocations:\")\nprint(df_locations.head())\nprint(\"\\nScript:\")\nprint(df_script.head())\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
    "\n# Some basic information about the datasets",
    "Configure pandas to display all columns and show dataframes'\n# up to a maximum of 10 rows (for readability)\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 10)",
    "Clean up missing and bad data",
    " Display the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Explore the data - Have a look at the five first rows",
    "Ensure working directory is correct\nos.getcwd()",
    "Inspect general information from the datasets\nprint('characters columns',df_characters.columns)\nprint('\\n\\nlocations columns',df_locations.columns)\nprint('\\n\\nscript lines columns',df_script.columns)\nprint('\\n\\nepisodes columns',df_episodes.columns)",
    " Create a new column for the spacy embeddings for each line in the script\ndf_script['spacy_doc'] = df_script['normalized_text'].apply(lambda x: nlp(x))",
    "Checking the datasets",
    " Display the first few rows of the scripts dataframe\ndf_script.head()",
    " Display some general information about the datasets\nprint('Characters\\n')\nprint(df_characters.info())\nprint(df_characters.head())\nprint('\\nLocations\\n')\nprint(df_locations.info())\nprint(df_locations.head())\nprint('\\nScript\\n')\nprint(df_script.info())\nprint(df_script.head())\nprint('\\nEpisodes\\n')\nprint(df_episodes.info())\nprint(df_episodes.head())",
    "#number of script lines\nlen(df_script)",
    "Show the data from the episode CSV file\ndf_episodes.head()",
    "\n# Merge the dialogue with the corresponding characters and location\ndf_merged = df_script.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id')\ndf_merged = df_merged.rename(columns={'name': 'character_name'}).drop(columns='id')\ndf_merged = df_merged.merge(df_locations[['id', 'name']], left_on='location_id', right_on='id')\ndf_merged = df_merged.rename(columns={'name': 'location_name'}).drop(columns='id')",
    "display the first few rows of the characters dataframe\ndf_characters.head()",
    "Check data\nprint(\"Characters\")\nprint(df_characters.head(5))\nprint(\"Locations\")\nprint(df_locations.head(5))\nprint(\"Script\")\nprint(df_script.head(5))\nprint(\"Episodes\")\nprint(df_episodes.head(5))",
    "Let's take a look at the data.",
    "Previewing the characters dataframe",
    " Remove duplicate entries in character and location dataframes\ndf_characters = df_characters.drop_duplicates(subset='raw_character_text')\ndf_locations = df_locations.drop_duplicates(subset='raw_location_text')",
    "Create a spaCy object\nnlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser'])\n\n# Apply processing to each line in the script\ndocs = list(nlp.pipe(df_script['raw_text'], batch_size=1000, n_process=-1))",
    "# Now let's take a look at the first few rows of each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display setting\npd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 1000)\npd.set_option('display.width', 1000)",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    " Show info about the characters dataframe\ndf_characters.info()",
    "Check script head",
    "Set a path to the data directory.",
    "Remove unnecessary columns from the dataframe",
    "Preview the characters data\nprint(df_characters.head())\n\n# Display types and non-null values\nprint(df_characters.info())",
    " Remove invalid entries from the script\ndf_script_valid = df_script.dropna(subset=['raw_text'])\n\n# Convert seasons to integers, removing any trailing and leading whitespace\ndf_episodes['season'] = df_episodes['season'].str.strip().astype(int)",
    "Set notebook-related options for pandas and matplotlib",
    "Merge multiple tables to create a more complete table",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Set environment variables for PySpark\nos.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'\nos.environ['PYSPARK_DRIVER_PYTHON'] = '/usr/bin/python3'",
    "Convert character_id and location_id from float to int",
    " Display the first few rows of the dataframe to understand the data",
    "Merge all the information in a single DataFrame.",
    "Checking that the data has been read in correctly\nprint(df_script.head())",
    "Before we proceed, let's take a look at the top few rows of these datasets.",
    "Inspect the data",
    "# Set up word cloud\nmatplotlib.rcParams['figure.figsize'] = (12, 12)\nwordcloud = WordCloud(width = 4000, height = 4000, \n                background_color ='white', \n                stopwords = None, \n                min_font_size = 10)",
    "Check the number of lines, characters, locations and episodes\ndf_script.shape[0], df_characters.shape[0], df_locations.shape[0], df_episodes.shape[0]",
    "Visualization function",
    "Calculate the number of lines for each character\nlines_per_character = df_script['character_id'].value_counts()",
    "from stop_words import get_stop_words",
    "Let's first load all the data from the CSV files into Pandas dataframes.",
    " Look at the first 5 script lines to get an overview.",
    "Display the data in the dataframe for script lines with a head function",
    "Now, let's take a look at the first few rows of each dataframe to understand the data better.",
    "Shows the first 10 records for all the tables\nprint(\"Characters\")\nprint(df_characters.head(10))\n\nprint(\"\\nLocations\")\nprint(df_locations.head(10))\n\nprint(\"\\nScript lines\")\nprint(df_script.head(10))\n\nprint(\"\\nEpisodes\")\nprint(df_episodes.head(10))",
    "Data Preprocessing",
    "Display the size of the datasets\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script lines:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
    " Merge character and location in script\ndf_script_with_character = pd.merge(df_script, \n                                    df_characters,\n                                    left_on='character_id', \n                                    right_on='id').drop(['id'], axis=1).rename({'name': 'character_name'}, axis=1)",
    "Let's take a look at the structure of each of the dataframes by printing the first few rows.",
    "Viewing first 10 records of Simpsons Characters data",
    "Merge characters and locations with the main df_script DataFrame\ndf_script['character'] = df_script['character_id'].map(df_characters.set_index('id')['name'])\ndf_script['location'] = df_script['location_id'].map(df_locations.set_index('id')['name'])",
    "We join the dataframes to have a unique dataframe containing all the relevant information.",
    "Filter out incomplete script lines and join the tables",
    "Checking the dataframe, that it loads with the top of it",
    "# Print shapes of the DataFrames\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Extract the characters only from the first 1000 episodes\ncharacter_names = df_characters[0]['detect_name']\ndf_episodes_top_1000 = df_script[df_script['episode_id'] <= 1000]\nscript_characters = df_episodes_top_1000['character_id'].unique()\nscript_df_characters = pd.DataFrame(script_characters, columns=['character_id'])",
    "Quick inspection of the data sets to understand their structure and content",
    "Check if the script dataframe contains duplicate rows\nprint(f\"Number of duplicate rows in script dataframe: {df_script.duplicated().sum()}\")",
    "Set plot color scheme\nmatplotlib.style.use('ggplot')",
    " Remove columns without a name\ndf_characters = df_characters[df_characters.character_name.notnull()]\ndf_locations = df_locations[df_locations.location_name.notnull()]",
    "Check the script dataset",
    "Preview data files\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Create Indexers for each Dataframe",
    "# Convert speaker_id from string to int to match id in characters\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce').fillna(0).astype(int)",
    "Grouping by episode id and joining all lines by 'space'\ndf_script_grouped = df_script.groupby('episode_id').apply(lambda x: ' '.join(x['normalized_text']))\n\n# Merging with episode ids in order to have the same ordering.\ndf_script_grouped_pd = pd.DataFrame(df_script_grouped, columns=['script'])\ndf_script_grouped_pd = df_script_grouped_pd.merge(df_episodes, left_index=True, right_on='id').set_index('id').sort_index()\n\n# Credits\ndf_script_grouped = df_script_grouped_pd['script']\n\ndf_script_grouped_vc = df_script['episode_id'].value_counts().sort_index()",
    " Look at the first 5 elements in the characters dataframe\ndf_characters.head()",
    "Profiling the different dataset",
    "Checking data integrity\nprint(df_characters.shape, df_characters.character_id.nunique())",
    "Clean data\ndf_script_clean = df_script[\n    (df_script.raw_character_text != ' ') & (df_script.raw_character_text != 'Miss Hoover') & (df_script.raw_character_text != 'Miss Hoover & Martin') & \\\n    (df_script.raw_character_text != 'Miss Hoover & Terri & Martin') & \\\n    (df_script.raw_character_id != 8) & (df_script.raw_location_text != 'nan')\n]",
    "get_ipython().run_line_magic('matplotlib', 'inline')",
    "Checking data after loading from csv files.",
    "Display the first few rows of the script dataframe\ndf_script.head()",
    " Show the 10 first rows of the dataframe characters",
    "Ignore deprication warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)",
    "Clean data\n# Remove rows with empty strings or NA's from the script\ndf_script.dropna(inplace=True)\ndf_script = df_script[df_script['raw_text'] != '']\n# Remove faulty episode\ndf_episodes.drop([281], inplace=True)\n\n# Top 10 characters that appear in the scripts\ntop10_characters = df_script.character_id.value_counts().head(10)\ntop10_characters = df_characters.loc[top10_characters.indices].reset_index(drop=True)\n\n# Top 10 locations that appear in the scripts\ntop10_locations = df_script.raw_location_text.value_counts().head(10).reset_index()\ntop10_locations.columns = ['raw_location_text', 'count']",
    "Check the number of records in each dataframes.\nprint('Number of records in characters dataframe:', len(df_characters))\nprint('Number of records in locations dataframe:', len(df_locations))\nprint('Number of records in script dataframe:', len(df_script))\nprint('Number of records in episodes dataframe:', len(df_episodes))",
    " Display the first 5 rows of each table\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Show head of the characters dataframe\ndf_characters.head()",
    "Read few lines of the characters dataframe\ndf_characters.head()",
    "First, we start by making some basic \"exploratory data analysis\" (EDA) of the dataset.",
    "Limit the number of scripts to not run out of memory during these computations\ndf_script = df_script.iloc[:100000]",
    " Check the dataframes\ndf_characters.head()",
    "Checking first rows for each file\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Show the first few lines of the characters dataframe\ndf_characters.head()",
    "Information about the data.",
    " Setting up constants",
    "Merge data\ndf_script = pd.merge(df_script, df_episodes, how='inner', left_on='episode_id', right_on='id')",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Let's take a look to the first lines of each Dataframe.",
    "Filter the script for the provided episode ID and drop rows with no character ID",
    "Checking the data samples",
    "Install missing dependencies for spacy\n!python -m spacy download en_core_web_sm",
    "Set the 'id' column as index for easier access\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "Dataset information\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
    "Let's take a look at the first rows of each dataframe to understand what data is available:",
    "Display the first 5 lines of the table to understand its structure\ndf_characters.head()",
    "Loading pre-trained English tokenizer, tagger, parser, NER and word vectors\nnlp = spacy.load('en')",
    " Print out the first few rows of each dataframe\nprint(\"Characters:\")\nprint(df_characters.head())\n\nprint(\"\\nLocations:\")\nprint(df_locations.head())\n\nprint(\"\\nScript:\")\nprint(df_script.head())\n\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
    "# Ensure all have the same name for character id column\ndf_characters = df_characters.rename(columns={'id': 'character_id'})\ndf_locations = df_locations.rename(columns={'id': 'location_id'})",
    "Inspecting the schema of these DataFrames will help us understand the data better.",
    "Initial investigation of the datasets",
    "# Using spaCy's pre-built NLP model\nnlp = spacy.load(\"en_core_web_sm\")",
    "Rows and columns shown in their entirety\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    " Configure spacy\nnlp = spacy.load('en_core_web_sm')",
    " Display script data\ndf_script.head()",
    " Quick view on the Simpsons Dataset\nprint(\"Characters' dataset:\")\nprint(df_characters.head())\nprint(\"\\nLocations' dataset:\")\nprint(df_locations.head())\nprint(\"\\nEpisodes' dataset:\")\nprint(df_episodes.head())\nprint(\"\\nScript' dataset:\")\nprint(df_script.head())",
    "function that generate a word cloud from a given text",
    " Let's get an overview of these datasets.",
    "sns.set(style=\"darkgrid\")",
    " Checking the number of rows in each dataframe",
    " Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Join the datasets on the episode_id and write the resulting DataFrame to a CSV file.",
    "df_script.head()",
    "# Load the spaCy model\nnlp = spacy.load('en_core_web_sm')",
    "Starting with basic text preproceessing on 'raw_text' in 'df_script'.",
    "Create dummy variables for the characters lines' in the script dataframe",
    "df_script.head()",
    " Calculating number of conversations for the first 10 episodes",
    "Inspecting the first few rows of the characters dataframe.",
    "check the available data",
    "modules required for data visualization and analysis",
    "Set styles and color palettes for the matplotlib visualisations\nplt.style.use('fivethirtyeight')\nmatplotlib.rcParams['font.family'] = 'monospace'\nsns.set_palette(\"husl\", 7)",
    "Inspect the content of the \"simpsons_script_lines.csv\" dataset\ndf_script.head()",
    " Checking the shape and the first entries of the characters dataframe",
    "\ndf_script.head()",
    "Checking the structure of the various datasets",
    "# Check the top of the characters data\ndf_characters.head()",
    " Display the first few characters of the episodes dataframe\ndf_episodes.head()",
    "top 5 rows of the characters dataframe\ndf_characters.head()",
    " merge characters and script dataframe\ndf_characters.rename(columns={'id': 'character_id'}, inplace=True)\ndf_merged = pd.merge(df_script, df_characters, on='character_id', how='left')",
    "Check the contents of the characters dataframe.",
    "Check if the imports are working correctly.",
    "Remove unnecessary large strings from the loaded objects\ndf_script = df_script.drop('text', axis=1)",
    " Display the first few rows of the characters DataFrame\ndf_characters.head()",
    "Display columns\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    "Let's first look at the structure of the datasets.",
    "Set some pandas display options for better visualizations\npd.set_option('display.max_columns', 50)\npd.set_option('display.max_colwidth', 100)\npd.set_option('display.max_rows', 50)",
    "The line above reads several CSV files into pandas DataFrames.",
    "Remove unwanted columns from the dataframes\ndf_characters.drop(['raw_character_text', 'raw_location_text', 'spoken_words'], axis=1, inplace=True)\ndf_locations.drop(['normalized_text'], axis=1, inplace=True)\ndf_script.drop(['timestamp_in_ms', 'speaking_line', 'character_id', 'episode_id', 'location_id', 'raw_text'], axis=1, inplace=True)\ndf_episodes.drop(['image_url'], axis=1, inplace=True)",
    "function to get the character quotes",
    "checking my data\ndf_script.head()",
    " Check the content of the 'simpsons_script_lines.csv' DataFrame\ndf_script.head()",
    " Join all datasets",
    "Sanity check: show the first rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Merge the datasets to get all the information at one place.",
    "Set up spaCy\nnlp = spacy.load('en_core_web_sm')",
    "Filter only 10 most common locations\ntop10locations = ['Simpson Home', 'Moe\\'s Tavern', 'Springfield Elementary School', 'Kwik-E-Mart', 'Power Plant', \n                  'Springfield Nuclear Power Plant', 'Springfield Town', 'First Church of Springfield', \n                  'Simpson Living Room', 'Springfield Street']\ndf_script_top10locations = df_script[df_script.raw_location_text.isin(top10locations)]",
    " Ensure all csv files were correctly loaded\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect the contents of df_characters dataframe",
    "Preview the script dataframe\ndf_script.head()",
    "List of characters as a set and list\nset_characters = set(df_characters['character'].values)\nlst_characters = list(set_characters)",
    "Join the data frames to make the master data set",
    "Set seeding for reproducibility",
    "Limit to main character speeches.\ndf_script = df_script[df_script['speaking_line']]",
    "Initialize a spaCy model for natural language processing.",
    " Print out a summary of each dataset\nprint(\"Characters:\")\nprint(df_characters.info())\n\nprint(\"\\nLocations\")\nprint(df_locations.info())\n\nprint(\"\\nScript\")\nprint(df_script.info())\n\nprint(\"\\nEpisodes\")\nprint(df_episodes.info())",
    "Clone the dataframes to avoid any SettingwithCopyWarnings in the future",
    "display first 5 rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "display all columns of the dataframe\npd.set_option('display.max_columns', None)",
    "Setup Spacy\nnlp = spacy.blank('en')",
    "Display pandas outputs as we expect\npd.set_option('display.max_columns', None)",
    "Number of script lines in the dataset\nlen(df_script)",
    "Let's take a preview of the character data",
    "Inspect content of the characters file\ndf_characters.head()",
    "Create a generic stop words list to remove common words from our text analysis\nstop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]",
    "See the first few lines of the characters data.\ndf_characters.head()",
    "Inspect the dataframes",
    "Print the first 5 rows of df_characters\ndf_characters.head()",
    "Merge dataset\ndf_script.info()",
    "Explore the data from df_characters dataframe",
    "Verify the dataframes are correctly loaded\ndf_characters.head()",
    "check the data\ndf_characters.head()",
    "Specify an output location for any saved data.",
    " Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Now we have imported the required data into dataframes for further analysis.",
    " Display columns\ndf_script.columns",
    "Print out head of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "### Show the first lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Get division lines from each script line.",
    "Import custom classes, functions and variables\nfrom nlp_pipeline import NLPPipeline\nfrom bokeh_helper import generate_chart_markup\n\nnlp = spacy.load('en_core_web_sm')",
    "Create a subset of df_script that includes only the fields needed\ndf_script_subset = df_script[['id', 'episode_id', 'character_id', 'location_id', 'raw_text']].copy()",
    "Extract main characters\nmain_characters = df_script.raw_character_text.value_counts().head(17).index.tolist()",
    "Check the structure of script dataframe\ndf_script.head()",
    "Connections and configurations for your database",
    "Let's check the df_characters head",
    "...and more imports",
    " Print the first few rows of each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Further code will interact with the datasets loaded in the previous step to extract insights or perform analysis on The Simpsons script data.",
    "Merge df_script with df_characters and df_locations\ndf_script_characters_locations = pd.merge(\n    pd.merge(df_script, df_characters, on='character_id', how='left'),\n    df_locations,\n    on='location_id',\n    how='left'\n)",
    " Display the first few rows of the dataframe\ndf_script.head()",
    "Display dataframe 'df_characters'\ndf_characters.head()",
    " Check the dataframe entries count, dataframe columns and null values with pandas utilities.",
    "Select only the title, original_air_date, and us_viewers_in_millions columns from df_episodes.",
    "Check the character data first few rows",
    "Creating a NLP model with spacy",
    "display the first few rows of the characters dataframe\ndf_characters.head()",
    "Display all the columns of the df_script dataframe\npd.set_option('display.max_columns', None)\ndf_script.head()",
    "Set styles and ignore warnings",
    "Inspecting the data...",
    "Check if tables have been correctly imported",
    " Let's work with a smaller dataset containing only one episode script to demonstrate the analytical process.",
    "View the characters dataframe\ndf_characters.head()",
    "Checking the top 3 rows of the characters dataframe",
    " Merge the datasets",
    "Display shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "#   display(df_characters.head())\n#   display(df_locations.head())\n#   display(df_script.head())\n#   display(df_episodes.head())",
    "\ndf_script.head()",
    "Let's just go ahead and display the headers for each CSV file to understand their structure and data types.",
    " Remove unwanted columns from the dataframes\ncolumns_to_drop = ['id', 'number', 'raw_text', 'timestamp_in_ms']\n\ndf_characters.drop(columns=columns_to_drop, inplace=True, errors='ignore')\ndf_locations.drop(columns=columns_to_drop, inplace=True, errors='ignore')\ndf_script.drop(columns=columns_to_drop, inplace=True, errors='ignore')\ndf_episodes.drop(columns=columns_to_drop, inplace=True, errors='ignore')",
    " Display the first 5 rows of each DataFrame to see how the data is structured\nprint(\"\\n\\n\")\nprint(\"Characters:\")\nprint(df_characters.head())\n\nprint(\"\\n\\n\")\nprint(\"Locations:\")\nprint(df_locations.head())\n\nprint(\"\\n\\n\")\nprint(\"Script:\")\nprint(df_script.head())\n\nprint(\"\\n\\n\")\nprint(\"Episodes:\")\nprint(df_episodes.head())",
    "Filter out the data we're interested in and avoid Join operations.",
    " Let's take a look at each of these DataFrames to better understand the data.",
    "Create a sample of the dataframe\ndf_script_sample = df_script.sample(n=1000, random_state=0)",
    "Set the indexing of the DataFrames to be the index column, as the index will be useful manipulate the DataFrames.",
    "Check the contents of the characters table\ndf_characters.head()",
    "Merge episodes and characters datasets\ndf_merged = df_episodes.merge(df_characters, how='left', left_on='id', right_on='episode_id')",
    "Filter columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']].copy()\n\n# Merge the tables\ndf = df_script.copy()\ndf = df.merge(df_episodes, left_on='episode_id', right_on='id')\ndf = df.merge(df_characters, left_on='character_id', right_on='id')\ndf = df.merge(df_locations, left_on='location_id', right_on='id')\n\n# Save for later use\ndf.to_csv('data/merged_simpsons_dataset.csv', index=False)",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Inspect the DataFrame containing information about the characters.",
    " Set the style of the the plot\nmatplotlib.style.use('seaborn-whitegrid')",
    "# Name of the character we want to analyze\ncharacter_name = 'Lisa Simpson'\n\n# Filter the scripts df for the selected character\ndf_character = df_script[df_script.raw_character_text == character_name]",
    "Create an instance of language model\nnlp = spacy.load('en_core_web_sm')",
    "Initializing model and processing scripts...",
    " Check the content of the characters dataframe\ndf_characters.head()",
    "Merge characters, locations and episodes into the main dataframe\ndf_script_full = (df_script\n                  .merge(\n                      df_characters,\n                      how='left',\n                      left_on='character_id',\n                      right_on='id',\n                      suffixes=('_script', '_character')\n                  )\n                  .merge(\n                      df_locations,\n                      how='left',\n                      left_on='location_id',\n                      right_on='id',\n                      suffixes=('','_location')\n                  )\n                  .merge(\n                      df_episodes,\n                      how='left',\n                      left_on='episode_id',\n                      right_on='id',\n                      suffixes=('','_episode')\n                  )\n                 )",
    "The first thing we'll do with the script data is to connect the script lines to episode, character and location ids.",
    "Inspect each dataframe and display its first five rows",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    " Strip whitespaces around episode names to avoid duplicates\ndf_episodes['normalized_name'] = df_episodes['normalized_name'].str.strip()",
    "Show the result of the first execution of the characters data base",
    "Random seed for reproducibility\nnp.random.seed(42)",
    "Delete the index from the CSV files",
    "Ensure dataframes are sorted by index",
    " Look at the head of the script dataframe to understand its structure\ndf_script.head()",
    "Show the first 5 rows of each dataframe to get a sense of the data",
    "Show data\ndf_script.head()",
    "Customize pandas display settings\npd.set_option('display.max_columns', None)",
    "Create a column for the script\ndf_script['text'] = df_script['normalized_text'].str.lower()",
    "Let's take a look at the first few rows of each dataset to understand what kind of data we're working with.",
    "Merge the datasets to create a single dataframe with all the information we need.",
    "Check all columns",
    "Preview tables\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Set path to data dir\nDATA_DIR = 'data/'",
    "Preview all DataFrames\nprint('Characters DataFrame shape:', df_characters.shape)\ndf_characters.head()",
    "Show the first 5 records of the dataset\ndf_characters.head()",
    "Filter by spoken words\ndf_script_lines = df_script[df_script['speaking_line'] == True]",
    "Display the first few rows of the table containing the script lines.",
    "Inspect data\ndf_episodes.head()",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Display maximum columns when displaying the dataframe\npd.set_option('display.max_columns', None)",
    "Let's take a look at the first 5 rows of each of these DataFrames.",
    "Check if the data is correctly loaded\ndf_script.head()",
    "Check if we have loaded the datasets correctly",
    "tag::pre_requisites[]",
    "Inspect data types and missing values\ndf_script.info()",
    "Create a directory to save the visualization results\nif not os.path.exists('visualizations'):\n    os.makedirs('visualizations')",
    "Display the first few records of the characters data frame\ndf_characters.head()",
    "Character names often appear with spaces and uppercase letters and a dot at the end.",
    " Let's quickly look at what is contained in the datasets.",
    "Merge the datasets to add more dimensions to the data analysis\ndf_script_ext = pd.merge(\n    pd.merge(\n        pd.merge(df_script, df_characters, on='character_id', how='left'),\n        df_episodes,\n        on='episode_id',\n        how='left'\n    ),\n    df_locations,\n    on='location_id',\n    how='left'\n)",
    "Display pandas without truncation\npd.set_option('display.max_colwidth', None)",
    "Prune all bad data at the start\nprint(len(df_characters))\nprint(len(df_locations))\nprint(len(df_script))\nprint(len(df_episodes))",
    " Display data details\ndf_characters.info()\ndf_locations.info()\ndf_script.info()\ndf_episodes.info()",
    "View shape of datasets\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
    "We will start with the data exploration of the 'simpsons_script_lines.csv' file.",
    " Exploring the datasets",
    "Load the data",
    "Add encoding argument to read_csv calls to fix UnicodeDecodeError",
    "Merge script lines, characters and locations\ndf_merged = df_script.merge(df_characters, how='left', on='character_id')",
    " Visualization 1: Top 10 Characters by Number of Lines\ntop_10_characters_by_lines = df_script['normalized_name'].value_counts().head(10)\ntop_10_characters_by_lines.plot(kind='bar', figsize=(20,10))\nplt.xticks(rotation=45)\nplt.title('Top 10 Characters by Number of Lines')\nplt.xlabel('Character Name')\nplt.ylabel('Number of Lines')\nplt.show()",
    "Start by filtering only the dialogues by Homer Simpson.",
    "Load the trained English tokenizer, tagger, parser, NER and word vectors",
    "Remove unwanted columns from characters, locations and episodes dataframes",
    " Display the dimension of the dataset\nprint(\"Characters dimension: \", df_characters.shape)\nprint(\"Locations dimension: \", df_locations.shape)\nprint(\"Episodes dimension: \", df_episodes.shape)\nprint(\"Script dimension: \", df_script.shape)",
    "merge the script and episodes into a single dataframe",
    " Replacing NaN with empty string\ndf_script.fillna(\"\", inplace=True)",
    "Preview the data\ndf_characters.head()",
    "Subset df_episodes to only take episodes from the first 12 seasons (up to 2001)",
    "We'll perform a quick check on the data.",
    "Create a new instance of the nlp pipeline\nnlp = spacy.load('en_core_web_md')",
    "Explore the datasets\ndf_characters.head()",
    "Explore the characters dataframe\ndf_characters.head()",
    "Inspect the first few rows of each dataframe to understand the data",
    "Filter for \"Lisa Simpson\" character\ndf_lisa_lines = df_script[df_script['character_id'] == 9]\n\n# Show the top 5 rows\ndf_lisa_lines.head()",
    "Ensure data is as expected\ndisplay(df_characters.head(5))\ndisplay(df_locations.head(5))\ndisplay(df_script.head(5))\ndisplay(df_episodes.head(5))",
    "Display the dataframes to check they have been loaded correctly\ndf_characters",
    "First, let's take a look at the first few rows of each dataframe to understand what kind of data we're working with.",
    " We need a parser to process the script\nnlp = spacy.load('en_core_web_sm')",
    "Ensure all scripts have a unique identifier\ndf_script = df_script.drop_duplicates(subset='id')",
    "\ndf_script.head()",
    " 1. Display the first 5 rows for the characters dataframe\ndf_characters.head()",
    "Strip leading/trailing whitespaces in text\n\ndf_script['raw_text'] = df_script['raw_text'].str.strip()",
    "Define constant strings for specific data fields.",
    "Filter only by the \"The Simpsons\" show\ndf_episodes = pd.merge(df_episodes, df_script, on='episode_id')\ndf_episodes = df_episodes[df_episodes['title'].str.contains('Simpsons')]\n\ndf_episodes.groupby('title').agg({\n    'number': 'first',\n    'us_viewers_in_millions': 'first',\n    'views': 'first',\n    'imdb_rating': 'first'\n})",
    " Some cleaning of fields and datatypes",
    " Let's take a look at the first few rows of each dataframe to understand its structure.",
    "Enable large screen support\npd.set_option('display.max_rows', 500)",
    " Display the columns of the script data frame\ndf_script.columns",
    "The dataset contains the following tables:",
    " Display a sample of the dataset\ndf_script.head()",
    "Filtering only those records which have been spoken by a character (non-null value)",
    "Add newline character in the end",
    "Set up the matplotlib figure",
    "Check and display the first 5 rows of each DataFrame",
    "View the first few rows of the dataframe to understand the data better\ndf_characters.head()",
    "concatenate locations and script dataframes",
    "Store all unique script IDs in a list for further processing.",
    " Let's take a look at the first few rows of each dataset.",
    "Let's print the first 5 rows from each dataframe to better understand their structure.",
    "Inspect the first few rows of the characters DataFrame\ndf_characters.head()",
    "Lets see what each dataframe looks like",
    "A sample of the characters dataset\ndf_characters.head()",
    "Remove the rows with missing values.",
    "Let's have a look at the first few rows of each DataFrame to understand their structure.",
    "Clean names from locations dataset and assign an unique identifier for each name",
    "Checking simpsons_characters data",
    "\n# Print the first lines of the table related to the characters present in the series\ndf_characters.head()",
    "View the first few lines of the characters dataframe\ndf_characters.head()",
    "Applying a simple filter to exclude meaningless descriptions, e.g. \"opening sequence\"",
    "Remove quotations around the speaker name in the script data\ndf_script['character_id'] = df_script['character_id'].str.replace('\"', '')\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.replace('\"', '')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\"', '')",
    " Show the first few characters of the main datasets\ndf_script.head()",
    "inspect the first 5 rows of the df_characters dataframe\ndf_characters.head()",
    "Inspect the first few entries of the characters dataframe",
    "Count the number of lines in df_script\nlen(df_script)",
    " Checking the first few rows of the characters dataframe\ndf_characters.head()",
    "We have imported the necessary libraries and now we are loading the datasets using pandas.read_csv() function and resetting the index for each dataframe.",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    " Merge characters and script\ndf_char_scripts = pd.merge(df_script, df_characters, on='character_id', suffixes=(\"\", \"_char\"), how=\"left\")",
    "Let's take a look at the characters data.",
    "Defines the character names by its reception of the user defined name in a lowercase manner for searching consistency",
    "Preview the data\nprint(\"Characters data\")\nprint(df_characters.head(2))\nprint(\"\\nLocations data\")\nprint(df_locations.head(2))\nprint(\"\\nScript data\")\nprint(df_script.head(2))\nprint(\"\\nEpisodes data\")\nprint(df_episodes.head(2))",
    "Setting correct datatypes for the dataframes",
    "Select required columns from df_characters\ndf_characters = df_characters[['id', 'name', 'normalized_name', 'gender']]\ndf_characters.head()",
    "Inspectig the first few lines of the df_characters dataframe",
    "Split names into first and last names\ndf_characters[['first_name', 'last_name']] = df_characters.character.str.split(\"_\", expand=True)",
    " Check out the first entries for each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Show the first 5 characters in the characters dataframe\ndf_characters.head()",
    "Explore the datasets",
    "Inspect the first few rows of each dataframe to understand their structure and available data",
    "Checking if the data has been loaded properly",
    "Join script lines with character and episode information\ndf_script['character_name'] = df_script['character_id'].apply(lambda x: df_characters.loc[df_characters['id'] == x, 'name'].values[0] if len(df_characters.loc[df_characters['id'] == x, 'name'].values) > 0 else '')\ndf_script['location_name'] = df_script['raw_location_id'].apply(lambda x: df_locations.loc[df_locations['id'] == x, 'name'].values[0] if len(df_locations.loc[df_locations['id'] == x, 'name'].values) > 0 else '')\ndf_script['episode_title'] = df_script['episode_id'].apply(lambda x: df_episodes.loc[df_episodes['id'] == x, 'title'].values[0] if len(df_episodes.loc[df_episodes['id'] == x, 'title'].values) > 0 else '')\ndf_script['imdb_rating'] = df_script['episode_id'].apply(lambda x: df_episodes.loc[df_episodes['id'] == x, 'imdb_rating'].values[0] if len(df_episodes.loc[df_episodes['id'] == x, 'imdb_rating'].values) > 0 else '')",
    "Inspecting first few records",
    "Settings\npd.set_option('display.max_columns', None)",
    "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Let's look at the first few rows of each of these dataframes to understand their structure and contents.",
    "Data Processing",
    " Let's take a look at the structure of the datasets.",
    "\ndf_characters.head()",
    "check the number of null values in each column of the df_script dataframe\ndf_script.isnull().sum()",
    "Let's start by taking a quick look at the first rows of each dataframe.",
    "Create a new data frame containing only episode name, character name, and dialogue.",
    "Add missing columns to df_script\ndf_script['full_text'] = df_script['raw_text'] + \" \" + df_script['normalized_text'].fillna(\"\")",
    " Display the scripts dataframe to understand its structure\ndf_script.head()",
    "Display the header of the DataFrame to understand its structure\ndf_script.head()",
    "Structure df_characters and df_locations to allow seaborn to easily plot the value_counts().",
    "BERT model\nnlp = spacy.load('en_trf_bertbaseuncased_lg')",
    "Data organization\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\ndf_script = df_script.merge(df_locations, on='location_id', how='left')",
    "View first 5 rows of script data\ndf_script.head()",
    "Remove the excess index column and display the first few rows of the dataframe\ndf_script = df_script.iloc[:, 1:]\ndf_script.head()",
    " Set default pandas option\npd.set_option('display.max_columns', None)",
    "Dataset content\nprint(\"characters shape:\", df_characters.shape)\nprint(\"locations shape:\", df_locations.shape)\nprint(\"script shape:\", df_script.shape)\nprint(\"episodes shape:\", df_episodes.shape)",
    "Merge datasets: Location to Episode\ndf_locations_ep = df_locations.merge(df_episodes,\n                                     on='id',\n                                     how='right')\n# Change the order of columns\n# Get the list of columns\ncols = df_locations_ep.columns.tolist()\n# Print the list\nprint(cols)",
    " Display the first few rows of the dataframe for characters\ndf_characters.head()",
    "In this step, we have read the CSV files into pandas dataframes for further processing and analysis.",
    "Remove useless columns from characters and locations DataFrames\ndf_characters = df_characters[['id', 'name', 'normalized_name']]\ndf_locations = df_locations[['id', 'name', 'normalized_name']]",
    " Check the import\nprint(\"Datasets loaded successfully.\")",
    " Remove punctuation and lowercase all text\ndf_script['normalized_text'] = df_script['raw_text'].str.replace('[^\\w\\s]','').str.lower()",
    "Let's take a look at the dataframes.",
    "\n# Display the first few lines of the script DataFrame\ndf_script.head()",
    "Set Jupyter output display options for large dataframes\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\npd.set_option('display.width', 1000)",
    "Show the head of the characters dataframe\ndf_characters.head()",
    "Select your character of interest from the list of characters. Fill in the character name in the variable below.",
    "Main dataframe head\ndf_script.head()",
    "Let's take a look at the dataframes to understand their structure and the type of information we have.",
    "Creating a subset of the DataFrame to focus on a specific episode for analysis",
    " Take a look at the dataframes to understand their structure and content\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Light text preprocessing",
    "Print a few lines of each dataset to demonstrate what kind of data is included.",
    "Set seed for reproducibility\nnp.random.seed(42)",
    "df_characters.info()",
    "Display max word in each column of the datasets\npd.options.display.max_colwidth = None",
    " For some reason, the index column `Unnamed: 0` is created during csv\n#  reading; we need to remove this from the dataframes.",
    " Display the head of the characters DataFrame\ndf_characters.head()",
    "Merge character, location and episode data into the script data\ndf_script = pd.merge(df_script, df_characters, on='character_id', how='left')\ndf_script = pd.merge(df_script, df_locations, on='location_id', how='left')\ndf_script = pd.merge(df_script, df_episodes, on='episode_id', how='left')",
    " Now let's see the structure of each table to better understand the data.",
    "Check the first few rows of the df_script dataframe\ndf_script.head()",
    "Display the first few rows of each dataframe to verify that the data was loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "display the 5 first rows\ndf_script.head()",
    "Text preprocessing\n# We want to preprocess the spoken words, removing special characters and non-useful information in order to create a wordcloud\ndf_script_processed = df_script[['raw_character_text', 'spoken_words']].dropna().copy()\ndf_script_processed['spoken_words'] = df_script_processed['spoken_words'] \\\n    .str.replace(r'[^A-Za-z\\s]', '') \\\n    .str.lower()\n\n# Using Spacy for our corpora of text\nnlp = spacy.load('en')\n\n# Let's filter the characters names from the text\n# We'll perform only Named Entity Recognition and keep the identified characters\ndf_script_processed = df_script_processed[:int(len(df_script_processed)/50)]\nidentified_characters = {}\nfor character in tqdm(df_script_processed.raw_character_text.unique()):\n    character_doc = nlp(character)\n    identified_characters[character] = list(set([ent.text for ent in character_doc.ents if ent.label_ == 'PERSON']))\n\n# Let's double-check the presence of those characters and their identification\n{\n    character: identified_characters[character]\n    for character in identified_characters\n    if identified_characters[character]\n}",
    " Display the first few lines of each dataframe to understand the data",
    "Joining datasets",
    " Merge episodes and script lines\ndf_episodes['id'] = df_episodes['id'].astype(int)\ndf_merged = df_script.merge(df_episodes, left_on='episode_id', right_on='id').iloc[:, 2:]\n\n# Add location names\ndf_merged = df_merged.merge(df_locations, how='left', left_on='raw_location_text', right_on='raw_location_text')\n\n# Keep relevant columns\ndf_merged = df_merged[[\n    'id', 'spoken_words', 'raw_location_text', 'name', 'normalized_name', 'production_code', 'original_air_date', 'season', \n    'number_in_season', 'number_in_series', 'us_viewers_in_millions', 'views', 'imdb_rating', 'imdb_votes', 'image_url'\n]].rename({\n    'spoken_words': 'dialogue',\n    'raw_location_text': 'location',\n    'name': 'episode_name',\n    'normalized_name': 'location_name'\n}, axis=1)",
    "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Show the first few rows of the characters dataframe\ndf_characters.head()",
    "Display all columns in dataframes\npd.set_option('display.max_columns', None)",
    " Display the first 5 rows of each table\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Setting display options for the notebooks\npd.set_option('display.max_colwidth', None)",
    "Text data will be manipulated with spaCy and some langague model (medium or large one) is needed to preceed.",
    "Show first few rows of characters dataframe\ndf_characters.head()",
    "Inspecting the first 5 rows of the characters DataFrame",
    "Change the episode air date to a datetime object\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], infer_datetime_format=True)",
    "Display all the columns in the script dataframe",
    " Display the first few rows of the characters dataframe.\ndf_characters.head()",
    "pd.set_option('max_columns', None)",
    "Inspecting the first three rows of the df_characters dataframe.",
    "inspect the first few rows of each dataframe to see its structure.",
    "Merge the tables\ndf = df_script.merge(df_episodes, how='left', on='episode_id')",
    "Data cleaning: Missing values",
    "View dataset\ndf_characters.head()",
    "Filtering lines with character and location information from the script\ndf_script_filtered = df_script[\n    df_script['raw_character_text'].isin(df_characters['name']) &\n    df_script['raw_location_text'].isin(df_locations['name'])\n].copy()",
    " preprocess each script line",
    " Set the missing episode in df_characters DataFrame",
    "Specify the columns that are useful in the context of this analysis",
    "\nprint(df_characters)",
    "Sample the dataframe by printing each distinct value and it's frequency\nfor idx, value_count in df_characters.nunique().iteritems():\n    print(idx, value_count)",
    " Check the first few rows of the characters data\ndf_characters.head()",
    "Set the 'id' column as index for faster lookups\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "Show the first rows of the characters dataset\ndf_characters.head()",
    " Set up Spacy\nnlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])",
    " make sure transformations of default Jupyter mode is off\npd.set_option('mode.chained_assignment', None)",
    "Set up spaCy\nnlp = spacy.load('en')",
    "Optional line if 'data' folder is not in the same as the script and '(df_characters...)' is commented out\nbasepath = 'data/'",
    " Check the first 5 rows for each DataFrame to get an idea of the data",
    " Look at directory contents\n!ls data",
    " Show the first few rows of each table",
    " Display the number of rows and columns for each dataframe\nprint(\"characters:\", df_characters.shape)",
    "Show big pictures\nmatplotlib.rcParams['figure.figsize'] = [40, 20]",
    "Query the latest version of a dataset\nprint(df_script.query('episode_id == 75 and number_in_episode >= 2 and number_in_episode <= 5'))",
    "Mergeing characters and locations dataframe to script line so that we have the character and location for each line",
    " Print few lines of data to see what is present\ndf_characters.head()",
    "Ensure the dataframe (df_script) has the character_id, location_id\ndf_script = df_script[~(df_script.is_na() == True)]",
    "Display first 5 rows of each dataframe",
    "Display the first few rows of the dataframe containing the script lines.",
    "Check the contents of the dataset\ndf_script.head()",
    "Display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "summary of data\nprint(\"characters:\", df_characters.shape)\nprint(df_characters.head())\nprint(\"locations:\", df_locations.shape)\nprint(df_locations.head())\nprint(\"script:\", df_script.shape)\nprint(df_script.head())\nprint(\"episodes:\", df_episodes.shape)\nprint(df_episodes.head())",
    "Check if the dataframes have been read correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Let's first have a look at the data.",
    " Display top rows of the dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Viewing first ten records of the dataframe which contains the script for the scenes of all the episodes",
    "View statistics of all DataFrames\nprint(\"\\n- Springfield's Data -\")\nprint(\"\\n- Characters -\\n\", df_characters.info())\nprint(\"\\n- Locations -\\n\", df_locations.info())\nprint(\"\\n- Episodes -\\n\", df_episodes.info())\nprint(\"\\n- Scripts -\\n\", df_script.info())",
    "jupyter notebook... so much power!\ndf_script.head(20)",
    " Filter only the contributions of the main characters\nmain_characters = ['marge', 'homer', 'bart', 'lisa', 'maggie', 'sideshow', 'ned', 'krusty', 'milhouse', 'chief']\ndf_script_main_characters = df_script[df_script['raw_character_text'].str.lower().isin(main_characters)]",
    "Merge script lines with characters\ndf_script = df_script.merge(df_characters, on='character_id', how='inner')\n\n# Merge script lines with locations\ndf_script = df_script.merge(df_locations, on='location_id', how='inner')\n\n# Merge script lines with episodes\ndf_script = df_script.merge(df_episodes, on='episode_id', how='inner')",
    "Test to ensure the data has been read correctly\ndf_characters.head()",
    "Check if scripts lines has the episode ID",
    " Let's take a look at the columns of each dataframe and some of its rows to understand the data.",
    "Ignore all future warnings to improve readibility, since they clutter the output too much\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)",
    "Set index of scripts to line_id\ndf_script.set_index('id', inplace=True)",
    "Code to load data from CSV files into pandas dataframes",
    "Remove NaN values from 'character_id' column, and convert it to int\ndf_script = df_script.dropna(subset=['character_id'])\ndf_script['character_id'] = df_script['character_id'].astype(int)",
    "# Show sample data for characters\ndf_characters.head()",
    "Hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
    "Print the characters dataframe\nprint('Characters dataframe')\nprint(df_characters.head())\n\n# Print the locations dataframe\nprint('\\nLocations dataframe')\nprint(df_locations.head())\n\n# Print the script dataframe\nprint('\\nScript dataframe')\nprint(df_script.head())\n\n# Print the episodes dataframe\nprint('\\nEpisodes dataframe')\nprint(df_episodes.head())",
    " Display the first few rows of each dataframe to understand the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Drop one column because the indexcol is exported as a column",
    "Print how many episodes our dataset contains",
    " Remove duplicate character and location names\ndf_characters.drop_duplicates(subset =\"name\", inplace = True)\ndf_locations.drop_duplicates(subset =\"name\", inplace = True)",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Data loading and preprocessing",
    "Merge the episodes with the script\ndf_episodes['id'] = df_episodes['id'].astype(int)\ndf_script = pd.merge(df_script, df_episodes, how='inner', left_on=df_script['episode_id'], right_on=df_episodes['id'])",
    "Explore data available.",
    "Merge episodes and script\ndf_episodes = df_episodes.rename(columns={'id':'episode_id'})\ndf = df_script.merge(df_episodes, on='episode_id')",
    "Checking few records\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "This is an example of loading CSV data into pandas dataframes in Python. The dataframes are named df_characters, df_locations, df_script, and df_episodes. The dataframes will hold the data from the CSV files 'simpsons_characters.csv', 'simpsons_locations.csv', 'simpsons_script_lines.csv', and 'simpsons_episodes.csv', respectively.",
    "Fetch a subset of the data and decrease it for efficiency",
    "Display the first row of the dataframe.",
    " Disabling the Warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
    " Display basic information about dataframes",
    " Sample data\ndf_script.head(), df_locations.head()",
    "\n# Display head of the characters DataFrame\ndf_characters.head()",
    " Load in the data from the CSV files into pandas DataFrames.",
    "Print the head of the 'script' dataset\ndf_script.head()",
    "Let's have a look at the data.",
    "View some data info\nprint('Characters info')\nprint(df_characters.info())\n\nprint('\\n-------------------\\n')\nprint('Locations info')\nprint(df_locations.info())\n\nprint('\\n-------------------\\n')\nprint('Script info')\nprint(df_script.info())\n\nprint('\\n-------------------\\n')\nprint('Episodes info')\nprint(df_episodes.info())",
    "Filtering the data to retain only the lines from the Simpsons character named 'Marge'",
    "Check if the data was properly loaded",
    " Display basic information for the dataframes\nprint('Characters dataframe:')\nprint(df_characters.head())\nprint('\\nLocations dataframe:')\nprint(df_locations.head())\nprint('\\nScript dataframe:')\nprint(df_script.head())\nprint('\\nEpisodes dataframe:')\nprint(df_episodes.head())",
    "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Check the first 5 rows of the characters DataFrame\ndf_characters.head()",
    "Show a few samples of the characters dataframe",
    "Load the 'simpsons_script_lines.csv', 'simpsons_episodes.csv', 'simpsons_characters.csv', and 'simpsons_locations.csv' files into pandas dataframes.",
    "Inspect the first few rows of each dataframe to understand its structure and content\ndf_characters.head()",
    "Show first 5 rows of each dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect the first few rows of each dataframe to understand the data",
    "Display the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "# Merge script and location with character information\n# WARNING: this step can take a few minutes as it requires to process all the textual data\ndf_merged = pd.merge(df_script,\n                     df_characters,\n                     how='left',\n                     left_on='character_id',\n                     right_on='id')\n\ndf_merged = pd.merge(df_merged,\n                     df_locations,\n                     how='left',\n                     left_on='location_id',\n                     right_on='id')",
    "Check the general information of the Python DataFrames",
    "Print the first few records of the characters dataset\ndf_characters.head()",
    "Inspect data types and missing values\ndf_characters.info()",
    " Load Spacy NLP model\nnlp = spacy.load('en_core_web_sm')",
    "Filter unnecessary columns\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id']]",
    " Creating folder to save images",
    " Check the first 5 rows of the script dataframe\ndf_script.head()",
    "# Initialize spaCy's tokenizer\nnlp = spacy.load('en_core_web_sm')",
    "Columns in the lines dataframe that we'll use:\n## Speaking character\n## Spoken text\n## Season\n## Episode\n## Location\n## Character gender",
    "Check the first few rows of each dataframe to understand the data",
    "Look at the top few rows of each dataframe to understand the data structure\ndf_characters.head()",
    "Display all columns to know which one to remove\npd.set_option('display.max_columns', None)",
    " Join script lines with character id\ndf_script = df_script.merge(df_characters[['id', 'raw_character_text']], left_on='character_id', right_on='id', how='left')",
    "Set random seed for reproducibility\nnp.random.seed(42)",
    "Set maximum number of columns displayed in pandas\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Filtering for the episode with the most lines and including only spoken lines",
    "Load pre-trained spaCy model\nnlp = spacy.load('en_core_web_sm')",
    "Check the structure of characters, locations, scripts and episodes datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Quick glance at the dataset\ndf_script.head()",
    "\ndf_characters['raw_character_text']",
    " show first 5 lines of each dataframe\nfor name, df in zip(['Characters', 'Locations', 'Script', 'Episodes'], [df_characters, df_locations, df_script, df_episodes]):\n    print(name)\n    print(df.head(), '\\n\\n')",
    "id we loaded all the datasets correctly?",
    "Define ordering of seasons and episodes\nseason_episode_order = {\n    (1, 1): 1,   (1, 2): 2,   (1, 3): 3,   (1, 4): 4,\n    (2, 1): 5,   (2, 2): 6,   (2, 3): 7,   (2, 4): 8,\n    (3, 1): 9,   (3, 2): 10,  (3, 3): 11,  (3, 4): 12,\n    (4, 1): 13,  (4, 2): 14,  (4, 3): 15,  (4, 4): 16,\n    (5, 1): 17,  (5, 2): 18,  (5, 3): 19,  (5, 4): 20,\n    (6, 1): 21,  (6, 2): 22,  (6, 3): 23,  (6, 4): 24,\n    (7, 1): 25,  (7, 2): 26,  (7, 3): 27,  (7, 4): 28,\n    (8, 1): 29,  (8, 2): 30,  (8, 3): 31,  (8, 4): 32,\n    (9, 1): 33,  (9, 2): 34,  (9, 3): 35,  (9, 4): 36,\n    (10, 1): 37, (10, 2): 38, (10, 3): 39, (10, 4): 40,\n    (11, 1): 41, (11, 2): 42, (11, 3): 43, (11, 4): 44,\n    (12, 1): 45, (12, 2): 46, (12, 3): 47, (12, 4): 48,\n    (13, 1): 49, (13, 2): 50, (13, 3): 51, (13, 4): 52,\n    (14, 1): 53, (14, 2): 54, (14, 3): 55, (14, 4): 56,\n    (15, 1): 57, (15, 2): 58, (15, 3): 59, (15, 4): 60,\n    (16, 1): 61, (16, 2): 62, (16, 3): 63, (16, 4): 64,\n    (17, 1): 65, (17, 2): 66, (17, 3): 67, (17, 4): 68,\n    (18, 1): 69, (18, 2): 70, (18, 3): 71, (18, 4): 72,\n    (19, 1): 73, (19, 2): 74, (19, 3): 75, (19, 4): 76,\n    (20, 1): 77, (20, 2): 78, (20, 3): 79, (20, 4): 80,\n    (21, 1): 81, (21, 2): 82, (21, 3): 83, (21, 4): 84,\n    (22, 1): 85, (22, 2): 86, (22, 3): 87, (22, 4): 88,\n    (23, 1): 89, (23, 2): 90, (23, 3): 91, (23, 4): 92,\n    (24, 1): 93, (24, 2): 94, (24, 3): 95, (24, 4): 96,\n    (25, 1): 97, (25, 2): 98, (25, 3): 99, (25, 4): 100,\n    (26, 1): 101, (26, 2): 102, (26, 3): 103, (26, 4): 104,\n    (27, 1): 105, (27, 2): 106, (27, 3): 107, (27, 4): 108,\n    (28, 1): 109, (28, 2): 110, (28, 3): 111, (28, 4): 112,\n    (29, 1): 113, (29, 2): 114, (29, 3): 115, (29, 4): 116,\n    (30, 1): 117, (30, 2): 118, (30, 3): 119, (30, 4): 120,\n    (31, 1): 121, (31, 2): 122, (31, 3): 123, (31, 4): 124,\n    (32, 1): 125, (32, 2): 126, (32, 3): 127, (32, 4): 128\n}",
    " Join the dataframes",
    "Set up matplotlib\nfont = {'family' : 'normal',\n        'weight' : 'bold',\n        'size'   : 22}\n\nmatplotlib.rc('font', **font)",
    "Preview the characters data\ndf_characters.head()",
    " Set index to 'id' for all dataframes\ndf_script.set_index('id', inplace=True)\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "Preprocessing\n# ",
    " Let's take a look at the data to understand what we are working with.",
    "Setting up the data directory path\ndata_dirpath = \"data\"",
    "Let's take a first look at the data.",
    "Check head of dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "to make it easier to join on the episode\ndf_script['id'] = df_script['episode_id']",
    "# cheek NaN values in dataframes\nprint('Characters NaN values: ' + str(sum(df_characters.isna().sum())))\nprint('Locations NaN values: ' + str(sum(df_locations.isna().sum())))\nprint('Script NaN values: ' + str(sum(df_script.isna().sum())))\nprint('Episodes NaN values: ' + str(sum(df_episodes.isna().sum())))",
    "Set options for pandas\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', 500)",
    "#split the huge script file to disable the huge warning of 15GB\ndf_script1 = df_script.iloc[:300000]\ndf_script2 = df_script.iloc[300000:]",
    "Display the first few rows of each dataframe to understand the data",
    "#List of stopwords\nstopwords = spacy.lang.en.stop_words.STOP_WORDS",
    "View the characters dataframe\ndf_characters.head()",
    " Join the dataframes on the corresponding keys to create a unified dataframe",
    "Visualize the correlation matrix of the dataset\nmatplotlib.rcParams['figure.figsize'] = [12, 7]\nmatplotlib.rcParams['figure.dpi'] = 80\ncorrelation_matrix = df_script.corr()\nplt.imshow(correlation_matrix, cmap='hot', interpolation='nearest')\nplt.colorbar()\nplt.title('Correlation matrix')\nplt.show()",
    "Filter out any rows missing a location, character, or raw text\ndf_script = df_script[\n    df_script.raw_location_id.apply(lambda x: not pd.isnull(x)) &\n    df_script.raw_character_id.apply(lambda x: not pd.isnull(x)) &\n    df_script.raw_text.apply(lambda x: type(x) != float) # Ensure that the text column is a string\n]",
    "\n# Merge data for convenience\ndf_merged = pd.merge(\n    df_script,\n    df_episodes,\n    how=\"left\",\n    on=\"episode_id\",\n    suffixes=(\"_script\", \"_ep\")\n)",
    "View first 10 rows of each DataFrame\nfor df, name in zip([df_characters, df_locations, df_episodes, df_script], \n                    ['Characters', 'Locations', 'Episodes', 'Script']):\n    display(HTML(f\"<h2>{name}</h2>\"))\n    display(df.head(10))",
    "# Join script database with characters\ndf_characters_info = df_script.join(df_characters.set_index('id'), on='character_id')\n\n# Join characters info database with locations\ndf_locations_info = df_characters_info.join(df_locations.set_index('id'), on='location_id')",
    "Let's start by looking at some general statistics for our datasets.",
    "Set max display columns\npd.set_option('display.max_columns', 500)",
    "Inspect the dataframe shapes",
    "Set the font preferences and other preferences to make the plots look nicer",
    "Check content of these tables\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check the first 5 rows of the characters DataFrame\ndf_characters.head()",
    " Display the head of the characters dataframe\ndf_characters.head()",
    "Display the first few rows of the script dataframe to understand its structure\ndf_script.head()",
    "# Display the first 5 rows of the 'df_characters' dataframe\ndf_characters.head()",
    "Let's take a look to the columns present in the different datasets.",
    "Check the data and its format\ndf_episodes.head()",
    "# Print the dataframes information to have a better understanding of their structure\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
    " Checking the data types of every column",
    "Visualize each character's distribution of lines in the dataset\ndf_characters_count = df_script['raw_character_text'].value_counts()\ndf_characters_count = df_characters_count[df_characters_count > 50]  # Filter low count characters\n\n# Sort by value count\ndf_characters_count.sort_values(inplace=True)\n\n# Plot histogram\nplt.barh(df_characters_count.index, df_characters_count.values)\nplt.title('Character line count distribution')\nplt.xlabel('Line count')\nplt.ylabel('Character')\nplt.show()",
    "Print the head of the characters dataframe\ndf_characters.head()",
    "Remove empty quips (some lines have only a quip, or the quip is part of the dialog [1/3, 1/3])\ndf_script = df_script.dropna(subset=['spoken_words'])",
    "Check the dataframes\ndf_characters.head()",
    "Let's check the first rows of each table",
    "Preview the characters dataframe\ndf_characters.head()",
    "Limit the dataframe only to the first column",
    "Inspect the Simpsons script data to get an idea of its structure and the information available.",
    "pd.set_option('display.max_columns', None)",
    "Define feature engineering pipeline using Transformers\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass BasicProcessing(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X, y=None):\n        X['usertagvalue'] = X['url'].apply(lambda x: x.split(':')[1] if isinstance(x, str) else '')\n        X['UUID'] = X['usertagvalue'].apply(lambda x: x.split('/')[0] if isinstance(x, str) else '')\n        return X",
    " Display the first few rows of each dataframe to understand its structure and the available columns.",
    " Subsets\ndf_episodes.head()",
    "Notes for dataframes:\n# df_characters: \n# df_locations: \n# df_script: id|episode_id|number|raw_text|timestamp_in_ms|speaking_line|character_id|location_id\n# df_episodes: id|title|original_air_date|production_code|season|number_in_season|number_in_series|us_viewers_in_millions|views|imdb_rating|imdb_votes|image_url|video_url\n",
    " Join characters name to scripts\ndf_characters = df_characters.rename(columns={'id':'character_id', 'name':'character_name'})\ndf_script = df_script.merge(df_characters[['character_id', 'character_name']], how='inner', on='character_id')",
    " Display the different dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "# Disable warning\npd.options.mode.chained_assignment = None",
    " Set environment variable for gensim word2vec model path\nos.environ[\"GENSIM_DATA_DIR\"] = \".\"",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Display the first few rows of the dataframe.",
    " Defining the problem\n\n# We're given a dataset of Simpson's scripts and we want to use natural language processing (NLP) techniques to better understand the show.",
    "Combine locations and scripts\ndf_script_locations = df_script.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_location'))",
    "Check the first 5 rows of df_characters DataFrame\ndf_characters.head()",
    "Name columns consistently across datasets.",
    "Fix some properties with the types they should have\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].replace(np.nan, 0).astype('int64')\ndf_script['raw_text'] = df_script['raw_text'].replace(np.nan, '')\ndf_script['speaking_line'] = df_script['speaking_line'].astype(bool)\ndf_script['character_id'] = df_script['character_id'].replace(np.nan, -1).astype('int32')\ndf_script['location_id'] = df_script['location_id'].replace(np.nan, -1).astype('int32')",
    "Visualize the word cloud for the character speaking lines\nspeaking_lines = df_script.query('speaking_line').reset_index(inplace=False, drop=True)",
    "Split the text of every script line into individual words.",
    "Merge all datasets\ndf_merged = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('', '_ep'))\ndf_merged = df_merged.merge(df_characters, left_on='character_id', right_on='id', suffixes=('', '_ch'))\ndf_merged = df_merged.merge(df_locations, left_on='location_id', right_on='id', suffixes=('', '_loc'))",
    "Inspect each dataframe using the .info() and .head() methods to understand the data",
    " Display a few basic details about the datasets.",
    "# Remove empty episodes in script\ndf_script = df_script.dropna(subset=['episode_id'])",
    "Filtering for the first episode as an example\ndf_episode_1 = df_script[(df_script['episode_id'] == 1)].copy()\ndf_episode_1.rename(columns={'raw_text':'text'}, inplace=True)",
    "Explore the structure of the characters dataframe\nprint(df_characters.info())",
    "# Initialize spaCy\nnlp = spacy.load(\"en_core_web_sm\")",
    "Remove all the non speaking lines from the script data frame\ndf_script = df_script[df_script.speaking_line == True].copy()",
    "Setting current directory\nos.chdir('SIMPSONS_DATASET/')",
    "Limit the dataframe to the first 5,000 rows for faster experimentation\ndf_script = df_script.iloc[:5000]",
    "Check if the dataframe creation is successful\ndf_characters",
    "We can remove some entries from df_characters that do not contribute to our analysis.",
    "imple display the first few rows of each DataFrame for a quick inspection\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Limit the script to only include spoken words by characters\ndf_script = df_script[df_script['speaking_line'] == True]",
    "We use 'reset_index(inplace=False, drop=True)' to reset the index of the DataFrame without inserting it as a column and dropping the current index.",
    "Remove unused columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'speaker_line', 'timestamp_in_ms', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words']]\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]\ndf_locations = df_locations[['id', 'name']]",
    "Creating a dummy script dataframe for the splash screen",
    "Merge the characters and script dataframes",
    "Explore the characters dataset\ndf_characters.head()",
    "Let's check the loaded datasets",
    "Select Season 1\ndf_script_s1 = df_script[df_script['episode_id'].isin(df_episodes[df_episodes['season']==1]['id'])]",
    " extended information to usersupport uniterrupted work.\npd.set_option('display.max_columns', None)",
    "print shape of each dataframe\nprint(\"Characters DataFrame Shape: \", df_characters.shape)\nprint(\"Locations DataFrame Shape: \", df_locations.shape)\nprint(\"Script DataFrame Shape: \", df_script.shape)\nprint(\"Episodes DataFrame Shape: \", df_episodes.shape)",
    "Check the number of episodes in the dataset and the first few lines of the dataframe",
    "Merge df_characters and df_script\ndf_script = df_script.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id', suffixes=(None, '_character'))",
    " Show head of each DataFrame\nprint(\"Characters DataFrame:\")\nprint(df_characters.head())\nprint(\"\\nLocations DataFrame:\")\nprint(df_locations.head())\nprint(\"\\nScript DataFrame:\")\nprint(df_script.head())\nprint(\"\\nEpisodes DataFrame:\")\nprint(df_episodes.head())",
    "Data operations",
    " Check columns of each dataframe\nprint(\"Characters columns:\", df_characters.columns)\nprint(\"Locations columns:\", df_locations.columns)\nprint(\"Script columns:\", df_script.columns)\nprint(\"Episodes columns:\", df_episodes.columns)",
    " Split lines into a list",
    "%%\n#warning\n",
    "Look at the first rows of the characters dataset\nprint(df_characters.head())",
    " Display max 500 columns/rows\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)",
    " Displaying the original dataset's first few lines to get a sense of the information contained.",
    "Since we already have the scripts, characters, and locations data, we will focus on text preprocessing, including part-of-speech tagging and named entity recognition.",
    "Function to join lines from one chracter in one episode as a single line\ndef dialogByCharacterAndEpisode(dataframe):\n    dfs = dataframe.groupby(['episode_id','character_id'])['raw_text'].apply(lambda x: ' '.join(x)).reset_index()\n    for index,row in dfs.iterrows():\n        episode_id = row['episode_id']\n        character_id = row['character_id']\n        raw_text = row['raw_text']\n        series = dataframe[(dataframe['episode_id'] == episode_id) & (dataframe['character_id'] == character_id)]['raw_text']\n        for index, value in series.items():\n            dataframe.at[index,'raw_text'] = raw_text\n    dataframe.drop_duplicates(subset =['episode_id','character_id'], keep = 'last', inplace = True)\n    return dataframe",
    "Check if all dataframes have been loaded successfully\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check the character dataframe",
    "drop the first 3 (out of 27) columns as they are not useful: id, episode_id and number",
    "Display up to 6 rows\ndf_script.head(6)",
    "Inspecting each of the datasets",
    "# Display up to 35 columns (if the dataframe has more than 35 columns)\npd.set_option('display.max_columns', 35)\n\n# Display up to 200 rows\npd.set_option('display.max_rows', 200)",
    "Extract Locations and Character locations from script lines\nlocations = df_script.raw_location_text.dropna().tolist()\ncharacters = df_script.raw_character_text.dropna().tolist()",
    " Cleaning and merging the data",
    "Display top 5 rows of characters dataframe\ndf_characters.head()",
    "Preview data\ndf_characters.head()",
    "Detect entities and sentiment from the script using SpaCy.",
    "combine the script data with the character & location data.",
    " Display the first few rows of the dataframe to understand its structure and contents\ndf_characters.head()",
    "# Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Create a list of all character names and their corresponding tokens using Spacy",
    "The simpsons_characters.csv, simpsons_locations.csv, and simpsons_episodes.csv files contain the metadata for characters, locations, and episodes, respectively.",
    "Remove unwanted columns from the dataframes",
    "Add missing columns to fullfil the schema and fill the NaN records with empty strings\ndf_script=df_script[df_script['normalized_text'].notna()]\ndf_script=df_script[df_script['spoken_words'].notna()]",
    " Display an overview of the dataframes\nprint(\"Characters: \")\ndisplay(df_characters.head())\n\nprint(\"\\nLocations: \")\ndisplay(df_locations.head())\n\nprint(\"\\nScript: \")\ndisplay(df_script.head())\n\nprint(\"\\nEpisodes: \")\ndisplay(df_episodes.head())",
    "display first lines of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Print the first 5 rows of the dataframe for easy viewing.\ndf_characters.head()",
    "Set the index for optimal merge and search performance\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "Show the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Let's take a look at the first few rows in each dataframe to understand the data structure.",
    "Create a list of documents, one per episode, and a dataframe containing each episode title",
    "Show the first few script lines.",
    " Optional: limit the number of script lines to speed up computation\n# df_script = df_script.head(1000)",
    "Get documents by location",
    " Load Spacy English model\nnlp = spacy.load('en_core_web_sm')",
    "Visualize the most frequent words in the script lines.",
    "Set the display options when displaying all columns.",
    " Get first look of the simpsons script dataframe\nprint(\"DataFrame Dimension (Rows, Columns):\", df_script.shape)\nprint(\"\\nDataFrame Columns:\\n\", df_script.columns)\ndf_script.head()",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Check the style of the dataframes' columns for DataFrame df_script",
    "Merging datasets\ndf_merge = df_script.merge(df_episodes, on='episode_id', how='inner')\ndf_merge = df_merge.merge(df_characters, on='character_id', how='inner')\ndf_merge = df_merge.merge(df_locations, on='location_id', how='inner')\n\n# Moving the merge key to the front\ncols = list(df_merge)\ncols.insert(0, cols.pop(cols.index('id')))\ndf_merge = df_merge.loc[:, cols]",
    "df_main_chars = df_characters[df_characters['raw_character_text'].isin(main_chars)]\ndf_main_chars.head()",
    "Character level counts",
    "Display the first few rows of the character dataset\ndf_characters.head()",
    "data/simpsons_script_lines.csv is represented as 'data/simpsons_script_lines.csv'",
    "Creating a single frame containing only the episodes that are both in df_script and df_episodes",
    "Function to display the Word Clouds",
    " Set up spaCy model\nnlp = spacy.load('en_core_web_sm')",
    "View data fetched from CSVs",
    "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Display the number of rows and columns in each dataset\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
    "Creating and inspecting the spark DataFrame",
    "Check availability of GPU\nimport tensorflow as tf\nfrom tensorflow.python.client import device_lib\n\n# Check all available devices if GPU is available\nprint(device_lib.list_local_devices())",
    "Remove the first index column from DataFrames\ndf_episodes = df_episodes.iloc[:,1:]\ndf_characters = df_characters.iloc[:,1:]\ndf_locations = df_locations.iloc[:,1:]\ndf_script = df_script.iloc[:,1:]",
    "Look at the first few rows of the characters dataframe",
    " Let's take a look at the structure of these dataframes.",
    " Display the dataframe\ndf_script.head()",
    " Show the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Preview data\ndf_characters.head()",
    "Data preparation - this cell fixes the types of the columns and filters the dataframe by date",
    "Merge the dataframes into a single dataframe for analysis\ndf_merged = df_script.merge(df_episodes, on='episode_id')\r\ndf_merged = df_merged.merge(df_characters, on='character_id')\r\ndf_merged = df_merged.merge(df_locations, on='location_id')",
    "Concatenate the character name and speaking line into one string in a new column\ndf_script['raw_text'] = df_script['raw_character_text'] + ': ' + df_script['spoken_words']",
    "Preview the dataframes\ndf_characters.head()",
    " Check the result and the shape.",
    "Look at the characters dataframe\ndf_characters.head()",
    "TF-IDF for scripts\nfrom sklearn.feature_extraction.text import TfidfVectorizer",
    " Analyze the characters data\nprint(df_characters.head())",
    "Show the top few rows of the script dataset\ndf_script.head()",
    " Output the first 5 rows of each dataframe to understand the data structure\ndf_characters.head(5), df_locations.head(5), df_script.head(5), df_episodes.head(5)",
    "Joining the character names to the script and drop those which are not known",
    "Display columns to have a sense of the data",
    "Check the first five rows of the `df_characters` DataFrame",
    "# Setting up the NLP pipeline\nnlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])",
    "Display the first few rows of the characters data frame\ndf_characters.head()",
    " Check the format of the datasets\nprint(\"Characters dataset:\")\nprint(df_characters.head())\nprint(\"\\nLocations dataset:\")\nprint(df_locations.head())\nprint(\"\\nScript dataset:\")\nprint(df_script.head())\nprint(\"\\nEpisodes dataset:\")\nprint(df_episodes.head())",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Show the first lines of the `df_characters` dataframe\ndf_characters.head()",
    "# Show the first 5 rows of the dataframe\ndf_script.head()",
    "Create a \"Scripted_line\" that join the \"spoken_words\" of each character and each location",
    "Replace NaN values with appropriate ones",
    "Checking the shape of each dataframe",
    "Merge script and character dataframes\ndf_script['character'] = df_script['character_id'].apply(lambda x: df_characters['name'][x])\ndf_script['location'] = df_script['location_id'].apply(lambda x: df_locations['name'][x])\ndf_script['raw_location_id'] = df_script['location_id']\ndf_script['location_id'] = df_script['location']",
    "Setting up pandas so we can see the data in a nice tabular fashion (with scrolling)\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', -1)",
    "Display a preview of each dataset\nprint(\"Characters dataset preview\")\nprint(df_characters.head(3))\nprint(\"Locations dataset preview\")\nprint(df_locations.head(3))\nprint(\"Script dataset preview\")\nprint(df_script.head(3))\nprint(\"Episodes dataset preview\")\nprint(df_episodes.head(3))",
    "Set the character_name to be the index of df_characters",
    "Inspect the dataframes",
    "Inspecting the characters dataframe",
    "Display all columns to understand the structure of the data\npd.options.display.max_columns = None",
    "Merge characters, locations, and episode name into script data\ndf_data = pd.merge(df_script, df_characters[['id', 'name', 'normalized_name']],\n                   left_on='character_id', right_on='id').drop(columns=['id']).rename(\n    columns={'name': 'character_name', 'normalized_name': 'character_normalized_name'})\ndf_data = pd.merge(df_data, df_locations[['id', 'name', 'normalized_name']],\n                   left_on='location_id', right_on='id').drop(columns=['id']).rename(\n    columns={'name': 'location_name', 'normalized_name': 'location_normalized_name'})\ndf_data = pd.merge(df_data, df_episodes[['id', 'title']],\n                   left_on='episode_id', right_on='id').drop(columns=['id']).rename(\n    columns={'title': 'episode_title'})",
    "Checking the first few rows of the `df_script` DataFrame to understand its structure and contents.\ndf_script.head()",
    " Cleaning the comma from column name\ndf_characters = df_characters.rename(columns={x: x.replace(',', '') for x in df_characters.columns})\ndf_locations = df_locations.rename(columns={x: x.replace(',', '') for x in df_locations.columns})\ndf_script = df_script.rename(columns={x: x.replace(',', '') for x in df_script.columns})\ndf_episodes = df_episodes.rename(columns={x: x.replace(',', '') for x in df_episodes.columns})",
    "Show some script lines\ndf_script.head(10)",
    "Set seed for reproducibility\nnp.random.seed(0)",
    "limit the number of rows to use for easy of computation\ndf_script_subset = df_script.iloc[:10000]",
    "Print the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Load data into a pandas dataframe.",
    "Merge script with character, location and episode\ndf = (df_script\n      .merge(df_characters, how='left', on='character_id', suffixes=('', '_character'))\n      .merge(df_locations, how='left', on='location_id', suffixes=('', '_location'))\n      .merge(df_episodes, how='left', on='episode_id', suffixes=('', '_episode')))",
    "Check the results\ndf_episodes.head()",
    "Check the shape of the dataframes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "\n# Declare functions\n# Defining a function for cleaning and tokenizing the text\ndef clean_and_tokenize(text, nlp):\n    # Cleaning and parsing using SpaCy\n    text_cleaned = nlp(text)\n    return [token.lemma_ for token in text_cleaned if not token.is_punct and not token.is_stop and not token.is_space]\n\n# Defining a function for creating a bag of words\ndef create_bow(documents, nlp):\n    # Get the words from the documents\n    words = [word for document in documents for word in clean_and_tokenize(document, nlp)]\n    return Counter(words)\n\n# Load the SpaCy model\nnlp = spacy.load('en_core_web_sm')",
    "Change index name for better consistency\ndf_characters.index.name = 'character_id'\ndf_locations.index.name = 'location_id'\ndf_episodes.index.name = 'episode_id'\ndf_script.index.name = 'line_id'",
    "Inspect dataframes\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
    "Set up spacy\nnlp = spacy.load('en_core_web_sm')",
    "# This variable stores the file paths to the csv files in the data folder\nfile_paths = {\n    'characters': 'data/simpsons_characters.csv',\n    'locations': 'data/simpsons_locations.csv',\n    'script': 'data/simpsons_script_lines.csv',\n    'episodes': 'data/simpsons_episodes.csv'\n}",
    "Set options for pandas\npd.set_option('display.max_columns', None)",
    "Take a look at the dataframes\ndf_characters.head()",
    " Setting up spacy\nnlp = spacy.load(\"en_core_web_sm\")",
    "Image styles\n# Matplotlib styles\nplt.style.use('ggplot')",
    "Check the contents of df_characters dataframe",
    "Inspecting the first 5 rows of the df_script dataframe",
    "Replace NaN values with empty strings\ndf_script = df_script.fillna('')",
    "Creating an instance of the WordCloud class.",
    " Limit the script data to only containing the main characters",
    "\n# Display the first few rows of the characters table\ndf_characters.head()",
    "Checking Character details",
    "Check the first five rows of the characters dataframe\ndf_characters.head()",
    "Viewing the first few lines of each of our dataframes to better understand the data",
    "Filter lines that are spoken by the main characters\nmain_characters = df_characters[df_characters['char_is_primary']==1]",
    " Display our data to get an overview\ndf_characters.head()",
    "Check the imported datasets",
    "View all available columns in the characters dataframe\ndf_characters.columns",
    "Inspect the first 3 rows of the main dataset (i.e., df_script)\ndf_script.head(3)",
    "Check first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Create a pandas series based on the script list of speakers.",
    "Check the first rows of characters.csv\ndf_characters.head()",
    "Filter to have only the lines from the first seasons\ndf_script_first_season = df_script.loc[df_script['episode_id'] <= 138].copy()",
    "Display first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "This will load the datasets into pandas dataframes for further analysis.",
    "Check shape of all the dataframes",
    "Check the content of the script dataset.",
    "Check that the data has been properly loaded\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Checking if all the csv files were read correctly",
    "Check the contents of each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect DataFrame shapes\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script lines:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
    "Let's take a look at the structure of each dataframe.",
    "Inspect the dataframe's initial rows.",
    "merge all into one dataframe",
    "To allow for better readability of the script lines, we will introduce a column representing the season and the episode number in the script lines dataframe.",
    " Connect to the SQLite database using the sqlalchemy package using the create_engine function in the sqlalchemy module.",
    "Filtering bad lines from dataset\ndf_script = df_script[df_script['raw_character_text'].notna()]\ndf_script = df_script[df_script['spoken_words'].notna()]",
    "Add additional character metadata\ndf_characters = df_characters.merge(df_script[['character_id', 'raw_character_text']], left_on='id', right_on='character_id', how='inner')\ndf_characters.rename(columns={'raw_character_text': 'name_original'}, inplace=True)",
    " Merge the script data with the character data\ndf = df_script.merge(df_characters, on='character_id', how='left')\ndf = df.merge(df_locations, on='location_id', how='left')",
    "Some lines exploration\nprint(df_characters.info())\nprint(df_locations.info())",
    " Remove unwanted column\ndf_script = df_script.drop('id', axis=1)",
    " Additional imports for NLP analysis",
    "Find and replace the ids of the speaking character, location, episode, and season in the script lines dataframe.",
    "Merging the datasets based on the IDs to create one large dataset.",
    " Define the speaker for each line in the script\ndf_script = df_script.merge(df_characters.rename(columns={'character_name': 'speaker'}), on='speaker_id')",
    "Filter out the non-Simpsons episodes\ndf_episodes = df_episodes[df_episodes['id'].isin(df_script['episode_id'])]",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Remove the special value lines, we will not use them in this analysis",
    "Merge scripts with character information\ndf_script_extended = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id')\n\n# Create a list with all unique episode titles\nepisode_titles = df_episodes['title'].unique()\n\n# Create a dictionary with episode transcripts\nepisode_transcripts = {title: df_script[df_script['episode_id'] == id_]['normalized_text'].str.cat(sep=' ') \n                       for title, id_ in zip(episode_titles, df_episodes['id'])}",
    "Create synonym dictionary to improve consistency in location names",
    "Data Preprocessing",
    "use read_csv from pandas to read in the csv files and reset the index of each dataframe",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Check the data structure of the episodes data\nprint(f'Episodes shape: {df_episodes.shape}')\ndf_episodes.head()",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Display the dimension of each data infront",
    "Jupyter notebook needs some modifications in the matplotlib settings to properly show the visualizations.",
    "Displays the head of the dataframes to understand how the data looks like",
    "Load data from DataFrame",
    "Quickly displaying basic information about the datasets",
    "Filter the script data to only keep the rows from the training set and the characters and locations available in the corresponding dataframes.",
    "Create a dataframe by merging `df_script` with `df_characters` on the `character_id` field.",
    "Merging `simpsons_script_lines` with `simpsons_episodes` across the `episode_id` column",
    "Print basic info for each dataframe\nprint(\"Characters Dataset:\")\nprint(df_characters.info())\n\nprint(\"\\nLocations Dataset:\")\nprint(df_locations.info())\n\nprint(\"\\nScript Dataset:\")\nprint(df_script.info())\n\nprint(\"\\nEpisodes Dataset:\")\nprint(df_episodes.info())",
    "Set a seed for reproducibility.",
    " Configure pandas to display all columns when showing DataFrames\npd.set_option('display.max_columns', None)",
    "Display the first 5 rows of each dataframe to understand the data",
    "Show the first few rows of the script dataframe\ndf_script.head()",
    "Let's inspect the first few lines of each dataframe to understand the structure of the data.",
    "Remove unnecessary columns from the dataframes",
    "Remove annoying characters from character names",
    "Display the head of each dataframe to understand what's in the dataset\nprint(\"Characters dataframe:\")\ndisplay(df_characters.head())",
    "f Script (first lines)\ndf_script.head()",
    " Join the dataframes on the appropriate columns\ndf_joined = (df_script\n            .merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('_script', '_episod'))\n            .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character'))\n            .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('_script', '_location')))",
    "A sample of the data\ndf_script.head()",
    "Show the first few lines of each dataframe to understand their structure\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()",
    "Limiting the data in the script to only 10,000 rows to improve computational performance\ndf_script = df_script.head(10000)",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Insightful Data Analysis to Understand the Simpsons Dataset and Character Interactions",
    " Merge locations into script df\ndf_script_locations = pd.merge(df_script, df_locations, how='left', left_on='location_id', right_on='id').drop(columns=['id', 'location_id']).rename(columns={\"name\": \"location\"})",
    "# Display first 5 rows of characters data\ndf_characters.head()",
    "Join Scripts and character names to get sentences with character names\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.lower()\ndf_characters['name'] = df_characters['name'].str.lower()\ndf_main = pd.merge(df_script, df_characters,  how='left', left_on=['raw_character_text'], right_on = ['name']).drop(['name'], axis=1)",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Check the first 5 rows of each of the 4 dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check if all the csv files in data were loaded correctly\ndf_characters.head()",
    "let's take a first look at the data.",
    " Display the first few rows of the dataframe to understand its structure\ndf_script.head()",
    " Look at the first few rows of `df_characters` dataframe\ndf_characters.head()",
    "# Show first 5 rows of the characters dataframe\ndf_characters.head()",
    " Merge the episode details into the main script lines dataframe\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Display the first 5 lines of simpsons_characters table\ndf_characters.head()",
    "Check that the datasets have been correctly loaded",
    "EDA - Samples",
    "Set pandas to display all columns for dataframes\npd.set_option('display.max_columns', None)",
    "Join script with characters and locations names\ndf_script_characters = df_script.join(df_characters, on='character_id', rsuffix='_character')\ndf_script_locations = df_script_characters.join(df_locations, on='location_id', rsuffix='_location')\n\n# Move data to new columns, and fill NaN values with empty strings\ndf_script_locations['raw_character_name'] = df_script_locations['name']\ndf_script_locations['raw_location_name'] = df_script_locations['name_location']\ndf_script_locations['raw_text'] = df_script_locations['normalized_text']\ndf_script_locations['spoken_words'] = df_script_locations['raw_text']",
    "allow us to display large string in our dataframes\npd.options.display.max_colwidth = 200",
    "Display settings\npd.options.display.max_columns = 50",
    "Cleaning the dataset",
    "Set the date for the simpson_episodes dataframe",
    "Filter out episodes older than 1990.",
    "We'll look at the character and location dataframes first.",
    "Let's display the first few rows of each dataframe to understand their structure.",
    " Function to pre-process text\ndef clean_text(text):\n    # Remove numbers\n    text = ''.join(word for word in text if not word.isdigit())\n    # Remove punctuation and make everything lower case\n    return ''.join(word.lower() for word in text if word.isalpha() or word.isspace())",
    "Let's take a look at these datasets.",
    "%load_ext autoreload\n%autoreload 2",
    "Clean non-existant or old-fashioned episodes from df_script\ndf_script_cleaned = df_script.merge(df_episodes,on='episode_id')\ndf_script_cleaned = df_script_cleaned[(df_script_cleaned['original_air_year']>=1989) & (df_script_cleaned['original_air_year']<=2018)]\ndf_script = df_script_cleaned",
    "Setting to display all columns in the dataframe\npd.set_option('display.max_columns', None)",
    "Intializes spacy model\nnlp = spacy.load('en_core_web_sm')",
    "Selecting the main characters of the Simpsons",
    "Drop the index column from the dataframes that was read with the csv.",
    "Set seed for reproducibility",
    "remove punctuation and numbers from the text",
    "Check if all dfs have unique string ids",
    "Check the first few rows of each dataframe to see what data they contain.",
    "'Type' of each df\nprint(\"df_characters:\", type(df_characters))\nprint(\"df_locations:\", type(df_locations))\nprint(\"df_script:\", type(df_script))\nprint(\"df_episodes:\", type(df_episodes))",
    "Check the first lines of each dataframes\ndf_characters.head()",
    "Check the size of our datasets",
    "# set up matplotlib parameters to fit these charts in readme\n\nmatplotlib.rcParams.update({'font.size': 22})",
    "Inspect the characters dataframe",
    "Exploring the datasets",
    "select the necessary columns from the dataframes",
    "reate a new plot\nplt.figure( figsize=(20,10) )",
    "Check data shape\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Episodes:', df_episodes.shape)\nprint('Script:', df_script.shape)",
    " Display the first few records of the dataframe\ndf_script.head()",
    "Let's print the first couple of lines of each of these tables to see what we're working with.",
    "EDA on the characters dataset",
    "Check the first rows of each dataframe\ndf_characters.head()",
    "Checking for any null rows in the dataset\nprint(\"Number of null rows in script dataset:\", df_script.isnull().sum().sum())\nprint(\"Number of null rows in character dataset:\", df_characters.isnull().sum().sum())\nprint(\"Number of null rows in location dataset:\", df_locations.isnull().sum().sum())\nprint(\"Number of null rows in episodes dataset:\", df_episodes.isnull().sum().sum())",
    " Quick exploration of the characters dataset\ndf_characters.head()",
    "In this code, we are reading CSV files into pandas dataframes using the `pd.read_csv` method. This allows us to work with the data from these files using the DataFrame data structure provided by the pandas library. We also use the `reset_index` method to reset the index of the dataframes.",
    "Show the first 5 lines of the \"df_script\" dataframe.",
    " Look at the info to see missing data\ndf_episodes.info()",
    "Prerequisite: we need to remove characters that don't have a description and locations without a note.",
    "Let's see how the data looks by displaying the first few rows of each dataframe.",
    " Ensure that the dataset has the correct encoding to avoid errors when dealing with text data\ndf_script = pd.read_csv('data/simpsons_script_lines.csv', encoding='latin1')\ndf_script.head()",
    "Set up the word cloud dictionary and the function to plot it.",
    "Inspect the first few rows of the characters DataFrame\ndf_characters.head()",
    "Display the first few rows of each dataframe to understand the data",
    "Inspect the dataframes",
    "Visualise the data",
    "\ndef get_script_character(script_id):\n    '''\n    INPUT\n    script_id: int - the id of the script\n    \n    OUTPUT\n    A string representing the character\n    \n    Given a script id, returns the simpson character of the line.\n    '''\n    return df_script['character_id'][df_script['id'] == script_id].values[0]",
    "specific imports\nfrom sklearn.cluster import KMeans\nfrom sklearn.feature_extraction.text import TfidfVectorizer",
    "Inspecting the raw data to see what we have here...",
    " Merge script, episodes, characters and location data into one dataframe",
    "# Do some data exploration to get a feel for the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Explore the datasets\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "\ndf_script.head()",
    " Quick look at the data",
    "Set the 'id' column as the index for each DataFrame\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    " Check that the data has been loaded correctly\nprint(df_characters.head())",
    " Display the first few rows of each DataFrame to understand its structure\ndf_characters.head()",
    "Merge script with characters\ndf_merged = pd.merge(df_script, df_characters, how='left',\non=['character_id'], suffixes=('', '_char'))",
    "Setting up Spacy\nnlp = spacy.load('en')",
    "Check the first few rows of the dataframe to see what it looks like.",
    "Let's take a look at the first few rows of each DataFrame to understand its structure.",
    "Merge dataframes to join the information into one dataframe",
    "Visualize first few rows of the dataframe\ndf_script.head()",
    "Check memory usage before cleaning\nmem_usage = df_script.memory_usage(deep=True).sum() / 1024**2  # convert bytes to megabytes\nprint('Memory usage of dataframe is {:.2f} MB'.format(mem_usage))\n\n# Create a dictionary to store the optimal data types for each column to reduce memory usage\ndtypes = {'id': 'int32',\n          'episode_id': 'int32',\n          'number': 'int16',\n          'character_id': 'float32',  # NaN values\n          'location_id': 'float32',   # NaN values\n          'raw_text': 'string',       # special data type StringDtype\n          'timestamp_in_ms': 'int64',\n          'speaking_line': 'string',  # special data type StringDtype\n          'character_image_url': 'string',  # special data type StringDtype\n          'location_image_url': 'string',   # special data type StringDtype\n          'spoken_words': 'string',         # special data type StringDtype\n          'normalized_text': 'string',      # special data type StringDtype\n          'word_count': 'int16'}",
    "Setting seed for reproducibility\nseed = 123",
    "We will look into script dataframe first.",
    "df_script.head()",
    "Reduce dataset to only relevant characters\ncharacters = [\n    \"Lisa Simpson\",\n    \"Bart Simpson\",\n    \"Marge Simpson\",\n    \"Homer Simpson\",\n    \"Maggie Simpson\",\n    \"Charles Montgomery Burns\",\n    \"Milhouse Van Houten\",\n    \"Ned Flanders\",\n    \"Principal Skinner\",\n    \"Lenny Leonard\",\n    \"Carl Carlson\",\n    \"Waylon Smithers\",\n    \"Krusty the Clown\",\n    \"Grampa Simpson\",\n    \"Dr. Julius Hibbert\",\n    \"Selma Bouvier\",\n    \"Patty Bouvier\",\n    \"Kent Brockman\",\n    \"Edna Krabappel\",\n    \"Nelson Muntz\",\n    \"Sherri and Terri\",\n    \"Jimbo Jones\",\n    \"Martin Prince\",\n    \"Seymour Skinner\",\n    \"Rod Flanders\",\n    \"Todd Flanders\",\n    \"Moe Szyslak\",\n    \"Barney Gumble\",\n    \"Kirk Van Houten\",\n    \"Luann Van Houten\",\n    \"Apu Nahasapeemapetilon\",\n    \"Ralph Wiggum\",\n    \"Chief Wiggum\",\n    \"Snake Jailbird\",\n    \"Judge Constance Harm\"\n]",
    " Set pandas settings (these could also be at the top of the file)\npd.set_option('display.max_columns', None)",
    "Expand the width of columns in order to view text data more completely\npd.options.display.max_colwidth = 400",
    "Print the first few rows of each dataframe to understand the data",
    "Print the size of the dataframes to ensure they were loaded successfully\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
    "Setting random seed for reproducibility\nnp.random.seed(0)",
    "# We set the custom null value '???' as standard NaN. We also fix the characters_id datatype\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce')\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)",
    "Merge with mapping files",
    "Extract only 1% of the rows for a reasonable runtime during the analysis\ndf_script = df_script.sample(frac=0.01, random_state=1).reset_index(inplace=False, drop=True)",
    "Ensure we can see all the columns\npd.set_option('display.max_columns', 500)",
    "Create a datetime object from the air date of each episode",
    " Replace NaN values with empty strings\ndf_script = df_script.fillna('')",
    "Checking for missing values in our data.",
    "We are importing multiple dataframes from CSV files using pandas and storing them in variables.",
    "Preview the characters dataset\ndf_characters.head()",
    "Check what is inside the table of characters",
    "Merge script lines with characters and episodes\ndf_merged = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id')\ndf_merged = pd.merge(df_merged, df_episodes, how='left', left_on='episode_id', right_on='id').rename(columns={'name_x':'character', 'normalized_name':'location', 'name_y':'episode'})\n\n# Visualize the data\ndf_merged.head()",
    " Remove unused columns from the dataframes",
    "Merging all the datasets based on \"episode_id\"\ndf = pd.merge(df_script, df_episodes, on='episode_id')\ndf = pd.merge(df, df_characters, on='character_id')\ndf = pd.merge(df, df_locations, on='location_id')",
    "ensure data consistency\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]\ndf_locations = df_locations[df_locations['id'].isin(df_script['location_id'])]\ndf_characters = df_characters[df_characters['id'].isin(df_script['character_id'])]",
    "Create datasets for each episode",
    "check out the data to give an overview of what we are working with\ndf_episodes.info()",
    "Cleaning the column names\ndf_episodes.columns = [e.lower().replace(' ', '_') for e in df_episodes.columns]\ndf_script.columns = [e.lower().replace(' ', '_') for e in df_script.columns]\ndf_characters.columns = [e.lower().replace(' ', '_') for e in df_characters.columns]\ndf_locations.columns = [e.lower().replace(' ', '_') for e in df_locations.columns]",
    "Check the df_scripts dataframe",
    "# The full text of the scripts is too large to load here. We'll be working with a slice of the data\nprint(df_script.shape)\ndf_script.head()",
    "Check the data loaded correctly\ndf_characters.head()",
    "Clean the scripts data\ndf_script_dropna = df_script.dropna(subset=['raw_text'])\ndf_script_dropna = df_script_dropna[df_script_dropna.raw_text != '']\ndf_script_dropna.reset_index(inplace=True, drop=True)",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Printing out the Structure of the tables",
    "Code completion not necessary.",
    "We will start by loading the data from the CSV files into pandas DataFrames.",
    "Set seaborn aesthetic parameters to defaults\nimport seaborn as sns\nsns.set()",
    "Set the pandas display options for better visualisation of the DataFrames\npd.set_option('display.max_columns', None)\npd.set_option('max_colwidth', None)",
    "Display data\ndf_characters.head()\ndf_locations.head()\ndf_script.head()\ndf_episodes.head()",
    "Clean gcs authentication so it doesn't throw a user warning because we are not going to use GCS in this example\nos.environ['GOOGLE_APPLICATION_CREDENTIALS'] = ''",
    "Now, we will use the read_csv() function from pandas to load the CSV files into DataFrames.",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "Merge dataframes for easy data manipulation",
    "\n# We only need raw lines from the script\ndf_script = df_script[df_script.speaking_line]",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Display a preview of the data loaded from the csv files",
    " View a few example rows from each DataFrame to understand its structure\nprint(\"\\nCharacters DataFrame:\")\nprint(df_characters.head(3))\nprint(\"\\nLocations DataFrame:\")\nprint(df_locations.head(3))\nprint(\"\\nScript DataFrame:\")\nprint(df_script.head(3))\nprint(\"\\nEpisodes DataFrame:\")\nprint(df_episodes.head(3))",
    " Examine the script data to get more familiar with it\ndf_script.head()",
    "Download the large English model for spaCy",
    "Merge characters and script dataframe\ndf_characters = df_characters.rename(columns={'id': 'character_id'})\ndf_script = df_script.merge(df_characters, how='left', on='character_id')",
    "Let's have a look at the script data:",
    "Merge scripts with characters and locations\ndf_raw = df_script.merge(df_characters, how='inner', left_on='character_id', right_on='id')\ndf_raw = df_raw.merge(df_locations, how='inner', left_on='location_id', right_on='id')\n\n# Save the raw merged dataframe\ndf_raw.to_csv('data/simpsons_script_merged_raw.csv', index=False)",
    "Initialization of spacy\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])",
    " Let's check the structure of the datasets",
    "We can begin by exploring the different datasets and understanding their structure and content.",
    "Extracting df_characters subcolumns and reseting the index",
    "# Check the contents of the characters DataFrame\ndf_characters.head()",
    "Select only the columns we need",
    "# an example of a simple query\ndf_script[df_script['normalized_text'].str.contains('coffe')].head()",
    "We have the following dataframes available:\n# - df_characters: Information about the characters\n# - df_locations: Information about the locations\n# - df_script: Information about the script lines\n# - df_episodes: Information about the episodes",
    "Let's explore the data by showing the first 5 rows of each dataframe.",
    "Check what the dataset looks like\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "# Display options\npd.set_option('display.max_columns', None)",
    "Remove spaces from column names\ndf_characters.columns = df_characters.columns.str.replace(' ', '_')\ndf_locations.columns = df_locations.columns.str.replace(' ', '_')\ndf_script.columns = df_script.columns.str.replace(' ', '_')\ndf_episodes.columns = df_episodes.columns.str.replace(' ', '_')",
    "Remove unnecessary columns and join the dataframes",
    "# Let's start by displaying the first rows of each dataframe to understand the structure of the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Merge the datasets",
    "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Check the first rows\ndf_script.head()",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Remove stopwords from script lines and combine them by episode Id",
    "Start by exploring the content of the dataset.",
    "Set pandas to display all columns in dataframes\npd.set_option('display.max_columns', None)",
    " Display basic information about the datasets\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
    "Show the first few rows of the episodes DataFrame\ndf_episodes.head()",
    "Display first few rows of the dataframe\ndf_script.head()",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    " Show the first 5 elements of the script DataFrame.",
    "Ensure target folders for visualization exist in the filesystem",
    "# Ensure matplotlib works correctly with Jupyter\n%matplotlib inline",
    " Let's start by overviewing the data.",
    "Check the dataframe schema",
    "Check the data format and potential issues in the data.",
    " Filter scripts to only use episodes from the TV show\ndf_script = df_script[df_script['episode_id'] <= 600].reset_index(inplace=False, drop=True)",
    "# Print first 5 rows of the dataframe\ndf_script.head()",
    "Join the datasets together\ndf_all = pd.merge(\n    pd.merge(pd.merge(df_script, df_episodes, on='episode_id'), df_characters, on='character_id'),\n    df_locations,\n    on='location_id'\n)",
    " Converts strings to datetime\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], format='%Y-%m-%d')",
    "General configuration\nLARGE_SIZE = 22\nMEDIUM_SIZE = 18\nSMALL_SIZE = 14",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Set index for fast access",
    "Checking if pickle files already exists",
    "Merge characters and location information into the script dataframe",
    "Check the loaded dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Separate the script data by episodes.",
    "Display all columns for a better view\npd.options.display.max_columns = None",
    "Filter the data to only include character and location information that is in the script data\ncharacters_in_scripts = df_script[\"raw_character_text\"].unique()\nlocations_in_scripts = df_script[\"raw_location_text\"].unique()\n\ndf_characters = df_characters[df_characters[\"name\"].isin(characters_in_scripts)].reset_index(drop=True)\ndf_locations = df_locations[df_locations[\"name\"].isin(locations_in_scripts)].reset_index(drop=True)",
    "Combining the data into one dataframe",
    " First, let's take a look at the data quickly by looking at the first few entries of each dataframe.",
    "Load language model\n# This may take a while\nnlp = spacy.load('en_core_web_md')",
    "subset making the code run faster\ndf_script_subset = df_script.iloc[:50000]",
    " Basic information on the datasets\nprint('Characters:')\nprint(df_characters.head(2).T)\nprint('\\nLocations:')\nprint(df_locations.head(2).T)\nprint('\\nScript lines:')\nprint(df_script.head(2).T)",
    " Check the shapes of the imported DataFrames\nprint(f'df_characters shape: {df_characters.shape}')\nprint(f'df_locations shape: {df_locations.shape}')\nprint(f'df_script shape: {df_script.shape}')\nprint(f'df_epsiodes shape: {df_episodes.shape}')",
    "Show the first 5 rows of each dataframe to understand the data structure",
    "set some pandas options for better display\npd.set_option('display.max_columns', None)",
    "Check the correct loading of the `characters` dataframe\ndf_characters.head()",
    "Keep only some locales from the script lines dataframe",
    "Merges all labeled data in one dataframe.",
    "Remove unwanted columns from each dataframe",
    "Preview the script df\ndf_script.head()",
    "## Initial inspection of the data",
    " Let's take a look at the structure of these dataframes.",
    "Data inspection",
    "Merge script lines with the characters and locations\ndf_merged = pd.merge(df_script, df_characters, left_on='character_id', right_on='character_id', suffixes=('_script', '_character'))\ndf_merged = pd.merge(df_merged, df_locations, left_on='location_id', right_on='location_id', suffixes=('_df_merged', '_location'))",
    "Let's take a quick look at the data to understand what we are working with.",
    "Count the characters that have spoken in the show.",
    "displaying all dataframes for exploration\ndf_characters.head(), \ndf_locations.head(), \ndf_script.head(), \ndf_episodes.head()",
    "Get some information on each dataframe (i.e., data types and non-null values)",
    "Check the dataframes content\nprint(df_script.head())",
    "Check the shape of each dataframe\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    " Check the number of rows and columns for each dataframe\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "Data sets memory usage\nprint('Character datatypes:')\nprint(df_characters.dtypes)\nprint(\"\")\n\nprint('Locations datatypes:')\nprint(df_locations.dtypes)\nprint(\"\")\n\nprint('Script datatypes:')\nprint(df_script.dtypes)\nprint(\"\")\n\nprint('Episodes datatypes:')\nprint(df_episodes.dtypes)",
    "Check the basic information in each dataset\ndef info_data(dataframe, name):\n    print(\"Exploring the Data\")\n    print(\"Overview of the data \"+name+\":\" )\n    return (dataframe.head())",
    " Check the first five rows of the characters dataframe\ndf_characters.head()",
    "View scripts\ndf_script.head()",
    "Limiting the number of records for the sake of memory and CPU limitations\ndf_script = df_script.sample(n=1000, random_state=1)",
    "Turning off the scientific notation (e) when displaying numbers",
    " We define the default style for matplotlib visualizations.",
    "Remove duplicates from characters, locations and episodes dataframes\ndf_characters.drop_duplicates(subset=['name'], inplace=True)\ndf_locations.drop_duplicates(subset=['name'], inplace=True)\ndf_episodes.drop_duplicates(subset=['title'], inplace=True)",
    "A sample of the data tables.",
    "Example of finished data loading and basic data information",
    " Drop the first column, which is not needed",
    " Preview the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "View format of `script` DataFrame\ndf_script.head()",
    "Some Quick Overviews",
    "Fix someone's typo in sample code\nDataFrame name on each final line should be in the left hand side in place of pandas module name.",
    " These dataframes contain self-contained data, including both raw and pre-processed data as well as metadata about the datasets.",
    " View dataframe structure\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
    "Remove trailing whitespace from columns\ndf_characters.columns = df_characters.columns.str.strip()\ndf_locations.columns = df_locations.columns.str.strip()\ndf_script.columns = df_script.columns.str.strip()\ndf_episodes.columns = df_episodes.columns.str.strip()",
    "Drop the \"id\" column, this will be redundant since we will use the index as identifier",
    "Filter out bad orders (for example when a main character doesn't talk)\nprint('Rows before cleaning:', df_script.shape[0])\ndf_script = df_script.loc[df_script['raw_character_text'].isin(df_characters['character_text'])]\ndf_script = df_script[df_script['spoken_words'].str.len() > 0]\nprint('Rows after cleaning:', df_script.shape[0])",
    "Let's display the heads of the DataFrames to have a first look at the data\ndf_locations.head(), df_characters.head(), df_episodes.head(), df_script.head()",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Visualize the first few rows of the characters dataframe\ndf_characters.head()",
    "Show first script lines\ndf_script.head(3)",
    "Ensure matplotlib uses the default style\nmatplotlib.style.use('default')",
    "  display(df_script.head())",
    "Take a look at the dataframes and the structure of the data in each of them\ndf_characters.head()",
    "Filter the dialogues with the main characters",
    " Displaying the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Setting custom parameters for better visualization of head/tail\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
    "Checks the content of the script data\ndf_script.head()",
    "Checking the data to see if it has been loaded correctly",
    " Remove unnecessary columns\ndf_characters = df_characters[['id', 'name', 'normalized_name']]\ndf_locations = df_locations[['id', 'name', 'normalized_name']]\ndf_episodes = df_episodes[['id', 'title']]\ndf_script = df_script[['episode_id', 'number', 'raw_text']]",
    "We need to remove some columns and nan values from scripts dataframe",
    "Preprocess data",
    "Check how the dataframes are looking",
    "Let's take a look at the first 5 rows of each dataframe.",
    " Print the missing values percentage of each dataframe\nprint('Characters:', df_characters.isna().mean())\nprint('Locations:', df_locations.isna().mean())\nprint('Script:', df_script.isna().mean())\nprint('Episodes:', df_episodes.isna().mean())",
    "merge main tables using foreignkeys and other columns\ndf_merged = df_script.merge(df_episodes, on='episode_id', suffixes=('', '_ep'))\ndf_merged = df_merged.merge(df_characters, on='character_id', suffixes=('', '_ch'))\ndf_merged = df_merged.merge(df_locations, on='location_id', suffixes=('', '_l'))",
    " Set up spaCy\nnlp = spacy.load('en_core_web_sm')",
    "Display settings\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', None)",
    "Read embeddings created by glove-python\ndf_embeddings = pd.read_csv('data/word_embeddings.csv')",
    "Set pandas to display in Jupyter as many columns as possible\npd.set_option('display.max_columns', None)",
    "Sample the data to have a look at their structure\ndf_characters.sample(5)",
    "Inspect first few rows of each dataset\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Drop rows where gender data is incorrect (1 row) and duplicate index column",
    " Split the \"raw_text\" column according to dialogue_BEGIN and _END",
    " Merge the datasets into a single one based on 'episode_id' and 'id' columns.",
    "Inspect first few rows of the characters DataFrame\ndf_characters.head()",
    " Compute the top 10 characters, using the number of words in their lines\ntop_10_characters = df_script[df_script['raw_character_text'].isin(df_characters['character'])]\ntop_10_characters = top_10_characters.groupby('raw_character_text').apply(lambda x: x['word_count'].sum()).reset_index(name='num_words')\ntop_10_characters = top_10_characters.sort_values(by='num_words', ascending=False)\ntop_10_characters = top_10_characters.head(10)",
    "Compute values for training samples.",
    " Information of the dataframe related to the Simpsons series",
    "Merge the data into one dataframe",
    "Let's start by taking a look at the first few rows of each dataframe to understand its structure and the kind of data it contains.",
    "Check the loaded data\ndf_characters.head()",
    "Data exploration",
    " Preprocesing - Merge datasets",
    "Remove non dialogue records for dialogue prediction",
    "Check point 1",
    " Display the first 5 rows of the script dataframe\ndf_script.head()",
    "Ensure that we only consider spoken lines, and remove the rest.",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Display the data for simpsons characters dataframe",
    "Print the first 5 rows of the characters DataFrame\ndf_characters.head()",
    "Set up spacy\nnlp = spacy.load('en_core_web_sm')",
    "ensure scriptLine order\ndf_script = df_script.sort_values(by=['episode_id', 'timestamp_in_ms']).reset_index(inplace=False, drop=True)",
    "Merge the three files together\ndf = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_character'))",
    "Filter out the non-dialogue meaning lines",
    "Select only relevant columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'timestamp_in_ms','speaking_line', 'character_id', 'location_id']]\n\n# Remove NaNs\ndf_script = df_script.dropna(subset=['raw_text', 'speaking_line', 'character_id', 'location_id'])\n\n# Reset indexes\ndf_script = df_script.reset_index(drop=True)",
    "# Merge lines and character df; only keep lines by Simpsons characters\ndf_character_lines = df_script.merge(df_characters, how='inner', on='character_id')",
    " Check all dataframe's first entries to have an idea of their columns and data",
    " Clean the dataset\ndf_script = df_script[df_script.raw_location_text.notnull()]\ndf_script = df_script[df_script.raw_character_text.notnull()]\ndf_script = df_script[df_script.raw_character_text.str.strip() != '']\ndf_script = df_script[df_script.raw_location_text.str.strip() != '']\ndf_script.reset_index(drop=True, inplace=True)",
    " Display the first few rows of the characters DataFrame\ndf_characters.head()",
    " Remove the empty lines\ndf_script = df_script[df_script[\"raw_character_text\"].notna()].reset_index(inplace=False, drop=True)",
    " Display first few rows of each dataset\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()",
    "\ndf_script.head()",
    "Check the shape of each dataframe\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Merge the tables to contain all necessary information needed for the analysis.",
    "Data Preprocessing",
    "Merge data into one dataframe",
    "Inspect df_characters",
    "Understand the structure of each dataframe",
    "Inspect data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Display top rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check the first rows of the dataframe and its datatypes\ndf_script.head()",
    "Check a few initial lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check the content of each table\nprint(f\"Characters table: {len(df_characters)} lines\")\nprint(f\"Locations table: {len(df_locations)} lines\")\nprint(f\"Script table: {len(df_script)} lines\")\nprint(f\"Episodes table: {len(df_episodes)} lines\")",
    "# Print basic information about the data\nprint(\"Characters:\")\nprint(df_characters.info())\nprint(df_characters.head(2))\nprint(\"\\nScript:\")\nprint(df_script.info())\nprint(df_script.head(2))",
    " To avoid compatibility issues with matplotlib, you should specify the type of backend you want to use. For example:",
    " Keep the useful columns\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_character_text', 'raw_location_text']]",
    "# Time to process the data and to create a word cloud\n# Filling up the NaN values with empty string\ndf_script = df_script.fillna('')\n# Concatenating the string fields of the data frame\ndf_script['spoken_words_concat'] = df_script['raw_text'] + ' ' + df_script['normalized_text'] + ' ' + df_script['spoken_words']",
    "Checking first few rows of each dataframe.",
    " Inspect what the dataframes look like",
    "Check the length of each DataFrame\nprint(f\"Number of characters: {len(df_characters)}\")\nprint(f\"Number of locations: {len(df_locations)}\")\nprint(f\"Number of script lines: {len(df_script)}\")\nprint(f\"Number of episodes: {len(df_episodes)}\")",
    "Set custom matplotlib settings\nmatplotlib.rcParams.update({\n    'font.size': 14,\n    'figure.figsize': (10, 8),\n    'figure.facecolor': '#00000000',\n    'axes.labelsize': 12,\n    'axes.labelcolor': '#ffffff',\n    'axes.labelweight': 'bold',\n    'axes.titlesize': 16,\n    'axes.titlecolor': '#ffffff',\n    'axes.titleweight': 'bold',\n    'xtick.labelsize': 10,\n    'ytick.labelsize': 10,\n    'legend.fontsize': 12,\n    'legend.title_fontsize': 14\n})",
    "Set the index of the episodes dataframe to use the episode_id as index",
    "Display first 5 rows of characters dataframe\ndf_characters.head()",
    " Characters present in the script\ncharacters_present = df_script['character_id'].unique()",
    "checking the datatypes and the first five rows of each dataframe",
    " Print the first 5 rows of the characters dataframe\ndf_characters.head()",
    " Limiting the number of documents to 500 for performance reasons.\ndf_script = df_script.iloc[:500]",
    "Display first 5 rows for each of the datasets\nprint(\"\\n\\nCharacters:\")\nprint(df_characters.head())\n\nprint(\"\\n\\nLocations:\")\nprint(df_locations.head())\n\nprint(\"\\n\\nScript:\")\nprint(df_script.head())\n\nprint(\"\\n\\nEpisodes:\")\nprint(df_episodes.head())",
    "\nnlp = spacy.load(\"en_core_web_sm\")",
    "Filter out the script with no character_id.",
    "Filter only the 'Springfield Elementary School' location\ndf_script_springfield_school = df_script[\n    df_script['raw_location_text'] == 'Springfield Elementary School'\n]",
    "Setting seed for reproducibility\nnp.random.seed(0)",
    "To avoid encoding issues, we'll specify the encoding as ISO-8859-1 when reading the Simpsons script lines.",
    " Some nice-to-have package settings\npd.set_option('display.max_colwidth', None)",
    "Check the content of the first dataset (characters)",
    "Delete first column (index) and unnecessary columns\ndf_script = df_script.drop(columns=['id', 'episode_id', 'number', 'raw_text'])",
    "Check the first entries of each DataFrame",
    "Preview the script dataframe\ndf_script.head()",
    "Display the first few rows of the script lines dataframe\ndf_script.head()",
    "Print the first few rows of the script dataset\ndf_script.head()",
    "function to get characters lines",
    "Let's take a look at the schema of these tables.",
    "Check the first row of each dataframe\ndf_characters.head(1)",
    "Let's check the size of the datasets",
    "Show all available columns, including the index",
    "Display the number of lines of each character",
    "Display the dataframe types\nprint(df_characters.dtypes)\nprint(df_locations.dtypes)\nprint(df_script.dtypes)\nprint(df_episodes.dtypes)",
    "Just taking a look at the first few rows of each DataFrame to understand the data better\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "\n# Join episode and script data\ndf_script_episodes = df_script.join(df_episodes, on='episode_id', rsuffix='_episode')\n\n# Print the first five rows\ndf_script_episodes.head()",
    "Remove useless columns from each dataframe",
    "Load the character and location label encoders",
    "Explore the first rows of the characters dataset\ndf_characters.head()",
    "Display the first few rows of each dataframe to get an understanding of the data",
    "Check the dataframe shape and first few rows for script dataframe\nprint(df_script.shape)\ndf_script.head()",
    "Remove punctuation and numbers from lines for each character\n#df_script = df_script.sample(frac=0.1, replace=True, random_state=1) # Uncomment this line to test your code with only a fraction of the data\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('[^A-Za-z\\s\\']','')\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\d+','')",
    "Remove duplicate script lines, and merge character, location, and episode data into the script data.",
    "View top few rows of characters dataframe\ndf_characters.head()",
    "Create a WordCloud of the script_lines in the field spoken_words.",
    "Drop the first column, which is just the row index.",
    "# Create a \"doc\" object for each episode script line containing annotations\ndf_script['doc'] = list(nlp.pipe(df_script['normalized_text'], batch_size=5000))",
    "Cleans up a few things first\nfor df in [df_characters, df_locations, df_script, df_episodes]:\n    if 'Unnamed: 0' in df.columns:\n        df.drop(['Unnamed: 0'], axis=1, inplace=True)",
    "Check the content of the \"Simpsons Characters\" dataset",
    "Minimum data\ndf_script = df_script.dropna(subset=['character_id', 'location_id'])\n\n# Merge the data\ndf_script = df_script.merge(\n    df_episodes[['id', 'title', 'original_air_date']],\n    how='left', left_on='episode_id', right_on='id'\n).merge(\n    df_characters[['id', 'character_name']],\n    how='left', left_on='character_id', right_on='id'\n).merge(\n    df_locations[['id', 'location_name']],\n    how='left', left_on='location_id', right_on='id'\n)",
    "Create an in-memory SQLite database that we can use to execute SQL queries\nfrom sqlalchemy import create_engine\n\n# This is a simple way to store and manipulate data.\n# We could also use this in-memory storage to filter data and create useful\n# transformations that we could then export to a more scalable solution\nengine = create_engine('sqlite://', echo=False)",
    "Set the random seed for reproducibility\nnp.random.seed(0)",
    "Limit number of script lines for testing purposes\ndf_script = df_script.head(5000)",
    "Create a word cloud of the most common words in the script lines\nscript = \" \".join(df_script.raw_text.values)\nwordcloud = WordCloud(width = 2000, height = 1000, random_state=1, background_color='black',\n                      colormap='Set2', collocations=False, stopwords = WordCloud.STOPWORDS,\n                     max_words=50).generate(script)\n\n# Plot the word cloud\nplt.figure(figsize=(20, 10), facecolor=None)\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.tight_layout(pad=0)\n\nplt.show()",
    " Visualize head of the characters dataframe\ndf_characters.head()",
    "import the functions\nfrom helpers import clean_text, wasserstein, simplify_movie_name",
    "List available datasets\ndatasets = [df_characters, df_locations, df_script, df_episodes]",
    "Safety measure to prevent truncation of long string columns\npd.options.display.max_colwidth = 100",
    "Visualize data\nprint(f'Number of episodes: {len(df_episodes)}')\nprint(f'Number of characters: {len(df_characters)}')\nprint(f'Number of locations: {len(df_locations)}')",
    " Show the top 5 rows of the episodes DataFrame\ndf_episodes.head()",
    " Define Project Constants",
    " This will cause pandas  to pretty print upto 200 columns and 100 rows.",
    "Check the three base datasets\ndf_characters.head()",
    " Display first 5 characters of the dataframe\ndf_script.head()",
    "[Optional] Remove characters who appear in less than 10 episodes.",
    "Filter out non-dialogue script lines, remove irrelevant columns, and save to CSV\ndf_script = df_script[df_script['speaking_line'] == True].reset_index(inplace=False, drop=True)",
    "Test the merge capabilities on index for 'episodes' and 'script'\ndf_ep_sc = df_script.merge(df_episodes, on='episode_id')\nprint(f'{len(df_script)} merged with {len(df_episodes)} on episode_id to {len(df_ep_sc)}')",
    " Display a sample of the data for each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Create a list of episodes.",
    "Concatenate and replace utterance id with string\r\ndf_final = pd.concat([df_script, df_characters, df_locations, df_episodes], axis=1, join='inner')",
    " Display read data for characters.",
    "Set output dataframe display to show entire content\npd.set_option(\"display.max_columns\", None)\npd.set_option(\"display.max_colwidth\", -1)",
    " Preprocessing",
    " We can see that we're successful in loading the datasets by also calling the `.head()` function on each one of them.",
    "Check the shape of each dataframe\nprint(\"Characters df shape:\", df_characters.shape)\nprint(\"Locations df shape:\", df_locations.shape)\nprint(\"Script df shape:\", df_script.shape)\nprint(\"Episodes df shape:\", df_episodes.shape)",
    "Here we load the datasets we'll be using for the analysis.",
    " Observe first entries of the provided data\ndfs = {\n    \"Characters\": df_characters,\n    \"Locations\": df_locations,\n    \"Script lines\": df_script,\n    \"Episodes\": df_episodes\n}",
    " Generate wordcloud of the most common character names\nwordcloud = WordCloud(background_color='white',\n                      width=1600,\n                      height=800,\n                      max_words=50).generate_from_frequencies(dict(df_characters['name'].value_counts(normalize=False)))\n\nplt.figure(1, figsize=(16, 8))\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()",
    "Print the first three rows of each dataframe to quickly get an overview of their contents\nprint('\\nCharacters:')\nprint(df_characters.head(3))\n\nprint('\\nLocations:')\nprint(df_locations.head(3))\n\nprint('\\nScript:')\nprint(df_script.head(3))\n\nprint('\\nEpisodes:')\nprint(df_episodes.head(3))",
    " Show all columns\npd.set_option('display.max_columns', None)",
    "Display the first few rows\ndf_script.head()",
    "Set correct datatypes for each column\ndf_episodes.head()",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Build corpus for script lines",
    "Display the first few rows of the dataframe\ndf_characters.head()",
    "Print the first few lines of the characters dataframe\nprint(df_characters.head())",
    " Let's inspect the head of each dataframe to make sure all the columns were read in correctly.",
    "Merge episodes with script data\ndf = df_script.merge(df_episodes, on='episode_id', how='inner')",
    "Find the names of all the columns in the dataframe",
    "Inspect the characters data\ndf_characters.head()",
    "algunas veces aparece un error en la lectura del dataframe con formato incorrecto o inesperado, por lo que se debe ajustar el formato con un encoding especfico.",
    " Retain only the rows with non-null values in the speaking line column\ndf_script_cleaned = df_script[df_script['speaking_line'].notnull()]",
    "Display the first few rows of each dataframe to understand their structure\ndf_characters.head()",
    "Let's check the first few rows of each DataFrame to understand its structure better.",
    " Set option to display all columns in the notebook\npd.set_option('display.max_columns', None)",
    "Link the episodes to the script lines\ndf_script['episode'] = df_script.apply(lambda row: df_episodes.iloc[row['episode_id']].number, axis=1)",
    "Set current directory\nos.chdir('C:/Users/Nicolas/Google Drive/0 - Udacity/7 - Data Engineering Capstone/')",
    "NLP model\nnlp = spacy.load('en_core_web_md')",
    "Example of value you have access in the dataframe",
    " Merge data for better databasing - we will merge script and character/location databases",
    " Display data\nwith pd.option_context('display.max_rows', 10, 'display.max_columns', None, 'display.max_colwidth', 30):\n    display(df_characters, df_locations, df_script, df_episodes)",
    "Let's check the top word frequency in the simpsons lines",
    "Dependencies:\n# pandas\n# numpy\n# spacy\n# matplotlib\n# wordcloud\n# tqdm",
    "Display first 5 lines of the characters dataset\ndf_characters.head()",
    " View the first few rows of the dataframe\ndf_script.head()",
    " Data cleaning",
    " Merge script and episode data\ndf_script_episode = df_script.merge(df_episodes, how='left', on='episode_id')",
    " Show the top 5 rows of the dataframe to understand the data\ndf_script.head()",
    " Now let's take a look at the first few rows of each dataframe to understand their structure and contents.",
    " Seems good, let's move on.",
    "Check the data a bit",
    "Remove lines without character id and without quotes\ndf_script = df_script.loc[df_script['character_id'].notna() & df_script['quote'].notna()]",
    "Merge lines with episode info\ndf_all = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_episode'))",
    "Exploring the characters dataset",
    "Preview dataframe with script lines\ndf_script.head()",
    "Merge the datasets 'df_script' and 'df_episodes'",
    " Convert id columns to int to enable merges",
    " Set the context for the analysis - the n-th episode and the minimum number of words for the lines",
    "Setting the parameters for the word cloud.",
    " Install the 'en_core_web_sm' model of spaCy\n!python -m spacy download en_core_web_sm",
    "Let's put the scipts together by episodes",
    " optionally suppress some warnings\nimport warnings\nwarnings.simplefilter(\"ignore\", UserWarning)",
    " Set up spaCy\nnlp = spacy.load('en_core_web_sm')\n\n# Process the script data with spaCy (only applied when not already contained in the dataframe)\nif 'spacy_processed' not in df_script.columns:\n    doc = df_script['raw_text'].progress_apply(lambda x: nlp(x))\n    df_script.insert(1, 'spacy_processed', doc)  # Insert spaCy processed data in a column in the dataframe.",
    " show schema of characters\nprint(df_characters.dtypes)\nprint(df_characters.head())\n\n# show schema of locations\nprint(df_locations.dtypes)\nprint(df_locations.head())",
    "Remove unncessary columns that have 90% or more of missing values",
    "Dsiplay the first rows of the characters dataframe",
    "rsample 10% of script\ndf_script = df_script.sample(frac=0.1, random_state=0)",
    "Drop useless columns and contents from the dataset",
    "Data preprocessing",
    " Merge script with characters and locations names\ndf = df_script.merge(df_characters[['id', 'name']], how='left', left_on='character_id', right_on='id')\ndf = df.rename(columns={'name': 'character_name'}).drop('id', axis=1)\ndf = df.merge(df_locations[['id', 'name']], how='left', left_on='location_id', right_on='id')\ndf = df.rename(columns={'name': 'location_name'}).drop('id', axis=1)",
    "Exploring the characters dataset",
    "To see the first lines of each dataframe, we can run \"\"\"\"df.head()\"\"\"\" for each one",
    " I'm going to start by showing the first 5 rows of the 4 dataframes to get an understanding of the data.",
    "The last few commands in the script load several datasets into pandas DataFrames. These DataFrames will be used for data analysis and visualization.",
    "Data Preprocessing and Cleaning",
    "Merge the character line with the character.",
    "Show the first few rows of the dataframe containing all script lines",
    "Categorize the script lines by character",
    "Print the shapes of the datasets\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Quick look at the dataframes",
    "Adds characters information to script dataframe\ndf_script = pd.merge(df_script,\n                     df_characters,\n                     left_on='character_id',\n                     right_on='id').drop(columns=['id'])\n\n# Adds locations information to script dataframe\ndf_script = pd.merge(df_script,\n                     df_locations,\n                     left_on='location_id',\n                     right_on='id').drop(columns=['id'])\n\n# Adds episodes information to script dataframe\ndf_script = pd.merge(df_script,\n                     df_episodes,\n                     left_on='episode_id',\n                     right_on='id').drop(columns=['id'])\n\ndf_script.head()",
    "Remove unnecessary columns from dataframes",
    "Show the first few rows of the script dataset\ndf_script.head()",
    "function to extract episode number from raw data",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "set index to unique keys\ndf_characters = df_characters.set_index('id')\ndf_locations = df_locations.set_index('id')\ndf_script = df_script.set_index('id')\ndf_episodes = df_episodes.set_index('id')",
    "# This is a special utility function that helps clean the memory (RAM) by performing garbage collection\n# It's not that important to understand the details of this function, but it can help us avoid running out of memory\ndef clean_memory():\n    \"\"\"\n    Perform a full garbage collection and return the memory usage\n\n    Returns\n    -------\n    memory_usage: float\n        Memory usage in GB after running the garbage collection\n    \"\"\"\n    gc.enable()\n    gc.collect()\n    return psutil.Process(os.getpid()).memory_info().rss / 10**9",
    "Merge the characters and script dataframes\ndf = pd.merge(df_characters, df_script, left_on='id', right_on='character_id', suffixes=('_characters', '_script'))\ndf = pd.merge(df, df_locations, left_on='location_id', right_on='id', suffixes=('', '_locations'))",
    "Now we will display the first 5 rows of the characters dataframe.",
    "Remove potential duplicate rows from characters, locations, episodes dataframes\ndf_characters.drop_duplicates(inplace=True)\ndf_locations.drop_duplicates(inplace=True)\ndf_episodes.drop_duplicates(inplace=True)",
    "Let's first analyze the characters.",
    "Merge the different datasets by their episodes' ID",
    "Preview the first 5 lines of the table\ndf_script.head()",
    " Load pre-trained spacy word vectors\nnlp = spacy.load('en_core_web_md', disable=['tagger', 'parser', 'ner'])",
    "suffle the data\ndf_script = df_script.sample(frac=1, random_state=0)",
    "Read data head",
    "Normalize `character_name` of `simpsons_script_lines.csv` and `normalized_name` of `simpsons_characters.csv` using spacy's `nlp` model.",
    " Print the shapes of our dataset\nprint(\"Characters shape:\", df_characters.shape)\nprint(\"Locations shape:\", df_locations.shape)\nprint(\"Script shape:\", df_script.shape)\nprint(\"Episodes shape:\", df_episodes.shape)",
    "Exploratory Data Analysis (EDA)",
    "Print data shapes\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "Explore the dataset\n#df_script.info()",
    "Let's start by examining the structure of `df_characters`.",
    "Merge characters and locations on episode_id\ndf_characters_locations = df_characters.merge(df_locations, on='episode_id')",
    "Visualizing the data",
    "Inspect the first few rows of each dataframe to understand the data",
    "Parse locations, characters and scripts",
    "display(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Take a look at the first 5 rows of the characters data\ndf_characters.head()",
    "Look at the first 3 rows of the characters dataframe and check if there are missing values",
    "Explore the dataframes (i.e., dimensions, first few rows, data types, NaNs)",
    "Inspect the first lines of the characters dataframe\ndf_characters.head()",
    "Drop unnecessary columns\ndf_characters = df_characters.drop(columns=['Normalized Name','Normalized Role'])\ndf_locations = df_locations.drop(columns=['Normalized Name'])\ndf_episodes = df_episodes.drop(columns=['Image URL','Production Company','US Viewers In Millions','Unnamed: 7','Video URL'])\n\n# Remove the last row which contains meta-information\n\n# Enumerating each dataframe\nfor idx, df in enumerate([df_characters, df_locations, df_script, df_episodes]):\n    # Adding the index as a column\n    df['DataFrame Index'] = idx\n\n    # Set index as DataFrame Index\n    df.set_index(['DataFrame Index','id'], inplace=True)\n\n# Reassign the new column ordered\ndf_script = df_script[['episode_id','number','character_id','location_id','raw_text',\"spoken_words\",\"timestamp_in_ms\"]]\n\ndf_script.head()",
    "Merge the dataframes to simplify the analysis\ndf_merge = pd.merge(df_script, df_episodes, how='left', on='episode_id')\ndf_merge = pd.merge(df_merge, df_characters, how='left', on='character_id')\ndf_merge = pd.merge(df_merge, df_locations, how='left', on='location_id')\n\nprint('Number of entries: {}'.format(len(df_merge)))",
    " Check data\ndf_script.head()",
    "Integration of my methods",
    "modules=BERTComponents(embedding_dim=768)",
    "Words clouds for most common words in Simpson show\n# Prepare data\ntext = ' '.join(df_script.raw_text.fillna(''))\n\n# Generate word cloud\nwordcloud = WordCloud(width = 800, height = 400, \n                background_color ='black', \n                min_font_size = 10).generate(text)\n\n# plot the WordCloud image                        \nplt.figure(figsize = (8, 8), facecolor = None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad = 0)",
    "Inspect the dataframes to understand their structure and what kind of information they contain.",
    "Set path to local data as the data folder is not in the working directory",
    " Print the character DataFrame\ndf_characters.head()",
    "Df tail for inspection\nprint(df_characters.tail(5))",
    " Helper functions",
    " Display the first 3 rows of each dataframe\ndf_characters.head(3)",
    "Define a function to create a word cloud from a given text",
    "Fix ids\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)\ndf_script['location_id'] = df_script['location_id'].fillna(-1).astype(int)",
    "Set script data types explicitly",
    "Display the first rows of the dataframe\ndf_script.head()",
    "Drop rows with empty or missing dialogue in df_script\ndf_script = df_script.dropna(subset=['normalized_text'])\ndf_script = df_script[df_script['normalized_text']!='']\n# (Optional: drop some other columns we won't use in this example to save memory)\ncolumns_to_drop = ['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'original_text', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text', 'word_count']\ndf_script = df_script.drop(columns=columns_to_drop)",
    "Combine script lines with metadata\ndf_joined = df_script.set_index('episode_id').join(\n    df_episodes.set_index('id'),\n    rsuffix='_ep'\n).join(\n    df_characters.set_index('id'),\n    rsuffix='_ch'\n).join(\n    df_locations.set_index('id'),\n    rsuffix='_loc'\n).reset_index()",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Create dictionary mapping character IDs to character names\ncharacter_id_to_name = {character_id: name for character_id, name in zip(df_characters['id'], df_characters['name'])}",
    "###############\n# Data Analysis\n###############",
    "Time to start by looking at the data.",
    "Print the dataframes to understand their structure\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Return the first 5 rows of the characters DataFrame\ndf_characters.head()",
    "Show the number of script lines and episodes in the dataset\nprint(f\"Number of script lines: {df_script.shape[0]:,}\")\nprint(f\"Number of episodes: {df_episodes.shape[0]:,}\")",
    " Preview the characters dataframe\ndf_characters.head()",
    "Inspect the first few rows of the character dataframe\ndf_characters.head()",
    "Rename some of the columns for clarification.",
    "For demonstration purpose, we limit the analysis to a short subset\ndf = df_script.loc[:1000].copy()\ndf.head()",
    "Let's take a look at the first few lines of each DataFrame.",
    "Display the first 5 rows of the characters dataset\ndf_characters.head()",
    "Definitions (for brevity)",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Set seed for reproducibility\nnp.random.seed(42)",
    "Inspecting the dataframes",
    "Data Preprocessing",
    "Set dataset type and name\ndf_characters.name = 'characters'\ndf_locations.name = 'locations'\ndf_script.name = 'script'\ndf_episodes.name = 'episodes'",
    "Let's first explore the data to see what information we have available.",
    "Brief look at our datasets\ndf_characters.head()",
    " Show the first rows of the dataframe\ndf_script.head()",
    " Displaying the first few lines of each dataframe to get an overview of the data structure",
    " Let's look at the first few records of each dataframe.",
    " Let's take a quick look at our data!",
    " We should begin with a quick about the data.",
    "Merge script csv with characters and locations\ndf_merged = pd.merge(df_script, df_characters, how='left', left_on=['character_id'], right_on=['id'])",
    "Merge script lines, characters and episodes\ndf_all = (\n    df_script[['episode_id', 'character_id', 'id']]\n    .merge(\n        df_episodes[['id', 'season', 'number']],\n        how='inner',\n        left_on='episode_id',\n        right_on='id'\n    )\n    .merge(\n        df_characters[['id', 'name']],\n        how='inner',\n        left_on='character_id',\n        right_on='id'\n    )\n    .drop(['id_x', 'id_y', 'episode_id', 'character_id'], axis=1)\n)\n\n# Add 'season_episode' column\ndf_all['season_episode'] = df_all['season'].astype(str) + '-' + df_all['number'].astype(str)\n\n# Replace character_id=-1 by character name 'unknown'\ndf_all['name'] = df_all['name'].mask(df_all['name'] == 'not said', 'unknown')\n\n# Display the final dataframe\ndf_all.head()",
    "Filter out miscellaneous characters",
    "Check the first rows of the characters DataFrame\ndf_characters.head()",
    " Select the unique lines with dialogues from all scripts and drop missing values",
    " as we have large datasets at our disposal, we will print out the sizes of them so that we get the sense of how many records we have for each entity.",
    "View the characters dataframe\ndf_characters.head()",
    " We will also set the max_columns option of pandas so that we can see all columns while displaying the DataFrames.",
    "Check our data\nprint(f'Characters: {df_characters.shape[0]}')\nprint(f'Locations: {df_locations.shape[0]}')\nprint(f'Script lines: {df_script.shape[0]}')",
    "Set environment variable for matplotlib\nos.environ['MPLCONFIGDIR'] = os.getcwd()",
    " Preview the data to understand the structure and contents of each dataframe",
    "select features to keep\ndf_script = df_script[[\n    'episode_id',\n    'number',\n    'raw_text',\n    'raw_character_text',\n    'spoken_words',\n    'raw_location_text',\n    'normalized_text',\n    'word_count'\n]]",
    "Filter empty script lines",
    " Display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Set pandas to display wider columns, and lower the number of rows to display for brevity\npd.options.display.max_colwidth = 100\npd.options.display.max_rows = 10",
    " Filter out unnecessary columns and rows.",
    "Preview the episodes dataset\ndf_episodes.head()",
    " Showing head of df_characters to understand its structure\ndf_characters.head()",
    " Display dataframe headers\ndf_characters.head()",
    "Remove unnecessary columns from the characters dataframe",
    "Train a model for named entity recognition (NER) with spaCy.",
    "Print the head of the dataframe to get an overview of the data\nprint(df_script.head())",
    "Splitting the script into lines and joining with characters and locations",
    " Some global configs\npd.set_option('display.max_columns', None)",
    "Check the first 2 rows of the dataset\nprint(df_script.head(2))",
    "Combine Episodes and Script dataframes.",
    "Check the content of each dataframe\ndf_characters.head()",
    "In the dataset, the following fields are available:\n# - Characters\n# -- id: character id\n# -- name: character name\n# -- normalized_name: normalized character name\n# -- gender: character gender\n# -- normalized_gender: normalized character gender\n# -- number_of_dialogues: number of dialogues the character has\n# -- first_appearance: character's first appearance in the series\n# -- id: location id\n# -- name: location name\n# -- normalized_name: normalized location name\n# -- frequency: frequency of the location\n# - Script Lines\n# -- id: script line id\n# -- episode_id: episode id\n# -- number: line number in the episode\n# -- raw_text: raw text of the line\n# -- timestamp_in_ms: timestamp of the line\n# -- speaking_line: a boolean that indicates whether a character speaks the line\n# -- character_id: character id\n# -- location_id: location id\n# -- normalized_text: normalized line text\n# -- word_count: word count of the line text\n# - Episodes\n# -- id: episode id\n# -- title: episode title\n# -- original_air_date: original air date of the episode\n# -- production_code: production code of the episode\n# -- season: season in which the episode is\n# -- number_in_season: episode number in the season\n# -- number_in_series: episode number in the series\n# -- us_viewers_in_millions: number of US viewers, in millions, when the episode aired\n# -- views: number of views, in thousands\n# -- imdb_rating: imdb rating of the episode\n# -- imdb_votes: number of imdb votes for the episode\n# -- image_url: image url of the episode",
    "drop nan values\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'normalized_text'])",
    "display first 5 rows of each dataframe\ndfs = [df_characters, df_locations, df_script, df_episodes]\nfor i, df in enumerate(dfs):\n    print(f\"\\nDataframe df_{i} :\")\n    print(df.head())",
    "Check the data in each DataFrame\nprint(\"Characters\")\ndisplay(df_characters.head(4))\n\nprint(\"Locations\")\ndisplay(df_locations.head(4))\n\nprint(\"Script\")\ndisplay(df_script.head(4))\n\nprint(\"Episodes\")\ndisplay(df_episodes.head(4))",
    "Sample the data to get a sense of what's in it\ndf_script.sample(10)",
    "Display all the tables in the dataset\nwith pd.option_context('display.max_rows', None, 'display.max_columns', None):\n    print(df_characters.head())\n    print(df_locations.head())\n    print(df_script.head())\n    print(df_episodes.head())",
    "Display the first few lines of the dataframe with the character data\ndf_characters.head()",
    "Merge the dataframes to obtain a single dataframe containing all the information about the scripts.",
    " View the characters dataframe",
    "Let's have a look at our data.",
    "Remove casing in the `character_name` column\ndf_characters['character_name'] = df_characters['character_name'].str.lower()",
    "We start by examining the first few rows of each dataframe.",
    "Merge the datasets on episode_id and character_id",
    "Set pandas display options for easier visualization of our datasets\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', None)",
    "This process builds WordClouds for the 10 most common words of each script line, character, and location.",
    "Inspecting the data\ndf_characters.info()",
    "Create a new column with the lowercased lines\ndf_script['spoken_words_lower'] = df_script['spoken_words'].str.lower()",
    "Check if the path exists\nif not os.path.exists('images'):\n    os.makedirs('images')",
    "Display head of the script data\ndf_script.head()",
    "Inspecting first few rows of dataset\ndf_episodes.head()",
    "Display all columns of the dataframes\npd.set_option('display.max_columns', None)",
    "\n# Caching pre-trained model\nnlp = spacy.load('en_core_web_sm')",
    "Explore the data structure\nprint(\"Characters:   \", df_characters.shape)\nprint(\"Locations:    \", df_locations.shape)\nprint(\"Script:       \", df_script.shape)\nprint(\"Episodes:     \", df_episodes.shape)",
    "Data organization\ndf_episodes = df_episodes.dropna(subset=['id']).set_index('id')\ndf_script = df_script.dropna(subset=['episode_id']).set_index('episode_id')\ndf_characters = df_characters.dropna(subset=['id']).set_index('id')\ndf_locations = df_locations.dropna(subset=['id']).set_index('id')",
    "Display settings\npd.set_option('display.max_columns', None)",
    "Rename wrongly named character_id column\ndf_episodes = df_episodes.rename(columns={'id': 'episode_id'})",
    " Check the first few rows of the characters dataframe\ndf_characters.head()",
    "Join all data.",
    "We'll start by taking a look at the first few rows of each of the dataframes to understand their structure and the kind of data they contain.",
    "Quick look at the data\ndf_characters.head()",
    "Check the content of the first 5 rows of the dataframe containing the characters",
    "Display dataset shapes\nprint(\"Characters (rows, columns):\", df_characters.shape)\nprint(\"Locations (rows, columns):\", df_locations.shape)\nprint(\"Script lines (rows, columns):\", df_script.shape)\nprint(\"Episodes (rows, columns):\", df_episodes.shape)",
    " Spacy nlp only needs to be initiated once\nnlp = spacy.load('en_core_web_sm')",
    "from scripts.data_cleaning import clean_script, align_lines",
    "Display the head of the DataFrame df_characters\ndf_characters.head()",
    "Let's take a look at the first few rows of each dataframe.",
    "Load the spaCy model\nnlp = spacy.load('en_core_web_sm')",
    " Some useful variables\nnames = list(df_characters.raw_character_text)\nlocations = list(df_locations.raw_location_text)",
    "Check few if the dataframes to get an idea of the data.",
    "Check the script dataframe\ndf_script.head()",
    "pd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', -1)",
    "Show the first few rows of the characters dataframe\ndf_characters.head()",
    "Displays all columns\npd.set_option('display.max_columns', None)",
    "Let's check the first couple of rows of each data frame.",
    "Clean the dialoguue data\ndf_script.head()",
    "Check if script was loaded correctly\ndf_script.head()",
    " Hide progress bars when running loops\ntqdm.pandas()",
    "Check the contents of the characters dataframe for any missing or NaN values\ndf_characters.head()",
    "Subsetting the dataframe for columns of interest\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id']]\n\n# Initial Data Exploration\nprint('\\n','#'*120,'\\n','DATAFRAME HEAD','\\n','#'*120,'\\n',df_script.head(5),'\\n','#'*120)",
    "Display the first few rows of the dataframe\ndf_script.head()",
    "Add any additional libraries and set config parameters here.",
    "Display the dataframes' content\ndf_characters",
    "Display the first few rows of the dataframe df_script\ndf_script.head()",
    "Let's take a quick look at what these datasets contain.",
    "Display the first few rows of the characters dataframe to understand its structure\ndf_characters.head()",
    "\nprint(\"Import successful\")",
    "Set random seed\nnp.random.seed(0)",
    "Merge the scripts with the corresponding characters and locations\ndf_character_script = df_characters.merge(df_script, on='character_id')\ndf_merged = df_character_script.merge(df_locations, on='location_id')",
    "Check the import and data loading",
    "df_script = df_script[df_script[\"episode_id\"].isin(df_episodes[df_episodes[\"season\"].isin(range(2, 10))][\"id\"])]\ndf_script = df_script.reset_index(inplace=False, drop=True)",
    "Let's take a look at the structure and first few rows of each DataFrame.",
    "The first step is to preprocess the data.",
    "Let's display the first few lines of each dataframe to understand their structure and content better.",
    "display(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "df_script.head()",
    "Remove \"cc by-sa 2.0\" from the end of all the lines in simpsons_episodes.csv\n# (this is bad practice, be careful in your own projects, kids!).",
    "Declare seasons for easy iteration",
    "Data Preprocessing",
    " Display settings\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    " Let's inspect each DataFrame to understand its structure and the data it contains.",
    "Setting the backend of matplotlib to a specific value to avoid any issues",
    "Data preprocessing",
    "Get the characters played by the actors (not from the script)",
    "Check missing values\ndf_script.isnull().sum()",
    "Mapping data for easier cleanup.",
    "Check first rows of `df_characters`\ndf_characters.head()",
    "Subset of the first 100 episodes from \"The Simpsons\" dataset\ndf_episodes_subset = df_episodes[df_episodes['id'] <= 100]",
    "Displaying head of df_episodes\ndf_episodes.head()",
    " Look at the first few rows of the characters DataFrame\ndf_characters.head()",
    "Print the number of lines in each of the tables",
    "Check dataframes loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_episodes.head())\nprint(df_script.head())",
    "Checking DataFrame shapes\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
    "Filtering dataset to include only the first 20 seasons\ndf_episodes_first_20_seasons = df_episodes[df_episodes['season'] <= 20]\n# converting date of release to a datetime object\ndf_episodes_first_20_seasons['original_air_date'] = pd.to_datetime(df_episodes_first_20_seasons['original_air_date'])\n\ndf_episodes_first_20_seasons.head()",
    "# Show first rows of the characters table\ndf_characters.head()",
    "How many entries do we have for each dataset?",
    "Merge dataframes",
    "Display first 5 records\ndf_script.head()",
    "View the first few records of the characters dataframe\ndf_characters.head()",
    " Now, we will prepare the data for analysis.",
    "Let's take a look at the data to understand its structure.",
    "Set the style of matplotlib plots\nmatplotlib.pyplot.style.use('dark_background')",
    "Set the max displayed columns to 100 and the rows to 50",
    "Visual representation and render output \npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', -1)",
    " Visualize the first few rows of the characters dataframe\ndf_characters.head()",
    "Preview the datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Merge the character information into the script\ndf_script = df_script.merge(df_characters, how=\"inner\", on=\"character_id\")",
    " Verify that the data was read correctly\ndf_characters.head()",
    "Explore first 10 records of the dataset\ndf_episodes.head(10)",
    "Since we are using Jupyter notebooks, we add the magic command %matplotlib inline to ensure that matplotlib works correctly with Jupyter.",
    "Check data you just loaded",
    "now, let's get an overall sense of the data we're working with.",
    "Inspect the structure of each of the dataframes",
    "Look at the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "inspect the first rows of the characters DataFrame\ndf_characters.head()",
    "Load the data files into Pandas dataframes",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "Create a function to filter the data frames by season.",
    "Merge script with characters and locations data\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('', '_character'))\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id', suffixes=('', '_location'))",
    " Display the first few rows of the script dataset\ndf_script.head()",
    "Merge the characters and locations dataframes to the script dataframe using the 'character_id' and 'location_id' columns respectively.\ndf_script = df_script.merge(df_characters, on='character_id', how='left')",
    "Visualize the top 10 characters by number of lines\ndf_character_lines = df_script.groupby('character_id')['id'].count().reset_index()\ndf_character_lines = df_character_lines.sort_values('id', ascending=False).head(10)\ndf_character_lines = df_character_lines.merge(df_characters, left_on='character_id', right_on='id')\ndf_character_lines = df_character_lines.set_index('name')\n\nplt.figure(figsize=(15, 8))\nplt.bar(df_character_lines.index, df_character_lines['id'], color='orange')\nplt.title('Top 10 Characters by Number of Lines')\nplt.xlabel('Character')\nplt.ylabel('Number of Lines')\nplt.xticks(rotation=45)\nplt.show()",
    "# Turn off notebook package\n%reload_ext autoreload\n%autoreload 2",
    "checking the head of each dataframe to understand its structure and what fields are available.",
    " Remove the values with missing features 'character_id'\ndf_script = df_script[df_script['character_id'].notna()].reset_index(inplace=False, drop=True)",
    "\ndf_script.head()",
    "Check shapes of DataFrames",
    "# We'll work with the script text\ndf_script.head()",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    " Feature Engineering",
    "Visualising some basic character and location information",
    "Check the dataframes\ndf_characters.head()",
    "Cut the data to match the observations we have",
    "Check the first 5 lines of each dataframe",
    "Display the head of the characters dataframe\ndf_characters.head()",
    "Turn: sample the data\npd.set_option('display.max_columns', None)\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Join all available data to create a master dataframe.\n# Join characters\ndf = df_script.join(df_characters, on='character_id', lsuffix='_script', rsuffix='_character', how='left')\n\n# Join locations\ndf = df.join(df_locations, on='location_id', lsuffix='_script', rsuffix='_location', how='left')\n\n# Join episodes\ndf = df.join(df_episodes, on='episode_id', lsuffix='_script', rsuffix='_location', how='left')",
    " Display top of the Characters DF\ndf_characters.head()",
    "Display the first 5 rows of the table to understand its structure\ndf_script.head()",
    "Visualize characters data\ndf_characters.head()",
    "Dimensions\nprint(df_script.shape)\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_episodes.shape)",
    "Set custom color palette\ncolors = ['#FF8C00', '#FF4500', '#FF0000', '#DC143C', '#B22222', '#8B0000', '#FFA07A', '#FA8072', '#E9967A', '#F08080', '#CD5C5C', '#DC143C']",
    "Display all columns for each dataframe\npd.set_option('display.max_columns', None)",
    "Check the content of the episodes dataframe",
    " Display the first few rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    " Explore data - characters dataframe",
    "Let's display the first few lines of each of these DataFrames to understand their structure and contents.",
    "Remove useless columns.",
    "Data Processing",
    "Where are the .csv files stored?",
    " View the first few rows of the dataframe\ndf_script.head()",
    "Create an entity recognizer and add it to the pipeline",
    "Enable or download the following models by running:\n# !python -m spacy download en_core_web_sm\n# !python -m spacy download en_core_web_md",
    " Merge script lines with episodes and selected only the relevant columns\ndf_merged = df_script.merge(df_episodes, on='episode_id')\ndf_merged = df_merged[['id', 'episode_id', 'number', 'timestamp_in_ms', 'raw_text', 'spoken_words', 'timestamp_in_ms', 'character_id']]\n\n# Add the character and location names to the merged dataset\ndf_merged = df_merged.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_character'))\ndf_merged = df_merged.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_location'))",
    " Print the shape of the DataFrames\nprint(\"Characters df shape :\", df_characters.shape)\nprint(\"Locations df shape :\", df_locations.shape)\nprint(\"Script df shape :\", df_script.shape)\nprint(\"Episodes df shape :\", df_episodes.shape)",
    "# Look at the first few lines of the characters data frame\ndf_characters.head()",
    "Inspect the data",
    "Characters\ndf_characters.head()",
    " Display the first rows of the characters dataframe\ndf_characters.head()",
    "Function to preprocess text data",
    "In this snippet, we are reading the data from CSV files into Pandas DataFrames. These DataFrames will then be used for data analysis and visualization.",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "Get some info on the data sets\nprint(f'{len(df_script)} lines of script')\nprint(f'{len(df_episodes)} episodes')\nprint(f'{len(df_characters)} characters')\nprint(f'{len(df_locations)} locations')",
    " Take a look at the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Join the datasets on the column \"episode_id\"",
    "\ndf_character_ep = pd.read_csv('data/simpsons_episodes_characters.csv')",
    "Data cleaning and formatting",
    " Display the first five rows of the dataframe\ndf_characters.head()",
    "Now that we have imported the necessary libraries and loaded the datasets, we can proceed with the data analysis and visualization.",
    "Visualize the most common words using a word cloud",
    "Displaying the head of the DataFrame characters\ndf_characters.head()",
    "Visually inspect initial dataset shapes and feature names",
    "Explore the data to understand the structure and content.",
    "Show first 5 rows of the dataframe for the script of the Simpsons",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Visualize the most common words in the simpsons script lines",
    "Merge and print a sample of the data",
    "Extract the main characters\nmain_characters = ['marge', 'homer', 'bart', 'lisa', 'maggie', 'skinner', 'ned', 'krabappel', 'burns', 'milhouse', 'moe',\n                   'comic', 'carl', 'lenny', 'apu', 'duffman', 'barney', 'abraham', 'edna', 'jimbo', 'nelson', 'patty',\n                   'selma', 'waylon', 'mrburns', 'reverend', 'snake', 'willie', 'karl', 'ralph', 'troy', 'lionel', 'hawk',\n                   'artie', 'snowball', 'herb', 'maggie', 'frink', 'jasper', 'kishimoto', 'montgomery', 'hans', 'lou',\n                   'krusty', 'barney', 'barney', 'mayor', 'sideshow', 'krustofsky', 'robert', 'lucas', 'luann']\ndf_script = df_script[df_script.raw_character_text.str.lower().isin(main_characters)]",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    "Filter episodes from season 1 and 2\ndf_episodes_1_2 = df_episodes[(df_episodes['season']==1) | (df_episodes['season']==2)]",
    "Display the first few lines of the script data to understand its structure\ndf_script.head()",
    "Display the first 5 lines of the characters dataframe\ndf_characters.head()",
    "## Data Cleaning and Exploration",
    " Let us take a glance at the data to get a better understanding of the dataset.",
    "checking for missing data\ndf_satistics = pd.DataFrame()\ndf_satistics['characters'] = dict(count = df_characters.shape[0])\ndf_satistics['locations'] = dict(count = df_locations.shape[0])\ndf_satistics['episodes'] = dict(count = df_episodes.shape[0])\ndf_satistics['script_lines'] = dict(count = df_script.shape[0])\n\ndf_satistics",
    "Merge `df_script` with `df_episodes`\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')",
    "Enable the processing of large datasets by pandas\npd.options.display.max_rows = 10",
    "Merge episodes data to script data\ndf_script = pd.merge(df_script, df_episodes[['id', 'imdb_rating', 'number_in_series', 'original_air_date', 'original_air_year']], how='left', left_on='episode_id', right_on='id', suffixes=('_script', '_episodes')).drop(columns=['id_epsiodes'])",
    " Helper function to display an image\ndef display_wordcloud(wordcloud):\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")",
    "Read data from CSV files and reset index to ensure the data is correctly formatted for further processing.",
    "Display the first few records of the characters dataframe\ndf_characters.head()",
    "added index reset and inplace variable",
    "# Merge script with character information\ndf_script = df_script.rename(columns={'raw_character_text': 'name'})\ndf_script_extended = df_script.merge(df_characters, on='name', how='left')\n\ndf_script_extended.head()",
    "First, we read the data from CSV files into pandas DataFrames for further processing and analysis.",
    " Tweak the display parameters to always show at least a part of every column's content\npd.set_option('max_colwidth', 300)",
    " Remove extra index column from dataframes\ndf_characters = df_characters.iloc[:,1:]\ndf_locations = df_locations.iloc[:,1:]\ndf_script = df_script.iloc[:,1:]\ndf_episodes = df_episodes.iloc[:,1:]",
    " Checking the first few rows of the characters dataframe",
    "Visualize the dataframe scripts using a treemap",
    " Quick look at the contents of each file",
    " Merge episodes and scripts into a single dataframe\ndf_episodes.rename(columns={'id': 'episode_id'}, inplace=True)\ndf = pd.merge(df_script, df_episodes, on='episode_id')",
    "Delete rows from the script where the normalized_text is missing.",
    "Let's display the first 5 rows of each dataframe to understand what kind of data we are working with.",
    "take a peek at the characters file\ndf_characters.head()",
    "Check the dataset shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    " Viewing the first five rows of the characters dataframe\ndf_characters.head()",
    "Visualizing data\n# Counting lines for each character\nlines_per_character = df_script['character_id'].value_counts()\nlines_per_character = lines_per_character.reset_index(inplace=False)\nlines_per_character.columns = ['character_id', 'lines']",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Merge character information into the script dataframe\ndf_full = pd.merge(\n    df_script,\n    df_episodes,\n    how='left',\n    on='episode_id',\n    suffixes=('_script', '_episode')\n)\n\ndf_full = pd.merge(\n    df_full,\n    df_characters,\n    how='left',\n    on='character_id',\n    suffixes=('', '_character')\n)",
    "Question 5: Should we preprocess the text data further before we create a Wordcloud?",
    "Load pre-trained spacy model\nnlp = spacy.load('en_core_web_sm')",
    "def load_pipeline():\n    # Load the multi-task NER model\n    nlp = spacy.load('en_core_web_sm')\n\n    # Add labels for the NER 'Character' and 'Location'\n\n    # Character labels\n    for character in df_characters['name']:\n        nlp.entity.add_label(character)\n\n    # Location labels\n    for location in df_locations['name']:\n        nlp.entity.add_label(location)\n\n    return nlp",
    "Selecting main columns for characters and script DataFrames\ndf_characters = df_characters[['id', 'name']]\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'normalized_text', 'character_id', 'location_id']]",
    "# Create path\nif not os.path.exists('images/'):\n    os.makedirs('images/')",
    "Path to the output directory\nOUTPUT_DIR = 'output'",
    "Show the first few rows of the dataframe df_characters\ndf_characters.head()",
    "Check if data was correctly loaded\ndf_characters.head()",
    "Display the dataframes\ndf_script.head(), df_characters.head(), df_locations.head(), df_episodes.head()",
    "To_DO load all datasets and print the columns names and shapes to confirm everything was read correctly",
    "Check/Reset Index\ndf_characters = df_characters.reset_index(inplace=False, drop=True)\ndf_locations = df_locations.reset_index(inplace=False, drop=True)\ndf_script = df_script.reset_index(inplace=False, drop=True)\ndf_episodes = df_episodes.reset_index(inplace=False, drop=True)",
    " Pretend to run the importing of data and keep going with the notebook",
    "Select the script for episode 1 (June 15, 2017)",
    " Clean up the datasets\ndf_locations = df_locations.drop(columns=['id', 'normalized_name'])\ndf_characters = df_characters.drop(columns=['id', 'normalized_name'])\ndf_episodes = df_episodes.drop(columns=['id'])\n\n# Filter script to only load rows from the first 8 seasons",
    " Initializes a spaCy pipeline with the English model",
    "Define some constants to make the scripts easier to read\nMIN_LINES = 50\nMIN_DIALOG_LEN = 4",
    " Get the script from Treehouse\ndf_script_medium = df_script.head(1000)",
    "For the purpose of this analysis, we are only going to use the gender column from the simpsons_characters.csv file.",
    "Merge character and location to script\ndf_script = df_script.merge(df_characters[['character_id', 'character_name']], \n                            how='left', on='character_id')\ndf_script = df_script.merge(df_locations[['location_id', 'location_name']], \n                            how='left', on='location_id')",
    "List the script dataset to understand its structure\ndf_script.head()",
    "Merge script line with characters and locations\ndf_script = df_script.merge(df_episodes[['id', 'season', 'number', 'title']], on='id', how='left')",
    " Define file paths for storing visualizations",
    "Auxiliary code to display all columns\npd.set_option('display.max_columns', None)",
    "Encoding errors in dataframe_character dataset\ndf_characters[df_characters.original_title.str.contains('')]",
    " Print first 5 rows from 'script' dataframe\ndf_script.head()",
    " Merge locations, script lines and episodes into one dataframe\ndf_merged = (df_script\n             .merge(df_locations, how='left', on='raw_location_text')\n             .merge(df_episodes, how='left', left_on='episode_id', right_on='id'))\n\n# Merge with characters to include Speaker/Listener names\ndf_merged = df_merged.merge(df_characters, how='left', left_on='raw_character_text', right_on='name')",
    "Check data shapes\nprint(df_characters.shape)",
    "Check the first few rows of the characters dataframe\ndf_characters.head()",
    "Start by loading the datasets into pandas DataFrames.",
    "Display general information about the datasets\nprint('[INFO] Characters')\ndf_characters.info()\nprint('\\n[INFO] Locations')\ndf_locations.info()\nprint('\\n[INFO] Script')\ndf_script.info()\nprint('\\n[INFO] Episodes')\ndf_episodes.info()",
    "Set the style of the plots.",
    " Checking the first few rows of the characters dataframe.",
    "Display script lines dataset\ndf_script.head()",
    " Preprocessing\n# Ensure no Null values for character_id\ndf_script = df_script[~df_script[\"character_id\"].isnull()]",
    " Display the first few rows of the dataframe to understand its structure\ndf_characters.head()",
    "merge episodes with characters and locations\ndf_episodes_chars_locs = pd.merge(df_episodes, df_characters, on='episode_id')\ndf_episodes_chars_locs = pd.merge(df_episodes_chars_locs, df_locations, on='episode_id')",
    "define primary key (episode_id and number)\ndf_episodes = df_episodes.rename(columns={'id':'episode_id'})\ndf_episodes = df_episodes.set_index('episode_id', drop=False)",
    "Filter by gold quality and main characters",
    "Display the first 5 rows of the characters dataframe\ndisplay(df_characters.head(5))",
    "Create empty DataFrame for capturing entities\ndf_entities = pd.DataFrame(columns=['id', 'text', 'label'])\n\nnlp = spacy.load('en_core_web_sm')",
    "Remove whitespaces from headers and make them lowercase\ndf_characters.columns = df_characters.columns.str.strip().str.lower().str.replace(' ', '_')\ndf_locations.columns = df_locations.columns.str.strip().str.lower().str.replace(' ', '_')\ndf_script.columns = df_script.columns.str.strip().str.lower().str.replace(' ', '_')\ndf_episodes.columns = df_episodes.columns.str.strip().str.lower().str.replace(' ', '_')",
    "Inspect dataframes to get an idea of their structure\ndf_script.head()",
    "Encoding all the dataframes by ASR for simplicity\ndf_characters = df_characters.astype('category')\ndf_locations = df_locations.astype('category')\ndf_episodes = df_episodes.astype('category')",
    "For full transparency I will provide the first few rows of the dataframe",
    "Exploratory Data Analysis (EDA)",
    "Display the first few rows of the dataframe\ndf_script.head()",
    "It seems that the code was written to read several CSV files into pandas dataframes. This is likely to be part of a data analysis or data visualization project related to the TV show \"The Simpsons.\"",
    "Print head of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Let's first take a look at the structure and content of each of these datasets.",
    " By importing data, we can access the datasets and start working with the Simpson's script.",
    " Check the number of different characters and locations",
    "We have read the CSV files into Pandas dataframes.",
    "Inspect the first 5 rows of the dataset\ndf_script.head()",
    "Previewing the dataframes",
    " Remove potential corrupted data\ndf_script = df_script[df_script['location_id'].notnull()].copy()",
    "Visualize missing data",
    "Show simple breakdowns of dataframes",
    "hansoo = ['Homer Simpson', 'Marge Simpson', 'Bart Simpson', 'Lisa Simpson', 'Maggie Simpson', \n          'Ned Flanders', 'Krusty the Clown', 'Milhouse Van Houten', 'Chief Wiggum', 'Grampa Simpson', \n          'Lenny Leonard', 'Mayor Quimby', 'Nelson Muntz', 'Principal Skinner', 'Sideshow Bob', \n          'C. Montgomery Burns', 'Comic Book Guy', 'Edna Krabappel', 'Moe Szyslak', 'Apu Nahasapeemapetilon', \n          'Kent Brockman', 'Waylon Smithers', 'Ralph Wiggum', 'Groundskeeper Willie', 'Martin Prince', \n          'Doctor Hibbert', 'Officer Lou', 'Mrs. Krabappel']",
    "Some adjustments\npd.options.display.max_columns = None",
    "Inspect the characters dataframe.",
    " Visualize the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Quick look at dataframe shape\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "Take a look at the first 5 rows of df_characters.\ndf_characters.head()",
    "Join dataframes",
    "Create client for speech recognition service.",
    "Let's preview the data in each DataFrame to ensure everything loads correctly.",
    "Filter out unnecessary characters from the script dataframe\ncharacters = df_characters['id']\nmask = df_script['character_id'].apply(lambda x: x in characters.to_list())\ndf_script = df_script[mask]",
    "We will start by analyzing the characters' lines.",
    "# What does the df contain?\ndf_script.head()",
    "# Data preload\ncharacters = df_characters.to_dict(orient='records')\nlocations = df_locations.to_dict(orient='records')\nepisodes = df_episodes.to_dict(orient='records')\n\n# Show episodes' data\ndf_episodes.head()",
    "Display first rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Extract relevant columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'normalized_text', 'raw_character_text',\n                       'spoken_words', 'normalized_text', 'word_count']]\n\n# Removing leading/trailing spaces from al fanmes\ndf_characters['character'] = df_characters['character'].str.strip()\ndf_locations['raw_location_text'] = df_locations['raw_location_text'].str.strip()\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.strip()",
    "# Definition of preprocessing function to remove time from the dialogue\ndef remove_scene_description(text):\n    return text.split(':')[-1]",
    "Set the index appropriately for each DataFrame\ndf_characters.set_index(\"id\", inplace=True)\ndf_locations.set_index(\"id\", inplace=True)\ndf_episodes.set_index(\"id\", inplace=True)\ndf_script.set_index(\"id\", inplace=True)",
    "# show the first few rows of each table\nprint(\"Characters\")\nprint(df_characters.head())\n\nprint(\"\\nLocations\")\nprint(df_locations.head())\n\nprint(\"\\nScript\")\nprint(df_script.head())\n\nprint(\"\\nEpisodes\")\nprint(df_episodes.head())",
    " Print the shape of the dataframes to check if the files are read correctly",
    "to retain the original dataframes unchanged, let's make copies of them for data processing:",
    "Verify that the datasets have been loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Inspect the first few rows of the characters dataframe\nprint(df_characters.head())",
    "Merge the dataset on episode, character, location, and script together.",
    "Reading first line of each dataframe",
    "Season filter\nseasons = []",
    "Check the structure of the datasets\ndf_characters.head()",
    "# Checking the df_characters dataframe\ndf_characters.head()",
    "Create a subplot\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(13, 20))",
    "Quick peek at the data\ndf_characters.head()",
    "Checking if any script lines have Common Core information\ndf_script[df_script[\"norm_id\"].str.contains(\"CZ\", na=False)]",
    "Limit number of float output to 3 decimal points\npd.set_option('display.float_format', lambda x: '%.3f' % x)",
    "Check the first few rows of the characters data\ndf_characters.head()",
    " Display the first few records of the characters dataframe\ndf_characters.head()",
    "Optional: Uncomment the line below to view the first few rows of the dataframe\n# df_script.head()",
    "Let's take a look at the dataframes to understand their structures.",
    "# Preview of the characters dataset\ndf_characters.head()",
    "Prepare data for modeling",
    " Let us first take a look at the structure of the data of each dataframe.",
    "Sample of script dataframe\ndf_script.head()",
    "Inspect the data samples.",
    "Because we are working with real-life data, let's take a look at the first few rows of each dataset to understand their structure.",
    "Create character, location and episode maps to go from string to int and vice versa",
    " Check the shape of the imported data\nprint('Number of characters:', df_characters.shape[0])\nprint('Number of locations:', df_locations.shape[0])\nprint('Number of script lines:', df_script.shape[0])\nprint('Number of episodes:', df_episodes.shape[0])",
    "Print the first few lines of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Check the size of the imported DataFrames",
    "Create a connection to Postgres database using sqlalchemy library.",
    "Explore datasets",
    "Inspect the dataframes",
    "Filtering the scripts with null information and multiple characters",
    "Filter unspecified locations, replace ~140 duplicates by hand\ndf_locations = df_locations[~df_locations['normalized_text'].isin(['*unspecified location', 'unspecified'])]",
    "Combine character and location information with script data\ndf_merged = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('', '_episode'))\ndf_merged = df_merged.merge(df_characters, left_on='character_id', right_on='id', suffixes=('', '_character'))\ndf_merged = df_merged.merge(df_locations, left_on='location_id', right_on='id', suffixes=('', '_location'))",
    "df_characters.head()",
    "Check if your datasets have been read correctly",
    "Look at first rows of characters dataframe\ndf_characters.head()",
    "# Concatenate location names\nlocation_names = '|'.join([location.lower() for location in df_locations['raw_location_text'].unique()])\nlocation_names",
    "# Set to initial variables.\ncharacters_vocab = None\nword_to_ix = None",
    "Join datasets",
    "Creating a full dataframe with all the columns together",
    "Set maximum display rows/columns for better visual inspection",
    "Cleaning data",
    "Check the shape and top rows of each dataframe\ndf_characters.head(), df_characters.shape",
    "Display datasheets header",
    "Display the first 5 rows of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Merge characters, locations and script\ndf = df_script.merge(df_characters, left_on='character_id',\n                     right_on='character_id', suffixes=('_script', '_character'))\ndf = df.merge(df_locations, left_on='location_id', right_on='location_id', suffixes=('_script', '_location'))",
    "View the dataset shapes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "# Show entire dataframes in printed output\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    "Since there is no specific file path for the datasets, the code reads the CSV files with the 'read_csv' function from the pandas library and then resets the index of the resulting dataframes.",
    "Now it's time to explore the data. Let's start by inspecting the first few rows of the characters dataframe.",
    "Set pandas display options for better data visualization\npd.options.display.max_columns = None\npd.options.display.max_rows = None\npd.options.display.max_colwidth = 1000",
    "Create a connection to the database",
    "Remove text data with incorrect or missing values",
    "# Load the spaCy model\nnlp = spacy.load('en_core_web_sm')",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    " Preprocess the script dataset to filter out non-dialogue lines and combine multiple lines from the same character into a single entry.",
    " Show dataframes schemas",
    "Check data shapes\nprint(\"Characters shape:\", df_characters.shape)\nprint(\"Locations shape:\", df_locations.shape)\nprint(\"Script shape:\", df_script.shape)\nprint(\"Episodes shape:\", df_episodes.shape)",
    " Assign colors to characters, locations, and episodes so that plots are understandable.",
    "Display all columns for each dataframe\nfor df in [df_characters, df_locations, df_script, df_episodes]:\n    print(df.columns)",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Get the outfit color of the characters",
    "display first few rows of the dataframe\ndf_characters.head()",
    "The structure for the script line dataframe is:\ndf_script.head()",
    "Let's take a look at the data to understand its structure.",
    "Create directory to save figures if it doesn't exist\nif not os.path.exists('figures'):\n    os.mkdir('figures')",
    " Display the number of rows and columns for each dataset\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "\ndf_script.head()",
    "Check the content of a few scripts\ndf_script.head()",
    "Inspect the first five rows of the characters DataFrame\ndf_characters.head()",
    " Examine the first few lines of the characters dataframe\ndf_characters.head()",
    "Quick overview of the datasets\nprint('Characters: {}'.format(df_characters.shape))\nprint('Locations: {}'.format(df_locations.shape))\nprint('Script: {}'.format(df_script.shape))\nprint('Episodes: {}'.format(df_episodes.shape))",
    "Define dimensionality of each dataset\nn_characters = len(df_characters)\nn_locations = len(df_locations)\nn_episodes = len(df_episodes)\nn_scripts = len(df_script)\n\nprint(f'DataFrame \"Characters\" contains {n_characters} rows')\nprint(f'DataFrame \"Locations\" contains {n_locations} rows')\nprint(f'DataFrame \"Episodes\" contains {n_episodes} rows')\nprint(f'DataFrame \"Script\" contains {n_scripts} rows')",
    " VISUALIZING SCRIPT DATA\ndf_script.head()",
    "Inspect the structure and data types of the datasets",
    " Let's apply some basic data explorations to see what is inside these datasets.",
    "Let's start by exploring the data.",
    "Print headers and .head() of dataframes\nprint(\"\\nCharacters:\")\nprint(df_characters.head())\nprint(\"\\nLocations:\")\nprint(df_locations.head())\nprint(\"\\nScript:\")\nprint(df_script.head())\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
    "Dataset Exploration",
    "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Inspect the data",
    "Inspect and verify datasests",
    "Visual exploration of the data\n# Display random samples of each dataframe\nprint('Characters dataframe :')\nprint(df_characters.sample(5))\nprint('\\nLocations dataframe :')\nprint(df_locations.sample(5))\nprint('\\nScript dataframe :')\nprint(df_script.sample(5))\nprint('\\nEpisodes dataframe :')\nprint(df_episodes.sample(5))",
    "Display first 5 rows of characters dataframe\ndf_characters.head()",
    "Display the first few records of the characters dataframe\ndf_characters.head()",
    "Check the first few rows of each dataset\nprint(\"Characters:\")\nprint(df_characters.head())\n\nprint(\"\\nLocations:\")\nprint(df_locations.head())\n\nprint(\"\\nScript:\")\nprint(df_script.head())\n\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
    " Display the first few lines of the characters DataFrame\ndf_characters.head()",
    "# Display the first 5 records of the script lines dataframe\ndf_script.head()",
    " Check the list of transcript's columns to use the one we want to.",
    "Creating wordcloud of character dialogue\n# Process of creating wordcloud\n# 1. merges the script lines dataframe with the characters dataframe \n# on the character, episode_id columns of the script lines dataframe and the \n# id column of the characters dataframe\n# 2. filter out characters where gender is not provided\n# 3. filter out script lines that are not spoken or have no spoken_words\n# 4. filter out episodes that have not been aired or have not started\n# 5. perform sentiment analysis on the spoken_words and assign the sentiment through a column\n# 6. create word cloud of the dialogue of a character",
    "Let's display the head of these DataFrames to understand the data better.",
    "Visualisation du nombre de lignes par saison\ndf_episodes['production_season'].value_counts().sort_index().plot(kind='bar', figsize=(15, 5))\nplt.title('Nombre de lignes par saison')\nplt.xlabel('Saison')\nplt.ylabel('Nombre de lignes')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()",
    " Display the number of rows and columns for each dataframe\nprint(f'Characters: {df_characters.shape}')\nprint(f'Locations: {df_locations.shape}')\nprint(f'Script: {df_script.shape}')\nprint(f'Episodes: {df_episodes.shape}')",
    " Display maximum columns and expanded width\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)",
    " Print info of the datasets\nprint('Characters:')\nprint(df_characters.info())\nprint()\nprint('Locations:')\nprint(df_locations.info())\nprint()\nprint('Script:')\nprint(df_script.info())",
    " Add column with the full name of the character and the location to the script lines dataframe\ndf_script = (\n    df_script\n    .merge(df_characters[['id', 'name']], left_on='character_id', right_on='id', suffixes=(None, '_character'))\n    .merge(df_locations[['id', 'name']], left_on='location_id', right_on='id', suffixes=(None, '_location'))\n)",
    "Merge the dataframes together into a single dataframe based on the episode id.",
    "Extract the main characters\nmain_characters = [\n    'marge', 'homer', 'bart', 'lisa', 'maggie', \n    'milhouse', 'krusty', 'burns', 'smithers', 'moe', \n    'ned', 'apu', 'barney', 'skinner', 'ralph', 'kent', \n    'gary', 'carl', 'lenny', 'chief', 'edna', 'selma', 'patty', \n    'maggie', 'todd', 'marty', 'rod', 'troy', 'lionel', 'patty'\n]\n\n# Load the spaCy model\nnlp = spacy.load('en_core_web_sm')",
    "We need to also force the conversion of str-``NaN`` to ``np.nan`` again as done during Data Cleaning.",
    "Visualize the number of lines per episode\ndf_episodes['id'] = df_episodes['id'].apply(str)\ndf_script['episode_id'] = df_script['episode_id'].apply(str)\n\nlines_per_episode = df_script['episode_id'].value_counts().reset_index()\nlines_per_episode.columns = ['episode_id', 'num_lines']\n\nlines_per_episode = lines_per_episode.merge(df_episodes, left_on='episode_id', right_on='id')\nlines_per_episode = lines_per_episode.sort_values(by='original_air_date')\nlines_per_episode['episode_id'] = lines_per_episode['id']  # Rename because there is another column with the same name, and we need it for the next step.",
    "This data was made available by Alexandru Papiu and we can find this data in kaggle community.",
    " Visualize missing values as a matrix",
    "Most of the time, the data in pandas dataframes is read-only. This means that the methods and attributes are in place, to ensure that the data doesn't get manipulated accidentally.",
    " Filter 1 of 1: Imaginationland\n# Due to the lack of imagination in this dataset, the following TV Series will be used\n# The Simpsons\ntv_series = 'the simpsons'",
    " Merge episodes with script\ndf_episodes_script = df_episodes.set_index('id').join(df_script['episode_id'].value_counts().sort_index(), how='outer').rename(columns={'episode_id': 'script_lines_count'})",
    " Merge the episodes' data into the script's data\ndf_script = df_script.merge(df_episodes, on=['episode_id'], how='inner')",
    "Sample the dataframe and identify the column names and their associated meanings",
    "Set up Pandas to show all columns when displaying DataFrames\npd.set_option('display.max_columns', None)",
    " Remove unwanted columns and rows from DataFrames to reduce memory usage and increase speed.",
    " We will leave the Timestamp as it is, we will drop the other character_colums, and the raw text, we will leave the spoken_words since that's the one we will make embeddings about",
    "Limiting the script dataset to only the scenes taking place in a location.",
    "Estimate minutes required to read each script line\nword_per_minute = 200 # estimation\ndf_script['word_count'] = df_script['spoken_words'].apply(lambda x: len(x.split()))\ndf_script['read_duration'] = df_script['word_count'] / word_per_minute",
    "- Element displaysdf_script.head()",
    " Check the structure of one of the dataframes\ndf_script.head()",
    "Let's start by examining the contents of each of the datasets.",
    "Checking the top 5 rows of the characters dataframe",
    "Let's have a look at the first few lines of each DataFrame.",
    " Check the structure of the script lines table\ndf_script.head()",
    " Display an overview of the data in the datasets",
    "Join characters, locations, script lines and episodes",
    "Note: The 'data' folder is expected to be in the same directory as this Jupyter Notebook.",
    "Setting up spaCy\n# We'll need spaCy's tokenizer and stopwords list\nnlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"ner\"])",
    "View first few rows of characters dataframe\ndf_characters.head()",
    "Filter episodes\ndf_episodes_filtered = df_episodes[(df_episodes['original_air_year'] > 1989) & (df_episodes['original_air_year'] < 2000)]",
    "General imports",
    "Merge the information of the script, characters, and locations into one dataframe for easy access.",
    "Let's start by taking a look at the data from the 'simpsons_characters.csv' file.",
    "Show the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Print the first few rows of each dataframe to understand their structure\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"\\n---------------------------------\")\nprint(\"\\nLocations\")\nprint(df_locations.head())\nprint(\"\\n---------------------------------\")\nprint(\"\\nScript\")\nprint(df_script.head())\nprint(\"\\n---------------------------------\")\nprint(\"\\nEpisodes\")\nprint(df_episodes.head())",
    "Preview the first few entries of the script dataset\ndf_script.head()",
    "Check the import content\nprint(\"Characters: \", df_characters.head())\nprint(\"Locations: \", df_locations.head())\nprint(\"Script: \", df_script.head())\nprint(\"Episodes: \", df_episodes.head())",
    "Display the first few rows of each DataFrame to get an idea of the data",
    " Display the first few records of the characters dataset\ndf_characters.head()",
    " Print the number of observations in each data frame\nprint(f\"Number of characters: {len(df_characters)}\")\nprint(f\"Number of locations: {len(df_locations)}\")\nprint(f\"Number of script lines: {len(df_script)}\")\nprint(f\"Number of episodes: {len(df_episodes)}\")",
    "Initial filtering and cleanup\n# Basic cleanup. Most important, we convert the column type of episode_id to int, further below we need that for filtering.\ndf_script_filtered = df_script.dropna(subset=['raw_text', 'character_id'])\n\n# Merge duplicates and do other cleanup operations\ndf_characters = df_characters.set_index('id').sort_index()\ndf_characters['name'] = df_characters['name'].str.lower()",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Load the pre-trained spacy model\nnlp = spacy.load('en_core_web_sm')",
    "Inspect a few rows\ndf_script.sample(5, random_state=20)",
    " Display df_characters head",
    "Let's take a look at the first few rows of each dataframe to understand the data structure.",
    "This dataset is designed for educational approaches, by no means do I own this data nor am Iancer at Fox.",
    "# Use the OS module to handle operating system specific operations\nimport os",
    "Character names\ncharactersdf = [name.lower() for name in list(df_characters['character_name'])]",
    " Check if script line and episode have same id",
    "Choose a specific dataframe to work with (e.g. df_characters, df_locations, df_script, df_episodes)",
    "View the first 5 rows of the characters DataFrame to understand its structure and content\ndf_characters.head()",
    "Print the first 10 rows of the characters dataframe\ndf_characters.head(10)",
    "Check size and structure of each table\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Show the first few rows of the characters dataset\ndf_characters.head()",
    "Check the shapes of the imported DataFrames\nprint(\"Shape of characters DataFrame: \", df_characters.shape)\nprint(\"Shape of locations DataFrame: \", df_locations.shape)\nprint(\"Shape of script DataFrame: \", df_script.shape)\nprint(\"Shape of episodes DataFrame: \", df_episodes.shape)",
    "Check out the first few rows of each dataframe\ndf_characters.head()",
    "Check the size of the datasets\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Concatenate location and episode in the script dataframe",
    "Covert character_id and location id to int\ndf_script['character_id'] = df_script['character_id'].astype('Int64')\ndf_script['location_id'] = df_script['location_id'].astype('Int64')",
    "Checking the first rows for the script dataframe.",
    "What's inside each dataset?",
    "Clean data and preprocess text",
    "\n# Show the first few lines of the characters DataFrame\ndf_characters.head()",
    "Join all data together\ndf = df_script.copy()",
    "Testing whether these imports work",
    "# You can ignore this cell, it is only for checking the available attributes and methods of a pandas DataFrame\n[df_characters.",
    " Display basic information on the datasets\nprint(\"Characters Dataset\\n\")\nprint(df_characters.head())\nprint(\"\\n-------------------------------------\\n\")\nprint(\"Locations Dataset\\n\")\nprint(df_locations.head())\nprint(\"\\n-------------------------------------\\n\")\nprint(\"Script Dataset\\n\")\nprint(df_script.head())\nprint(\"\\n-------------------------------------\\n\")\nprint(\"Episodes Dataset\\n\")\nprint(df_episodes.head())",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    " Set the display columns for the DataFrame to avoid truncation of the data",
    "Filter unnecessary columns in the episodes dataframe",
    "Use this to render graphs. Filter to \"x11\" if it doesn't render.plt.gca().get_figure_manager().window.showMaximized()",
    "Data overview\ndf_script.head()",
    "Ensure the episode_id is a string\ndf_script['episode_id'] = df_script['episode_id'].astype(str)",
    "to do\n# - Take into account the compound name of some characters/locations in the script\n# - apply the above points to the script\n# - count which characters appear in the most locations & vice versa\n# - sentiment analysis for reviews\n# - topic analysis for the reviews",
    "Inspect the dataframes dtype",
    "# Display some dataframes\ndf_script.head()",
    "Let's take a look at the format and content of the script data.",
    " Remove 'overseas_episode_production_code' column\ndf_episodes.drop(['overseas_episode_production_code'], axis=1, inplace=True)",
    "# Ensure the data has been loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Check the information in each dataframe.",
    "Create an 'id' for each episode and character ID\ndf_script['episode_id'] = df_script['episode_id'].apply(str)\ndf_script['id'] = df_script.index.astype(str)\ndf_characters['id'] = df_characters.index.astype(str)\ndf_locations['id'] = df_locations.index.astype(str)\ndf_episodes['id'] = df_episodes['id'].astype(str)",
    "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Inspect first 5 rows of each table\nfor df, name in zip([df_characters, df_locations, df_script, df_episodes],\n                    ['Characters', 'Locations', 'Script', 'Episodes']):\n    print(f'First 5 rows of {name} table:')\n    display(df.head())\n    print('\\n\\n')",
    "During the code above, the code loads the necessary datasets using pandas and the `read_csv` function. The datasets loaded include `simpsons_characters.csv`, `simpsons_locations.csv`, `simpsons_script_lines.csv`, and `simpsons_episodes.csv`. Each dataset is read into a pandas DataFrame and then reset the index to ensure a clean, continuous index.",
    "A LOT of warnings will occur from this chunk of code and that happens because pandas uses a lot of chained assignment in the code, which has been optimized but is not supported by Pylint and other tools. Pylint will let us know about this and suggest that we use the `at` method instead of the chained operators to access the data of our dataframe.",
    " Multiple lines of code to explore and analyze the data will go here.",
    " We will create a single dataframe which includes episodes, locations, characters and script lines information.",
    "Configure matplotlib styles and defaults\nplt.style.use('fivethirtyeight')",
    " CHeck first few rows of each table",
    "Check the shape of the dataframes\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    " Data Preprocessing",
    "Set the file paths to be used\nscript_path = 'data/simpsons_script_lines.csv'\ncharacters_path = 'data/simpsons_characters.csv'\nlocations_path = 'data/simpsons_locations.csv'\nepisodes_path = 'data/simpsons_episodes.csv'",
    " Display the top few rows of the DataFrame\ndf_characters.head()",
    " Do work on df_characters, df_locations, df_script, and df_episodes.",
    "Download the larger English model for spaCy, which is needed for the named entity recognition (NER) functionality.\n!python -m spacy download en_core_web_lg",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    "Inspect data types and missing values",
    "Preview the first few rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Preview the first 5 rows of each dataframe to understand their structure\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "The columns we are interested in are:\ndf_script: \"episode_id\", \"number\", \"raw_text\"\ndf_episodes: \"id\", \"title\", \"original_air_date\"\ndf_locations: \"id\", \"name\"\ndf_characters: \"id\", \"name\"",
    "Quick overview of the data\nprint(\"Characters data:\")\nprint(df_characters.head())\nprint(\"\\nLocations data:\")\nprint(df_locations.head())\nprint(\"\\nScript data:\")\nprint(df_script.head())\nprint(\"\\nEpisodes data:\")\nprint(df_episodes.head())",
    "Display all columns for the script dataframe to have a better understanding of the dataframe",
    "quick look at the characters data\ndf_characters.head()",
    "Change directory to parent\nos.chdir(os.pardir)",
    "Display some basic information about the datasets\nprint('Characters')\nprint(df_characters.info())\nprint(df_characters.head())\nprint()\nprint('Locations')\nprint(df_locations.info())\nprint(df_locations.head())\nprint()\nprint('Script')\nprint(df_script.info())\nprint(df_script.head())\nprint()\nprint('Episodes')\nprint(df_episodes.info())\nprint(df_episodes.head())",
    "Visually show the first 5 rows of the characters dataframe.",
    "Check that the data was loaded correctly\ndf_script.head()",
    "Filter script by season",
    "Check that the content of the DataFrames was loaded correctly\ndf_script.head()",
    "First, we import the required libraries and then load the Simpsons dataset using pandas. The dataset contains information about characters, locations, script lines, and episodes from the Simpsons TV show.",
    "Change epsiode air date to datetime\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'])",
    "First we read the datasets into pandas DataFrame.",
    " Print the first few rows of the dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Merge Echo and Hero columns in case they contain complementary information",
    "Merge characters, locations and episodes information into script data\ndf_script['character_name'] = df_script['character_id'].apply(lambda x: df_characters[df_characters['id'] == x]['name'].values[0])\ndf_script['location_name'] = df_script['location_id'].apply(lambda x: df_locations[df_locations['id'] == x]['name'].values[0])\ndf_script['episode_title'] = df_script['episode_id'].apply(lambda x: df_episodes[df_episodes['id'] == x]['title'].values[0])\ndf_script['episode_season'] = df_script['episode_id'].apply(lambda x: df_episodes[df_episodes['id'] == x]['season'].values[0])\ndf_script['episode_number'] = df_script['episode_id'].apply(lambda x: df_episodes[df_episodes['id'] == x]['number_in_season'].values[0])",
    "Extract lines from the script that absolutely fit in the simpsons_episodes DataFrame",
    "Show the first few rows of the characters dataframe\ndf_characters.head()",
    " Show head of characters dataframe",
    " Check data\nprint(\"Number of characters: \", len(df_characters))\nprint(\"Number of locations: \", len(df_locations))\nprint(\"Number of episodes: \", len(df_episodes))\nprint(\"Number of script lines: \", len(df_script))",
    "Check the dataframes\ndf_script.head()",
    "Display the dataframes to inspect the first few rows of each dataframe\ndf_characters",
    " Set the max display width and max display rows for pandas dataframes\npd.set_option('display.max_colwidth', 300)\npd.set_option('display.max_rows', 300)",
    " Select only the \"The Simpons\" TV show\ndf_episodes_subset = df_episodes.query('original_air_date > \"1989-12-01\"').reset_index(inplace=False, drop=True)",
    "Let's inspect our datasets",
    "Function to clean the scripts",
    " Display all columns of the dataframe\npd.set_option('display.max_columns', None)\n# Display all rows of the dataframe\npd.set_option('display.max_rows', None)",
    "Check dataframe shapes\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    " Let's sample the characters dataset and understand its structure.",
    "Filter the locations to keep only the ones present in the script lines dataset.",
    "Setting up variables",
    "Load the spaCy English model\nnlp = spacy.load('en_core_web_sm')",
    "Merge\ndf_merge = df_script.merge(\n    df_episodes,\n    left_on='episode_id',\n    right_on='id',\n    suffixes=('_script', '_ep')\n)",
    "Let's take a look at the first 5 rows of each dataframe to understand their structure.",
    " Display basic information about the datasets",
    "Quick look at the dataframes\ndf_characters.head(3)",
    "Exploring the dataset and quick looks at the data.",
    "Display scripts\nscript_cols = ['episode_id', 'number', 'raw_text']\ndf_script[script_cols].head()",
    "begin by displaying the first few records of each DataFrame.\ndf_characters.head()",
    " Set a seed for reproducibility",
    "Helper function to clean a line of text and process it with spaCy",
    "Merge the characters, locations, and script dataframes to create a master dataframe",
    "First, let's take a look at the contents of these datasets to understand their structure and the type of information they contain.",
    "# Checking whether the df_characters dataframe has been loaded correctly\ndf_characters.head()",
    "Create merge of episodes and script\ndf_episodes['id'] = df_episodes.id.astype(str)\ndf_script['episode_id'] = df_script.episode_id.astype(str)\ndf_mergerd = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id').drop(['id'], axis=1)",
    "check that data read correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "View Data\ndf_characters.head()",
    "Inspect one of the dataframes (e.g. characters)",
    "Create a subset of the script dataframe to contain only episodes 1 to 500",
    " Display first 5 records for characters dataset\ndf_characters.head()",
    "Let's look at the structure of each of these DataFrames.",
    "Join the data on episodes, script and characters",
    " In order to analyse the script, we will load the data into a dataframe for easier querying",
    " Remove unwanted or unnecessary characters from `raw_text` dictionary values and convert them to lowercase",
    "Now you can start with the current assignments and any analysis or code snippet you want to work on.",
    "Merge lines and episodes\ndf = pd.merge(df_script, df_episodes, on='episode_id')",
    "Load the data in memory\nimport zipfile\n\nwith zipfile.ZipFile('data/simpsons.zip', 'r') as zip_ref:\n    zip_ref.extractall('data/')",
    " Data example: Characters\ndf_characters.head()",
    " Set Seed for Reproducibility\nnp.random.seed(seed=42)",
    " Combine and sort the datasets based on the key IDs",
    "Data pre-processing",
    "# Change the input path here\ninput_path = \"data\"",
    "Sanitizing script\ndf_script.isnull().sum()",
    "Setting up spaCy\nnlp = spacy.load('en_core_web_sm')\n\n# Disabling other pipes\nother_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\nwith nlp.disable_pipes(*other_pipes):\n    doc = nlp(\"I am learning how to build chatbots\")\n    for ent in doc.ents:\n        print(ent.text, ent.start_char, ent.end_char, ent.label_)",
    " Load the spacy model for preprocessing the text.",
    "Explore the first rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Look at first characters in the datasets to decide which column to use as character in script dataframe\ndf_characters.head()",
    " Check the first few rows for each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "View the first five rows of the characters dataframe\ndf_characters.head()",
    " Convert to correct types",
    "Downloading the large English model for spaCy, please wait...",
    " Show the first 5 rows of the 'simpsons_characters' DataFrame\ndf_characters.head()",
    "Limit the amount of displayed rows for each dataframe\npd.set_option('display.max_rows', 10)",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Check the first 5 rows of the dataset\ndf_script.head()",
    "Merge datasets",
    " Setting the environments seed for reproducibility\nnp.random.seed(1)",
    "Enable the 'en' module if there's no model loaded\nif not 'nlp' in locals():\n    print(\"Loading English module...\")\n    nlp = spacy.load('en')",
    " Show the first 5 rows of each dataframe to verify that everything has been loaded properly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "# Preprocessing of the script\n\n# Remove the missing values\ndf_script = df_script.loc[~df_script['raw_text'].isna()]\n\n# Create a dictionary having as key the raw character text and as value the characters' unique identifier\ncharacters_dict = {name:(uid,lines) for uid,name,lines in zip(df_characters['character_id'],df_characters['raw_character_text'], df_characters['spoken_words'])}",
    "Display settings\npd.set_option('display.max_columns', None)",
    "Create a connection to the PostgreSQL database",
    " Explore scripts dataset\n\ndf_script.head()",
    "Inspect first 5 rows of the characters dataframe\ndf_characters.head()",
    " For the purposes of this analysis, the following columns are extracted:\n\nExtracting only necessary columns from the `script_lines` dataset:\n\n- `episode_id`\n- `number`\n- `raw_text`\n- `timestamp_in_ms`\n- `speaking_line`\n- `character_id`\n\nExtracting only necessary columns from the `characters` dataset:\n\n- `name`\n- `id`\n\nExtracting only necessary columns from the `locations` dataset:\n\n- `name`\n- `id`",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Display the dimensions of each table in the dataset\nprint(\"Dimensions of characters table: \", df_characters.shape)\nprint(\"Dimensions of locations table: \", df_locations.shape)\nprint(\"Dimensions of script table: \", df_script.shape)\nprint(\"Dimensions of episodes table: \", df_episodes.shape)",
    "Simple example functions to test the interaction of the extension with the specific environment.",
    "Check the first rows of each DataFrame to understand what I'm dealing with",
    "Check the head of the dataset\ndf_script.head()",
    " View the first 10 rows of the characters dataframe\ndf_characters.head(10)",
    "# Merge datasets based on common keys\ndf_merged = df_script.merge(df_characters, on='character_id', how='left')",
    "Inspect the first few rows of each DataFrame to understand the structure and data types.",
    "Create a full script from the line's dataframe and join by episode id\ndf_episode_scripts = df_script.groupby('episode_id').apply(lambda x: ' '.join(x.speaking_line)).reset_index(name='full_script')",
    "Let's start by taking a look at the first few rows of each dataframe to understand their structure and contents.",
    "Inspect the character dataframe\ndf_characters.head()",
    "Display configurations\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    "Extract all the character names\ncharacters = df_characters.character_name.unique()",
    "Merge the script lines with character names and episode titles\ndf = df_script.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id').rename(columns={'name': 'character_name'})\ndf = df.merge(df_episodes[['id', 'title']], left_on='episode_id', right_on='id').rename(columns={'title': 'episode_title'})",
    "Add timestamp to the script dataframe",
    "Show the first three lines of the characters dataframe\ndf_characters.head(3)",
    "Convert raw_text to string\ndf_script['raw_text'] = df_script['raw_text'].astype(str)",
    "View the characters dataframe\ndf_characters.head()",
    "Data cleaning",
    " Add an additional column to the script dataframe which holds the character name.",
    "Inspect the head of each dataframe to understand the data",
    "Data frame sample\ndf_script.head()",
    "Look at the first 5 rows of each dataframe.",
    " Filtered season scripts\ndf_script_filtered = df_script[df_script['episode_id'] <= df_script[df_script['season']==15]['episode_id'].max()]",
    "Show the first few rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Check the number of entries in each dataset\nprint(f'Number of script lines: {len(df_script)}')\nprint(f'Number of characters: {len(df_characters)}')\nprint(f'Number of locations: {len(df_locations)}')\nprint(f'Number of episodes: {len(df_episodes)}')",
    "Check for missing data\ndf_characters.info()",
    "Check the data\ndf_characters.head()",
    "Display the first few rows of the characters DataFrame\ndf_characters.head()",
    "# Set random seed for reproducibility\nnp.random.seed(0)",
    " Set seeds\nnp.random.seed(0)",
    "Merge the characters, locations, episodes and scripts dataframes",
    " Remove unwanted columns\ndf_script.drop(columns=['id', 'episode_id', 'number'], inplace=True)",
    "View the first few rows of the script dataframe\ndf_script.head()",
    "Select only the lines with a speaking character and a proper location\ndf_script = df_script[(~df_script.raw_location_text.isna()) & (~df_script.character_id.isna())]",
    "Merge df_script with df_episodes to get more details in the same df",
    "Show the first 5 rows of the characters dataframe\ndf_characters.head()",
    " Merge script with characters, locations and episodes names",
    "Wordcloud on all the characters lines",
    "Extract main columns\ndf_episodes = df_episodes[['id', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season', 'number_in_series', 'us_viewers_in_millions', 'views', 'imdb_rating','imdb_votes']]\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms']]\ndf_characters = df_characters[['id', 'first_name', 'last_name']]\ndf_locations = df_locations[['id', 'name']]",
    "Checking the data and its shape\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
    "Inspect the structure of the dataframes",
    "Visualizing data, to understand it better!",
    "Show the first couple of rows of each dataframe\ndf_episodes.head(), df_script.head(), df_characters.head(), df_locations.head()",
    "View some basic data about the characters dataframe\ndf_characters.head()",
    " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Display all the columns in the dataframes\npd.options.display.max_columns = None",
    " Validate the import of the dataframes\ndisplay(df_characters.head(2))\ndisplay(df_locations.head(2))\ndisplay(df_script.head(2))\ndisplay(df_episodes.head(2))",
    "Drop unwanted columns from the dataframes",
    "See the first entries of the characters dataset\nprint(df_characters.head())",
    "Visualise 5 random rows of script dataset\ndf_script.sample(5)",
    "display(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    " Merge episodes with scripts\ndf_episodes['id'] = df_episodes.id.astype(float)\ndf_script['episode_id'] = df_script.episode_id.astype(float)\n\ndf_merged = pd.merge(df_script,\n                     df_episodes,\n                     how='left',\n                     left_on='episode_id',\n                     right_on='id')",
    "Combine the text from all the script lines into a single string for wordcloud generation\nscript_text = \" \".join(df_script['normalized_text'].fillna(''))",
    "Visualize the number of lines per character\ndf_characters['line_count'] = df_script['character_id'].value_counts()\ndf_characters_merged = df_characters.merge(df_locations, left_on='location_id', right_on='id', how='left')\ndf_characters_merged['line_count'] = df_characters_merged['line_count'].fillna(0)",
    "Check for missing script lines and drop them\nmissing = df_script.isnull().sum()\nprint(missing[missing > 0])",
    "Change the format of the air_date column to datetime\ndf_episodes['air_date'] = pd.to_datetime(df_episodes['air_date'])",
    "Set seed for reproducibility\nnp.random.seed(0)",
    "View the first few rows of the characters dataframe\ndf_characters.head()",
    "Check the content of the episodes dataset\ndf_episodes.head()",
    "The Simpsons dataset files have been read into pandas DataFrames.",
    "Set 'raw_text' to script's rightmost side\ndf_script = df_script[['episode_id', 'raw_text']]",
    "Root path\nROOT = os.getcwd()",
    "Let's take a quick look at what our datasets contain.",
    "View the first few rows of the characters dataframe\ndf_characters.head()",
    "\"\"\"Data statistics\"\"\"",
    "Display settings for the pandas dataframes\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
    "Create a copy of the dataframe with the script lines\ndf_script_filtered = df_script.copy()",
    "Display general information of the datasets\nprint('Characters dataset')\nprint(df_characters.info())\nprint(df_characters.head())\nprint('\\nLocations dataset')\nprint(df_locations.info())\nprint(df_locations.head())",
    "Inspect dataframes first 5 rows",
    "Preview dataframe\ndf_script.head()",
    "Inspect the first few rows of each dataframe to understand its structure and the information it contains.",
    "Removing lines corresponding to non-dialogue actions from the script dataframe",
    " Print data examples",
    " Display all columns\npd.set_option('display.max_columns', None)",
    "Merge the tables to have all relevant information in one data frame",
    "Exploring the structure of the data",
    " Visualize the number of lines per character\ncharacter_name = 'homer simpson'\ncharacter_lines = df_script[df_script['character_id'] == character_name]['raw_character_text']\n\n# Generate the word cloud\nwordcloud = WordCloud(width = 1000, height = 500).generate(' '.join(character_lines))\n\n# Plot the word cloud\nplt.figure(figsize=(15, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")",
    " Display the first 5 rows of each DataFrame.\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Clean text data",
    "Check data sample\nprint(df_characters.head())",
    "Checking head of each dataframe to understand the data",
    "Checking for any null values\nprint(df_characters.isnull().sum())\nprint(df_locations.isnull().sum())\nprint(df_script.isnull().sum())\nprint(df_episodes.isnull().sum())",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Place code to further analyze the Simpsons dataset here.",
    "Check the contents of the first few rows of the dataframe\nprint(df_script.head())\n\n# Check the number of rows and columns in the dataframe\nprint(df_script.shape)",
    "Limit number of rows to display to make the data more manageable\npd.options.display.max_rows = 10",
    " Create directory for saving generated visualisations\nif not os.path.exists('visualizations'):\n    os.makedirs('visualizations')",
    "Load spacy model.",
    "Check the datasets\nprint(\"Characters:\")\ndisplay(df_characters.head())\n\nprint(\"Locations:\")\ndisplay(df_locations.head())\n\nprint(\"Script:\")\ndisplay(df_script.head())\n\nprint(\"Episodes:\")\ndisplay(df_episodes.head())",
    "get request parameters\nrequest_args = request.args",
    "Setup data for spacy processing",
    "Lets print the first 5 rows of the dataset and analyze the data",
    "Declare variable with all seasons",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Build a dataframe with episodes and their scripted lines\nlines = []\nfor _, episode in df_episodes.iterrows():\n    episode_id = episode['id']\n    episode_lines = df_script[df_script['episode_id'] == episode_id]\n    lines.append({\n        \"id\": episode_id,\n        \"title\": episode['title'],\n        \"original_air_date\": episode['original_air_date'],\n        \"number_in_series\": episode['number_in_series'],\n        \"number_in_season\": episode['number_in_season'],\n        \"season\": episode['season'],\n        \"lines\": episode_lines\n    })\n\ndf_episodes_lines = pd.DataFrame(lines)",
    "Let's peek into each of the DataFrames",
    "\ndf_characters.head()",
    "# Show head of episodes\ndf_episodes.head()",
    "VIEW ALL AVAILABLE DATA\ndf_script",
    "Merge the dataframes together\ndf_merged = df_script.merge(df_characters, on='character_id')\ndf_merged = df_merged.merge(df_locations, on='location_id')\ndf_merged = df_merged.merge(df_episodes, on='episode_id')",
    " Join the df_episodes and df_script DataFrame on the 'episode_id' column\ndf = df_script.merge(df_episodes, on='episode_id')",
    "Show missing values again\ndf_script.isnull().sum()",
    " Display setup\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', 60)",
    "Show the head of the script dataframe\ndf_script.head()",
    "Extract character lines from the script dataframe and join the location and episode names",
    " Drop dialogues in scenes as the same scene can be in multiple episodes",
    "Checking the first 5 rows of each dataframe",
    "Data cleaning since Dan's data set still has mentioned speaker but no spoken words, and no ids line by line",
    "Let's first take a look at the data.",
    "Check the first few entries of the characters dataframe\ndf_characters.head()",
    "limits the number of different items in a list",
    " Making it easier to recognize the characters used in the dataset.",
    "Set maximum display columns for easier visualization\npd.set_option('display.max_columns', 500)",
    "Filtering out \"bad\" records on on df_script",
    "Visualisation of the Simpsons dataset",
    "Select only the columns that we're interested in:\n- character_id\n- raw_character_text\n- raw_location_text",
    "Check if the dataset has been loaded correctly",
    "# Function to load data from CSV files\ndef load_data(file_name):\n    return pd.read_csv(file_name).reset_index(inplace=False, drop=True)",
    "Checking number of null values in each dataframe",
    "Remove rows where the `spoken_words` column contains bad data\ndf_script = df_script[df_script['spoken_words'].apply(lambda x: isinstance(x, str))]",
    "Explore the data\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    " Some initial cleanup",
    "Run some code to verify everything is loaded as expected",
    "Display the word cloud for the top 25 characters.",
    "Set the seed for reproducibility\nnp.random.seed(0)",
    "Inspect the tables' heads",
    "Print the number of lines with missing character, location or raw_text, if any.",
    " Display the first few rows of the dataframe\ndf_script.head()",
    "(.....continues on)",
    "\ndf_characters",
    "Inspect dataset for missing values\ndf_script.isna().sum()",
    "Look at the first few rows of the script dataframe\ndf_script.head()",
    "Inspect the dataframes to get a better sense of the data.",
    "Merge episodes\ndf_episodes_script = df_episodes.merge(df_script, on='episode_id')",
    " Remove the index from csv load",
    "Display resulting dataframe head\ndf_script.head()",
    "Data transformation\n# Select important columns from the df_script dataframe\ndf_script = df_script[['episode_id', 'number', 'timestamp_in_ms', 'character_id', 'location_id', 'raw_text']]\n\n# Merge the df_script dataframe with the df_episodes dataframe\ndf_episodes['episode_id'] = df_episodes.index + 1  # The episode_id starts at 1 instead of 0\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')\n\n# Merge the df_script dataframe with the df_characters dataframe\ndf_script = pd.merge(df_script, df_characters, left_on='character_id', right_on='id', suffixes=('', '_character'))\n\n# Merge the df_script dataframe with the df_locations dataframe\ndf_script = pd.merge(df_script, df_locations, left_on='location_id', right_on='id', suffixes=('', '_location'))",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Merge dataframes\ndf_script = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('', '_ep')).drop(columns=['id', 'id_ep'])",
    "tokenization by nltk and punctuation removal\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nnltk.download('stopwords')\nnltk.download('punkt')\nstop_words = set(stopwords.words('english'))",
    "# Set data folder\ndata_folder = 'data/'",
    " Display the first few rows of each dataframe to understand their structure and contents.",
    "Check for null values in each dataframe\ndf_characters.isnull().sum()",
    " Select columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]",
    "Set some plot configs for visual consistency",
    "Inspect the first 3 records of the characters dataframe",
    "Print quick statistics about our datasets",
    " Check three first characters dataframe\ndf_characters.head(3)",
    "Inspect the structure and contents of the dataframes\nprint('Characters:')\ndisplay(df_characters.head())\n\nprint('Locations:')\ndisplay(df_locations.head())\n\nprint('Script:')\ndisplay(df_script.head())\n\nprint('Episodes:')\ndisplay(df_episodes.head())",
    "\nscripts = df_script[['normalized_text']].copy()",
    "Setting up matplotlib style\nplt.style.use('ggplot')",
    "Set the font family and size for matplotlib plots\nplt.rcParams['font.family'] = 'Arial'\nplt.rcParams['font.size'] = 12",
    "Simple view of the datasets",
    "Checking the first few rows of each dataset to get an idea of the information available.",
    "List of unique characters\nprint(\"Number of characters: {}\".format(len(df_characters.character_id.unique())))\ndf_characters.head()",
    "Select few random rows for a visual inspection\ndf_script.sample(10)",
    "# Merge scripts and episodes tables\ndf_episodes.rename(columns={'id': 'episode_id'}, inplace=True)\ndf_joined = df_script.merge(df_episodes, on='episode_id', how='left')",
    "Load the spacy language model\nnlp = spacy.load('en_core_web_sm')",
    "Visualize the script lines DataFrame head\ndf_script.head()",
    "Load the pre-trained spaCy model for English language\nnlp = spacy.load(\"en_core_web_sm\")",
    " Calculate the number of unique locations and characters in the dataset\nnum_unique_locations = df_locations['name'].nunique()\nnum_unique_characters = df_characters['name'].nunique()\n\nprint(f'There are {num_unique_locations} unique locations in the dataset')\nprint(f'There are {num_unique_characters} unique characters in the dataset')",
    "Remove non-UTF-8 characters from the \"raw_character_text\" and \"spoken_words\" columns\ndf_script['raw_character_text'] = df_script['raw_character_text'].apply(lambda x: x.encode('utf-8', 'ignore').decode('utf-8'))\ndf_script['spoken_words'] = df_script['spoken_words'].apply(lambda x: x.encode('utf-8', 'ignore').decode('utf-8'))",
    "Check the head of the characters dataframe",
    "Inspect the table schemas and dtypes to determine how to perform joins between tables.",
    " Merge dataframes to get all the information in one place\n# Let's analyze the line by line script data\ndf_script.head()",
    " Set the seed for numpy random number generator for reproducibility\nnp.random.seed(5)",
    "View first 5 rows of the characters dataframe\ndf_characters.head()",
    "Merge scripts with locations\ndf_merged = pd.merge(df_script, df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_location'))\n\n# See the data\ndf_merged.head()",
    "Check the \"?\" column in the table.",
    "Remove 'blacklisted' or special characters from the script lines",
    " Find seasons in the data\ndf_episodes['season'].unique()",
    "Set plot style\nplt.style.use('fivethirtyeight')",
    " Merge the characters, locations, episodes and script dataframes.",
    "Check some content from the characters DataFrame\ndf_characters.head()",
    "Let's see what these datasets actually contain.",
    "Set seed for reproducibility\nnp.random.seed(42)",
    "# Create \"simpsons\" folder\nif not os.path.exists('simpsons'):\n    os.mkdir('simpsons')",
    "# Create a new temporary dataframe with the necessary data and set correct data types\ndf_script_temp = df_script[['episode_id', 'number', 'raw_text', 'character_id']].copy()\ndf_script_temp['episode_id'] = df_script_temp['episode_id'].astype(int)\ndf_script_temp['character_id'] = df_script_temp['character_id'].astype(float)",
    "Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
    "Set the precision for Pandas\npd.set_option('precision', 2)",
    "Setting seed for reproducibility\nnp.random.seed(0)",
    "\npd.set_option('display.max_columns', None)",
    " Let's take a look at first few lines of each of these DataFrame using the head() method.",
    "Return the first few rows of each dataframe to inspect the data.",
    " Initialize models\nnlp = spacy.load('en_core_web_sm')",
    " Display the size of the DataFrames to have an overview of the data available",
    "Merge script with episodes\ndf_episodes['id'] = df_episodes['id'].astype(int)\ndf_script = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=('_script', '_episode'))",
    "Check out the contents of these DataFrames\nprint('Characters:')\ndisplay(df_characters.head())\nprint('Locations:')\ndisplay(df_locations.head())\nprint('Script:')\ndisplay(df_script.head())\nprint('Episodes:')\ndisplay(df_episodes.head())",
    " Viewing content first rows\ndf_characters.head()",
    "\n# Small prepossessing of the csv files\ndf_script = df_script.dropna(subset=['normalized_text'])\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)",
    "Github link: https://github.com/alexkenan/simpsons_scripts_analysis\n# Quick dataframe shaping\nprint('Shape:')\nprint(f'Characters: {df_characters.shape}')\nprint(f'Locations: {df_locations.shape}')\nprint(f'Script: {df_script.shape}')\nprint(f'Episodes: {df_episodes.shape}')\n\n# Display insteresting attributes about the data\nprint(f'Sample characters:')\nprint(df_characters.sample(5))\nprint(f'Sample locations:')\nprint(df_locations.sample(5))\nprint(f'Sample episodes:')\nprint(df_episodes.sample(5))",
    "Check the first few rows of the characters dataset\ndf_characters.head()",
    " Explore the content of the dataframes.",
    "Print the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Display the data frames\ndf_characters, df_locations, df_script, df_episodes",
    "# Let's start by cleaning the script dataframe\ndf_script.info()",
    "Display the first 5 script lines.",
    "Let's take a first look at each of these datasets.",
    "Set the font for saving as pdf. Set properties for rendering of fonts\n\nmatplotlib.rcParams['pdf.fonttype'] = 42  # Embedded subset (only the used characters)",
    "Load the scripts and select season 1\ndf_script_s1 = df_script.loc[df_script['episode_id'] <= 13].copy()",
    "unique writers\ndf_script.writer_id.unique()",
    "Let's first take a look at how the data looks like.",
    "Display first few rows of the characters dataframe\ndf_characters.head()",
    "Show the first 10 row of the dataframe 'df_characters'\ndf_characters.head(10)",
    "Merge data frames",
    "Determine the number of records in each of the dataframes.",
    "Inspect the dataframes",
    " Set the maximum number of rows and columns displayed when printing DataFrames\npd.set_option('display.max_rows', 500)",
    "Clean up dataframe columns\ndf_characters.columns = df_characters.columns.str.lower().str.replace(' ', '_')\ndf_characters = df_characters.set_index('id')\n",
    "Visualise lines and word count\nline_lengths = df_script['raw_text'].str.len()\nword_lengths = df_script['raw_text'].str.split().apply(lambda x : len(x) if x != [''] else 0)\n\nplt.figure(figsize=(20, 5))\n\nplt.subplot(1, 2, 1)\nline_lengths.plot(kind='hist', bins=100, ax=plt.gca())\nplt.title('Line lengths')\n\nplt.subplot(1, 2, 2)\nword_lengths.plot(kind='hist', bins=100, ax=plt.gca())\nplt.title('Word lengths')\n\nplt.show()",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Inspect a sample of the characters dataframe\ndf_characters.head()",
    "Check what kind of data we have for characters, locations, scripts, and episodes\nprint('Characters')\nprint(df_characters.head(), end='\\n\\n')\n\nprint('Locations')\nprint(df_locations.head(), end='\\n\\n')\n\nprint('Script')\nprint(df_script.head(), end='\\n\\n')\n\nprint('Episodes')\nprint(df_episodes.head(), end='\\n\\n')",
    "Check if the data loaded correctly\nprint(\"Characters\")\ndisplay(df_characters.head(2))\nprint(\"Locations\")\ndisplay(df_locations.head(2))\nprint(\"Script\")\ndisplay(df_script.head(2))\nprint(\"Episodes\")\ndisplay(df_episodes.head(2))",
    "Keep a copy of the original dataset just in case\ndf_characters_orig = df_characters.copy()\ndf_locations_orig = df_locations.copy()\ndf_script_orig = df_script.copy()\ndf_episodes_orig = df_episodes.copy()",
    "Remove corrupt data\ndf_script = df_script[df_script['character_id'].isin(df_characters['id'])]\ndf_script = df_script[df_script['location_id'].isin(df_locations['id'])]",
    "Separate the columns containing the text data that we care about:\ntext_columns = ['raw_character_text', 'spoken_words', 'raw_location_text', 'normalized_text']",
    "View the content of each file",
    " Merge scripts with characters and cleaning\ndf_script = df_script.merge(df_characters[['id', 'name']], 'left', left_on='character_id', right_on='id')",
    "Check data\ndf_script.head()",
    " Display first rows of the characters data\ndf_characters.head()",
    "# Display maximum columns and rows when displaying dataframes\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    "Merge lines with episodes and characters\ndf_merged = df_script.merge(df_episodes, how='left', on='episode_id')\ndf_merged = df_merged.merge(df_characters, how='left', left_on='character_id', right_on='index')\n\n# Add locations\ndf_merged = df_merged.merge(df_locations, how='left', left_on='location_id', right_on='index')",
    " Step 1: get rid of row copies and script lines with no speaker\ndf_script_cleaned = df_script.drop_duplicates('id').dropna(subset=['raw_character_text']).copy()",
    "Checking the first few rows of the characters dataframe",
    "Show the first lines of all the DataFrames\nprint(\"Characters DataFrame - shape\", df_characters.shape)\nprint(df_characters.head())\nprint(\"\\nLocations DataFrame - shape\", df_locations.shape)\nprint(df_locations.head())\nprint(\"\\nScript DataFrame - shape\", df_script.shape)\nprint(df_script.head())\nprint(\"\\nEpisodes DataFrame - shape\", df_episodes.shape)\nprint(df_episodes.head())",
    "Create a copy to avoid loading the data again and again\ndf = df_script.copy()",
    "Merge the script and character dataframe\ndf_script = df_script.merge(df_characters.add_prefix('character_'), left_on='character_id', right_on='character_id', how='left')",
    "Set the style of matplotlib plots",
    " Viewing the first few rows of the characters dataframe\ndf_characters.head()",
    "Let's take a peek at the first few entries in each dataframe.",
    "Data exploration and analysis",
    "Check the head of the script dataframe to understand its structure\ndf_script.head()",
    "Print the first few rows of the characters dataframe\ndf_characters.head()",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Remove unnecessary columns from dfs\ndf_characters = df_characters.drop(columns=['id'])\ndf_locations = df_locations.drop(columns=['id'])\ndf_script = df_script.drop(columns=['id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'production_code', 'original_air_date'])\ndf_episodes = df_episodes.drop(columns=['id', 'image_url', 'video_url'])",
    "Inspect the first few entries of each dataframe to understand the data",
    "Inspect dataframes' first few rows",
    "We should change NaNs for empty strings\ndf_script = df_script.fillna('')",
    "Clean dataframe so that only lines of dialogue are kept\ndf_script = df_script[df_script['speaking_line'] == True]\n\n# Merge dataframes\ndf_merged = df_script.merge(df_episodes, on='episode_id', how='left')\n\n# Remove unnecessary columns\ndf_merged.drop(['imdb_rating', 'imdb_votes', 'video_url', 'image_url', 'production_code'], axis=1, inplace=True)\n\n# Drop rows with NaN values in 'normalized_text' column\ndf_merged.dropna(subset=['normalized_text'], inplace=True)\n\n# Display first few rows of dataframe\ndf_merged.head()",
    "Checking the first 5 rows of 'df_characters' dataframe\ndf_characters.head()",
    "Check the number of characters, locations and episodes",
    "Limit rows to 50000 to avoid memory errors and makes things faster\ndf_script = df_script[:50000]",
    "Create a pandas series with the base names, surnames and full names of the characters.",
    "Set a custom color palette for Seaborn and matplotlib\nplt.rcParams['axes.prop_cycle'] = plt.cycler(color=plt.cm.tab10.colors)",
    " Display top 10 rows of each dataframe\nprint('Characters\\n')\nprint(df_characters.head(), '\\n\\n')\n\nprint('Locations\\n')\nprint(df_locations.head(), '\\n\\n')\n\nprint('Script\\n')\nprint(df_script.head(), '\\n\\n')\n\nprint('Episodes\\n')\nprint(df_episodes.head())",
    "Data loading",
    "Merge all dataframes into one, creating a unified dataframe with all information",
    "Merge all data into one dataframe",
    "Now we have the datasets loaded into DataFrames, let's take a look at each one of them.",
    " let's take a look at individual dataframes to understand their structure and contents\ndf_characters.head()",
    "Display the first few lines of the episodes dataframe\ndf_episodes.head()",
    "Merge the scripts with their respective episodes, characters, and locations.",
    "Remove the rows having NaN values in certain columns from the dataframe df_script",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Quick look at the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Get the main characters from the script\nmain_characters = df_characters[df_characters['is_main_character'] == True]\nmain_characters_names = list(main_characters['name'].values)",
    "\nimport warnings\nwarnings.filterwarnings('ignore')",
    " For spaCy\nnlp = spacy.load('en_core_web_sm')",
    "Lowercase the name fields for better linking",
    "Print the first few lines of each dataframe\nprint('Characters')\nprint(df_characters.head())\nprint('\\nLocations')\nprint(df_locations.head())\nprint('\\nScript')\nprint(df_script.head())\nprint('\\nEpisodes')\nprint(df_episodes.head())",
    "import sqlite3",
    "Creating a virtual environment",
    "Convert stringified list to list",
    "check if all finishes properly\n[df_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape]",
    "Let's take a look at the first few rows of our datasets to understand their structure.",
    "Inspect the first 5 records of the characters dataframe\ndf_characters.head()",
    " Let's take a look at the first few rows of each DataFrame to understand the structure of the data.",
    "heck all tables\nprint(df_characters.head())\n\nprint(df_locations.head())\n\nprint(df_script.head())\n\nprint(df_episodes.head())",
    "Show summary\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
    "Join episodes with script\ndf_episodes_script = df_episodes.merge(\n    df_script, \n    how='inner', \n    left_on='id',\n    right_on='episode_id'\n).reset_index(inplace=False, drop=True)",
    "The first thing to do is to remove NaN values.",
    "Filtering the script dataframe to only include spoken lines (i.e., not stage directions or observations)",
    "Filter out stories that are too short.",
    "Preview the data to understand its structure and contents\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "View the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Display the first 5 lines of the dataframe for inspection\ndf_script.head()",
    "Inspect the first few rows of each dataframe to understand its structure and contents.",
    "Let's start by taking a quick look at some of the data to understand its structure.",
    "Creating the wordclouds requires some data-wrangling, so I'm going to start by providing me  the functions for pre-processing the data.",
    " Show head of the characters dataframe\ndf_characters.head()",
    "Check the character dataset",
    "Add GDP data to the dataframe\ngdp_per_capita_data = pd.read_csv('data/gdp_per_capita.csv')\n\n# Set the ISO 3166-2 codes as the index to facilitate combining the datasets\ngdp_per_capita_data.set_index('Country Code', inplace=True)\n\n# Convert any special or missing values (e.g. '..') to NaN\ngdp_per_capita_data.replace('..', np.NaN, inplace=True)\n\n# Save the converted data\ngdp_per_capita_data.to_csv('data/gdp_per_capita_cleaned.csv')",
    "EDA",
    "Inspect head of characters dataframe",
    "Dictionary that maps episode ids to episode codes\nepid_to_code = dict(zip(df_episodes.id, df_episodes.production_code))",
    "Load the custom Spacy pipeline if available, if not initialize and save it for later.",
    "Merge datasets to have a comprehensive view of the data\ndf_merged = df_script.join(df_episodes, on='episode_id', rsuffix='_episode')",
    "NLP Library\nnlp = spacy.load('en_core_web_sm')",
    "Check that all imports have been successful\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Data pertaining to the lines spoken by characters and that location are contained in specific tables.",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Chaging paths in df_script table",
    "# Check the content of script lines\nprint(df_script.head())",
    "First 5 rows of df_characters\ndf_characters.head()",
    "Filtering necessaary columns for further processing and analysis",
    "Check the number of rows and columns\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "Check the shape of each dataframe to gain a first understanding of the data",
    "Show content of each dataset\nprint(\"\\n[INFO] Show content of each data set.\")\nprint(\"\\n[INFO] 1. Simpsons characters.\")\nprint(df_characters.head())\nprint(\"\\n[INFO] 2. Simpsons locations.\")\nprint(df_locations.head())\nprint(\"\\n[INFO] 3. Simpsons episodes.\")\nprint(df_episodes.head())\nprint(\"\\n[INFO] 4. Simpsons script.\")\nprint(df_script.head())",
    "Print a summary of the data in each DataFrame\nprint('Characters:')\nprint(df_characters.info())\nprint('\\nLocations:')\nprint(df_locations.info())\nprint('\\nScript:')\nprint(df_script.info())\nprint('\\nEpisodes:')\nprint(df_episodes.info())",
    "Move 'The simpsons' to the front of the list\ndf_episodes['title'] = df_episodes['title'].apply(lambda x: 'The Simpsons' if 'The Simpsons' in x else x)\ndf_episodes['title'] = df_episodes['title'].apply(lambda x: 'The Simpsons' if x == 'Duh, The Simpsons' else x)",
    "Show some lines to get a feeling of how the data looks like\ndf_script.head(2)",
    " Check first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect \"df_characters\" DataFrame",
    "Inspect the script dataframe to understand its structure and the kind of information it contains.",
    "What is the most relevant information in the datasets?",
    "pd.set_option('display.max_columns', None)",
    "Preview the data\ndf_characters.head()",
    "Let's first start by exploring the dataset and understanding its structure.",
    "Display first few rows of the characters dataframe\ndf_characters.head()",
    "Look for file\nos.listdir('data')",
    "We will first review the data to understand its structure and content.",
    "df_script.head()",
    "Display the first few rows of each dataframe to understand its structure.",
    "Display settings for the pandas dataframe viewer in Jupyter notebooks\npd.options.display.max_columns = None\npd.options.display.max_rows = None",
    "Let's take a look at the different datasets and see how they are structured.",
    " Show the first 5 rows of the characters dataframe",
    " Let's take a look at the structure of each dataframe.",
    "# We will provide examples based on quotes involving 'Homer Simpson'.\nhomer_id = df_characters.loc[df_characters['character_name'].str.contains('Homer Simpson')].index[0]\nhomer_quotes = df_script.loc[df_script['character_id'] == homer_id]\nhomer_quotes.head()",
    "Display dataframe\ndf_script.head()",
    " One-hot encode the year and season\ndf_episodes = df_episodes.join(pd.get_dummies(df_episodes.season, prefix='season'))\ndf_episodes = df_episodes.join(pd.get_dummies(df_episodes.air_date.dt.year, prefix='year'))",
    "Merge `df_script` with `df_characters` on `character_id`\ndf_script_char = df_script.merge(df_characters, on='character_id', how='left')\n# Merge `df_script` with `df_locations` on `location_id`\ndf_script_char_loc = df_script_char.merge(df_locations, on='location_id', how='left')\n# Merge `df_script` with `df_episodes` on `episode_id`\ndf = df_script_char_loc.merge(df_episodes, on='episode_id', how='left')",
    "Let's take a look at the dimensions of the datasets.",
    "Create a new column `text_len` that contains the length of `spoken_words` if not `NaN`, and 0 if `NaN`",
    "Print first few lines of each dataframe\nprint('Characters:')\nprint(df_characters.head())\nprint('\\n\\nLocations:')\nprint(df_locations.head())\nprint('\\n\\nScript:')\nprint(df_script.head())\nprint('\\n\\nEpisodes:')\nprint(df_episodes.head())",
    "We are importing data from CSV files and loading them into pandas dataframes for further analysis.",
    " Let's start by taking a look at the structure of these files.",
    "Adjust size of plots in the notebook\nplt.rcParams['figure.figsize'] = [15, 8]",
    "Extract all sentences said by a certain character in a specific episode.",
    "Visualise the data in the table",
    "inspect the first few lines of each dataframe\ndf_script.head(), df_characters.head(), df_locations.head(), df_episodes.head()",
    "Display first few lines of the dataframe df_script\ndf_script.head()",
    "Let's take a look at the first few lines of each dataframe.",
    "Setting the default style\nmatplotlib.style.use('ggplot')",
    " Filter out the script lines that are between the major characters, and keep only the ones that are in between locations.",
    "Information about the transcript dataset\nprint(\"Number of transcript lines:\", len(df_script))\ndf_script.head()",
    "Convert timestamps to datetime\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], errors='coerce').fillna(0).astype(np.int64)\ndf_script['timestamp'] = pd.to_datetime(df_script['timestamp_in_ms'], unit='ms')\n\n# Convert timestamps to datetime\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], errors='coerce')",
    "Creatign a path for the assets folder",
    "Remove duplicate rows\ndf_script.drop_duplicates(subset=['character_id', 'episode_id', 'raw_text'], inplace=True)",
    "Load the dataset into pandas dataframes",
    "Set some pandas options for printing and set the random seed for reproducibility.",
    "Set up variables for each field type to make the code more readable.",
    "Inspect the data\ndf_script.head()",
    "Let's preview the datasets and look at some basic statistics.",
    "View the first few rows of the characters DataFrame\ndf_characters.head()",
    "Let's explore the data to understand its structure and content.",
    "The data came from Kaggle and is, to the best of my knowledge, a cleaned version of the original one.",
    "Removing data that doesn't fit our use case from the dataframe",
    "Load Spacy model\nnlp = spacy.load('en_core_web_sm')",
    "Check data\ndf_characters.head()",
    "\n# Drop incomplete data\ndf_script = df_script.dropna(subset=['normalized_text'])\n\n# Perform a left join to add the character names to the script data\n# Drop the character_id column\n# Fill NaN values from the speaking_line column with False\ndf_joined = df_script.merge(df_characters, on='id', how='left').drop(columns=['character_id']).fillna(value={'speaking_line': False})\n\n# Remove non-speaking script lines\ndf_speaking = df_joined[df_joined['speaking_line']].copy()",
    "Inspect the table of characters.",
    "Merge scripts with episodes\ndf_scripts_episodes = df_script.merge(df_episodes, on='episode_id', how='outer')",
    "Replace NaN values with empty strings\ndf_script = df_script.fillna('')",
    "Merge data in meaningful way.",
    "Display first few rows of the characters dataframe\ndf_characters.head()",
    "check the shape of all the datasets\nprint('The shape of the character dataset is: {}'.format(df_characters.shape))\nprint('The shape of the location dataset is: {}'.format(df_locations.shape))\nprint('The shape of the script dataset is: {}'.format(df_script.shape))\nprint('The shape of the episodes dataset is: {}'.format(df_episodes.shape))",
    "Notification that the dataframes have been loaded",
    " We'll start with loading the datasets and understanding their structure, before moving on to the NLP analysis.",
    "We'll use a pre-trained NER model from spaCy to assign named entities to the text.",
    "Extract characters' genders and ages\ngenders = {}\nages = {}\n\nfor index, row in df_characters.iterrows():\n    genders[row['id']] = row['gender']\n    ages[row['id']] = row['age']",
    "Inspect the first few rows of each dataframe to understand its structure and contents.",
    "Create a lower case version\ndf_script['normalized_text'] = df_script['raw_text'].str.lower()",
    "Display first rows of the script data\ndf_script.head()",
    "The three first DataFrame have an unwanted column\ndel df_characters['Unnamed: 0']\ndel df_locations['Unnamed: 0']\ndel df_script['Unnamed: 0']",
    "Let's see some basic information from each dataset.",
    " Limit the number of rows printed in the notebook\npd.options.display.max_rows = 5",
    "View some records\nprint(df_characters.head())",
    "The first step is to preprocess the data, starting with the script lines.",
    "Join the characters and locations to the script data\ndf_script_characters = df_script.join(df_characters.set_index('character_id'), on='character_id', rsuffix='_character')\ndf_script_locations = df_script_characters.join(df_locations.set_index('location_id'), on='location_id', rsuffix='_location')",
    "Merge the data to get a single dataframe containing all information about each line of script.",
    "Limit script to certain episode_id.\nepisode_id = 1",
    "Show the top 20 rows of the characters dataframe\ndf_characters.head(20)",
    "Show the first few rows of the characters dataframe\ndf_characters.head()",
    "Show first 5 rows of the dataframe 'df_characters'\ndf_characters.head()",
    "Filtering the columns to keep only those which would be useful for modeling and analysis",
    "# Let's check if the data has been correctly loaded\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Scripts:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "Inspecting the structure of each table",
    "Declare input parameters",
    "Check for missing values in the datasets\nprint('Missing values in the characters dataset:', df_characters.isnull().values.any())\nprint('Missing values in the locations dataset:', df_locations.isnull().values.any())\nprint('Missing values in the script dataset:', df_script.isnull().values.any())\nprint('Missing values in the episodes dataset:', df_episodes.isnull().values.any())",
    "Display the top 10 rows of each dataframe to understand their structure and data",
    "Set seed for NLP\nnp.random.seed(42)",
    " Displaying the number of unique values in each column",
    "To get a feel for the data, let's take a look at the first few rows of each dataframe.",
    "Checking the head of the dataframe",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Remove useless columns for this script\ndf_script.drop(['id', 'episode_id', 'number'], axis=1, inplace=True)",
    "Inspect the first few rows of each dataframe to understand its structure and available features.",
    "Set parameter to display all columns",
    "# Display the first few lines of the Simpsons characters dataset\ndf_characters.head()",
    "Check the content of the script dataset to see what it looks like\ndf_script.head(5)",
    "Display the first few rows of each dataframe",
    "Check dataframe shapes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    " Add a newline after the data import statements for better organization",
    "Print the first 5 rows of each dataframe to understand the data structure better",
    "Text preprocssing",
    " Take a look at the first few records of each dataset\nprint(\"Characters\")\ndisplay(df_characters.head())\n\nprint(\"Locations\")\ndisplay(df_locations.head())\n\nprint(\"Script\")\ndisplay(df_script.head())\n\nprint(\"Episodes\")\ndisplay(df_episodes.head())",
    " Set the index of the script to be the episode_id",
    "Load embeddings model\nnlp = spacy.load('en_core_web_lg')",
    " Add column of lowercase words to the dataframe",
    "As we can see, we've added multiple CSV files to Pandas DataFrames for further processing and analysis.",
    " Display summary information for the characters dataset\nprint('Characters dataset:')\nprint(f'- Number of rows: {len(df_characters)}')\nprint('- Columns:', list(df_characters.columns))",
    " Show the first rows of the characters dataset\ndf_characters.head()",
    "Filtering only the spoken lines and relevant columns\ndf_script = df_script[(df_script['speaking_line'] == True) & (df_script['raw_character_text'].notna())]\ndf_script = df_script[['raw_character_text', 'spoken_words', 'episode_id']]\n\n#Renaming columns for clarity\ndf_script.columns = ['character', 'dialogue', 'episode_id']",
    "pd.set_option('display.max_columns', None)",
    " Sample the dataset\nsample_size = 10000\n\ndf_script = df_script.sample(sample_size)",
    "Print head of each table\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Displaying the dataframe types to start understanding their structures\nprint(df_characters.dtypes)\nprint(df_locations.dtypes)\nprint(df_script.dtypes)\nprint(df_episodes.dtypes)",
    "Inspect dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "df_script.head()",
    "\n#* Here we read in the data using pandas read_csv function and reset the index on the dataframes.",
    "Check number of lines for each Character ID",
    "Check the number of rows and the column names of the episodes dataframe\ndf_episodes.shape, df_episodes.columns",
    "Inspect the first few rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Take a look at the dataframes",
    "Inspecting the first elements of the characters dataframe\ndf_characters.head()",
    "Merge lines and episodes\ndf_episodes.rename(columns={'id':'episode_id'}, inplace=True)\ndf_script_lines_episodes = df_script.merge(df_episodes, on='episode_id')",
    "Display head of scripts DataFrame\ndf_script.head()",
    "Print sample data\nprint(df_characters.head(2))\nprint(df_locations.head(2))\nprint(df_script.head(2))\nprint(df_episodes.head(2))",
    "Check the first few entries of the Simpsons script dataset to understand its structure and contents\ndf_script.head()",
    "Display the first 5 rows of df_characters\ndf_characters.head()",
    "Displaying the first 5 rows of the episodes dataframe to visualize the data",
    "return the first 5 rows in the characters DataFrame\ndf_characters.head()",
    "Split the script into individual lines, i.e. split the script into lines and append them to a list",
    "Data directory\nDATA_DIR = 'data'",
    " Set working directory\nos.chdir('..')",
    "Preview the character dataframe\ndf_characters.head()",
    "Install spacy language model for NER\n!python -m spacy download en_core_web_sm",
    "Create an instance of the spacy class\nnlp = spacy.load('en_core_web_sm')",
    "Filter non-ascii characters to avoid encoding issues\ndf_script = df_script[df_script['raw_character_text'].apply(lambda x: x.isascii())]\ndf_script = df_script[df_script['raw_location_text'].apply(lambda x: x.isascii())]",
    "pd.set_option('display.max_columns', None)",
    "Setting characters and locations to lowercase\ndf_characters['normalized_name'] = df_characters['name'].str.lower().str.strip()\ndf_characters['normalized_name'] = df_characters['normalized_name'].str.replace(\" \", \"_\")\n\ndf_locations['normalized_name'] = df_locations['name'].str.lower().str.strip()\ndf_locations['normalized_name'] = df_locations['normalized_name'].str.replace(\" \", \"_\")",
    " Display the first few rows of the script dataframe\ndf_script.head()",
    " Display first 5 rows of the dataframe\ndf_script.head()",
    "Create a subset of df_script that contains only spoken lines",
    " Display the head of the characters dataframe\ndf_characters.head()",
    "Create a column with the length of each line\ndf_script['length'] = df_script['raw_text'].apply(len)",
    "Merge the specified dataframe with the scripts dataframe",
    " Define the path to your data folder in 'simpsons_path'",
    " Limit rows for quick debugging\n# df_script = df_script[:100000]",
    "Show the head of the characters dataframe\ndf_characters.head()",
    "Show overview of the datasets\nprint(f'There are {len(df_characters)} characters, {len(df_locations)} locations, {len(df_script)} script lines and {len(df_episodes)} episodes.')",
    "In this code, we are importing the necessary libraries and reading the data using pandas from the given CSV files. We are resetting the index of the dataframes and storing them in the variables df_characters, df_locations, df_script, and df_episodes respectively.",
    "Preprocess character names to standardize them for later integration with the script data.",
    " Merge transcript with the rest\ndf_script['id'] = df_script['episode_id']\ndf = pd.merge(df_script, df_episodes, on='id')",
    " Show first few rows of characters dataframe\ndf_characters.head()",
    "Check if the data has been loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Remove the .csv from the name of the file so that now we only have the table name.",
    " Display the first few rows of each dataframe to understand what kind of data is available\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Setting limit of rows and columns to see when displaying dataframes\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)",
    " Let's take a look at the data first.",
    " Load the processed data from pickle files",
    "Check first few lines of all imported datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "from gensim.test.utils import common_texts\nfrom gensim.corpora.dictionary import Dictionary",
    " Display dimensions of datasets\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
    "Display full columns in dataframes\npd.set_option('display.max_colwidth', None)",
    "Display basic information about the dataframes\nprint('\\n---Characters---')\nprint(df_characters.info())\nprint(df_characters.head())\n\nprint('\\n---Locations---')\nprint(df_locations.info())\nprint(df_locations.head())\n\nprint('\\n---Script---')\nprint(df_script.info())\nprint(df_script.head())\n\nprint('\\n---Episodes---')\nprint(df_episodes.info())\nprint(df_episodes.head())",
    "Check if the indexes are correct in each dataframe\ndf_characters.head()",
    "Merge datasets to simplify the data analysis process and have various attributes of the script lines in the same DataFrame.",
    " Display the first 5 rows of each dataframe to get an overview of the data",
    "display available dataframes\ndir()",
    "Preview the characters dataframe\ndf_characters.head()",
    " Preview the first 5 rows of the characters dataset\ndf_characters.head()",
    "pd.set_option('display.max_columns', None)",
    " Check the shape of the datasets\nprint(\"Characters dataset shape: {}\".format(df_characters.shape))\nprint(\"Locations dataset shape: {}\".format(df_locations.shape))\nprint(\"Script dataset shape: {}\".format(df_script.shape))\nprint(\"Episodes dataset shape: {}\".format(df_episodes.shape))",
    "We will explore the dataframes first by looking at the first few rows of each dataframe.",
    " Import the spacy language model\nnlp = spacy.load('en_core_web_sm')",
    " Now, we can take a look at the content of each dataset.",
    "Set the pandas display options for broader coverage\n# Also, disable the SettingWithCopyWarning (not good, but our code uses original dataframe)\npd.set_option('display.max_rows', 300)\npd.set_option('display.max_columns', 300)\npd.set_option('display.width', 1000)\npd.set_option('mode.chained_assignment', None)",
    "Let's start by examining the data.",
    "1. Data overview and preprocessing",
    "Preview the characters dataframe\ndf_characters.head()",
    "Display the first few rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "print('df_characters shape: {}'.format(df_characters.shape))\nprint('df_locations shape: {}'.format(df_locations.shape))\nprint('df_script shape: {}'.format(df_script.shape))\nprint('df_episodes shape: {}'.format(df_episodes.shape))",
    "Merge multiple dataframes into a single one based on 'episode_id' column and create a boolean mask for a sample episode",
    "Quick look at the dataframes",
    "Show the first few rows of the characters dataframe\ndf_characters.head()",
    "View the script dataframe\ndf_script.head()",
    "Inspect the structure of some of the loaded dataframes",
    " Preprocess the data",
    "Print out the sizes of the datasets to quickly ensure all datasets have been loaded correctly\nprint(f\"Characters Dataset: {len(df_characters)}\")\nprint(f\"Locations Dataset: {len(df_locations)}\")\nprint(f\"Script Dataset: {len(df_script)}\")\nprint(f\"Episodes Dataset: {len(df_episodes)}\")",
    "Locally generated Imports",
    "Check fewesr phrases in a string\nfewest_phrases_count = 3",
    " Select main characters only\nmain_characters = [\n    \"marge\", \"homer\", \"bart\", \"lisa\", \"maggie\", \"skinner\", \"ned\", \"burns\",\n    \"milhouse\", \"moe\", \"krusty\", \"ralph\", \"apu\", \"barney\", \"nelson\", \"todd\",\n    \"edna\", \"bob\", \"itchy\", \"patty\", \"selma\", \"lionel\", \"patty\", \"selma\",\n    \"tilly\", \"sideshow\", \"abe\", \"krabappel\", \"carl\", \"lenny\", \"frink\"\n]\n\n# Filter main characters lines\ndf_script_main = df_script[df_script.raw_character_text.str.lower().isin(main_characters)]\n\n# Filter non trivial lines\ndf_script_main = df_script_main[df_script_main.spoken_words.str.len() > 2]",
    "Create a directory to save the plots\nos.makedirs('plots', exist_ok=True)",
    "Function to display some lines around a given line index\ndef show_context(idx, nbL=2):\n    for i in range(nbL, 0, -1):\n        print(f'{df_script.iloc[idx - i].raw_character_text} - {df_script.iloc[idx - i].spoken_words}')\n    print('## -------------------------------------------------- ##')\n    print(f'{df_script.iloc[idx].raw_character_text} - {df_script.iloc[idx].spoken_words}')\n    print('## -------------------------------------------------- ##')\n    for i in range(1, nbL+1):\n        print(f'{df_script.iloc[idx + i].raw_character_text} - {df_script.iloc[idx + i].spoken_words}')",
    "Retrieve the conversation for episodes that contain 2 or more characters.",
    " Time to redo them after reworking the the dirty data",
    "Explore characters, locations, script lines, and episodes dataframes",
    "Increase pandas display\npd.set_option('display.max_columns', None)",
    "Set up directories for output\nimgdir = os.path.normpath('visualizations/')  # directory to save images\nos.makedirs(imgdir, exist_ok=True)",
    "Let's take a look at the first few rows of each DataFrame to understand the data's structure.",
    "Replace NaN values with empty strings\ndf_script = df_script.fillna('')",
    " Let's start by taking a look at the first few rows of each dataframe.",
    "# Display the first 5 records of the characters dataframe\ndf_characters.head()",
    "View general information about our datasets\nprint('\\nInformation about the characters dataset:')\ndisplay(df_characters.info())",
    "Display the top 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "View the content of the episodes dataframe\ndf_episodes.head()",
    "View the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "Inspecting the characters dataframe",
    "Show the available dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect script line data\ndf_script.info()",
    "Check the data to take the appropriate action if needed",
    " Display the first few rows of each dataframe to understand the data",
    "Add what data are available",
    " Show info of dataset of characters.",
    "# Helper function to show lines based on a condition\ndef where(df, condition):\n    return df[condition]\n\n# Helper function to retrieve text from the script\ndef get_script_text(df, episode_number):\n    return df[df['episode_id'] == episode_number]['raw_text'].values",
    " Add a column with the appropiate characters to df_script\ndf_script = df_script.merge(\n    df_characters[['id', 'name']],\n    how='left',\n    left_on='character_id',\n    right_on='id'\n)",
    "Print some data about the characters dataframe\nprint(df_characters.head())",
    "Show the first five rows of each dataframe to understand the data",
    "Visualize the number of lines per character\ndf_script['character_id'].value_counts().hist()",
    "Preprocess the data, e.g. remove unneeded columns, merge on shared information, etc.",
    "Create a variable with the file name to easily reference and open it",
    "Collect all spoken lines of a character\nlines = []\nfor index, row in tqdm(df_characters.iterrows(), total=df_characters.shape[0]):\n    character_name = row['name']\n",
    "Check the data shape\nprint(df_characters.shape)",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Remove the invalid rows where the character data is incorrect.",
    "Filter out lines that have no character\ndf_script = df_script[df_script['character_id'] != 2]",
    "Check for missing values in each dataframe\nprint(df_characters.isnull().sum())\nprint(df_locations.isnull().sum())\nprint(df_script.isnull().sum())\nprint(df_episodes.isnull().sum())",
    "Using the index as the ID for each entity, i.e., character, location, and episode.",
    "Merge the relevant dataframes",
    "Checking the first few rows of characters dataframe\ndf_characters.head()",
    "Change types for memory optimization\ndf_script['normalized_text'] = df_script['normalized_text'].astype('str')\ndf_script['spoken_words'] = df_script['spoken_words'].astype('str')\ndf_script['raw_text'] = df_script['raw_text'].astype('str')\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].astype('float32')",
    "Merge characters, locations and script\ndf_merged = pd.merge(df_script, df_characters, left_on='character_id', right_on='id').merge(df_locations, left_on='location_id', right_on='id')",
    "Display datasets' shapes\nprint(f'characters: {df_characters.shape}, '\n      f'locations: {df_locations.shape}, '\n      f'script: {df_script.shape}, '\n      f'episodes: {df_episodes.shape}')",
    " Show first rows of df\ndf_characters.head()",
    "Remove rows with missing values from the following DataFrames:",
    "Display scripts dataframe\ndf_script.head(3)",
    "Import the required libraries and read the CSV files into pandas dataframes.",
    " We need to move string-based features to lowercase for later uses in case sensitive searches",
    " Look at the first 5 rows of the characters dataframe.",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "Merge the datasets",
    "Inspecting the dataframe for the first time",
    "Display the dataframe containing the characters/actors information",
    "Filter out characters, locations and episodes not used in the script\nall_characters_in_script = df_script['raw_character_text'].value_counts().index.tolist()\nall_locations_in_script = df_script['raw_location_text'].value_counts().index.tolist()\nall_episodes_in_script = df_script['episode_id'].value_counts().index.tolist()\n\ndf_characters = df_characters[df_characters['raw_character_text'].isin(all_characters_in_script)].reset_index(inplace=False, drop=True)\ndf_locations = df_locations[df_locations['raw_location_text'].isin(all_locations_in_script)].reset_index(inplace=False, drop=True)\ndf_episodes = df_episodes[df_episodes['id'].isin(all_episodes_in_script)].reset_index(inplace=False, drop=True)",
    "Print the header of each loaded dataset\nprint('### Characters ###')\nprint(df_characters.head(), end='\\n\\n')\nprint('### Locations ###')\nprint(df_locations.head(), end='\\n\\n')\nprint('### script lines ###')\nprint(df_script.head(), end='\\n\\n')\nprint('### Episodes ###')\nprint(df_episodes.head(), end='\\n\\n')",
    "Brief exploration and cleaning\n(df_script['timestamp_in_ms'].notna()).sum()",
    " Merge data to enrich dataset",
    " Enable the TQDM notebook extension in order to display a progress bar for data processing tasks\ntqdm.pandas()",
    "Setting index on 'id' column for easy reference",
    "Inspector\ndf_script.inspect()",
    "Printing the head of the scripts dataframe\ndf_script.head()",
    "# Select only lines spoken by Homer\nhomer_script_lines = df_script[df_script['raw_character_text'] == 'Homer Simpson']",
    "Print general info about datasets\nprint(f'Simpsons Characters: {len(df_characters)}')\nprint(f'Simpsons Locations: {len(df_locations)}')\nprint(f'Simpsons Script: {len(df_script)}')\nprint(f'Simpsons Episodes: {len(df_episodes)}')",
    "We will focus only on the \"Simpsons script lines\" file for this analysis.",
    "Iterating through the pandas dataframe\nfor index, row in df_script.iterrows():\n    if index == 5:\n        break\n    # Do something by accessing the row\n    print(row)",
    "Update index and print shapes\ndf_characters.reset_index(inplace=True, drop=True)\ndf_locations.reset_index(inplace=True, drop=True)\ndf_script.reset_index(inplace=True, drop=True)\ndf_episodes.reset_index(inplace=True, drop=True)\n\n# Print shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Merge lines with episodes\nepisode_lines=pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id').rename(columns={\"id_x\": \"line_id\"}).rename_axis('id').reset_index(drop = True)",
    "Let's start by displaying some general information about the datasets.",
    "Explore the structure of the characters DataFrame\nprint(df_characters.head())",
    "Add custom colors for the plot\ncolors = ['lightskyblue', 'lightcoral']\nmatplotlib.rcParams['axes.prop_cycle'] = matplotlib.cycler(color=colors)",
    "View a sample of the Simpsons characters dataset\ndf_characters.head()",
    "Display first few characters of the datasets\nprint(\"Characters\")\ndisplay(df_characters.head())\n\nprint(\"\\n\\nLocations\")\ndisplay(df_locations.head())\n\nprint(\"\\n\\nScript\")\ndisplay(df_script.head())\n\nprint(\"\\n\\nEpisodes\")\ndisplay(df_episodes.head())",
    "Select dialouges from episode one\nep1_id = 3\ndf_ep1 = df_script[df_script['episode_id'] == ep1_id].copy()\n\n# Display the first few rows of the dataframe\ndf_ep1.head()",
    "Create and display the dataframe with all the information from a full script.",
    "Check the first rows of the characters dataframe",
    " Display the dataset shapes\nprint(f'Shape of characters dataset: {df_characters.shape}')\nprint(f'Shape of locations dataset: {df_locations.shape}')\nprint(f'Shape of script dataset: {df_script.shape}')\nprint(f'Shape of episodes dataset: {df_episodes.shape}')",
    "Select episode of interest\nepisode_of_interest = 'Simpsoncalifragilisticexpiala(AnnoyedGrunt)cious'",
    "Set the pandas display options for the presentation of the data in the Jupyter Notebook",
    "View the first few rows of the characters DataFrame\ndf_characters.head()",
    " Set the index of the DataFrames appropriately",
    " Displaying the first few rows of each dataframe to understand the data",
    "Let's take a look at the structure of each of the DataFrames.",
    "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Load spaCy\nnlp = spacy.load(\"en_core_web_sm\")",
    "\n# Plots configuration\nplt.style.use('seaborn')",
    "Display all columns of the dataframes\npd.set_option('display.max_columns', None)",
    "Set keys for each dataframe",
    "Let's start by looking at the structure of the databases we have just loaded.",
    "Create a sample of the line dataframe that works fast\nnp.random.seed(1)\ndf_script_sample = df_script.sample(n=10000)",
    "utils and settings\ntqdm.pandas()\npd.set_option('display.max_colwidth', 150)",
    " Display information for the characters dataset\ndf_characters.info()",
    "We can start by exploring the first rows of each dataframe to understand the structure and contents of the data we are dealing with.",
    "Check all files have been loaded properly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display spacy's name entity recognizer for a given sentence on adequate log level.",
    "I will start by examining the script data.",
    "Print the first 5 rows of the characters dataframe\nprint(df_characters.head())",
    "Ensure that characters and locations have names\ndf_characters['name'] = df_characters['name'].apply(lambda x: x.lower() if isinstance(x, str) else '')\ndf_locations['name'] = df_locations['name'].apply(lambda x: x.lower() if isinstance(x, str) else '')",
    "NLP model for Named Entity Recognition (NER)\nnlp = spacy.load('en_core_web_sm')",
    "te: replace 'data/' with the correct path if the data files are not located in the 'data' subdirectory.",
    "Check data imported correctly\ndf_characters.head()",
    "Preview the dataframes",
    "Set path to Simpsons data folder\npath = 'data'",
    " Show how the DataFrame df_characters looks like\ndf_characters.head()",
    "df_script with some cleaning",
    "Sample the script dataframe",
    "Replace NaN values with '' in the script dataframe\ndf_script['normalized_text'] = df_script['normalized_text'].map(lambda x: '' if pd.isnull(x) else x)",
    "Inspect first 5 rows of character dataset\ndf_characters.head()",
    "Inspect the dataframe with the characters",
    " Let's now take a quick look at the structure and contents of these dataframes.",
    "Inspect and display the head of the characters dataframe\ndf_characters.head()",
    "Optional: A sneek peek into the data helps understanding the contents.",
    "View some of the data\ndf_characters.head()",
    "Check the head of the characters dataframe",
    "Check the data shape and format",
    " display the first few rows of the characters dataframe\ndf_characters.head()",
    "Check the first few rows of the characters dataframe\ndf_characters.head()",
    " Merge data\ndf = df_script.merge(df_episodes, on='episode_id')\ndf = df.merge(df_characters, on='character_id')\ndf = df.merge(df_locations, on='location_id')",
    " Explore the dataframes sizes and first rows\nprint(\"Characters dataframe - rows:\", df_characters.shape[0], \"columns:\", df_characters.shape[1])\nprint(\"Locations dataframe - rows:\", df_locations.shape[0], \"columns:\", df_locations.shape[1])\nprint(\"Script dataframe - rows:\", df_script.shape[0], \"columns:\", df_script.shape[1])\nprint(\"Episodes dataframe - rows:\", df_episodes.shape[0], \"columns:\", df_episodes.shape[1])\n\ndf_script.head()",
    "The top-level directory containing the CSV files is called \"data\". If you are using a different directory, please replace \"data\" with the appropriate directory name.",
    " Check dataframe shapes\nprint(\"Characters dataframe shape:\", df_characters.shape)\nprint(\"Locations dataframe shape:\", df_locations.shape)\nprint(\"Script dataframe shape:\", df_script.shape)\nprint(\"Episodes dataframe shape:\", df_episodes.shape)",
    "Replace nans in speaking line with empty string\ndf_script['normalized_text'] = df_script['normalized_text'].fillna('')",
    "Let's have a look at the dataframes and the structure of the data.",
    "Preview the data in each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Set random seed for reproduction of results\nnp.random.seed(0)",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    "\n# Load the language model\nnlp = spacy.load('en_core_web_sm')",
    "# Strip leading and trailing whitespaces from string columns\ndf_script = df_script.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)",
    "Now we have all the data loaded. Let's explore each DataFrame to understand its structure and the kind of information it provides.",
    " Extract Environment Variables",
    "Function to get a character's lines in a specific episode",
    "Let's first explore what each dataset looks like.",
    " Display the contents of the episodes dataframe\ndf_episodes.head()",
    "check missing data\ndf_script.info()",
    "To Do: Implement word cloud for Simpsons script lines",
    "Display the first few rows of the dataset\ndf_characters.head()",
    "Inspect the structure of each table",
    "Checking dataframes",
    "View the first 5 lines of df_characters\ndf_characters.head()",
    " Visual check of the first rows of the dataframes",
    "Check if the imports and data are loaded properly\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "Declare which columns to be used for each dataframe.\nchar_fields = [\n    'id',\n    'name'\n]\n\nloc_fields = [\n    'id',\n    'name'\n]\n\nep_fields = [\n    'id',\n    'title'\n]\n\nscript_fields = [\n    'episode_id',\n    'number',\n    'raw_text',\n    'character_id',\n    'location_id'\n]",
    "Remove leading/trailing whitespaces from scripts\ndf_script['raw_text'] = df_script['raw_text'].apply(lambda x: x.strip())",
    "Check if dataframes were correctly loaded",
    " Helper function to display a word cloud\ndef plot_wordcloud(wordcloud):\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")",
    "Visualizations of characters, locations and places in the Simpsons series",
    " Merge the tables to have everything in a single place\ndf = df_script.merge(df_episodes, on='episode_id', suffixes=('', '_episode'))\ndf = df.merge(df_locations, on='location_id', suffixes=('', '_location'))\ndf = df.merge(df_characters, on='character_id', suffixes=('', '_character'))",
    "Display the first 5 rows of the characters DataFrame\ndf_characters.head(5)",
    "Merge all data into a single dataframe",
    "Merge table to keep only scripts with a known character ID\ndf = pd.merge(df_script, df_characters, how='inner', on='id', suffixes=('', '_y'))\ndf = df[pd.notnull(df['normalized_text'])]",
    "pre-processing\n# Parse JSON columns in script and characters DataFrames\ndf_characters_gr = pd.DataFrame(list(df_characters['character'].apply(json.loads)))\ndf_locations_gr = pd.DataFrame(list(df_locations['location_text'].apply(json.loads))\ndf_script_td = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id')\n\n# Override the 'name' error from 'name' column from script DataFrame\ndf_script_td[\"name\"]= df_script_td[\"name\"].fillna(df_script_td[\"normalized_text\"])\ndf_script_td.drop(columns='normalized_text' , inplace=True)",
    " Let's inspect the first few rows of each DataFrame to understand their structure and contents.",
    "Encode lines by key and title.",
    "All the CSV files need to be found or imported in order to load the Simpsons dataset.",
    "Let's have a first look at the data we have.",
    "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    " df_script = df_script.dropna(subset=['normalized_text'])",
    " Create a new DataFrame merging 'df_episodes' with 'df_script'\ndf_merged = df_episodes.merge(df_script, on='id', suffixes=('_ep', '_script'))\n\n# Limitation\nLIMIT = None",
    "Explore the characters dataframe\ndf_characters.head()",
    "Build the dataframe to be used in this notebook with the characters' lines along with the episode id and name for further analysis.",
    "Check if we have the correct dataframes",
    "Set pandas to display long text\npd.set_option('display.max_colwidth', -1)",
    "General configuration of library settings\npd.set_option('display.max_columns', 50)\nnlp = spacy.load('en_core_web_sm')",
    "Create a row identifier by combining 'episode_id' and 'timestamp_in_ms'\ndf_script[\"row_id\"] = df_script[\"episode_id\"].astype(str) + \"_\" + df_script[\"timestamp_in_ms\"].astype(str)",
    " Set all pandas outputs to be displayed completely\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)",
    "Merged dataframe on episode_id\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id', how='inner').head(50)",
    "Check the result\ndf_characters.head()",
    " merging characters and locations with the script lines\ndf_script_lines_characters = df_script_lines.merge(df_characters, on='character_id')\ndf_script_lines_characters_locations = df_script_lines_characters.merge(df_locations, on='location_id')",
    "Visualizing the length of the scripts per episode",
    "View the first few rows of the characters dataframe\ndf_characters.head()",
    " Show top few rows of each dataframe to understand the structure of the data.",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "\n# Display each of the 5 datasets\nprint('Characters:')",
    "# Let's see what data do we have\nprint('Columns:')\nfor column in df_script.columns:\n    print(f'\\t{column}')",
    "Inspect first few rows of each dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "# Show the first few rows of the characters DataFrame\ndf_characters.head()",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Check if installation of spaCy worked\n# Also needs the model \"en_core_web_sm\" to be installed\nnlp = spacy.load('en_core_web_sm')",
    " Display first 5 lines of characters dataset",
    "Basics for all of them\ndf_script['word_count'] = df_script['spoken_words'].apply(lambda x: len(x.split()))\ndf_script['title'] = df_episodes['title'][df_script['episode_id']-1].values\n\n# Display the conversation\ndf_script.head()",
    "Check how the tables look like",
    "Join to get the locations and entities present in every episode",
    " Sample the dataset\ndf_script.sample(10)",
    "Limit the number of script lines to 10000 to speed up computation\ndf_script = df_script.sample(n=10000, random_state=1)",
    "Inspect the first few rows of each dataframe to understand the structure of the data and the information it contains.",
    "Print the dataframes shapes\nprint('Characters df shape: ', df_characters.shape)\nprint('Locations df shape: ', df_locations.shape)\nprint('Script df shape: ', df_script.shape)\nprint('Episodes df shape: ', df_episodes.shape)",
    "Display all columns and the first 5 rows\nwith pd.option_context('display.max_columns', None):\n    display(df_script.head())",
    "Preview the datasets to understand their structure and content\ndf_characters.head()",
    " Display the data structures\ndf_characters.head(3)",
    "Examine the contents of the character dataframe\ndf_characters.head()",
    "# Show the first rows of the characters DataFrame\ndf_characters.head()",
    "Check first 3 rows of characters dataset",
    " Merge data together\ndf_merged = df_script.merge(df_episodes, how='left', on='episode_id')",
    "Merge datasets to get all relevant information into one dataframe",
    "Check the first few rows of the dataset to understand its structure\ndf_script.head()",
    "df_script.head()",
    " Check data shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Display the first few rows of the dataframe\ndf_characters.head()",
    "Merge datasets\ndf = df_script.merge(df_episodes, on='episode_id', how='left')",
    "Inspecting these DataFrames will help us understand what kind of information is available and how it is structured.",
    "Check df_characters columns\ndf_characters.head()",
    "set random seed for reproducibility\nnp.random.seed(0)",
    "Inspect dataframes",
    " Set the display name for each character and location based on the columns shown above",
    " Displaying a simple head of the dataframes",
    "Merge locations and script_data\nlocations_script = df_locations.rename(columns={\"id\": \"location_id\"}).merge(\n    df_script.rename(columns={\"location_id\": \"script_location_id\"}),\n    how='left',\n    on='location_id'\n)",
    "top 5 rows of the characters dataframe\ndf_characters.head()",
    "Importing the necessary libraries for the analysis of data from \"The Simpsons\" TV show, including spacy, pandas, numpy, and wordcloud. Also, custom imports like tqdm and Counter for additional functionalities.",
    " Check for missing values",
    "df_script = df_script.drop(['index'], axis=1)",
    " Set a seed for reproducibility",
    "Remove invalid rows from df_script",
    "Increases the range of the rows displayed when 'print' displays the dataframe.",
    "Remove some unused columns\ndf_script.drop(['spoken_words', 'raw_text', 'timestamp_in_ms', 'speaking_line'], axis=1, inplace=True)",
    "Define pre-processing functions",
    "Setting ambiguous caharacters_id to -9\ndf_script['character_id'].fillna(-9, inplace=True)",
    "Checking the first 5 rows of each dataset",
    " Load the cleaned files",
    "Create a spaCy nlp object\nnlp = spacy.load('en_core_web_sm')",
    "Some pandas options for better display and more helpful default behaviour.\npd.set_option('display.max_columns', None)\npd.options.mode.chained_assignment = None  # default='warn'",
    " Let's take a look at the first few rows of each dataframe:",
    "let's have a brief look at the data sets",
    "Check data sample sizes\nprint(f'Characters: {len(df_characters)}')\nprint(f'Locations: {len(df_locations)}')\nprint(f'Script lines: {len(df_script)}')\nprint(f'Episodes: {len(df_episodes)}')",
    "We'll start by performing some data exploration on the script data to get a feel for the data.",
    "print('Script:', df_script.shape)\nprint('Locations:', df_locations.shape)\nprint('Characters:', df_characters.shape)\nprint('Episodes:', df_episodes.shape)",
    "Check that the datasets have been loaded properly\ndf_characters.head()",
    "Look at the top 5 rows of df_script\ndf_script.head()",
    "Inspect the content of the episodes data frame",
    "Unify character IDs in 'df_script' CRUCIAL TO EXECUTE FIRST\ndf_script['character_id'] = np.where(df_script.raw_character_text == 'Other_Spuckler', 132,\n                               np.where(df_script.raw_character_text == 'Sherri/Terri', 140,\n                                        np.where(df_script.raw_character_text == 'Question\\'s Voice', 180,\n                                                 np.where(df_script.raw_character_text == 'French President', 321,\n                                                          df_script.character_id))))\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Homer'], 1, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Marge'], 2, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Bart'], 8, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Lisa'], 9, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Maggie'], 10, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Santa\\'s Little Helper'], 14, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Seymour Skinner'], 15, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Ned Flanders'], 16, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Grampa'], 17, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()[\"Krusty the Clown\"], 20, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Rev. Timothy Lovejoy'], 21, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Edna Krabappel'], 22, inplace=True)\ndf_script['character_id'].replace(df_characters.set_index('character_id').raw_character.str.split().to_dict()['Kent Brockman'], 25, inplace=True)",
    "Where are Simpsons Characters mentioned the most.",
    "Display the first few rows of the characters DataFrame\ndf_characters.head()",
    " pandas will default to truncating the output, so let's change it to display the all content of DataFrames in Jupyter.\npd.set_option('display.max_colwidth', None)",
    "Inspected the first values of each dataframe in search for the 'elusive' episode_id.",
    "Split the data into training and test sets",
    "Merge df_script and df_episodes on episode_id",
    " Connect to the database",
    "Set seed for reproducibility\nnp.random.seed(42)",
    "Check a random sample to see all the columns",
    "Preview the characters dataframe\ndf_characters.head()",
    "Setting the style of the plots\nmatplotlib.style.use('ggplot')",
    "Display the first 5 rows of each DataFrame to understand the data.",
    "\n# Let's take a look at the first rows of the characters dataframe\ndf_characters.head()",
    "# Merge scripts, characters and locations\ndf_temp = pd.merge(df_script, df_episodes, on='episode_id')\ndf_temp = pd.merge(df_temp, df_characters, left_on='character_id', right_on='id', suffixes=('', '_character')).drop(columns='id')\ndf_temp = pd.merge(df_temp, df_locations, left_on='location_id', right_on='id', suffixes=('', '_location')).drop(columns='id')",
    "Inspect the first few rows of the characters DataFrame\ndf_characters.head()",
    " Visualize the character and location dataframes",
    "View the first 5 records of 'df_characters'\ndf_characters.head()",
    "Display the first few rows of each dataframe\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()",
    "Sample the characters dataframe\ndf_characters.head()",
    "Checking the first 5 rows of the characters dataframe\ndf_characters.head()",
    "# Data Visualization Setup\nplt.style.use('fivethirtyeight')\nplt.rcParams[\"figure.figsize\"] = (14,7)",
    "Drop useless data\ndf_script = df_script.drop(['index', 'raw_text', 'timestamp_in_ms',\n                            'speaking_line', 'character_id', 'location_id',\n                            'raw_character_text', 'raw_location_text',\n                            'spoken_words'], axis=1)",
    " Display first few rows of characters dataframe\ndf_characters.head()",
    "convert ids to integers\ndf_script['episode_id'] = df_script['episode_id'].astype(int)\ndf_script['character_id'] = df_script['character_id'].astype(int)",
    "Display the first few rows of each table to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Check the data; specifically, the script data.",
    "Check basic informations (for instance, the first rows) of each dataframe",
    " Data inspection",
    " Set seeds for numpy and python to keep results consistent\nnp.random.seed(42)\nPYTHONHASHSEED = 0",
    "Check basic info about characters DataFrame\ndf_characters.info()",
    "Set the seed for reproducibility",
    "Filter out the episode ids that are in the lines dataset from the episodes dataset.",
    "Import dataset",
    "Show all columns in pandas\npd.set_option('display.max_columns', None)",
    "Create a mapping between character names and IDs for fast lookup\nchar_id_map = {}\nfor char in tqdm(df_characters.itertuples(), total=len(df_characters)):\n    char_id_map[char.character_name.lower()] = char.id",
    "pd.set_option('display.max_columns', None)",
    "Merge episode information into main script dataframe\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')",
    "Check what the data looks like",
    "We will be using the script dataset to extract insights and create a word cloud.",
    "Display first five rows of characters dataset\ndf_characters.head()",
    "Set the seed for reproducibility\nnp.random.seed(0)",
    "Display the dataframes\ndf_characters.head()",
    " Top-5 rows of the characters DataFrame\ndf_characters.head()",
    "Print the Characters data\nprint(df_characters.head(5))",
    "Show the first 3 rows of the `df_characters` dataframe\ndf_characters.head(3)",
    "Display the first few rows of the dataframe `df_characters`",
    "Check dataframes shape and types",
    "Instantiate the nlp object of Spacy",
    "Set up spaCy\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])",
    "Extract episode_id and raw_text from df_script\ndf_script = df_script[['episode_id', 'raw_text']]",
    "\n# Let's start by taking a look at the structure of our dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "I'm sorry, but I cannot execute this code as it is. I can only provide code completions and extensions.",
    "We will explore the dataset to understand the data better before we start working with it.",
    "Join the dataframes",
    " Set the environment variable for NLTK data file",
    "Display\ndf_script.head()",
    "Check if the dataframes have been properly loaded",
    "Get an overview of the Simpsons characters dataframe\nprint(\"Number of lines in the dataframe: \" + str(len(df_characters)), \"\\n\")\nprint(df_characters.head(), \"\\n\")\nprint(df_characters.info())",
    "# We use spacy's medium English model\nnlp = spacy.load('en_core_web_md')",
    "Filter out the episodes which script lines are not present in the dataset",
    "Merge all the datasets to get the full dataset",
    "Replace nans with empty strings\ndf_script = df_script.fillna('')",
    "Drop lines where either character or location is missing, and keep only id, character and location columns\ndf_script = df_script.dropna(subset=['character_id', 'location_id']).reset_index(inplace=False, drop=True).loc[:, ['id', 'character_id', 'location_id']]",
    "Check the first few script lines",
    "Let's take a look at the available data.",
    "Merge script lines with episodes\ndf_script = pd.merge(df_script, df_episodes,\n                     on='episode_id',\n                     how='left')",
    " Display first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    ")",
    "Let's get a feeling for the structure and information in these datasets.",
    " Set NaN strings to NaN values",
    "Tokenize the script lines using Spacy's en_core_web_sm model.",
    " Display the first few rows of each dataframe to understand the data",
    "# Load the model\nnlp = spacy.load('en_core_web_sm')",
    "View the first few entries in the characters dataframe\ndf_characters.head()",
    "First let's display the first few rows of each dataframe, to inspect what kind of information we've got:\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Set a default value for the number of elements.",
    "Exploratory Data Analysis (EDA)",
    "Select your favourite character\ndf_characters['character'].values",
    "Get the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_episodes.head(), df_script.head()",
    "Set pd display options for better data visualization in Jupyter notebooks",
    " Let's take a look at the structure of the dataframes.",
    "Checking data types and exploring missing values\nprint(df_script.info())",
    "Remove any neutral or irrelevant sentences and characters from the scripts\ndf_script = df_script[~df_script['raw_text'].str.contains(\"MAGGIE|MARGE|LISA|HOMER|BART|MAYOR QUIMBY|AINSWORTH|MAN'S VOICE|WOMAN'S VOICE|ALLURING VOICE|BART AND LISA|SQUEAKY VOICE|SFX|TALKING TO MAIN DOOR|SFX\")]",
    "Load Spacy in English\nnlp = spacy.load('en_core_web_sm')",
    " Connect to our DB\ncon = sqlite3.connect(\"data/simpsons_script_database.db\")\n\n# Create cursor\ncur = con.cursor()",
    " Combine character information with script lines\ndf_combined = df_script.merge(df_characters.add_suffix('_characters'), how='left', left_on='character_id', right_on='id_characters')",
    "we reset the index inplace and drop the old index column at the same time",
    "Check the content of the characters dataframe\nprint(df_characters.head())",
    " Merge the necessary columns",
    "Ensure script data is sorted by index\ndf_script = df_script.sort_values(by='index')",
    "Join episodes with scripts\ndf_episodes_scripts = df_episodes.set_index('id').join(df_script.set_index('episode_id')).reset_index()\n\n# Join characters with scripts\ndf_characters_scripts = df_characters.set_index('id').join(df_script.set_index('character_id'))\n\n# Join locations with scripts\ndf_locations_scripts = df_locations.set_index('id').join(df_script.set_index('location_id'))",
    "Print shape of each dataframe\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
    " Extracting the text of the script lines for further analysis",
    "Extracts the text column of a dataframe, creates a word cloud and plots it.",
    "Let's take a quick look at our datasets.",
    "Display the first few rows of each dataset to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Show all columns to know what can be used from each table\nfor column in [df_characters.columns, df_locations.columns, df_script.columns, df_episodes.columns]:\n    print(column)\n    print()",
    "Check if the episode ID from the script lines are in the episode dataframe\ndf_script_in_eps = df_script[df_script['episode_id'].isin(df_episodes['id'])]",
    "Data sanitization and exploration",
    "Visualize the characters dataset\ndf_characters.head()",
    " Checking the data\nprint(f'Characters: {len(df_characters)}')\nprint(f'Locations: {len(df_locations)}')\nprint(f'Script lines: {len(df_script)}')\nprint(f'Episodes: {len(df_episodes)}')",
    "Let's start by printing the first 5 lines of each of these datasets to understand how they look like.",
    "Total number of rows in the dataset\nscript_rows = df_script.shape[0]",
    "Extract script for a single episode",
    "# Load data\ndf_characters = pd.read_csv('data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\ndf_locations = pd.read_csv('data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\ndf_script = pd.read_csv('data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\ndf_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)",
    "We will start by loading the necessary datasets for our analysis.",
    "\n# from the 'simpsons_script_lines.csv' dataset, only keeping the first 5061 rows to decrease the dataset size and uploading time\ndf_script = df_script[:5061]",
    "Check the input data",
    " Display available dataframes in the dataset\nprint('Characters:')\ndisplay(df_characters.head(2))\nprint('Locations:')\ndisplay(df_locations.head(2))\nprint('Scripts:')\ndisplay(df_script.head(2))\nprint('Episodes:')\ndisplay(df_episodes.head(2))",
    "Inspecting the dataframes",
    "Ignore the warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
    "Extract script with characters and their gender\ndf_script_characters = df_script.merge(df_characters, left_on='character_id', right_on='id')\n\n# Filter only episodes in English\ndf_script_characters = df_script_characters[df_script_characters['episode_id'].isin(df_episodes[df_episodes['original_air_date']!='un-aired']['id'])]\n\n# Remove non-spoken lines\ndf_script_characters = df_script_characters[-df_script_characters.raw_text.str.contains('Marge:[\\s\\S]*|Homer:[\\s\\S]*|Bart:[\\s\\S]*|Lisa:[\\s\\S]*|Maggie:[\\s\\S]*|Gerald:[\\s\\S]*|Carl: [\\s\\S]*|Lenny:[\\s\\S]*|Seymour:[\\s\\S]*|Moe:[\\s\\S]*|Chief Wiggum: [\\s\\S]*|Montgomery Burns:[\\s\\S]*|Waylon Smithers:[\\s\\S]*|Krusty:[\\s\\S]*|Ned:[\\s\\S]*|Rev. Lovejoy:[\\s\\S]*|Edna: [\\s\\S]*|Milhouse:[\\s\\S]*|Skinner:[\\s\\S]*|Patty:[\\s\\S]*|Selma:[\\s\\S]*|Barney:[\\s\\S]*|Apu:[\\s\\S]*|Nelson:[\\s\\S]*|Jimbo:[\\s\\S]*|Dolph:[\\s\\S]*|Kearney:[\\s\\S]*|Rod:[\\s\\S]*|Todd:[\\s\\S]*|Maude:[\\s\\S]*|Helen:[\\s\\S]*|Miss.Hoover:[\\s\\S]*|Sherri:[\\s\\S]*|Terri:[\\s\\S]*|Martin:[\\s\\S]*|Santa\\'s Little Helper:[\\s\\S]*|Patty and Selma:[\\s\\S]*|Groundskeeper Willie:[\\s\\S]*|Bob:[\\s\\S]*|Frank:[\\s\\S]*|Dr. Hibbert:[\\s\\S]*|Jasper:[\\s\\S]*|Cletus:[\\s\\S]*|Sideshow Bob:[\\s\\S]*|Mayor Quimby:[\\s\\S]*|Snake:[\\s\\S]*|Disco Stu:[\\s\\S]*|Reverend Lovejoy:[\\s\\S]*|Wiggum:[\\s\\S]*|Ap...",
    " Set index of episodes to 'id' for faster searching.",
    "Wordcloud on character's names\n# Convert the list of character's names to a single string\nall_names = df_characters['name'].str.cat(sep=' ')\n\n# Create a WordCloud object\nwordcloud = WordCloud(width=800, height=400, max_font_size=150, background_color='black').generate(all_names)\n\n# Display the word cloud using matplotlib\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()",
    "Now, let's take a look at the first few rows of each dataset to understand their structure and contents.",
    "Helper function to pretty print a JSON object\nimport json\n\ndef pp_json(json_thing, sort=True, indents=4):\n    if type(json_thing) is str:\n        print(json.dumps(json.loads(json_thing), sort_keys=sort, indent=indents))\n    else:\n        print(json.dumps(json_thing, sort_keys=sort, indent=indents))",
    "Merge episodes and scripts\ndf = pd.merge(df_script, df_episodes, on=\"episode_id\", how=\"left\")",
    " We'll start by doing a bit of initial exploration of the data that we have.",
    " Demonstrating the data structure and number of entries in each dataset",
    "Merge characters and locations into the script DataFrame\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id')\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id')",
    "Display first 5 rows of the script dataframe.\ndf_script.head()",
    " Display how the dataframe looks\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_episodes.head())\nprint(df_script.head())",
    "Check missing values in the dataframes",
    "Now let's take a look at the first few rows of each of these DataFrames.",
    " Retrieve a subset of the Simpsons massive dataset\nseed = 42  # Seed used for every random function\ndocs_fraction = 0.05  # Fraction of the complete dataset we want to use\n\n# Get a subset of all characters\ndf_characters_sub = df_characters.sample(frac=docs_fraction, random_state=seed)\n# Get a subset of all location\ndf_locations_sub = df_locations.sample(frac=docs_fraction, random_state=seed)\n# Get a subset of all episodes\ndf_episodes_sub = df_episodes.sample(frac=docs_fraction, random_state=seed)\n# Get a subset of all script lines\ndf_script_sub = df_script[df_script['episode_id'].isin(df_episodes_sub['id'])]  # Use only script lines from the subselected episodes",
    "Check the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Let's see the first few entries in each of these dataframes.",
    " Sure, I can help you with that. What would you like to do next?",
    " Visualizations for different parts of the dataset\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\ndf_script.groupby('character_id').size().sort_values(ascending=False).head(10).plot(kind='bar', ax=ax1, title='Top 10 most lines spoken')\ndf_script.groupby('location_id').size().sort_values(ascending=False).head(10).plot(kind='bar', ax=ax2, title='Top 10 locations with most lines')\ndf_script.groupby('episode_id').size().plot(kind='bar', ax=ax3, title='Number of lines per episode')\n\n# Remove last xlabel as it is overlapping with the next plot\nax1.set_xlabel('')\nax2.set_xlabel('')\nfig.tight_layout()",
    "Check the data format for each dataframe\nprint(df_characters.dtypes)\nprint(df_locations.dtypes)\nprint(df_script.dtypes)\nprint(df_episodes.dtypes)",
    "Replace NaN with empty strings\ndf_script = df_script.fillna('')",
    " Show the head of each DataFrame\nprint('Characters:')\nprint(df_characters.head())\n\nprint('\\nLocations:')\nprint(df_locations.head())\n\nprint('\\nScript:')\nprint(df_script.head())\n\nprint('\\nEpisodes:')\nprint(df_episodes.head())",
    "Setting up environment for plot\nmatplotlib.rcParams['figure.figsize'] = [20, 10]\nnlp = spacy.load('en_core_web_sm')",
    "Display all columns\npd.set_option('display.max_columns', None)",
    " Display the first few rows of the dataframe containing the script lines.",
    " Load spaCy model\nnlp = spacy.load('en_core_web_sm')",
    "Set constants or options\n# Constants\nSEED = 42\n\n# Options\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    " Display basic information about the characters dataset\nprint(df_characters.info())",
    "# Set seed for reproducibility\nnp.random.seed(0)",
    "Explore the dataset\nprint(f'Number of data points for characters: {len(df_characters)}')\nprint(f'Number of data points for locations: {len(df_locations)}')\nprint(f'Number of data points for script lines: {len(df_script)}')\nprint(f'Number of data points for episodes: {len(df_episodes)}')",
    "First we need to understand the data in order to decide on any data cleaning that may be necessary.",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Set a seed for reproducibility",
    "Remove special values and characters from the 'raw_text' column of the script dataframe\ndf_script['raw_text'] = df_script['raw_text'].str.replace('-', ' ')\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\.\\.\\.', ' ')",
    "Function to filter the script by episode id.",
    " Let's check the data available.",
    "look at the data\ndf_script.head()",
    "Data exploration and cleaning",
    "------------------ Preprocessing ---------------------",
    "Split locations, removes duplicates, and assigns a unique identifier",
    " Show first rows of the table\ndf_script.head()",
    " Merge 'df_script' with 'df_episodes'\ndf_merged = df_script.merge(df_episodes, on='episode_id', how='left')",
    " Check the first few rows of the characters data.",
    "Aggregating script lines by character ID\nlines_per_character = df_script[df_script.speaking_line == True].groupby('character_id').agg('count').reset_index()\nlines_per_character = lines_per_character[['character_id', 'id']]\nlines_per_character.columns = ['character_id', 'line_count']",
    "Script lines are too big for the upload to GitHub, but you can find it here:\n# https://www.kaggle.com/ambarish/simpsons-script-lines#simpsons_script_lines.csv",
    "Combining all character lines to obtain a single document for each character.",
    "We can now use the previously defined read-in data frames for further data processing and analysis.",
    "Exploring the datasets",
    "Extract top speakers from the data\ntop_speakers = df_script.raw_character_text.value_counts(normalize=True).round(2)\ntop_speakers = top_speakers[0:20]\n\n# Plot top speakers\ntop_speakers.plot(kind='barh')",
    "check the first 5 lines of the dataframes to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Merge the script lines with the characters, locations and episodes dataframe",
    " Drop unnecessary columns from characters and locations\ndf_characters.drop(columns=['normalized_name', 'voice_actor_id', 'image_url', 'slug', 'gender', 'celeb_id', 'start_int', 'end_int', 'credit_id'], inplace=True)\ndf_locations.drop(columns=['image_url', 'slug'], inplace=True)",
    "check data\ndf_characters.head()",
    " Display information about the characters dataframe\nprint(df_characters.info())",
    "Setting the correct types of each column",
    " Data overview\ndf_characters.info()",
    "Display a sample of each dataframe to understand the data",
    "instantiate spacy\nnlp = spacy.load('en_core_web_sm')\n\n# function to preprocess the data\ndef process(text, model=nlp, max_length=1000000):\n    text = text[:max_length]\n    doc = model(text)\n    return [ent.text for ent in doc.ents]",
    " Show the data from the top 3 datasets\ndf_characters.head(), df_locations.head(), df_script.head()",
    "A fresh copy of the DataFrame is saved on-disk every time we preprocess the data, so we can load from that in future runs instead of having to re-run the code above.",
    "How to normalize the character names (lowercase, remove symbols, etc.) when working with the script data.",
    "Let's take a look at the script data.",
    " Set Seed to Reproduce Results\nseed = 42",
    " Check missing values in the dataset\ndf_script.isna().sum()",
    "Show the first few rows of the dataset to understand its structure\ndf_characters.head()",
    "display all the loaded dataframes with first rows",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Check out the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Set seed for reproducibility\nnp.random.seed(0)",
    "# Check the structure of script data\ndf_script.head()",
    " Merging the scripts with characters and locations datasets\ndf_script = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')\ndf_script = df_script.rename(columns={'name': 'character_name'})\ndf_script = pd.merge(df_script, df_locations, left_on='location_id', right_on='id')\ndf_script = df_script.rename(columns={'name': 'location_name'})",
    "Filtered out the rows that are not script lines or do not have any spoken words in the \"spoken_words\" column.",
    "let's merge the dataframes to get a dataset with all information in one place.",
    " Extracting the text of each line along with its corresponding character, location, and episode title.",
    " Let's take a look at the dataframes.",
    "Custom imports\nfrom tqdm import tqdm\nfrom collections import Counter",
    "Check the first few rows of the characters dataframe\ndf_characters.head()",
    "Let's have a look at the content of the script dataframe:\ndf_script.head()",
    "Filter out the script lines in locations.",
    "Setting environment variable for CUDA\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"",
    "Apply the long version to the script dataframe",
    "Limit the data for analysis for now: top 4 characters and top 4 locations.\ncharacters = ['Homer Simpson', 'Marge Simpson', 'Bart Simpson', 'Lisa Simpson']\nlocations = ['Simpson Home', \"Moe's Tavern\", 'Kwik-E-Mart', 'Springfield Elementary School']\n\n# Specific scripts / lines with the characters and locations:\ndf_script_character_limited = df_script[df_script.character_id.isin(df_characters[df_characters.raw_character_text.isin(characters)].index)]\ndf_script_location_limited = df_script[df_script.location_id.isin(df_locations[df_locations.raw_location_text.isin(locations)].index)]",
    "Initialize spacy\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])",
    " Due to the size of the dataset, we will drop rows with missing values in the following columns: `script`, `character_id`, `location_id`, and `raw_text`.",
    "Print the head of the characters dataframe\nprint(df_characters.head(5))",
    "Create a dataframe with the lines we intend to analyze.",
    " Display the dataframe of episodes using the head() function to display the first 5 rows.",
    "Set index for every dataframe",
    "Keep the original DataFrames unmodified\ndf_characters_orig = df_characters.copy()\ndf_locations_orig = df_locations.copy()\ndf_script_orig = df_script.copy()\ndf_episodes_orig = df_episodes.copy()",
    "Inspect data types and missing values in the scripts dataset",
    "Let's first familiarize with data topics by first exploring the structure of each DataFrame.",
    " Extract columns of interest\ndf_script = df_script[['episode_id', 'character_id', 'location_id', 'normalized_text']]",
    "merge the first and last names\ndf_characters['name'] = df_characters['name'].str.split().apply(lambda x: x[0] + '_' + x[1] if len(x) > 1 else x[0])\n\n# Load model\nnlp = spacy.load('en_core_web_sm')",
    " We will instantiate a `nlp` spacy model and then suppress and serach the tokens.",
    "Show examples of each dataset\ndf_characters.head()",
    "Filter relevant seasons and reset index\ndf_episodes = df_episodes[(df_episodes['season'] >= 3) & (df_episodes['season'] <= 28)].reset_index(inplace=False, drop=True)",
    "Look at the first 5 lines of the first 3 DataFrames to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Use pandas display option to show all the columns when displaying the dataframes\n# Setting the option affects all dataframes throughout the notebook\npd.set_option('display.max_columns', None)",
    "Let's take a glimpse at these datasets.",
    "Check that the character names have not changed\nassert len(set(df_characters.character_id) - set(df_script.raw_character_text)) == 0",
    "Check the data\nprint(df_characters.head())",
    "Converts raw text into dataframes.",
    "Set path to data and custom :func:`~utils` (for relative imports).",
    " Filter characters with non-resolved names\ndf_characters = df_characters[df_characters.raw_character_text.str.contains('Simpson') | df_characters.raw_character_text.str.contains('simpson')].reset_index(inplace=False, drop=True)",
    "Redimensionnement de la table `Locations`",
    "Extract lines for specific character\nhomer = df_script[df_script['character_id'] == 2]\nmarge = df_script[df_script['character_id'] == 1]\nbart = df_script[df_script['character_id'] == 8]\nlisa = df_script[df_script['character_id'] == 9]\nmaggie = df_script[df_script['character_id'] == 16]",
    " Select only the first 6 seasons of the data\ndf_script = df_script[df_script['season'] <= 6]",
    "Optionnally, since the dataset is large, we can retrieve just a subset of the data, for instance by using the code below:\n'''\ndf_characters = df_characters.head(100).copy()\ndf_locations = df_locations.head(100).copy()\ndf_script = df_script.head(1000).copy()\ndf_episodes = df_episodes.head(100).copy()\n'''",
    "Show the first few characters of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Print the first few rows of the characters dataframe\ndf_characters.head()",
    "Display the first few rows of each dataframe to get a sense of what the data looks like.",
    "Set up Spacy\nnlp = spacy.load('en')",
    " Set the default style for matplotlib to 'ggplot'\nmatplotlib.style.use('ggplot')",
    "We'll be using the df_script dataframe to analyze the script lines.",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "In case of reopening Jupyter notebook, we will reload the data without the need to run the entire notebook",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Setup the selected character ID and retrieve the chosen character's name",
    " Define the character models to use for NER (Named Entity Recognition)",
    "Get an overview of the characters dataset\nprint(df_characters.head())\n\n# Get an overview of the locations dataset\nprint(df_locations.head())\n\n# Get an overview of the script lines dataset\nprint(df_script.head())\n\n# Get an overview of the episodes dataset\nprint(df_episodes.head())",
    " We are importing necessary libraries and datasets to preprocess the Simpson script lines.",
    "Merge characters, locations and lines\ndf = pd.merge(df_script, df_characters, left_on='character_id', right_on='character_id',  how='inner')\ndf = pd.merge(df, df_locations, left_on='location_id', right_on='location_id', how='inner')",
    " Display the script dataframe\ndf_script.head()",
    "display basic statistics\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Merge main dataframe with characters and locations\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id', how='left')\ndf_merged = pd.merge(df_merged, df_characters, left_on='character_id', right_on='id', how='left')\ndf_merged = pd.merge(df_merged, df_locations, left_on='location_id', right_on='id', how='left')",
    " Visualize most common characters\ntop_characters = df_script['character_id'].value_counts().head(50)\ncharacters = [df_characters[df_characters['id']==i]['name'].values[0] for i in top_characters.index]\n\nplt.figure(figsize=(16, 8))\nplt.bar(characters, top_characters.values)\nplt.xticks(rotation=90)\nplt.show()",
    " Merge characters and their location\ndf_characters_location = pd.merge(df_characters, df_locations, how='left', left_on='location_id', right_on='id', suffixes=('character', 'location')).drop('idlocation', axis=1)",
    " Look at the script data frame\ndf_script.head()",
    "Concatenate the spoken words for each episode and speaker\ndf_script_concatenated = df_script.groupby(['episode_id', 'character_id']).agg({'spoken_words': ' '.join}).reset_index()",
    " Let's start by taking a look at the first few rows of each dataframe.",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Display df_characters's shape\nprint(\"df_characters has\", df_characters.shape[0], \"rows and\", df_characters.shape[1], \"column\")",
    " Data Cleaning",
    " Let's display basic informations for every dataframe",
    " Visual settings\nmatplotlib.rcParams['figure.figsize'] = [10, 5]\nmatplotlib.rcParams['figure.dpi'] = 200",
    "display all columns\npd.options.display.max_columns = None",
    "Display width to show most of the conversation\nNone;pd.set_option('display.max_colwidth', None)",
    " Pre-processing and Feature Generation",
    " Show df_scirpt for testing purposes\ndf_script.head()",
    "Right before we begin any analysis, let's take a look at the head of each dataframe.",
    "res/head()",
    "Initialize spacy\nnlp = spacy.load('en_core_web_md')",
    "Remove rows with NaN in \"raw_character_text\" or \"spoken_words\" columns\ndf_script = df_script.dropna(subset=['raw_character_text', 'spoken_words']).reset_index(drop=True)",
    "Select some columns and sample some data\n# This way, we can better understand the data we are working with\ndf_script.sample(10)[['normalized_text', 'spoken_words', 'raw_text', 'episode_id', 'character_id']]",
    " create new (and final) dataframe by merging 'df_episodes' and 'df_script' dataframes using a left join merging on 'episode_id' column\ndf_final = pd.merge(df_episodes, df_script, on='episode_id', how='left')",
    " Print the top 5 records of the characters dataframe\nprint(df_characters.head(5))",
    " Look at the first few rows of the characters dataframe\ndf_characters.head()",
    "We'll quickly inspect each of these dataframes.",
    "Copy the original dataframe into a new variable (in order to avoid reloading it from the CSV)",
    "Let's see the structure of the data.",
    " It's important to reset the index after reading the dataframes.",
    "Join dataframes on the character, location, episode and season fields, and reset index",
    "\n# Data has been read into dataframes. Can start analysis and visualization.",
    "Preview of the first 5 rows of each dataframe\nprint(\"df_characters:\")\nprint(df_characters.head())\nprint(\"df_locations:\")\nprint(df_locations.head())\nprint(\"df_script:\")\nprint(df_script.head())\nprint(\"df_episodes:\")\nprint(df_episodes.head())",
    "Optional run to display the number of components in each dataframe\n# Display the number of components in each dataframe\nprint(\n    f'Number of components in the Simpsons character dataframe: {df_characters.size}\\n'\n    f'Number of components in the Simpsons location dataframe: {df_locations.size}\\n'\n    f'Number of components in the Simpsons script dataframe: {df_script.size}\\n'\n    f'Number of components in the Simpsons episode dataframe: {df_episodes.size}'\n)",
    "Rescale the large image for easier viewing.\nplt.figure(figsize=(12, 12))\nplt.imshow(img, interpolation='nearest')\nplt.axis('off')\nplt.show()",
    "Merge characters(2) and locations(2) to the script DataFrame, so that every line is associated with a character and a location.",
    " View the first few rows of the characters dataframe\ndf_characters.head()",
    "Inspect Data\nprint(f'Dimensions of the Simpsons characters dataset: {df_characters.shape}')\nprint(f'Dimensions of the Simpsons locations dataset: {df_locations.shape}')\nprint(f'Dimensions of the Simpsons script dataset: {df_script.shape}')\nprint(f'Dimensions of the Simpsons episodes dataset: {df_episodes.shape}')",
    "Dramatization of the characters and locations\ndramatic_characters = df_script.character.str.upper()  # This project is not case sensitive\ndramatic_locations = df_script.raw_location_text.str.upper()  # Same here",
    "Print the character dataframe to understand the structure and contents\nprint(df_characters.head())",
    "Check to see if the imports and data were loaded correctly\n# Display the first few rows of each dataframe\nprint('Characters dataframe shape:', df_characters.shape)\nprint(df_characters.head(3))\nprint('\\n')\n\nprint('Locations dataframe shape:', df_locations.shape)\nprint(df_locations.head(3))\nprint('\\n')\n\nprint('Script dataframe shape:', df_script.shape)\nprint(df_script.head(3))\nprint('\\n')\n\nprint('Episodes dataframe shape:', df_episodes.shape)\nprint(df_episodes.head(3))",
    "Inspect the character dataset\ndf_characters.head()",
    "def_prune_dataset(df_script=df_script,\n                    df_characters=df_characters,\n                    df_locations=df_locations,\n                    df_episodes=df_episodes,\n                    list_lowercase_stopwords=['the', 'and', 'a', 'in', 'to', 'of', 'on', 'for', 'is', 'that',\n                                              'with', 'as', 'by', 'at', 'from', 'up', 'down', 'into', 'out', 'over',\n                                              'off', 'be', 'are', 'were', 'we', 'you', 'your', 'they', 'their', 'them'],\n                    list_successful_episodes=list_successful_episodes)",
    "Display first few rows of each dataframe\ndf_characters.head()",
    "Printing the first five rows of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "main()",
    "Joining datasets to have a comprehensive dataframe",
    "Display the top 5 rows of the 'characters' dataframe\ndf_characters.head()",
    "View the data.head() to check the first 5 rows of data\tload_data()",
    " Display the head of each dataset to get an overview of their structure\nprint(\"Characters:\")\nprint(df_characters.head())",
    "Display maximum 20 columns when displaying dataframes\npd.set_option('max_columns', 20)",
    "Explore the structure of episodes data\ndf_episodes.head(10)",
    "Wordcloud setup\nwc = WordCloud(width=800, height=400, max_words=200, background_color='white')",
    "Extract a smaller random sample of the data for faster visualization and exploration\ndf_script_sample = df_script.sample(n=10000, random_state=1)",
    " Display the contents of the four DataFrames with the .head() method\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "cosine similarity between two word vectors\ndef get_cosine_similarity(x, y):\n    return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))",
    "Merge the dataframes to get all the relevant information in one single dataframe",
    "# Remove rows that contain empty strings in columns of interest\ncolumns_of_interest = ['character_id', 'normalized_text', 'location_id', 'episode_id']\ndf_script = df_script.replace('', np.nan)\ndf_script.dropna(subset=columns_of_interest, inplace=True)",
    "Data Exploration",
    "Transform some columns to the right data type for memory reduction",
    "Setting the print to display the first 3 rows by default\nprint(df_characters.head(3))\nprint(df_locations.head(3))\nprint(df_script.head(3))\nprint(df_episodes.head(3))",
    "Inspect the first few rows of each dataframe to understand its structure and contents.",
    "Setup spaCy\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])",
    "# Install language model and dictionary for Enlgish\n!python -m spacy download en",
    " Remove special characters from character names, locations, and script lines and episode titles.",
    "Preprocess the data and perform exploratory data analysis (EDA)",
    "Look at the list of episodes\nfor i, row in df_episodes.iterrows():\n    print(row['title'], row['original_air_date'])",
    " Visualize the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "\n# Let's start by taking a look at the dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Discard rows with NaN values in the normalized_text column\ndf_script = df_script.dropna(subset=['normalized_text'])",
    "Display head of character dataframe\ndf_characters.head()",
    "Check data samples for consistency\ndf_episodes.head()",
    "Check out the first 5 rows of the characters dataframe",
    "Check if working directory contains data files\nprint(os.listdir('data'))",
    "# Show the first few lines of the dataset to understand its structure\ndf_script.head()",
    "Limpar dados desnecessrios",
    " Show all columns for the script dataframe\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)",
    "df_script.head()",
    "Combine the script lines with the episode titles",
    "Filter for the regular characters only\nmain_characters = [\n    'marge', 'homer', 'bart', 'lisa', 'maggie', 'chief_wiggum', 'moe', 'ned', 'skinner',\n    'patty', 'selma', 'milhouse', 'krusty', 'burns', 'moe', 'ted', 'apu', 'barney', 'lenny',\n    'carl', 'waylon_smithers', 'nelson', 'jimbo', 'martin', 'professor_frink', 'snake', \n    'cletus', 'edna', 'rainier_wolfcastle', 'simpsons'\n]",
    "Print the first 5 rows of the script dataframe.",
    "Attributes types to columns\ndf_script['id'] = df_script['id'].astype('string')\ndf_script['episode_id'] = df_script['episode_id'].astype('string')\ndf_script['number'] = df_script['number'].replace('?', np.nan).astype(float)\ndf_script['raw_text'] = df_script['raw_text'].astype('string')\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].replace('?', np.nan).astype(float)",
    "Display the first few rows of each dataframe to understand the data",
    "Set seed for reproducibility\nnp.random.seed(0)",
    "Inspection of the data.",
    "Create maps: lookup tables for location and character names",
    "Check the first few rows of the characters DataFrame",
    "Merge the datasets to combine script lines with character and location information.",
    "View first 5 rows of characters dataframe\ndf_characters.head()",
    "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Inspect collected tables and preview elements",
    "View the structure of the data.",
    " Check the first five rows of the characters DataFrame\ndf_characters.head()",
    "Optional: display pandas tables in notebook format",
    "Apply some fixes to the dataset and clean the text for further analyisis",
    "View the content of all the datasets\nprint('[INFO] Number of characters:', df_characters.shape[0])\ndf_characters.head()",
    "@click.command()",
    " Extract all locations\nlocations = df_locations.loc[:,'normalized_text']\nlocations = locations.dropna()\n\n# Extract all script lines\nscript = df_script.loc[:,'normalized_text']\nscript = script.dropna()\n\nscript.head()",
    "\ndf_script.head()",
    "Create a copy of df_script to work with",
    "Check that the data has been loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Display the first 10 rows of the dataframe of script lines.",
    "# Print the first few rows of df_characters to see the data\ndf_characters.head()",
    "# Enable extra logging for debugging (set to False for normal operation)\nDEBUG = False",
    " The script initially loads necessary libraries and datasets to begin the analysis. This includes pandas, numpy, spacy, matplotlib, and the WordCloud library for visualization. It also loads the custom imports tqdm and Counter. The script then loads several datasets such as simpsons_characters, simpsons_locations, simpsons_script_lines, and simpsons_episodes using pandas and assigns them to dataframes df_characters, df_locations, df_script, and df_episodes, respectively.",
    "Column `episode_id` and `id` are common between `df_episodes` and `df_script`",
    "Check for names, locations and episode mentioned in the script data",
    "Print number of characters and number of lines in the script\nprint(df_characters.shape[0])\nprint(df_script.shape[0])",
    "To avoid potential confusion and potential performance issues in your code, it is recommended to use the .copy() method when creating the new dataframes to avoid having views on the original dataframes.",
    "Global configurations\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    "Data Overview and Cleaning",
    "Check the content of the loaded DataFrames\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Unload all the NLTK stopwords\nimport nltk\nfrom nltk.corpus import stopwords\n\n#nltk.download('stopwords')\n\nstopwords = set(stopwords.words('english'))",
    " Looking at the first couple of entries of our characters dataset",
    "Display the first few rows of the characters dataset\ndf_characters.head()",
    "sample the characters dataframe\nprint(\"Characters dataframe shape: \", df_characters.shape)\ndf_characters.head()",
    "Display the first few rows of the characters dataset to understand its structure\nprint(df_characters.head())",
    "Print out the head of each dataframe to explore the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Join all data frames into a single one.",
    "Set seed for reproducibility\nnp.random.seed(0)",
    "Merging required dataframes for analysis - there will be repeated values as each line in the script has a unique id which maps back to the same episode and resulting title.",
    "Optional: use larger font size and set the default figure size\nplt.rcParams.update({'font.size': 22, 'figure.figsize': (10, 8)})",
    " Display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Remove the column that has been passed as an index from the CSV file",
    "\n# Check dataframe head\ndf_characters.head()",
    "Characters and lines in script are in the same table, while the locations are separate.",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Clean the data: Some characters and many locations have the honorific \"The\" in their name, which can confuse the API.",
    "Inspect the contents and structure of the script data\ndf_script.head()",
    "Look at the first 5 rows of the characters dataframe\ndf_characters.head()",
    "# Remove unnecessary numeric columns\ndf_characters = df_characters.drop(columns=['id'])\ndf_locations = df_locations.drop(columns=['id'])\ndf_script = df_script.drop(columns=['id', 'episode_id', 'number', 'raw_text','timestamp_in_ms'])\ndf_episodes = df_episodes.drop(columns=['id'])",
    " Checking for missing values in the dataset\nmissing_values = df_script.isnull().sum()\nmissing_values",
    "spacy.cli.download(\"en_core_web_sm\")",
    " Visualize the number of episodes per season\ndf_episodes['season'].value_counts().sort_index().plot(kind='bar')",
    "Let's explore the data to have an idea what is in the dataset.",
    "Inspect the format and structure of the data in the dataframes",
    "Bart in script dataframe\ndf_script_bart = df_script[df_script['raw_character_text'] == 'Bart']\n\n# Most common words in the Bart lines\ncounter = Counter(\" \".join(df_script_bart[\"spoken_words\"]).split())\ncounter.most_common(10)",
    "df_script.head()",
    "Show the first rows of the characters dataframe\ndf_characters.head()",
    "Remove unnecessary columns\ndf_characters.drop(columns=['id', 'image_url', 'imdb_url'], inplace=True)\ndf_locations.drop(columns=['id'], inplace=True)\ndf_script.drop(columns=['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms'], inplace=True)\ndf_episodes.drop(columns=['id', 'image_url', 'video_url', 'imdb_url', 'production_code'], inplace=True)",
    " Examine the structure of the data frames",
    "First we import the necessary modules we'll use throughout the code. Then, we read in the data from the CSV files into pandas DataFrames using `pd.read_csv()`.",
    "Check if the data loaded properly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Load sample script lines\ndf_script.sample(10)",
    "First, we begin by loading all the necessary data from CSV files using pandas. The data consists of information about Simpsons characters, locations, script lines, and episodes.",
    " df_script.info()",
    " Ensure the correct encoding of the dataframes\ndf_characters = df_characters.applymap(lambda x: x.encode('unicode_escape').\n              decode('utf-8') if isinstance(x, str) else x)\ndf_locations = df_locations.applymap(lambda x: x.encode('unicode_escape').\n             decode('utf-8') if isinstance(x, str) else x)\ndf_script = df_script.applymap(lambda x: x.encode('unicode_escape').\n            decode('utf-8') if isinstance(x, str) else x)\ndf_episodes = df_episodes.applymap(lambda x: x.encode('unicode_escape').\n              decode('utf-8') if isinstance(x, str) else x)",
    "Extract main characters from characters df\nmain_characters = df_characters[df_characters['raw_character_text'].str.contains('simpson', case=False)]['raw_character_text']\n\n# Prepare name matching (case insensitive & remove leading/trailing white space)\nmain_characters = main_characters.apply(lambda x: x.lower().strip())\n\n# Extract locations\nlocations = df_locations['name']\n\n# Extract episodes titles\nepisodes_titles = df_episodes['title']",
    "Ignore pandas warning about chained assignments\npd.options.mode.chained_assignment = None",
    "Show the first 10 elements of the characters dataframe\nprint('Characters dataframe')\nprint(df_characters.head(10))\nprint('\\n')",
    "Setting correct data types for the script data frame\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], errors='coerce').fillna(0).astype(np.int64)\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], downcast='integer')\n\ndf_script['number'] = pd.to_numeric(df_script['number'], errors='coerce').fillna(0).astype(np.int32)\ndf_script['number'] = pd.to_numeric(df_script['number'], downcast='integer')",
    " Display the first few entries of df_characters\ndf_characters.head()",
    "Inspect characters dataframe",
    "Let's have an overview of our datasets",
    "Constants\navg_sentence_len = 100  # each element is smaller than average sentence length, i.e is smaller than 100",
    " Vocs tambm precisaro fazer o download do modelo de lngua inglesa do spaCy. Voc pode fazer isso executando o seguinte comando no terminal ou prompt de comando:\n\npython -m spacy download en",
    "Merge location metadata into script dataframe\ndf_script = df_script.merge(\n    df_episodes.loc[:, ['id', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season']].add_prefix('episode_'),\n    left_on='episode_id',\n    right_on='episode_id'\n)",
    " remove 'id' column which is equivalent to the index\ndf_characters.drop('id',axis=1,inplace=True)\ndf_locations.drop('id',axis=1,inplace=True)\ndf_script.drop('id',axis=1,inplace=True)\ndf_episodes.drop('id',axis=1,inplace=True)",
    "Inspect datasets",
    "Let's first take a look at the dataframes to understand their structure and content.",
    "Display the first 5 rows of each dataframe to inspect their contents\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect the first few rows of each dataframe to understand their structure and contents\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "First, let's explore the data and look at the first few rows of each dataframe.",
    "Visualizing the missing values in the dataframe",
    "Removing rows with empty or NaN values in the 'normalized_text' column\ndf_script = df_script.dropna(subset=['normalized_text']).reset_index(inplace=False, drop=True)",
    "df_script.head()",
    "Let's take a look at the first 5 rows of these dataframes.",
    "Inspect the characters dataset",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Clean script\ndf_script = df_script[df_script['utterance'].str.find('SIMPSON') != 0]\ndf_script = df_script[df_script['utterance'].str.find('HOMER') != 0]\ndf_script = df_script[df_script['utterance'].str.find('BART') != 0]\ndf_script = df_script[df_script['utterance'].str.find('LISA') != 0]\ndf_script = df_script[df_script['utterance'].str.find('MARGE') != 0]",
    "display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "A take on entity extraction.\n# Tokenizing the description of Lisa at the start\nnlp = spacy.load(\"en_core_web_sm\")\ndoc = nlp(df_characters[0:1]['description'][0])\nfor token in doc:\n    print(token, token.pos_, token.dep_)",
    "Show dataframe head\ndf_episodes.head()",
    "Extracting just the dialogues and the respective character name from the original dataframe.",
    " Add dummy index to unique identify rows in the original dataframes\ndf_characters['orig_index'] = df_characters.index\ndf_locations['orig_index'] = df_locations.index\ndf_episodes['orig_index'] = df_episodes.index\ndf_script['orig_index'] = df_script.index",
    "Create a directory to save outputs\nif not os.path.exists('outputs'):\n    os.makedirs('outputs')",
    "Let's see how the datasets look.",
    "Set seed for reproducibility",
    " Set seed for reproducibility\nnp.random.seed(0)",
    " Set maximum columns and rows to display\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    "Set up Spacy\nnlp = spacy.load('en_core_web_sm')",
    "Tokenize, lemmatize, remove stopwords and punctuation, and lowercase the text\nnlp = spacy.load('en_core_web_sm')\n\n# Remove unwanted characters, stopwords, and make everything lowercase\nstopwords = spacy.lang.en.stop_words.STOP_WORDS",
    "Check files have been correctly loaded\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Let's take a look at the first few rows of each DataFrame to understand their structure.",
    " Join all text for each row and store in the 'text' column for each data frame\ndf_characters['text'] = df_characters['raw_character_text']\ndf_characters = df_characters.groupby('raw_character_text').agg({'text': ' '.join}).reset_index()\n\ndf_locations['text'] = df_locations['normalized_location_text']\ndf_locations = df_locations.groupby('normalized_location_text').agg({'text': ' '.join}).reset_index()\n\ndf_episodes['text'] = df_episodes['title']\ndf_episodes = df_episodes.groupby('title').agg({'text': ' '.join}).reset_index()",
    "Check the first dataframes rows",
    "Test if characters and locations are in the script dataframe\ncharacters_in_script = [char.lower() for char in df_script['raw_character_text'].unique()]\nlocations_in_script = [loc.lower() for loc in df_script['raw_location_text'].unique()]",
    "Let's view the first 5 rows of the characters DataFrame.",
    "Viewing the first few rows of the dataframes to understand the data",
    "Find the top 10 characters which are most active in the dialogue.",
    "Show first rows of Simpsons Characters dataset\ndf_characters.head()",
    "Check the first few rows of the dataframe for characters.",
    "Inspect the data types of each column\ndf_script.dtypes",
    "Let's take a look at the structure and the first few rows of these datasets.",
    "Check the first 5 rows of the characters dataframe to understand the data",
    "df_script.head()",
    "Join episodes with script\ndf = df_script.merge(df_episodes, on='episode_id')",
    "Acuna N (2015) write a small utility to enhance the pandas dataframe.",
    "Replace indicated speciees names for easier manipulation in the future\ndf_script.replace({\n    'simpsons': 'species_simpsons'\n}, inplace=True, regex=True)",
    "View script dataframe\ndf_script.head()",
    "# Display the data to understand the structure\ndf_script.head()",
    "Visualizing the Simpsons script data",
    "Check the Simpsons script data\ndf_script.head()",
    "Check first lines of the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Example: Show the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Define functions to preprocess text data",
    "# Let's take a look at the characters data\ndf_characters.head()",
    " we'll subset the data: only consider the complete script lines, and remove any stage directions.",
    "# Display the first rows of the characters dataframe\ndf_characters.head()",
    " Check the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display the first few rows of each dataframe to understand the data",
    "Print the first 5 rows of the characters DataFrame\ndf_characters.head()",
    " Display the first few rows of the dataframe to understand its structure\ndf_script.head()",
    "We will load the preprocessed data (to be precise, the cleaned data that we just created) to start with the text analysis process.",
    "Get relevant features from scripts dataframe",
    "\ndf_script.head()",
    "Extract principal data from column to ease .csv navigation",
    "Dropping the index again to be safe",
    "To get started, let's take a look at the first few rows of each dataframe to understand what kind of data we're working with.",
    "Displaying scripts for the first episode",
    "Inspect dataframes",
    "Preview dataframes\ndf_characters.head()",
    "Create path to save figures\nimg_path = 'images'\n# Create the directory if it does not exist\nif not os.path.exists(img_path):\n    os.makedirs(img_path)",
    "Feature selection\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]",
    "Checking for any null values \ndf_script.isnull().sum()",
    " View table top to understand data\ndf_characters.head()",
    "The script includes multiple dataset which shows the information for each episode, such as the annotated script lines, the characters, the locations, and the main events.",
    "Display basic information of each dataframe\n[df.info() for df in [df_characters, df_locations, df_script, df_episodes]]",
    "# Set the seed for reproducibility\nnp.random.seed(0)",
    "Lower case the script lines",
    "Inspect the first few rows of each dataframe to understand its structure and the kind of data we have",
    "Global data\nnlp = spacy.load('en')\n\n# Create a new column with the length of each line\ndf_script['length'] = df_script['raw_text'].apply(len)",
    " Load the Spacy pre-trained model for English language\nnlp = spacy.load('en')",
    "We can then start by exploring the content of each Dataframe.",
    "Remove unnecessary index column\ndf_script = df_script.iloc[:,1:]",
    "Display the script lines.",
    "lec df_episodes.head()",
    "Load the spaCy model\nnlp = spacy.load(\"en_core_web_sm\")",
    "View basic data info\nprint('characters: ', df_characters.shape, df_characters.columns)\nprint('locations: ', df_locations.shape, df_locations.columns)\nprint('script: ', df_script.shape, df_script.columns)\nprint('episodes: ', df_episodes.shape, df_episodes.columns)",
    " Mergethe two dataframes to get the character id",
    "Create a MongoDB database and import the data from CSV files",
    "Isolate the environment to only a select few directories for only python code to be executed",
    "NLP tools\nnlp = spacy.load('en_core_web_sm')",
    "Longest lines in the scripts\nlongest_script_lines = df_script[df_script['raw_text'].str.len() == df_script['raw_text'].str.len().max()]\nlongest_script_lines[['raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id']]",
    "Add status to script lines dataframe\ndf_script = df_script.merge(df_episodes[['id', 'production_code', 'season', 'number_in_season', 'number_in_series', 'air_date']], left_on='episode_id', right_on='id', suffixes=(False, False)).fillna(\"\")\ndf_script.rename(columns={'production_code': 'episode_production_code', \n                          'id': 'episode_id', \n                          'season': 'episode_season', \n                          'number_in_season': 'episode_number_in_season', \n                          'number_in_series': 'episode_number_in_series', \n                          'air_date': 'episode_air_date'}, inplace=True)",
    "Display the data\ndf_characters.head()",
    " Print dataframes' shape\nprint(f'Characters: {df_characters.shape}')\nprint(f'Locations: {df_locations.shape}')\nprint(f'Script: {df_script.shape}')\nprint(f'Episodes: {df_episodes.shape}')",
    " Download 'en_core_web_sm'\n!python -m spacy download en_core_web_sm",
    "Merge dataframes to improve data analysis capabilities.",
    "Prints the first five rowss of the characters dataframe\ndf_characters.head()",
    " Select only the lines with characters\ndf_script_with_characters_info = df_script.loc[~df_script[\"normalized_text\"].isna()].merge(\n    df_characters,\n    how=\"inner\",\n    left_on=\"raw_character_text\",\n    right_on=\"raw_character_text\"\n)",
    "Merge the lines with the episodes",
    "Rename 'id' to 'episode_id' and 'season' to 'episode_season' to enable easier linking between metadata\ndf_episodes = df_episodes.rename(columns={'id': 'episode_id', 'season': 'episode_season'})",
    " Check the dataframes\nprint('Characters:')\nprint(df_characters.head())\n\nprint('\\nLocations:')\nprint(df_locations.head())\n\nprint('\\nScript:')\nprint(df_script.head())\n\nprint('\\nEpisodes:')\nprint(df_episodes.head())",
    " Evaluating data quality\ndf_characters.info(), df_locations.info(), df_script.info(), df_episodes.info()",
    "Let's see what's inside these datasets:",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Display first 10 rows of the characters dataframe\ndf_characters.head(10)",
    "Explore the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Filter out the lines that are not real dialogues.",
    "Set verbose=True for SQL debugging\nos.environ['SQLALCHEMY_ECHO'] = 'True'\n\n# Create a connector using the preferred settings\n!username='' password='' host AWS_Web_Services_key='' Database_name='' !pip install records\nimport records  # from Database name ORM determined which database it should be connected and ORM performs this operation on behalf of us\n\ndef db_connector(*args, **kwargs):\n    return records.Database(*args, **kwargs)",
    "Show all columns\npd.options.display.max_columns = None",
    "iterate over character names that should be casted with actors.",
    " Merge the dataframes to get a single dataframe containing all the information we need.",
    "removing duplicate entries based on the 'id' column\ndf_characters = df_characters.drop_duplicates(subset='id')\ndf_locations = df_locations.drop_duplicates(subset='id')\ndf_script = df_script.drop_duplicates(subset='id')\ndf_episodes = df_episodes.drop_duplicates(subset='id')",
    "Set a seed for reproducibility",
    "Combine script, character, and location data\ndf_episodes_sub = df_episodes[['id', 'imdb_rating', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season']]\ndf_script_sub = df_script[['episode_id', 'character_id', 'location_id', 'norm_text']]",
    " Print size of datasets\nprint(\"Characters Shape:\", df_characters.shape)\nprint(\"Locations Shape:\", df_locations.shape)\nprint(\"Script Shape:\", df_script.shape)\nprint(\"Episodes Shape:\", df_episodes.shape)",
    "Merge characters, locations, and episodes into a single dataframe using left join with scripts dataframe.",
    " Show first rows of characters dataframe\ndf_characters.head()",
    "Create a variable to freeze so we don't run the entire notebook in one go.",
    "Columns of dataframe script\nprint(df_script.columns.tolist())",
    " Display the first 5 rows of the Simpsons characters dataset\ndf_characters.head()",
    "Examine the data\ndf_script.head()",
    "Setting DEPRECATED SettingWithCopy Warning to False\npd.set_option('mode.chained_assignment', None)",
    "To view the first few rows of the characters data frame\ndf_characters.head()",
    "Tokenizes a string into a list of words, filtering out unwanted tokens.",
    " Display the first 5 lines of the dataframe containing the script lines.",
    "Create columns with lower and punctuation-free lines of scripts for faster and smoother processing.",
    "Set pandas options to display all columns",
    "Let's visualize the Word Clouds of the script lines of the Simpsons.",
    "inspecting each dataframe\nprint(f\"Characters: {df_characters.shape[0]}\")\ndf_characters.head(2)",
    "Merge dataframes",
    "Display all columns for visibility\npd.set_option('display.max_columns', None)",
    "Let's look at the first few rows of each imported dataframes",
    "Quick inspection of first rows of df_script DataFrame\ndf_script.head()",
    " Look at the first rows of the dataframe to better understand its structure\ndf_script.head()",
    "ModuleNotFoundError: No module named 'spacy'\n# Install spacy by typing it into the anaconda terminal\n# pip install -U spacy",
    " Let's take a look at the first few rows of each DataFrame to understand their structure and contents.",
    "Do initial exploration of the data\ndf_script = df_script.drop(columns=['index', 'id', 'image_id', 'raw_text'])\nprint(df_script.head())\nprint('\\nNumber of dialogues: {}'.format(df_script.shape[0]))",
    "Convert 'raw_text' column to string type to avoid merge incompatibility later on\ndf_script['raw_text'] = df_script['raw_text'].astype(str)",
    "Data Cleaning and Preprocessing",
    " Let's take a look at the structure of these DataFrames.",
    "Define function to pre-process the text",
    " Show the top 5 rows of the characters dataframe\ndf_characters.head()",
    "Let's take a look at the dataframes we have thus far.",
    " inspect datasets' first few rows\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " switch data to built-in datasets if file not found\ndf_characters = df_characters if not df_characters.empty else pd.read_csv('https://raw.githubusercontent.com/bri-bri/ydata_synopsis/main/data/simpsons_characters.csv').reset_index(inplace=False, drop=True)\ndf_locations = df_locations if not df_locations.empty else pd.read_csv('https://raw.githubusercontent.com/bri-bri/ydata_synopsis/main/data/simpsons_locations.csv').reset_index(inplace=False, drop=True)\ndf_script = df_script if not df_script.empty else pd.read_csv('https://raw.githubusercontent.com/bri-bri/ydata_synopsis/main/data/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\ndf_episodes = df_episodes if not df_episodes.empty else pd.read_csv('https://raw.githubusercontent.com/bri-bri/ydata_synopsis/main/data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)",
    "View head of the character dataframe\ndf_characters.head()",
    "settings\npd.set_option('display.max_columns', None)",
    "Method to display shape of DataFrame\ndef display_shape(df, name):\n    print(f'{name} shape:', df.shape)",
    "Check the shape and headers\nprint('Shape of characters:', df_characters.shape)\nprint('Shape of locations:', df_locations.shape)\nprint('Shape of script lines:', df_script.shape)\nprint('Shape of episodes:', df_episodes.shape)\n\ndf_characters.head()",
    "Display the top 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "sampling data\ndf_characters = df_characters.sample(20)\ndf_locations = df_locations.sample(5)\ndf_episodes = df_episodes.sample(20)",
    "Let's quickly inspect and clean the data to get an overview.",
    " Display some information about the datasets\nprint(\"\\nInformation about the dataset - Characters\")\ndf_characters.info()\n\nprint(\"\\n\\nInformation about the dataset - Locations\")\ndf_locations.info()\n\nprint(\"\\n\\nInformation about the dataset - Script lines\")\ndf_script.info()\n\nprint(\"\\n\\nInformation about the dataset - Episodes\")\ndf_episodes.info()",
    " Display the character dataframe\ndf_characters.head(3)",
    "Create a sampling of the data to speed up the process\ndf_script = df_script.sample(frac=1)",
    "Set up spaCy\nnlp = spacy.load(\"en_core_web_sm\")",
    "Let's take the first look at the loaded datasets.",
    "Import the necessary pre-processing and feature extraction libraries.",
    "Configuration for preprocessing and analysis\nnlp = spacy.load('en_core_web_lg')\nnlp.max_length = 2000000",
    "We'll start by looking at some examples from the dataset `df_characters`.",
    "Show a small preview of the dataframes\nprint('--- Characters ---')\ndisplay(df_characters.head())\nprint('\\n\\n--- Locations ---')\ndisplay(df_locations.head())\nprint('\\n\\n--- Script ---')\ndisplay(df_script.head())\nprint('\\n\\n--- Episodes ---')\ndisplay(df_episodes.head())",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Look the five first data of the dataframe df_episodes\ndf_episodes.head()",
    " Show head of script dataframe\ndf_script.head()",
    "Merge DataFrames",
    "Start by checking the number of rows (i.e. lines, with one line being a character's speaking turn) in the script data.",
    " After importing the necessary libraries and loading the datasets, we can start examining the data to understand its structure and contents.",
    "Set consistent index name for all datasets\ndf_script.index.name = 'script_index'\ndf_locations.index.name = 'location_index'\ndf_characters.index.name = 'character_index'\ndf_episodes.index.name = 'episode_index'",
    "View first 5 rows of the characters dataframe\ndf_characters.head()",
    " Display the first few rows of the dataframe to understand its structure\ndf_characters.head()",
    "Create a Pandas DataFrame and display the first 5 rows\ndf_script = pd.DataFrame(df_script)\ndf_script.head()",
    "'Read' is not defined",
    "Checking if the import is successful.",
    "Set random_state for reproducible results\nnp.random.seed(0)",
    "wip - build character counts",
    "Declare global variables",
    "Check for null values in our datasets\nprint(\"Null values in characters DataFrame:\\n\", df_characters.isna().sum(), \"\\n\")\nprint(\"Null values in locations DataFrame:\\n\", df_locations.isna().sum(), \"\\n\")\nprint(\"Null values in script DataFrame:\\n\", df_script.isna().sum(), \"\\n\")\nprint(\"Null values in episodes DataFrame:\\n\", df_episodes.isna().sum())",
    "We'll take a look at how the datasets are structured and which fields might be useful for our analysis.",
    "merge the dataframes on episode_id\ndf = pd.merge(df_script, df_episodes, how='left', on='episode_id')\ndf = pd.merge(df, df_characters, how='left', left_on='raw_character_text', right_on='normalized_name')\ndf = pd.merge(df, df_locations, how='left', left_on='raw_location_text', right_on='normalized_name')",
    "Check the first few rows of each dataframe\ndf_script.head(), df_characters.head(), df_locations.head(), df_episodes.head()",
    "TODO: Check memory usage and optimize if needed",
    "Let's have a look at some data first.",
    "Helper function\ndef show_wordcloud(text):\n    # Create and generate a word cloud image:\n    wordcloud = WordCloud().generate(text)\n\n    # Display the generated image:\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.show()",
    "Change directory to the correct path\nos.chdir('./simpsons_dataset/')",
    "Check for nulls\nprint(df_characters.isnull().sum(), '\\n')\nprint(df_locations.isnull().sum(), '\\n')\nprint(df_script.isnull().sum(), '\\n')\nprint(df_episodes.isnull().sum(), '\\n')",
    "filter data for episode 1 of season 1 and for script type 'spoken'",
    "Displaying the first few rows of the dataframe\ndf_characters.head()",
    "Filter dialogues with at least one word comprised of alphabet characters\ndf_script_filtered = df_script[df_script['raw_character_text'].str.isalpha()].reset_index(inplace=False, drop=True)",
    "Let's display the first 10 episodes and their corresponding IMDb rating.",
    "Specify how the plots should be displayed in jupyter notebook",
    "print('Data loaded successfully!')",
    "Check the size of the dataframes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    " Show first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "First, let me go through the dataset and get to know the various fields and the data it holds.",
    "function: load_dataframes_cache: Load and cache dataframe functions\ndef load_dataframes_cache(f):\n    def wrapper(*args, **kw):\n        if os.path.exists(f.__name__):\n            print(f'Load {f.__name__} from cache')\n            return pd.read_pickle(f.__name__)\n        else:\n            df = f(*args, **kw)\n            print(f'Save {f.__name__} to cache')\n            df.to_pickle(f.__name__)\n            return df\n    return wrapper",
    "Reduce data size to speed up training\ndf_script = df_script[df_script['episode_id'] < 150].reset_index(inplace=False, drop=True)",
    "Show the first few elements of the characters dataframe to understand its structure\ndf_characters.head()",
    "Check the number of rows and columns for each dataframe\nprint(f\"Simpsons Characters: {df_characters.shape}\")\nprint(f\"Simpsons Locations: {df_locations.shape}\")\nprint(f\"Simpsons Script Lines: {df_script.shape}\")\nprint(f\"Simpsons Episodes: {df_episodes.shape}\")",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Remove the character_id and location_id\ndf_script.drop(columns=['character_id', 'location_id'], inplace=True)",
    "Let's take a peek at our datasets\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Analyse the first rows of the dataframes to get an idea of the data",
    "An example of the dataset\ndf_script.head()",
    "Filter list of characters in the scripts to only include the main characters",
    "Display the first few rows of the dataset for examination\ndf_script.head()",
    "View general information of the datasets\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
    "Convert datePublished column to pandas datetime\ndf_episodes['datePublished'] = pd.to_datetime(df_episodes['datePublished'])",
    "For reproducibility\nnp.random.seed(0)",
    "Let's display the first few rows of each dataframe to understand their structure and contents.",
    "alldata = df_script.join(df_episodes.set_index('id'), on='episode_id', rsuffix='_episode')\nalldata = alldata.join(df_characters.set_index('id'), on='character_id', rsuffix='_character')",
    " Optional: Display first rows of the \"script\" table to have a quick glance\nprint(df_script.shape)\ndf_script.head()",
    "General config\npd.set_option('display.max_colwidth', None)",
    " Compute time column from start and end timestamps\ndf_script['time'] = pd.to_datetime(df_script.timestamp_in, unit='s') - pd.to_datetime(df_script.timestamp_out, unit='s')",
    " Display the first few cells of the dataframe\ndf_script.head()",
    "Merge the datasets and display the first few rows",
    "  Drop first column from all dataframes\ndf_characters = df_characters.iloc[:,1:]\ndf_locations = df_locations.iloc[:,1:]\ndf_script = df_script.iloc[:,1:]\ndf_episodes = df_episodes.iloc[:,1:]",
    "Change script lines dataframe in order to fasten operations",
    " Combine the data in a single DataFrame for ease of manipulation.",
    " Turn off scientific notation for pandas\npd.set_option('display.float_format', lambda x: '%.3f' % x)",
    " Create an nlp object\nnlp = spacy.load('en_core_web_sm')",
    "Display all available columns\npd.options.display.max_columns = None",
    "# Show first 5 rows\ndf_script.head(5)",
    " Check datasets \ndf_characters.head()",
    " Visualize quick informations about datasets",
    "Display the head of the characters dataframe\ndf_characters.head()",
    " Set up variables\nfontsize = 40\nfont_path = 'data/JetBrainsMono-Bold.ttf'",
    "%load_ext autoreload\n%autoreload 2",
    " Create an engine to run SQL queries on the database\nfrom sqlalchemy import create_engine",
    "Check that the shape of each dataframe is correct\nprint(f'Shape of characters dataframe: {df_characters.shape}')\nprint(f'Shape of locations dataframe: {df_locations.shape}')\nprint(f'Shape of script dataframe: {df_script.shape}')\nprint(f'Shape of episodes dataframe: {df_episodes.shape}')",
    "Let's take a look at the structure of the datasets.",
    "Extract script for each episode and each character",
    "Remove 'time' from timestamp column and set it to datetime\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].str.split('.', expand=True)[0]",
    "look into the first 10 rows of the characters dataframe\ndf_characters.head(10)",
    "Setup matplotlib styles\nplt.style.use('fivethirtyeight')",
    "Data exploration and cleaning",
    "# Smarter overviews by joining the data\ndf_merged = df_script.copy()\ndf_merged = df_merged.join(df_episodes.set_index('id'), on='episode_id')\ndf_merged = df_merged.join(df_characters.set_index('id'), on='character_id', rsuffix='_character')\ndf_merged = df_merged.join(df_locations.set_index('id'), on='location_id', rsuffix='_location')",
    " Define a sample size that you want to analyze to speed up computations\nsample_size = 10000",
    "Inspect the first rows of the dataframe to get an idea of the data",
    "Check a sample of data from each dataframe\ndf_script.head()",
    " Limit the number of rows in the dataframes for faster processing during development\n# If processing power is not an issue, these lines can be commented out\ndf_characters = df_characters.head(500)\ndf_locations = df_locations.head(500)\ndf_script = df_script.head(500)\ndf_episodes = df_episodes.head(500)",
    " Print the basic data\nprint(\"# characters=\", len(df_characters))\nprint(\"# locations=\", len(df_locations))\nprint(\"# episodes=\", len(df_episodes))\nprint(\"# lines=\", len(df_script))",
    "Store script lines by episode ID\nepisode_script_lines = {}\nfor episode_id, group in df_script.groupby('episode_id'):\n    episode_script_lines[episode_id] = group['raw_text'].tolist()",
    " Display the first few rows of the script dataset\ndf_script.head()",
    "Show the first 5 rows of each dataframe to confirm data has been properly imported\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display the first few records of each DataFrame to understand its structure\nprint(\"Simpsons Characters DataFrame\")\ndisplay(df_characters.head())\n\nprint(\"Simpsons Locations DataFrame\")\ndisplay(df_locations.head())\n\nprint(\"Simpsons Script DataFrame\")\ndisplay(df_script.head())\n\nprint(\"Simpsons Episodes DataFrame\")\ndisplay(df_episodes.head())",
    " Visualizng dataframes with `head()` will print nicely as tables in Jupyter\ndf_characters.head()",
    "Let's start by exploring the data and understand its structure and contents.",
    "display the 5 first rows of the table\ndf_characters.head()",
    "Show the first few lines of the dataframe containing the script lines",
    "Add other file imports and related code here",
    "Some initial instructions and library imports for data analysis with The Simpsons dataset.",
    "Subset of characters that spoke over than 10 times\nmain_characters = df_script['raw_character_text'].value_counts()[df_script['raw_character_text'].value_counts()>10].index.values\ndf_script = df_script[df_script['raw_character_text'].isin(main_characters)]\n\n# replacing blank values\ndf_script = df_script.replace(\"\", np.nan)",
    "Sample data to understand the structure and contents of the data frames that have been created",
    " Setting the seed for reproducibility\nnp.random.seed(0)",
    " Check the loaded data\ndf_characters.head()",
    " make it easier to access data by using index\ndf_episodes.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)",
    "Let's take a look at the first few rows of each dataframe.",
    "Show how the dataset look\ndf_script.head()",
    "Pravdepodobne som niekde spravil chybu, pretoe z tejto asti neviem odhadn, o sa stalo. Prosm, odkte ma na predchdzajci riadok.",
    " Remove all non-spoken lines\ndf_script = df_script[df_script.speaking_line == True]",
    " Create a DataFrame consisting of only Bart's lines.\nbart_id = df_characters[df_characters.character_name == 'Bart Simpson'].character_id.values[0]",
    "matplotlib.rcParams['figure.figsize'] = [12, 8]",
    "Selecting \"The Simpsons\" TV show from the dataset",
    " Add some basic checks to the dataset",
    "Merge script dataframe with episode df",
    "Merge all datasets into one by episode_id\ndf = pd.merge(df_script, df_episodes, on='episode_id')\ndf = pd.merge(df, df_characters, on='character_id')\ndf = pd.merge(df, df_locations, on='location_id')",
    "Display first 5 records of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    " Imports required for data visualization and analysis, and loading datasets into pandas DataFrames.",
    "Merge script lines with characters and locations data\ndf_script_characters = df_script.merge(df_characters, on='character_id', suffixes=('', '_char')).merge(df_locations, on='location_id', suffixes=('', '_char')).merge(df_episodes, on='episode_id', suffixes=('', '_char'))",
    "Check if the code execution meets the objective",
    " view available data columns for characters, locations, and script\nprint(df_characters.columns)\nprint(df_locations.columns)\nprint(df_script.columns)",
    "Notice that 'data' is a directory containing the necessary CSV files.",
    " The path to the data is currently wrong. Let's fix that by modifying the path to the data.",
    "Reformat the character construction.\ndf_characters = df_characters[['id', 'name', 'normalized_name', 'gender', 'description', 'job', 'img_url']]",
    "Show the first few rows of the characters data\ndf_characters.head()",
    "List the head of each dataframe",
    "Inspect the structure of the datasets",
    " Optionally, you can remove the quotation marks if it starts to be difficult to manage in your local language.",
    " Remove all characters that did not appear in any script line\nto_remove = df_script[~df_script.raw_character_text.isin(df_characters.raw_character_text) & ~df_script.raw_character_text.isna()].raw_character_text.unique()\ndisplay(len(df_script))\ndf_script = df_script[~df_script.raw_character_text.isin(to_remove)]\ndisplay(len(df_script))",
    "Enable the tqdm \"notebook\" extension\ntqdm.pandas()",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Display the first few rows of the dataframe\ndf_characters.head()",
    "optional: remove non-spoken lines (if the line is not spoken by the characters)",
    " Show the head of the characters dataframe\ndf_characters.head()",
    " Display the first 5 rows of the script dataset\ndf_script.head()",
    " Replace NaN with empty string\ndf_script = df_script.fillna('')",
    "Let's make sure it's loaded correctly",
    "Some lines contain Bhutanese writing. Let's clean the data by removing them.",
    "Get all the quotes from the episodes and movies and join them in a single string\nscript = \" \".join(script for script in df_script['dialog'])",
    "Prevent the truncated display of dataframes|# Remove the display truncation for dataframes\npd.set_option('display.max_colwidth', None)",
    "# Data visualization\nimport seaborn as sns",
    "`reset_index(inplace=False, drop=True)` is unnecessary",
    "Load kaggle dataset\n#df_characters = pd.read_csv('/kaggle/input/the-simpsons-dataset/simpsons_characters.csv').reset_index(inplace=False, drop=True)\n#df_locations = pd.read_csv('/kaggle/input/the-simpsons-dataset/simpsons_locations.csv').reset_index(inplace=False, drop=True)\n#df_script = pd.read_csv('/kaggle/input/the-simpsons-dataset/simpsons_script_lines.csv').reset_index(inplace=False, drop=True)\n#df_episodes = pd.read_csv('/kaggle/input/the-simpsons-dataset/simpsons_episodes.csv').reset_index(inplace=False, drop=True)",
    "Create a data folder if it doesn't exist\nif not os.path.exists('data'):\n    os.makedirs('data')",
    "We are now reading in the CSV files using pandas and storing them in dataframes.",
    "Check if loaded correctly\nprint(df_characters)\nprint(df_locations)\nprint(df_script)\nprint(df_episodes)",
    "Check the data has been loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Set index to make filtering more explicit",
    "Explore datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Let's take a quick look at the contents of the data frames to understand the data structure.",
    "Set display options for the dataframes",
    "Inspect the contents of the characters dataframe",
    "Setting the path to the Simpsons dataset folder",
    "Show all available data\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', -1)\n\nprint('\\ndf_characters:', df_characters.shape)\ndisplay(df_characters.head(3))\n\nprint('\\ndf_locations:', df_locations.shape)\ndisplay(df_locations.head(3))\n\nprint('\\ndf_script:', df_script.shape)\ndisplay(df_script.head(3))\n\nprint('\\ndf_episodes:', df_episodes.shape)\ndisplay(df_episodes.head(3))",
    "Ensure reproductibility of the results\nnp.random.seed(0)",
    "Merge the datasets on 'episode_id' to have all relevant information in one dataframe.",
    "Filter out the non-dialogue lines from the script dataframe\ndf_script_dialogue = df_script[df_script['speaking_line'] == True]",
    "Merge the lines with the others DataFrames. This way we can have access to the episode information within the lines dataframe.",
    " Check the data to ensure everything is loaded correctly",
    " We'll have a look first at the structure and contents of these DataFrames.",
    "Optional: Display the first few rows of each dataframe to understand the data structure.",
    "Display the first 3 lines of the dataframe\ndf_script.head(3)",
    "Import our custom module\nimport simpsons_helper as sh",
    "Print the first 5 records of the characters data frame\ndf_characters.head()",
    "Display the head of the characters dataframe\ndf_characters.head()",
    " Simply display the dataframes to understand their structure and contents\ndf_characters",
    "clean empty string rows\ndf_script.replace('', np.nan, inplace=True)\ndf_script.dropna(inplace=True)",
    " Initialize spacy 'en' model, keeping only tagger component needed for lemmatization\nnlp = spacy.load('en', disable=['parser', 'ner'])",
    " Check the size and structure of each dataframe\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
    "FIREST, let's take a look at the schema of the data we have and decide how we should best merge it all together.",
    "Opt into using `resume_parser_ner_wiki_large` when using `spacy.load` as this one has the NER model loaded",
    " Display the first 3 rows of each dataframe\ndisplay(df_characters.head(3),\n        df_locations.head(3),\n        df_script.head(3),\n        df_episodes.head(3))",
    " Tokenizer for spacy model",
    "Sanitize data",
    " Remove rows with missing information in the script dataset\ndf_script.dropna(subset=['normalized_text', 'raw_text', 'word_count'], inplace=True)",
    "Quick look at the structure of the datasets",
    "Merge episodes with scripts\ndf_episodes['id'] = df_episodes['id'].astype(str)\ndf_script['episode_id'] = df_script['episode_id'].astype(str)\ndf = pd.merge(df_script, df_episodes, left_on = 'episode_id', right_on = 'id')",
    "Display data\nwith pd.option_context('display.max_rows', None):\n    display(df_characters.describe())\n    display(df_locations.describe())\n    display(df_script.describe())\n    display(df_episodes.describe())",
    "Install spaCy language model\n!python -m spacy download en",
    "Let's first have a look at the scripts data.",
    "Save scripts for each character",
    "Prepare for data exploration\n# Show all columns\npd.options.display.max_columns = 50",
    "Check the number of records\nprint(f'Number of records in df_characters: {df_characters.shape[0]}')\nprint(f'Number of records in df_locations: {df_locations.shape[0]}')\nprint(f'Number of records in df_script: {df_script.shape[0]}')\nprint(f'Number of records in df_episodes: {df_episodes.shape[0]}')",
    " Merge tables to allow more efficient manipulation of the data",
    "Query: Total number of characters, locations and episodes available in the dataset",
    " Display the first few rows of the dataframe for the characters.",
    "Examine the structure of the characters DataFrame",
    "filePath = data_path + '\\simpsons_script_lines.csv'",
    " Check the contents of script data.",
    "Display documentation for settings\npd.describe_option('display')",
    "Assign named spans to refer to specific episodes etc.",
    "Save the script data details for the prediction script and delete script data from memory after saving it",
    "Set the `display.max_columns` option in Pandas to `None` to show all columns in DataFrames\npd.set_option('display.max_columns', None)",
    "# shows the first 5 lines of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Checking the first few rows of the data.\ndf_script.head()",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Consider displaying the data to understand its structure and available columns.",
    "# create instance of the spacy model\nnlp = spacy.load('en_core_web_sm')\n\n# function to tokenize and clean the text\ndef preprocess_text(text):\n    # create spacy object\n    doc = nlp(text)\n    \n    # lemmatize and lowerize all the tokens\n    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and token.is_alpha]\n    \n    return ' '.join(tokens)",
    "Load Spacy\nnlp = spacy.load('en_core_web_md')",
    " Visualizations of the datasets",
    "Specify data type for 'episode_id' to int in all dataframes for later merging of data frames",
    "Filter the character list to remove non-character names or add missing characters\ncharacters_to_remove = ['narrator']\n\ndf_characters_filtered = df_characters[~df_characters['name'].str.lower().isin(characters_to_remove)]\ndf_characters_filtered.reset_index(drop=True, inplace=True)",
    "Removing script lines which are not associated with any speaking character.",
    "Lets start with simple statistics of dataframes",
    "Visualizacion de los datos",
    "Check some lines of the script DataFrame",
    "print the number of script lines ",
    "Since the snippet is incomplete, It cannot be executed. Therefore, I will provide an explanation regarding the code.\nThe code snippet provided contains the import statements for the required libraries along with the custom imports.\nIt also reads csv files for Simpsons characters, locations, script lines, and episodes into pandas dataframes.",
    "Associate spoken lines to characters and merge with episode information\nmask = df_script['character_id'].isin(df_characters['id'])\ndf_script = df_script[mask]\n\ndf_script = df_script.merge(\n    df_episodes,\n    how='left',\n    left_on='episode_id',\n    right_on='id')",
    " Check the first five rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Funnel script dataset into more manageable dataframe",
    "view each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Display the first rows from the characters dataframe\ndf_characters.head()",
    "Explore character data\ndf_characters.head()",
    "Display the first few lines of the script dataframe and metadata about the datasets",
    "Some functions from the script\ndef get_entity_text(text, entities):\n    '''Return text of the entites in the text'''\n    entities = eval(entities)\n    text = str(text)\n    new_txt = text\n    shifts = 0\n    for entity in entities:\n        if entity[0]+shifts != entity[1]+1+shifts:\n            new_txt = new_txt[:entity[0]+shifts] + '`' + text[entity[0]+shifts:entity[1]+1+shifts] + '`' + new_txt[entity[1]+1+shifts:]\n            shifts += 2\n        else:\n            new_txt = new_txt[:entity[0]+shifts] + '`' + '`' + new_txt[entity[0]+shifts:]\n            shifts += 1\n    return new_txt",
    "Merge the characters and locations into the main script dataframe\ndf_script = pd.merge(df_script, df_characters, how='left',\n                     left_on='character_id', right_on='id')\ndf_script = pd.merge(df_script, df_locations, how='left',\n                     left_on='location_id', right_on='id')",
    "It's actually recommended to create the indexes without using inplace=False, as it is deprecated in the latest version of pandas.",
    "Make scripts dataframe indexable by raw/positional index and id\ndf_script.set_index(pd.Index([df_script.id, df_script.index]), inplace=True)",
    "Sets the amount of words to display in WordCloud and also the font size.",
    " Visualisation code",
    "Create separate dataframes for the different characters of the show",
    "Data\ndf_characters.head()",
    "Visualize the dataframe elements using head()",
    "Check the content of the first 5 rows\nprint(df_characters.head())",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "View first 5 rows of characters data\ndf_characters.head()",
    "Create a dict to map character id to character name.",
    "Merge the 'simpsons_script_lines' dataframe ('df_script') with the 'simpsons_episodes' dataframe ('df_episodes') on the 'episode_id' column.",
    "Examine content of df_script\ndf_script.head()",
    "Set the seed for reproducibility\nnp.random.seed(0)",
    " Show the head of the episodes dataframe\ndf_episodes.head()",
    "Display the first few rows of each dataframe to understand the data",
    "Join the data frames",
    "df_script.head(10)",
    "Check head of the first dataframe\ndf_characters.head()",
    "Shows the first few rows of each dataframe.",
    " Enable f-strings in Python 2.7\nfrom future.builtins import (bytes, str, open, super, range,\n                           zip, round, input, int, pow, object)",
    "Check whether script dataframe has null values\ndf_script.isnull().sum()",
    "characters = df_characters.copy()\nlocations = df_locations.copy()\nscript = df_script.copy()\nepisodes = df_episodes.copy()",
    "Check the first 5 records of each CSV",
    "Creating a single df with characters and locations",
    "We can now take a lookt at the head of each DataFrame to understand better their structure",
    " Display the first few rows of the datasets\nprint(\"Characters Dataset\")\ndisplay(df_characters.head())\n\nprint(\"Locations Dataset\")\ndisplay(df_locations.head())\n\nprint(\"Script Dataset\")\ndisplay(df_script.head())\n\nprint(\"Episodes Dataset\")\ndisplay(df_episodes.head())",
    " Display the first few rows of the dataframe\ndf_script.head()",
    "Merge script data with character and location data\ndf_script_full = (df_script.merge(df_characters[['id', 'normalized_name']], \n                                  left_on='character_id', \n                                  right_on='id', \n                                  how='left')\n                            .rename(columns={'normalized_name': 'character_name'})\n                            .drop(columns='id')\n                            .merge(df_locations[['id', 'normalized_name']], \n                                   left_on='location_id', \n                                   right_on='id', \n                                   how='left')\n                            .rename(columns={'normalized_name': 'location'})\n                            .drop(columns='id')\n                  )\n\ndf_script_full.head()",
    "Exploring the Simpsons dataset",
    "Set MATPLOTLIB to use ggplot style\nplt.style.use('ggplot')",
    " We want to begin by exploring the contents of these DataFrames and understand how they are related to each other.",
    "Helper functions",
    "Let's see what our datasets look like.",
    "Visualization of the number of lines per characters.",
    "Keep only necessary columns to avoid RAM exhaustion",
    "What are the shapes of the datasets?",
    " Display the first few rows of each dataframe to know what information we have",
    "First five rows of the dataset\ndf_script.head(), df_characters.head(), df_locations.head()",
    "We'll start by exploring the data in each of these dataframes.",
    "Explore datasets dimensions",
    "Rename speaker and episode_id columns for clarity\ndf_script = df_script.rename(columns={'episode_id': 'id', 'character_id': 'speaker_id'})",
    "Check if the dataframes are successfully loaded\nprint(f'Characters dataframe: {df_characters.shape[0]} rows')\nprint(f'Locations dataframe: {df_locations.shape[0]} rows')\nprint(f'Script lines dataframe: {df_script.shape[0]} rows')\nprint(f'Episodes dataframe: {df_episodes.shape[0]} rows')",
    "Look at the first few rows of the characters dataframe.",
    "Setting random seed for reproducibility\nnp.random.seed(0)",
    " Load Wikipedia and GLoVe with Spacy's medium model",
    "Data inspection and exploration\ndf_episodes.head()",
    "Display the first, (2-30)mn, and last entries of the dataframe.",
    "Remove unused columns\ndf_script = df_script[['episode_id', 'id', 'character_id', 'location_id', 'raw_text']]",
    "Set seed for reproducibility\nnp.random.seed(0)",
    "Let's take a look at the first few rows of the characters dataframe to understand its structure.",
    "Get a sense for the data and the columns involved\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
    "Code to be continued...",
    " Display the first few rows of the dataframe\ndf_script.head()",
    "display the head of the dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "--------------  Preprocessing  --------------",
    "\n# Merge script, characters and locations dataframes on episode id\ndf_merged = df_script.merge(df_episodes, on='episode_id')\ndf_merged = df_merged.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_character'))\ndf_merged = df_merged.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_character', '_location'))",
    "Harmonize data column names and types",
    "Preview for each table\nprint(\"Characters:\")\nprint(df_characters.info())\nprint(df_characters.head())\nprint(\"\\nLocations:\")\nprint(df_locations.info())\nprint(df_locations.head())\nprint(\"\\nScript:\")\nprint(df_script.info())\nprint(df_script.head())\nprint(\"\\nEpisodes:\")\nprint(df_episodes.info())\nprint(df_episodes.head())",
    "filter main characters\nmain_characters = [\n    \"marge\",\n    \"homer\",\n    \"bart\",\n    \"lisa\",\n    \"maggie\",\n    \"grampa\",\n    \"abraham jay simpson\",\n    \"krusty\",\n    \"sideshow bob\",\n    \"charles montgomery burns\",\n    \"milhouse\",\n    \"chief wiggum\",\n    \"ned flanders\",\n    \"apu\",\n    \"moe\",\n    \"professor frink\",\n    \"barney\",\n    \"troy mcclure\",\n    \"lionel hutz\",\n    \"selma\",\n    \"patty\",\n    \"mayor quimby\",\n    \"waylon smithers\",\n    \"edna krabappel\",\n    \"dr. hibbert\",\n    \"reverend lovejoy\",\n    \"kent brockman\",\n    \"miss hoover\",\n    \"miss krabappel\",\n    \"groundskeeper willie\",\n    \"otto\",\n    \"maude flanders\",\n]",
    "Check the information contained in the transformed datasets",
    "check that the data is as expected\ndf_characters.head()",
    "Filter characters from main family",
    "Display the first rows of the characters DataFrame\ndf_characters.head()",
    "Create `date` and `time` columns, and merge with `df_script` \ndf_script = df_script.assign(\n    date=pd.to_datetime(df_script.timestamp_in_ms, unit='ms').dt.date,\n    time=pd.to_datetime(df_script.timestamp_in_ms, unit='ms').dt.time\n)\n\n# Merge\ndf_script = df_script.merge(\n    df_episodes[['id', 'season', 'number', 'title', 'original_air_date']],\n    left_on='episode_id', right_on='id'\n)\n\n# Column re-ordering for their better visualization\ndf_script = df_script[\n    [\n        'id', 'season', 'number', 'title', 'original_air_date', 'timestamp_in_ms', 'date', 'time', 'raw_text', 'speaking_line',\n        'character_id', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text'\n    ]\n]\n\n# The first `n` rows\ndf_script.head()",
    "Multiline mode DataFrame print\nfrom IPython.display import display",
    "We can see that we are reading in multiple CSV files using pandas and storing them into dataframes.",
    " Set up matplotlib style\nmatplotlib.style.use('ggplot')",
    "Look at the head of each dataset to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " This is a Python code that reads CSV files into pandas dataframes. The code uses the pandas library to read the CSV files and store the data in dataframes. These dataframes can then be used for further data analysis and manipulation.",
    "Working directory\nos.chdir('/mnt/data')",
    "Removing rows having - and NaN values in `script_text` column\ndf_script = df_script[df_script['raw_character_text'] != '-']\ndf_script = df_script[df_script['raw_character_text'].notna()]\ndf_script = df_script[df_script['speaking_line'] == True]",
    "Count of quotes per episode",
    "Let's display the first few lines of each dataframe to see what they look like.",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Make copy of data and set index\ndf_script_clean = df_script.copy()\ndf_script_clean.set_index('id', inplace=True)",
    "Displaying the number of characters, locations, script lines, and episodes in the datasets\nprint('Number of characters:', len(df_characters))\nprint('Number of locations:', len(df_locations))\nprint('Number of script lines:', len(df_script))\nprint('Number of episodes:', len(df_episodes))",
    "First, we import the necessary libraries and then read in the data from CSV files into Pandas dataframes.",
    "Check the dataframe shapes\nprint(\"Characters dataframe shape:\", df_characters.shape)\nprint(\"Locations dataframe shape:\", df_locations.shape)\nprint(\"Script dataframe shape:\", df_script.shape)\nprint(\"Episodes dataframe shape:\", df_episodes.shape)",
    "Checking the first few rows of the characters dataframe",
    "\u000f# 1.2 Load all data into a pandas dataframes\n# Show the dataframes structure\nprint(f'df_characters.shape:   {df_characters.shape}')\nprint(f'df_locations.shape:    {df_locations.shape}')\nprint(f'df_script.shape:       {df_script.shape}')\nprint(f'df_episodes.shape:     {df_episodes.shape}')",
    "Display the first few rows of each DataFrame to understand the data.",
    "Set up spacy\nnlp = spacy.blank(\"en\")",
    "Look at the head of the table to understand the data.",
    "Visualizations\n# Number of words per character\nword_counts = {\n    character: len(dialog.split())\n    for character, dialog in zip(df_script.raw_character_text, df_script.raw_text)\n}\n\n# Number of words per location\nlocation_word_counts = {\n    location: sum(len(dialog.split()) for dialog in df_script[df_script.raw_location_text == location].raw_text)\n    for location in df_script.raw_location_text.unique()\n}",
    "Inspect the dataframes",
    "Check\ndf_script.head()",
    "Checking the first 5 rows of the characters dataframe.\ndf_characters.head(5)",
    "Show all columns of each dataframe for easy access\npd.set_option('display.max_columns', None)",
    "This assumes that the folder `data` is located in the same directory as this notebook.",
    "Display settings for tables\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('max_colwidth', -1)",
    "Data exploration and data cleaning",
    "pre-processing\ndf_script = df_script[df_script[\"normalized_text\"].notnull()]",
    "Merge characters, locations and episodes on script dataframe",
    "Let's take a quick look at the scripts data.",
    "Inspect the dataframes to understand their structure and contents",
    "Display the first few entries of the characters data frame\ndf_characters.head()",
    "Clean Data",
    "Count the number of non-null values in each column of the dataframe\ndf_script.info()",
    "Read all the datasets and reset the index to ensure the data is properly formatted.",
    "nlp = spacy.load('en_core_web_sm')",
    "Check if null values are present in the datasets\nprint(\"Null character_birth_date: \", df_characters['character_birth_date'].isnull().values.any())",
    "check shapes\nprint(f\"df_characters: {df_characters.shape}\")\nprint(f\"df_locations: {df_locations.shape}\")\nprint(f\"df_script: {df_script.shape}\")\nprint(f\"df_episodes: {df_episodes.shape}\")",
    "Check missing data\nprint(df_characters.isna().sum())\nprint(df_locations.isna().sum())\nprint(df_script.isna().sum())\nprint(df_episodes.isna().sum())",
    " Look at the first 5 rows of each CSV file",
    "reate a new column containing the processed text from the spoken words in the script\ndf_script['processed_text'] = df_script['spoken_words'].apply(lambda x: nlp(x).text)",
    " Setting display options for pandas to display the entire dataframe and prevent value truncating\npd.set_option('display.max_colwidth', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)",
    "Check for missing data\nprint(df_episodes.info())",
    "Filter the dataframe to only include rows where the speaking line is associated with a character and a location.\ndf_script_char_loc = df_script[df_script['raw_character_text'].apply(lambda x: x in df_characters['character_name'].values)]\ndf_script_char_loc = df_script_char_loc[df_script_char_loc['raw_location_text'].apply(lambda x: x in df_locations['normalized_name'].values)]",
    "Check the data types for each column\ndf_script.info(verbose=True)",
    "Examine the dataframes to see what we are working with",
    " Remove unwanted columns\ndel df_script['id']\ndel df_script['number']\ndel df_script['raw_text']\ndel df_script['timestamp_in_ms']",
    "Display first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Checking the content of the characters dataframe",
    "Let's take a closer look at the data we're working with.",
    "Display the scripts dataframe\ndf_script.head()",
    " Display the first few rows of the dataframe\ndf_script.head()",
    "Join characters and script\ndf_characters_script = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')",
    " Preview the \"characters\" DataFrame",
    "Let's look at the some data to understand it better\ndf_episodes.head(2)",
    " Set the display options of pandas to have a\n# larger number of elements and to display more columns\npd.options.display.max_rows = 999\npd.options.display.max_columns = 999",
    "Plot some simple histograms for the episodes dataframe",
    "Rename the \"id\" columns to uniquely identify each table\ndf_characters.rename(columns={'id':'character_id'}, inplace=True)\ndf_locations.rename(columns={'id':'location_id'}, inplace=True)\ndf_script.rename(columns={'id':'line_id'}, inplace=True)\ndf_episodes.rename(columns={'id':'episode_id'}, inplace=True)",
    "Counting the number of lines in episodes",
    "Columns in df_episodes\nfor col in df_episodes.columns:\n    print(col)",
    "Display the first 10 entries of the characters dataframe\ndf_characters.head(10)",
    "We need to have some csv files saved in the 'data' directory. Additionally, we can make our Notebook find the utils.py file by adding it to the Python path.",
    "# Helper functions\ndef clean_text(text):\n    # For now, we simply remove non-alphanumeric characters and multiple spaces\n    return re.sub(r'[^A-Za-z0-9 ]+', '', text).lower().replace('  ', ' ').strip()\n\ndef get_episode_name(df, episode_id):\n    episode = df[df.id == episode_id]\n    if len(episode) > 0:\n        return episode.iloc[0].title\n    return ''",
    "We set the index as \"id\" because the field is unique.",
    " Show the first lines of the characters dataframe\nprint(df_characters.head())",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Check whether the data has been read successfully",
    "Show the first few rows of the characters dataframe\ndf_characters.head()",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "\n",
    "Display the first few characters of the datasets\nprint('Characters:')\ndisplay(df_characters.head())\nprint('Locations:')\ndisplay(df_locations.head())\nprint('Script:')\ndisplay(df_script.head())\nprint('Episodes:')\ndisplay(df_episodes.head())",
    "Check data shape\nprint(f\"Characters: {df_characters.shape[0]}\")\nprint(f\"Locations: {df_locations.shape[0]}\")\nprint(f\"Script lines: {df_script.shape[0]}\")\nprint(f\"Episodes: {df_episodes.shape[0]}\")",
    "Check the imported data for each table",
    "Len of each df\nlen(df_characters), len(df_locations), len(df_script), len(df_episodes)",
    "Check the first few rows of the characters data",
    "Optional: Display first few rows of the dataframe to understand the data",
    "Check dimensions",
    "Clean the text in the 'raw_text' column by removing extra spaces and converting to lowercase\ndf_script['clean_text'] = df_script['raw_text'].str.replace('\\'', ' ').str.lower().str.replace('[^a-z ]', '')\ndf_script['clean_text'] = df_script['clean_text'].str.replace(' +', ' ')",
    "Exploring the data\ndf_characters.head()",
    "Select one episode from the Simpsons and display its script lines.",
    "We'll print the first 3 rows of each dataframe to have a look at what we're dealing with.",
    "Inspect the first few rows of each dataframe to understand the data",
    "Fixing types and merging datasets",
    "Select conversation and extract lines by episode and character",
    " Optionally, you can display the first couple of lines for each of the DataFrames as well.",
    " Set correct types for character_id, location_id and episode_id\ndf_script = df_script.astype({'character_id': 'Int64', 'location_id': 'Int64', 'episode_id': 'Int64'})",
    "First, we read in the data from CSV files into pandas dataframes.",
    " Print all the datasets\nprint('Character Data: ', df_characters.head())\nprint('Location Data: ', df_locations.head())\nprint('Script Data: ', df_script.head())\nprint('Episode Data: ', df_episodes.head())",
    "Explore the data\ndf_script.head()",
    "No we will examine the first 10 rows of the dataset and see what we are dealing with.",
    " Let's examine the available data.",
    "# Initial exploration of the characters dataframe\ndf_characters.head()",
    "Path to where the pre-trained model is stored.\npath_to_model = 'model'\n\n# Load the pre-trained model\nnlp = spacy.load(path_to_model)",
    "Set the dataframe lenght display at its maximum value",
    "Create a subset of the script data that contains only the fields of interest",
    "Get the number of lines for the characters.",
    "Link the script to the episode.",
    " Display the first few rows of the dataframe\ndf_script.head()",
    " Join the table to have a complete table with all information",
    " Display the first few rows of each dataframe to understand their structure\ndf_characters.head()",
    "Setting the script dataframe id to be the index of the dataframe.",
    " Preview the characters dataframe\ndf_characters.head()",
    "Setting up the pipeline and processing the text data",
    "Set which cast member has which gender.",
    "# Coverting episode_number to int as it has some '.0' values\ndf_episodes.at[:, 'number'] = df_episodes['number'].fillna(0).astype(int)",
    "Check the first rows of each dataset\nprint('Characters')\nprint(df_characters.head())\nprint('\\nLocations')\nprint(df_locations.head())\nprint('\\nScript')\nprint(df_script.head())\nprint('\\nEpisodes')\nprint(df_episodes.head())",
    "Check what the script data looks like\ndf_script.head()",
    "Check the script lines dataframe\ndf_script.head()",
    "connectionstring = \"postgresql://user:password@localhost/simpsons\"\n",
    "Preview the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check if the dataframes were imported correctly\ndf_characters.head()",
    "Remove temporarily\nscript_subset = df_script.iloc[:5000].copy()",
    " Add the following line in order to keep the matplotlib plots in the notebook for \n# evaluation. Note that in regular Python we could use plt.show() which is not\n# needed in jupyter notebooks.\n%matplotlib inline",
    " Now we'll come up with a few potential questions to answer with the data.",
    " Setting up pandas display options for easy debugging",
    " Print the head of the script data frame\ndf_script.head()",
    "# Combine locations and episodes\n# First, rename the column to enable merging with episodes\ndf_locations.rename(columns={'id':'location_id'}, inplace=True)\n\n# Then, inner join the two dataframes on 'location_id'\ndf_location_episodes = df_locations.merge(df_episodes, on='location_id', how='inner')\n\ndf_characters.rename(columns={'id':'character_id'}, inplace=True)\ndf_main_character_episode = df_characters.merge(df_episodes, on='main_character_id', how='inner')",
    "Function to display word cloud for a given text\ndef plot_wordcloud(text, title, ax, max_words=200, stopwords=None):\n    # Generate the word cloud\n    wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=max_words, colormap='viridis', stopwords=stopwords).generate(text)\n\n    # Display the word cloud using matplotlib\n    ax.imshow(wordcloud, interpolation='bilinear')\n    ax.set_title(title)\n    ax.axis('off')\n    return ax",
    "Visualize data\ndf_script.head()",
    "Filter episode to have only the Simpsons (no specials)\ndf_episodes = df_episodes[~df_episodes['title'].str.contains('special')].reset_index(drop=True)",
    "Set all IDs to integers\ndf_script['episode_id'] = df_script['episode_id'].astype(int)\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].astype(int)\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)\ndf_script['location_id'] = df_script['location_id'].fillna(-1).astype(int)",
    "Just let's see the top lines of the episodes dataset\ndf_episodes.head()",
    " Display the first few rows of the characters DataFrame\ndf_characters.head()",
    "View some first lines of the data\ndf_episodes.head()",
    "Enable or download the spacy module by running the command below in the terminal:\n# python -m spacy download en\nimport spacy\nnlp = spacy.load(\"en\")",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Set numpy and pandas options for better display\nnp.set_printoptions(precision=2)\npd.set_option('display.max_columns',None)",
    "Let's display the first few rows of each of these DataFrames to better understand their structure and the data they contain.",
    "let's show first the available columns for each dataframe",
    "Check the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Remove script lines without any speaking character\ndf_script = df_script.dropna(subset=['character_id'])",
    "Create a mapping of characters to their gender.",
    "Visualize the first few rows of the script data\ndf_script.head()",
    "Inspect the dataframes to understand their structure and content\ndf_characters.head()",
    "Filtering characters with name \"Lisa\" in 'The Simpsons' dataset\nlisa_id = df_characters[df_characters['character_name'].str.contains('lisa', case=False)]['id'].values[0]\n\nlisa_lines = df_script[df_script['character_id'] == lisa_id]",
    "Inspect structure of each dataframe",
    "\ndef missing_values_table(df):\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() / len(df)\n    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n    mis_val_table_ren_columns = mis_val_table.rename(\n    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n    mis_val_table_ren_columns = mis_val_table_ren_columns[\n        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n    '% of Total Values', ascending=False).round(1)\n    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n          \" columns that have missing values.\")\n    return mis_val_table_ren_columns",
    "Take a peek at the first few rows of the \"script\" dataframe\ndf_script.head()",
    "View the first 10 rows of the characters dataset\ndf_characters.head(10)",
    "Load spacy model\nnlp = spacy.load('en_core_web_sm')",
    "Make use of the full dataset\npd.set_option('display.max_columns', None)",
    "Let's take a look at the first lines from each DataFrame to understand their structure.",
    "Setting series characters to lower case\ndf_characters['normalized_name'] = df_characters['name'].apply(lambda x: x.lower())",
    "some of the first attributes come from this explanation https://www.kaggle.com/pierremegret/dialogue-lines-of-the-simpsons#simpsons_script_lines.csv",
    "Locating the path of the current file",
    "let's focus on the script dataframe for now\ndf_script.head()",
    "Convert stringified lists into lists",
    "Separate the string with main and secondary characters into lists.",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Choose a series of columns to use as metadata for our lines of dialogue.",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Merge dataframes on 'script_id' if we want to have all the information in one dataframe.",
    "clean the script dataframe by dropping useless data",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    " Get the top 10 characters with the most lines in the script\ntop10_characters = df_script['raw_character_text'].value_counts().head(10)\n\n# Define a bar plot for the top10_characters\nplt.figure(figsize=(10,10))\ntop10_characters.plot(kind='bar')\n\n# Set the title and labels\nplt.title('Top 10 Main Characters by Number of Lines')\nplt.xlabel('Character name')\nplt.ylabel('Number of lines')\n\n# Show the bar plot\nplt.show()",
    "Set the max budget for the individual wordclouds\nmax_b = 100",
    "Set'token_default'space English-language'tokenizer.",
    "# Combine location data into script data\ndf_script_locations = df_script[\n    df_script['raw_location_text'].notna() & df_script['location_id'].isna()\n].merge(df_locations.add_prefix('loc_'), left_on='raw_location_text', right_on='loc_name', how='left').rename(columns={'loc_location_id': 'location_id'})\n\n# Update script data with location ids\ndf_script = df_script.merge(df_script_locations[['id', 'location_id']], on='id', how='left').fillna({'location_id': -1})",
    "# First 5 rows\ndf_characters.head()",
    "Let's check the size of these Dataframes",
    "Inspect the script data\ndf_script.head()",
    "Merge characters, locations and script\ndf_episodes = pd.read_csv('data/simpsons_episodes.csv').reset_index(inplace=False, drop=True)",
    "Create word cloud function",
    "Verify shape of the datasets\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Inspect df_script and df_episodes DataFrames\ndf_script.head()",
    " Set environment variable to specify data location\nos.environ['SIMPSONS_SCRIPT_LINE_DATA'] = 'data/simpsons_script_lines.csv'",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Display the script\ndf_script.head()",
    "Print the first 5 rows of the characters dataframe\ndf_characters.head()",
    "\ndf_script = df_script[['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text']].copy()",
    "Remove redundant columns from the dataframe",
    "Let's see the heads of the loaded dataframes.",
    "Inspect the first few rows of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Set plot style\nplt.style.use('fivethirtyeight')",
    "Custom imports",
    "Set up the print format so that we can see full dataframes rather than truncated versions\npd.set_option('display.max_colwidth', None)",
    " Preprocessing\n# Replacing NaN with np.nan\ndf_script = df_script.replace({pd.np.nan: None})",
    "Rename columns for consistency and readability\ndf_script = df_script.rename(columns={'normalized_text': 'spoken_words',\n                                      'raw_text': 'raw_spoken_words',\n                                      'timestamp_in_ms': 'timestamp',\n                                      'speaking_line': 'is_speaking_line',\n                                      'character_id': 'raw_character_id',\n                                      'location_id': 'raw_location_id'})",
    " Checking for script dataset duplicate and missing values",
    "TODO: Add description",
    "Data parallelisation, speeds up operations in pandas by splitting the data into chunks, each chunk can be processed on a different CPU core.",
    "Create a column with only the year of the episode for ease of analysis\ndf_episodes['year'] = df_episodes['original_air_date'].apply(lambda x: int(x.split('-')[0]))",
    "# Load spacy model\nnlp = spacy.load('en_core_web_sm')",
    "Let's see how the data looks like",
    "Load a large csv file in chunks for memory efficiency.\n# reading in a loop\nchunks = []\nchunksize = 10**6\nfor chunk in pd.read_csv('data/simpsons_script_lines.csv', chunksize=chunksize):\n    chunks.append(chunk)",
    " The first 3 lines of this code are meant to ensure that the spacing and the output of the dataframe are as expected.",
    "Optional: Display and explore the data to understand its structure and the available features and columns.",
    "\n# Initially show the first 5 rows of the dataframes to get an understanding of the data\nprint('Character df shape:', df_characters.shape)\nprint('Location df shape:', df_locations.shape)\nprint('Script df shape:', df_script.shape)\nprint('Episode df shape:', df_episodes.shape)",
    "Replace NaN with empty string\ndf_script = df_script.replace(np.nan, '', regex=True)",
    " Hashing of the script line text column",
    "Count lines ready for parsing",
    "# Make autocompletion work\n# Note: This is a temporary solution, the correct way to do it is by installing the plotnine package\nfrom plotnine import *",
    "Home directory\nhome = os.path.expanduser('~')\n\n# Spacy model\nnlp = spacy.load('en_core_web_sm')",
    "Setting some display options, and adding a custom color palette for plots.",
    "Estimate size of each data frame\ndf_sizes = {'characters': df_characters.memory_usage().sum(),\n            'locations': df_locations.memory_usage().sum(),\n            'script': df_script.memory_usage().sum(),\n            'episodes': df_episodes.memory_usage().sum()}\ndf_sizes",
    "Inspect the structure of the characters DataFrame",
    "Let's take a look at the data.",
    "Due to space limitations, I'll be skipping the code segment that contains repetitive assignments to dataframes",
    "Show all columns for DataFrame\npd.set_option('display.max_columns', None)",
    "Display basic information about the loaded datasets\nprint('\\nCHARACTERS')\ndisplay(df_characters.info())\ndisplay(df_characters.head(5))",
    "Show head of characters table\ndf_characters.head()",
    "Preview data\ndf_script.head()",
    "Set PATH to use the spaCy linguistic models.",
    "Preview the characters dataset\ndf_characters.head()",
    "Explore the characters dataset\ndf_characters.head()",
    "Set figure size for all matplotlib figures\nmatplotlib.rcParams['figure.figsize'] = [10, 5]",
    "Add a \"name\" column to the characters and locations dataframe for merging convenience",
    "Generating the wordcloud for an episode script line\ndef generate_wordcloud(episode_id, char_name=None, loc_name=None):\n    \"\"\"\n    Generate the wordcloud for a specific episode and an optional character and location appearing in it\n    \n    Args:\n    - episode_id: integer, identifier of the episode\n    - char_name: string, name of the character\n    - loc_name: string, name of the location\n\n    Returns:\n    - wordcloud: wordcloud object\n    - doc: spacy document\n    - counter_words: counter object\n    \"\"\"\n    # Retuning results\n    return wordcloud, doc, counter_words",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    "Check if the dataframes have been imported correctly\ndf_characters.head()",
    "Let's take a look at the data first.",
    "check whether dataframe is imported correctly",
    "Merge datasets to get a unified dataset for analysis\ndf_merged = df_script.merge(df_episodes, on='episode_id')",
    "Check the data shapes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "Remove irrelevant columns from script dataframe\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'timestamp_in_ms']]",
    "Inspecting first 3 rows of the characters DataFrame to understand the data",
    "Inspect the first few rows of each dataframe to understand the data",
    "Print the first 5 lines of the characters dataframe\nprint(df_characters.head())",
    "Change format of air_date to date and change TZ to UTC\ndf_episodes['original_air_date'] = pd.to_datetime(df_episodes['original_air_date'], errors='coerce')\ndf_episodes['original_air_date'] = df_episodes['original_air_date'].dt.tz_localize('US/Pacific').dt.tz_convert('UTC')",
    "Let's start by taking a look at the first few rows of each dataset.",
    "Check the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display first rows of the characters table\ndf_characters.head()",
    "Check if GPU is available\nimport tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))",
    "Setting to display all columns of the dataframes in the notebook\npd.set_option('display.max_columns', None)",
    "Merge datasets for a complete view of the data\ndf_complete = df_script.merge(df_episodes, how='left', on='episode_id')\ndf_complete = df_complete.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character')).drop(['id_script', 'id_character'], axis=1)\ndf_complete = df_complete.merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('_character', '_location')).drop(['id_character', 'id'], axis=1)",
    "Display the first few rows of the dataframe to understand its structure\ndf_script.head()",
    "Merge character & location into scripts dataframe\ndf_script = df_script.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id', suffixes=('', '_character'))\ndf_script = df_script.merge(df_locations[['id', 'name']], left_on='location_id', right_on='id', suffixes=('', '_location'))",
    "Inspect characters DataFrame\ndf_characters.head()",
    "Reformat script\ndf_script['timestamp_in_ms'] = pd.to_numeric(df_script['timestamp_in_ms'], errors='coerce')\ndf_script['timestamp_in_seconds'] = df_script['timestamp_in_ms'] / 1000\ndf_script['timestamp_in_minutes'] = df_script['timestamp_in_seconds'] / 60",
    " Merging script with characters and locations\ndf_script_chars = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_script', '')).drop(columns='id')\ndf_script_loca = df_script_chars.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_script', '')).drop(columns='id')",
    "Display the dataframe about characters in the Simpsons",
    "#Limiting characters and locations data to what is available in the script\nvalid_characters = df_script.character_id.unique()\ndf_characters = df_characters[df_characters.character_id.isin(valid_characters)]\nvalid_locations = df_script.location_id.unique()\ndf_locations = df_locations[df_locations.location_id.isin(valid_locations)]",
    " Preview the characters dataset\ndf_characters.head()",
    "Create lists from the dataframes to transfer more complex df operations to SQL in order to improve speed",
    "Merge script and episode data\ndf_script = df_script.merge(df_episodes, on='episode_id')\n\n# Display the merged dataset\ndf_script.head()",
    "Creation of the spacy model\nnlp = spacy.load('en_core_web_sm')",
    " print the dataframe columns\nprint(df_characters.columns)\nprint(df_locations.columns)\nprint(df_script.columns)\nprint(df_episodes.columns)",
    "Join script lines and characters\ndf_char_lines = pd.merge(df_script, df_characters, on='character_id', how='left')",
    " Display the first 10 rows of each DataFrame\ndf_characters.head(10)",
    "Optional: Disable warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
    "Check if GPU is available\n# torch.cuda.is_available()",
    "Let's take a look at the first few rows of each data frame.",
    "Set the default style of the plots\nmatplotlib.style.use('ggplot')",
    "Displaying 10 random rows from the script dataframe\ndf_script.sample(10)",
    "Filtering out of the dataframe to only retain the useful columns",
    " Concatenate script and episode data_frames\ndf = pd.concat([df_script, df_episodes], axis=1, keys='episode_id', join='inner')",
    "Setting Python to print a large number of columns\npd.options.display.max_columns = 50",
    "The first few lines of code above are importing necessary libraries and packages. After this, the code loads data from CSV files into pandas dataframes for further processing and analysis.",
    "Check the size of each dataset\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Filtering the seasons that only consider episodes of the TV show, and not others.",
    "I disabled the warning about the settingwithcopywarning.",
    "Display the header of the characters DataFrame\ndf_characters.head()",
    "# Joining dataframes\ndf_episodes['id'] = df_episodes['id'].astype(int)\ndf_script['episode_id'] = df_script['episode_id'].astype(int)\n\ndf = pd.merge(df_script, df_episodes, left_on='episode_id', right_on='id', suffixes=('_script', '_episodes'))\ndf = df[['id_script', 'episode_id', 'number', 'raw_text', 'timestamp_in_seconds',\n         'id_episodes', 'title', 'original_air_date', 'production_code', 'season', 'number_in_season',\n         'number_in_series', 'us_viewers_in_millions', 'views', 'imdb_rating', 'imdb_votes']]",
    "Lets check how the data looks like.",
    "Visualize some example data.",
    "Merge the datasets to get all relevant information in one dataframe",
    "Display top 3 rows of each dataframe\ndf_characters.head(3)",
    "Filter scripts to avoid using too much memory on temporary data\ndf_script_filtered = df_script[['episode_id', 'character_id', 'location_id', 'spoken_words']].copy()",
    "Explore the contents of the dataframes",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Inspect the first few rows of the characters dataframe\nprint(df_characters.head())",
    "View information of key tables\nprint('Characters')\ndisplay(df_characters.info())\ndisplay(df_characters.head())\n\nprint('Locations')\ndisplay(df_locations.info())\ndisplay(df_locations.head())",
    " Check the first few rows of the characters dataframe\ndf_characters.head()",
    "# Function to display the wordcloud\ndef plot_wordcloud(wordcloud):\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")",
    " Display the first five rows of the characters DataFrame\ndf_characters.head()",
    " Import necessary spacy models and libraries",
    "Check the number of records\nprint(\"Number of records in characters dataset:\", len(df_characters))\nprint(\"Number of records in locations dataset:\", len(df_locations))\nprint(\"Number of records in script dataset:\", len(df_script))\nprint(\"Number of records in episodes dataset:\", len(df_episodes))",
    " Preprocess script lines dataframe",
    "Checking the data shape and the headers",
    "Set seed for reproducibility",
    "Look at the structure of the Simpsons dataset",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Look at the first few records of the characters dataframe\ndf_characters.head()",
    "Preview the datasets\nprint(\"\\nPreview of 'simpsons_characters.csv'\")\nprint(df_characters.head())\nprint(\"\\nPreview of 'simpsons_locations.csv'\")\nprint(df_locations.head())\nprint(\"\\nPreview of 'simpsons_script_lines.csv'\")\nprint(df_script.head())\nprint(\"\\nPreview of 'simpsons_episodes.csv'\")\nprint(df_episodes.head())",
    "# Getting just the fields we are interested in\ndf_script = df_script[['episode_id', 'character_id', 'location_id', 'raw_text']]",
    "# Filter out the data with invalid episode_id\nvalid_episode_ids = set(df_episodes.id)\ndf_script = df_script[df_script['episode_id'].isin(valid_episode_ids)].reset_index(drop=True)",
    "# Setting up paths\ninput_filepath = 'data/simpsons_script_lines.csv'\noutput_filepath = 'data/simpsons_preprocessed_lines.csv'",
    "Now let's take a look at the content of each CSV file.",
    "\ndf_script.head()",
    "begin by loading the datasets",
    "Declare tasks using TQDM\ntqdm.pandas()",
    "Print the head of the dataframe containing the script lines.",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Explore the data\npd.set_option('display.max_columns', None)",
    "Merge datasets to simplify analysis",
    " Explore the structure of the data\ndf_script.head()",
    " For better performance, just use the latest 1000 lines of the script for now\ndf_script = df_script.loc[:1000]",
    "Get the most common utterances (which character speaks which words)",
    "Ensuring the PI works well in Jupyter for Matplotlib rebinding the\n# show() function to bypass the one provided by Jupyter\ndef show():\n   plt.show()",
    "Let's take a look at the first few script lines.",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Creating a corpus of documents, we select some particular collection of documents as our data source.",
    "Display the first 5 rows of each dataframe\nprint(df_characters.head(5))\nprint(df_locations.head(5))\nprint(df_script.head(5))\nprint(df_episodes.head(5))",
    " Visualise the top 10 characters by number of spoken words\ndf_script.groupby(\"character_id\")[\"word_count\"].sum().nlargest(10).sort_values().plot(kind=\"barh\", color=\"skyblue\")\nplt.xlabel(\"Number of words\")\nplt.title(\"Top 10 Characters by Number of Spoken Words\")\nplt.show()",
    "Inspect the data structure and contents to understand the data better",
    " Set the style of graphs to 'ggplot' for better visuals\nplt.style.use('ggplot')",
    "Merge the script and the character datasets\ndf_characters = df_characters.rename(columns=lambda x: \"character_\" + x)\ndf_script = pd.merge(df_script, df_characters, left_on=\"character_id\", right_on=\"character_id\", how='left')\n\n# Merge the script and the location datasets\ndf_locations = df_locations.rename(columns=lambda x: \"location_\" + x)\ndf_script = pd.merge(df_script, df_locations, left_on=\"location_id\", right_on=\"location_id\", how='left')",
    " Load model from spacy\nnlp = spacy.load('en_core_web_sm')\n\n# Spacy pipeline\nnlp.add_pipe('sentencizer')",
    " GloVe embeddings\nembeddings_index = {}\nf = open(os.path.join('data/glove.6B.100d.txt'), encoding=\"utf-8\")\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()",
    "Let's take a look at the first few rows of each dataset to understand what information is available.",
    "Join scripts with characters and locations\ndf_script = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\ndf_script = pd.merge(df_script, df_locations, how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))",
    "Check                               filenames\nfor eachfilename in os.listdir('data'):\n    print(eachfilename)",
    "Explicitly set encoding for docstring compatibility\ndf_characters = pd.read_csv('data/simpsons_characters.csv', encoding='utf-8').reset_index(drop=True)",
    "Create a dictionary that maps episode_id to episode\nepisode_dict = dict()\nfor index, row in df_episodes.iterrows():\n    episode = dict(row)\n    episode_dict[episode['id']] = episode",
    "Let's take a peak at some of the data.",
    "Drop unused columns\ndf_characters = df_characters.drop(columns=['id'])\ndf_locations = df_locations.drop(columns=['id'])\ndf_script = df_script.drop(columns=['id', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_text'])\n\n# Print the DataFrame shape\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    " Display our imported data\nprint('Characters')\ndisplay(df_characters.head(3))\nprint('Locations')\ndisplay(df_locations.head(3))\nprint('Episodes')\ndisplay(df_episodes.head(3))\nprint('Script')\ndisplay(df_script.head(3))",
    "Building dataset from these input dataframes.",
    "Display each table\nprint('Simpsons Characters')\ndisplay(df_characters.head())\n\nprint('Simpsons Locations')\ndisplay(df_locations.head())\n\nprint('Simpsons Scripts')\ndisplay(df_script.head())\n\nprint('Simpsons Episodes')\ndisplay(df_episodes.head())",
    "Data Exploration",
    "Check if the data has been read correctly\ndf_characters.head()",
    "Let's see how the characters dataset looks like\ndf_characters.head()",
    "Remove other voice and change NaN values to Unknown and a unknown values\ndf_script = df_script[(df_script[\"raw_text\"].str.startswith('(') == False)]\ndf_script = df_script.fillna('Unknown')\ndf_script = df_script[df_script['spoken_words'] != 'Unknown']",
    "Preview the first dataset to get an idea\ndf_characters.head()",
    " Expand the max column width to display the entire script line\npd.set_option('display.max_colwidth', None)",
    "Create an instance of the WordCloud class.",
    " Merge some dataframes to be used later on\ndf = df_script.merge(df_characters, how='inner', on='character_id')\ndf = df.merge(df_locations, how='inner', on='location_id')\ndf = df.merge(df_episodes, how='left', on='episode_id')\n\n# Show first rows\ndf.head()",
    "Let's print the first 2 rows of these DataFrames to get an idea of their structure.",
    "Let's display the first few rows of each dataframe to understand the data better.",
    "Set the stopwords and create the word cloud.",
    " Check of the data\nprint(df_episodes.head())\nprint(df_script.head())",
    "Check the data\ndf_characters.head()",
    "Exploring the core data selected for analysis & sentiment analysis -\ndf_script.head(5), df_characters.head(5), df_locations.head(5)",
    "Format and display the script data\ndf_script.head()",
    " View the first 5 rows of the characters DataFrame\ndf_characters.head()",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Load the Spacy model for English language\nnlp = spacy.load(\"en_core_web_sm\")",
    "Aggregating data on main locations and main characters\ndf_script_characters = df_script[df_script.raw_character_text.notnull()]\ndf_script_characters = df_script_characters.merge(\n    df_characters[['id', 'normalized_name', 'gender']],\n    left_on='raw_character_text', right_on='normalized_name',\n    how='left')",
    " Creating a single dataframe from the simpsons lines and episodes dataframes",
    "Show first row of data\ndf_characters.head(1)",
    " You can install or update required packages as per the context.",
    "Count the number of missing values in each column of df_script\ndf_script.isnull().sum()",
    " Optionally, limit the number of script lines for faster performance\n# df_script = df_script[:5000]",
    "Display the scripts DataFrame\ndf_script.head()",
    " Show head of the characters dataframe\ndf_characters.head()",
    " Display the first 10 rows of the characters dataframe\ndf_characters.head(10)",
    "Preprocessing\n# We first need to see what the data looks like.",
    " Tokenize the documents",
    "Load spaCy model\nnlp = spacy.load('en_core_web_md')",
    " Keep track of original length\nlen_original = len(df_script)",
    "Check the dataframes contents\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Extract information about the characters",
    "Visualize columns info\ndf_characters.head(3)",
    "Join tables by episode_id and get the main characters\ndf = pd.merge(\n    df_script,\n    # Get main characters per episode\n    (\n        df_script[df_script.raw_character_text.str.len() > 0]\n        .groupby('episode_id')\n        .agg({\n            'raw_character_text':\n            lambda x: Counter(x).most_common()[0][0]\n        })\n        .reset_index()\n    ),\n    on='episode_id'\n)\n\ndf = pd.merge(\n    df,\n    df_episodes,\n    on='episode_id'\n)",
    "Make sure we always call `reset_index` with `inplace=False` and ignore the warning",
    " Split the text in a list of words\nwords = script_lines[1].str.split(\" \")",
    "Setting up Spacy\n# For illustrative purposes, we will only look at the first 10000 script lines.\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Here we use parallelization to make the Spacy NLP tests faster\ntqdm.pandas()",
    " 10 first rows\ndf_characters.head(10)",
    " Let's take a look at the first few rows of each dataframe to understand their structure and contents.",
    "Save path to get product of current working directory and folder the script is placed in.",
    " Let's start by inspecting the structure of the dataframes.",
    " Define constant colors\ncolors = {\n    'red': '#FF5733',\n    'light red': '#FF8566',\n    'green': '#59955C',\n    'blue': '#3559FF',\n    'yellow': '#E5CC00',\n    'light yellow': '#FFEB4D',\n    'secondary blue': '#33CCFF',\n    'purple': '#A239CA',\n    'orange': '#FF8C1A',\n    'black': '#1A1A1A',\n    'dark grey': '#333333',\n    'grey': '#808080',\n    'light grey': '#B3B3B3',\n    'white': '#FFFFFF'\n}",
    "ensure matplotlib works correctly with Jupyter\n%matplotlib inline",
    " Ensure that all datasets have loaded correctly\nprint(f'Characters data shape: {df_characters.shape}')\nprint(f'Locations data shape: {df_locations.shape}')\nprint(f'Script data shape: {df_script.shape}')\nprint(f'Episodes data shape: {df_episodes.shape}')",
    " Display the first rows of the dataframe\npd.set_option('display.max_columns', None)",
    "Let's check the first few rows of each dataframe to understand its structure.",
    "Create is_simpsons column, filter and subset script lines",
    "Join the script with episodes and select a few basic columns\ndf = df_script.merge(df_episodes, on='episode_id')",
    "Merge the script lines with the episode info\ndf = pd.merge(df_script, df_episodes, on='episode_id')",
    "Initialize the SpaCy model\nnlp = spacy.load('en_core_web_sm')",
    " Merge dataset on character id, location id, and episode id",
    "The head method can be used to display the first few rows of the dataframe.\n# Display the first 10 rows of the dataframe\ndf_episodes.head(10)",
    " The top few rows of the character dataset\nprint(df_characters.head())",
    "Merge the script lines with episodes' details, characters, and locations.",
    "Loading the CSV files and resetting the index to ensure the data is correctly loaded and indexed.",
    "gallery of Simpson's character\ndf_characters.head()",
    "display first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Let's take a look at what we're dealing with in each case",
    "Display the first few rows of each dataframe to understand the data",
    " Check the first 5 rows of the \"Simpsons Characters\" dataset\ndf_characters.head()",
    "remove all redundant data in the script data\nscript_reduced_columns = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]\nscript_reduced_columns = script_reduced_columns.dropna()\n\nscript_merged = pd.merge(script_reduced_columns, df_characters, left_on='character_id', right_on='id')\nscript_merged = pd.merge(script_merged, df_locations, left_on='location_id', right_on='id')\n\nscript_merged = script_merged[['episode_id', 'number', 'raw_text', 'character_id', 'location_id', 'normalized_name_x', 'name_x', 'normalized_name_y', 'name_y']]\nscript_merged.columns = ['episode_id', 'number', 'raw_text', 'character_id', 'location_id', 'character_name_normalized', 'character_name', 'location_name_normalized', 'location_name']\n\nscript_merged[:5]",
    "display the first few rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "from datetime import datetime",
    " Some dataframes are too large, and loading them temporarily consume a lot of memory.\n# print(df_characters.head())\n# print(df_locations.head())\n# print(df_script.head())\n# print(df_episodes.head())",
    "Showing the dataframe shape\nprint ('Characters dataframe shape: {}'.format(df_characters.shape))\nprint ('Locations dataframe shape: {}'.format(df_locations.shape))\nprint ('Script dataframe shape: {}'.format(df_script.shape))\nprint ('Episodes dataframe shape: {}'.format(df_episodes.shape))",
    "Preprocessing function",
    "let's explore data provided.",
    "Show the first few rows of each dataframe to get an overview of the data",
    " Load the spaCy model\nnlp = spacy.load('en_core_web_md')",
    "Set pandas to display wide columns\npd.set_option('display.max_colwidth', None)",
    "Checking the head of the dataframe",
    "Display the first few rows of each dataframe to understand the data",
    "Display the first few rows of the script dataframe\ndf_script.head()",
    "# Check data content\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Let's take a look at the structure of the dataframes.",
    "Optional: Display the first few rows of each DataFrame to check the data",
    "Look at the first 5 rows of each dataframe\ndf_script.head(), df_characters.head(), df_locations.head(), df_episodes.head()",
    "Read Data\n# Set configurations\npd.set_option('display.max_colwidth', 100)\npd.set_option('display.max_columns', None)",
    "View the structure of one of the DataFrames\ndf_script.head()",
    " Settings for pretty print\nnp.set_printoptions(suppress=True)\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)",
    "Inspect each dataframe to understand its structure and content",
    "Merge dataframes",
    " Display the first few rows of the dataframe\ndf_characters.head()",
    " Check what's in the dataframes",
    "Set the script line ID as the index for easy retrieval of script lines",
    "Inspect the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Remove the first four columns from  `df_script` since they are redundant.",
    "Creating the word cloud for the most common words in the script lines",
    "We will display our dataset here",
    "to-do: combine dataframes",
    "Display basic info about the script dataframe\ndf_script.info()",
    "Inspect the content of the script dataset.",
    "checking the first few rows of the characters dataframe\ndf_characters.head()",
    "# Ensure the data has been imported correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "let's display the firt few rows of each dataframe to understand its structure.",
    "To ensure the data has been loaded correctly, we can use the `head()` function to display the first few rows of each DataFrame.",
    "# Merge script with characters and locations\ndf_script_characters = df_script.merge(df_characters, on='character_id')\ndf_script_characters_locations = df_script_characters.merge(df_locations, on='location_id')\n\n# Remove unwanted columns\ndf_script_characters_locations = df_script_characters_locations.drop([\n    'number',\n    'raw_text',\n    'timestamp_in_ms',\n    'speaking_line',\n    'character_id',\n    'location_id'\n], axis=1)",
    "Look at the first 5 script lines",
    " Display the first 5 rows of the characters DataFrame\ndf_characters.head()",
    "# Display statues and quantities\nprint('Data statues:')\nprint(f' - Characters: {df_characters.shape[0]}')\nprint(f' - Locations: {df_locations.shape[0]}')\nprint(f' - Script lines: {df_script.shape[0]}')\nprint(f' - Episodes: {df_episodes.shape[0]}')",
    "Inspect the content of the `characters` dataframe",
    "View data head\ndf_script.head()",
    "Merging the script and episode dataframes by the 'episode_id' column\ndf_merged = df_script.merge(df_episodes, on='episode_id')",
    "nlp = spacy.load(\"en_core_web_sm\")",
    "Let's start by taking a look at the first few rows of each dataframe.",
    "Remove any bad data points.",
    "Inspect the dataframes",
    "# Add separator for widely supported version info\n__pipeline = spacy.blank(\"en\")\n__pipeline.config[\"nlp\"][\"tokenizer\"][\"use_wildcard_tokenizer\"] = False",
    "Look at the content of each file.",
    "We can see the top of each dataframe by using the .head display method.",
    "Check the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Check the imported data\nprint(\"Characters data\")\nprint(df_characters.head())\nprint(\"Locations data\")\nprint(df_locations.head())\nprint(\"Script data\")\nprint(df_script.head())\nprint(\"Episodes data\")\nprint(df_episodes.head())",
    "Image folder\nIMG_FOLDER = 'images'",
    "# Functions for later\ndef get_character_name_from_id(char_id):\n    \"\"\"\n    Function to extract the name of a character from his ID\n    \"\"\"\n    return df_characters[df_characters.character_id == char_id]['name'].values[0]\n\ndef get_location_name_from_id(loc_id):\n    \"\"\"\n    Function to extract the name of a location from its ID\n    \"\"\"\n    return df_locations[df_locations.location_id == loc_id]['name'].values[0]",
    "# For this notebook, we are going to look at the script DataFrame\ndf_script.head()",
    "# Helper class to create a dataset\nclass Dataset:\n    script_columns = ['id', 'episode_id', 'number', 'raw_text', 'timestamp_in_ms',\n                      'speaking_line', 'character_id', 'location_id', 'raw_character_text',\n                      'raw_location_text', 'spoken_words', 'normalized_text', 'word_count']\n\n    character_columns = ['id', 'name', 'normalized_name', 'gender']\n\n    location_columns = ['id', 'name', 'normalized_name']\n\n    episode_columns = ['id', 'title', 'original_air_date', 'production_code',\n                       'season', 'number_in_season', 'number_in_series',\n                       'us_viewers_in_millions', 'views', 'imdb_rating', 'imdb_votes']\n\n    def __init__(self, episodes_df, characters_df, locations_df, script_df):\n        self.episodes_df = episodes_df\n        self.characters_df = characters_df\n        self.locations_df = locations_df\n        self.script_df = script_df\n        self.script_df['normalized_text'] = self.script_df.normalized_text.astype(str)",
    "Display the loaded dataframes\ndf_characters",
    "\nscript_simpsons = df_script.copy()",
    " Show first rows of the characters dataset\ndf_characters.head()",
    "Let's see what's inside the skript data.",
    " Set context\n# I usually do it in this way to not mess with the original df\ndf = df_script",
    "Display all the imported csv files",
    " Change index of all the dataframes to id of each corresponding entry\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "Check the first 5 rows of the characters dataframe.",
    " ensure every dataframe has an 'id' column\ndf_characters['id'] = df_characters.index\ndf_locations['id'] = df_locations.index\ndf_script['id'] = df_script.index\ndf_episodes['id'] = df_episodes.index",
    "Fixing the index of episodes due to the duplicate indexes",
    "Cleaning up the mess from the stupid Pandas.",
    " Reformat dataframe to have a consistent '_id' column\ndf_characters['_id'] = df_characters['id']\ndf_locations['_id'] = df_locations['id']\ndf_script['_id'] = df_script['id']\ndf_episodes['_id'] = df_episodes['id']\n\n# Set the indices to '_id'\ndf_characters.set_index('_id', inplace=True)\ndf_locations.set_index('_id', inplace=True)\ndf_script.set_index('_id', inplace=True)\ndf_episodes.set_index('_id', inplace=True)",
    " Show the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Display the first 3 rows of the characters dataframe\ndf_characters.head(3)",
    "Display all columns\npd.set_option('display.max_columns', None)",
    "Let's take a look at the first few rows of each DataFrame.",
    "Functions\ndef get_top_n_words(corpus, n=None):\n    vec = CountVectorizer(stop_words='english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]",
    " optional: inspect the datasets\ndf_characters.head()",
    "Check the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Checking the structure of the four datasets",
    "View the content of each dataset\ndf_characters.head()",
    "Selecting the seasons that we want to keep\ndf_episodes = df_episodes[df_episodes.season <= 12]\n\n# Merging the characters, locations and episodes with the script\ndf_simpsons = pd.merge(df_script, df_episodes, how='left', on='episode_id')\ndf_simpsons = pd.merge(df_simpsons, df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character'))\ndf_simpsons = pd.merge(df_simpsons, df_locations, how='left', left_on='location_id', right_on='id', suffixes=('_script', '_location'))",
    "Inspect the dataframe about the script lines",
    "Set seed for reproducibility\nnp.random.seed(0)",
    "Sometimes, the data from the csv might have excessive blank spaces, it is good practice to remove leading and trailing whitespace from your pandas dataframe.",
    "Display the first 5 rows of the episodes dataframe\ndf_episodes.head()",
    "Remove unnecesasry columns",
    "print('Loaded {:,} characters, {:,} locations, {:,} episodes, and {:,} script lines'.format(\n    len(df_characters), len(df_locations), len(df_episodes), len(df_script)\n))",
    " Display the first few rows of the characters DataFrame\ndf_characters.head()",
    " Check the content of the characters dataframe\ndf_characters.head()",
    "Preview the first few rows of the characters dataframe\ndf_characters.head()",
    "Word cloud of the simpsons locations",
    "Inspect the data frames to understand their structure and contents\ndf_characters.head()",
    "Check if the dataframes are loaded correctly",
    " Merge simpsons_script_lines with simpsons_episodes and simpsons_characters\ndf_script['id'] = range(df_script.shape[0])\ndf_episodes_script = pd.merge(df_script, df_episodes, on=\"episode_id\")\ndf_episodes_script_characters = pd.merge(df_episodes_script, df_characters, left_on=\"raw_character_text\", right_on=\"name\")",
    "60*'#'",
    "Displays the first 5 records in the characters dataframe.",
    "Inspect the first few rows of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Load the data and display the first few rows to understand the structure of the data\ndf_characters.head()",
    "Just checking if the data loaded properly",
    "Extracting main characters\nmain_characters = df_characters[df_characters['is_main_cast']]\nprint(main_characters)",
    "Fining the episode_title and corresponding  animation_frame for each line in df_script.\ndf_script = df_script.merge(\n    df_episodes[['id', 'title', 'original_air_date']],\n    left_on='episode_id',\n    right_on='id',\n    suffixes=('', '_episode')\n)",
    "New column containing the number of characters in each line\ndf_script['n_characters'] = df_script.raw_text.str.len()",
    " Display the first 5 rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Create a copy of the columns that will be modified",
    "We then split our dataset into two, an 80% subset for training and a 20% subset for testing.",
    "Exploratory data analysis",
    "Show the first few lines of the script data\ndf_script.head()",
    " Test\ndf_characters.head()",
    "This code snippet shows the necessary imports and data loading for a data analysis project on Simpsons TV show. The code uses pandas to load CSV files into dataframes and then performs some initial data processing.",
    "Merge script with episodes and characters\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', how='left', suffixes=('', '_character'))\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id', how='left', suffixes=('', '_location'))",
    "Preview all dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect the characters dataframe to understand its structure and columns\nprint(df_characters.head())\n# List unique values in the df_characters dataframe, and count the number of unique characters\nprint(df_characters.nunique())",
    "Show all table and column names\nprint(\"\\nCharacters Table\")\nprint(df_characters.dtypes)\nprint(df_characters.head(3))\nprint(\"\\nLocations Table\")\nprint(df_locations.dtypes)\nprint(df_locations.head(3))\nprint(\"\\nScript Table\")\nprint(df_script.dtypes)\nprint(df_script.head(3))\nprint(\"\\nEpisodes Table\")\nprint(df_episodes.dtypes)\nprint(df_episodes.head(3))",
    "Select the columns of interest and remove any potential NAs",
    "Drop unnecessary columns\ndf_characters = df_characters.drop(columns=['image_url'])\ndf_locations = df_locations.drop(columns=['image_url'])\ndf_episodes = df_episodes.drop(columns=['image_url'])",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Checking for correct import and dataframe display",
    "Preview the dataframes",
    " Displaying the head of the characters dataframe\ndf_characters.head()",
    "Have a quick look at the dataframes\ndf_characters.head(3)",
    "Path to Simpsons dataset\npath = \"/content/drive/MyDrive/Colab Notebooks/NLP/simpsons/\"\n\n# Visualize dataset\nprint(\">> Raw datasets:\")\nprint(f\"df_characters: {df_characters.shape}\")\nprint(f\"df_locations: {df_locations.shape}\")\nprint(f\"df_script: {df_script.shape}\")\nprint(f\"df_episodes: {df_episodes.shape}\")",
    "Select only Homer's lines \ndf_homer = df_script[df_script.character_id == 2]",
    "Display all columns of the script dataframe to visualise what information is available\npd.set_option('display.max_columns', None)\ndf_script.head()",
    "Show the first 5 rows of the script dataframe\ndf_script.head()",
    "Check the content of all tables to see if everything is consistent",
    "Get an idea of the structure of the data\nprint(f'Characters  : {df_characters.shape}')\nprint(f'Locations   : {df_locations.shape}')\nprint(f'Script      : {df_script.shape}')\nprint(f'Episodes    : {df_episodes.shape}')",
    " Some basic exploration of the datasets",
    "display first 5 records of the characters table\ndf_characters.head()",
    " Check the three datasets\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())",
    "Since the error is regarding the format the above code is correct.",
    " Merge episodes in each dataframe for consistency",
    " graphical preferences\nmatplotlib.rcParams['figure.figsize'] = (10.0, 5.0)",
    " cleaned data (removed 'number' column, since it's already the index)",
    "Transform character_id, location_id and episode_id to integers for every line\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce').fillna(0).astype(np.int64)\ndf_script['location_id'] = pd.to_numeric(df_script['location_id'], errors='coerce').fillna(0).astype(np.int64)\ndf_script['episode_id'] = pd.to_numeric(df_script['episode_id'], errors='coerce').fillna(0).astype(np.int64)",
    "subset_columns\u0012=['normalized_text', 'episode_id', 'character_id', 'location_id']",
    "Let's take a look at the structure of our data.",
    "Split location / raw_text.attrib_cleaned characters from script_lines\ndf_loc_identifier_script = df_script\\\n.merge(df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_loc')).drop(columns=['id','normalized_name','image_url'])\\\n.merge(df_characters, left_on='character_id', right_on='id', suffixes=('_loc', '_char')).drop(columns=['id','normalized_name','image_url'])",
    "Check for corrupted data\ndf_script.info()",
    "Prints to make sure everything is working properly.\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Infer the list of seasons based on the script\nseasons = sorted(df_script['raw_text'].map(lambda x: int(x.split('_')[1])).unique())\nseasons",
    "Check the first 5 rows of the characters dataframe.",
    " Length of dataframes\nlen(df_characters), len(df_locations), len(df_script), len(df_episodes)",
    "Looks good! Now we can continue with our analysis.",
    " Print the first 5 entries in the characters dataframe\ndf_characters.head()",
    "Display available columns for each dataset\nprint(df_characters.columns)\nprint(df_locations.columns)\nprint(df_script.columns)\nprint(df_episodes.columns)",
    "Checking the first few rows of data to understand the structure and content of the datasets.",
    "Remove unwanted columns from the dataframes",
    "Display the first 5 rows of the episodes dataframe\ndf_episodes.head()",
    " Display dimension of datasets\nprint(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
    " inline matplotlib\nmatplotlib.rcParams['figure.figsize'] = (13, 7)",
    "# Display basic information about the loaded datasets\nfor df, name in zip([df_characters, df_locations, df_script, df_episodes], \n                    ['Characters', 'Locations', 'Script', 'Episodes']):\n    print(f'Dataset: {name}\\n')\n    print(df.info())\n    display(df.head(5))\n    print('\\n' + '='*90 + '\\n')",
    "Variable declaration\nnlp = spacy.load(\"en_core_web_sm\")\n\ntqdm.pandas()",
    "Display first five rows of the characters dataframe\ndf_characters.head()",
    "Insights\n# Let's take a closer look at the episodes first.",
    "Check for missing values\ndf_script.isna().sum()",
    "Preview the episodes data\ndf_episodes.head()",
    "Display the first few rows of each DataFrame to understand the data",
    "matplotlib.rcParams.update({'font.size': 22})",
    " Displaying only the first 1000 records for performance reasons\ndf_script = df_script.head(1000)",
    "Display 5 rows of the dataframe to check if the data is loaded successfully.",
    " Filter the script to keep only the dialogue lines",
    " Join the characters and script dataframes with the script data.",
    "Do the join on the dataframes",
    "Filter out non-dialogue lines",
    " View a sample of the data in df_characters\ndf_characters.head()",
    "Setting up the model and analyzing the script data",
    "Set text variable and create a word cloud.",
    "Ensure the correct data types for each column",
    "Visualisationgies\nfontsize, collocations=False, random_state=42).generate_from_frequencies(word_freq)\nplt.figure(figsize=(12,10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()",
    "Inspect structure of each DataFrame\ndf_characters.info(), df_locations.info(), df_script.info(), df_episodes.info()",
    "Display the first 5 records of the characters dataframe\ndf_characters.head()",
    "Preprocess data\ndf_script = df_script[df_script['timestamp_in_ms'] < 6.0e+10]  # Filter out bad data\ndf_script = df_script[(df_script['character_id'] != 2) &  # Remove speaker 'None'\n                      (df_script['character_id'] != 1)]",
    "Counting the number of words in the script line and storing the count in a separate column",
    " Display first rows of the scripts dataframe\ndf_script.head()",
    "ner.load('en_core_web_sm')",
    "Check the dataframes\nprint(\"Characters dataframe\")\nprint(df_characters.head())\nprint()\nprint(\"Locations dataframe\")\nprint(df_locations.head())\nprint()\nprint(\"Episodes dataframe\")\nprint(df_episodes.head())\nprint()\nprint(\"Script dataframe\")\nprint(df_script.head())",
    "We have loaded the necessary libraries and datasets for our Simpsons script analysis. Now we can proceed with data exploration, cleaning, and analysis.",
    "Df at glance\ndf_script.head()",
    "Create a useful directory structure",
    " Explore the content of the characters' dataframe\ndf_characters.info()",
    " Print the first 5 elements of the characters dataframe\ndf_characters.head()",
    "Check the columns that we currently have in the script dataframe",
    "Extract main characters\nmain_characters = [\n    \"marge\", \"bart\", \"homer\", \"lisa\", \"maggie\",\n    \"kirk\", \"otto\", \"duffman\", \"selma\", \"patty\",\n    \"milhouse\", \"krusty\", \"apu\", \"moe\", \"carl\",\n    \"lenny\", \"ned\", \"cletus\", \"barney\", \"ralph\",\n    \"wiggum\", \"skinner\", \"hibbert\", \"frink\", \"snake\",\n    \"burns\", \"nelson\", \"edna\", \"rod\", \"todd\",\n    \"lovejoy\", \"apu\", \"frink\", \"fat tony\", \"duff\",\n    \"flanders\", \"bob\", \"artie\", \"sanjay\", \"ruth\",\n    \"sideshow\", \"tahiti bob\", \"tahiti bob\", \"disco stu\", \"wiggum\",\n    \"skinner\", \"krustofski\", \"lampwick\", \"krusty\", \"mccallister\", \n    \"lenford\", \"leopold\", \"selma\", \"patty\", \"shary\", \"edna\",\n    \"horatio\", \"junun\", \"roscoe\", \"chase\", \"chase\", \"thompson\", \n    \"frederick\", \"harvest\", \"eve\", \"martha\", \"lou\"\n]",
    "Encode the text data to UTF-8 to handle any special characters\ndf_characters = df_characters.apply(lambda x: x.astype(str).str.encode('utf-8', errors='ignore').str.decode('utf-8'))\ndf_locations = df_locations.apply(lambda x: x.astype(str).str.encode('utf-8', errors='ignore').str.decode('utf-8'))\ndf_script = df_script.apply(lambda x: x.astype(str).str.encode('utf-8', errors='ignore').str.decode('utf-8'))\ndf_episodes = df_episodes.apply(lambda x: x.astype(str).str.encode('utf-8', errors='ignore').str.decode('utf-8'))",
    "Merge the script with characters and locations",
    "Extract the first 1000 lines of the script for analysis\ndf_first_1000_lines = df_script.iloc[:1000]",
    " Show the first few rows of the dataframe \"df_script\"\ndf_script.head()",
    "Display the first few rows of each dataframe to understand their structure\nprint('Characters:')\ndisplay(df_characters.head())\n\nprint('Locations:')\ndisplay(df_locations.head())\n\nprint('Script:')\ndisplay(df_script.head())\n\nprint('Episodes:')\ndisplay(df_episodes.head())",
    "Preview the episodes dataframe\ndf_episodes.head()",
    "Merge all the datasets based on the common column (id)",
    " Set the right variable types for each column",
    "Look at the data table for characters\ndf_characters.head()",
    "Remove rows where the `ding_count` column is greater than 0",
    "Basic sanity checks",
    "create dictionary for character locations\ncharacter_to_locations = {}\n\nfor i, row in df_script.iterrows():\n    # If character hasn't been added to the dictionary yet, add it\n    if row['raw_character_text'] not in character_to_locations.keys():\n        character_to_locations[row['raw_character_text']] = []\n    \n    # If character location hasn't been added to the list yet, add it\n    if row['raw_location_text'] not in character_to_locations[row['raw_character_text']]:\n        character_to_locations[row['raw_character_text']].append(row['raw_location_text'])",
    "Merge data and visualize the counts of character mentions in the script data\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')\ndf_script = df_script.merge(df_characters, on='character_id', how='left')\nchar_mention_cnts = df_script['name'].value_counts()\n\nplt.bar(char_mention_cnts.index, char_mention_cnts.values)\nplt.xlabel('Character Name')\nplt.ylabel('Number of Mentions')\nplt.title('Number of Mentions of Each Character in the Script')\nplt.xticks(rotation=90)\nplt.show()",
    "Join the scripts with the character names and get rid of the other foreign columns.",
    "Display the character dataframe\ndf_characters",
    "Leave this cell to display images in notebook\nmatplotlib.rcParams['figure.figsize'] = (10, 10)",
    "Check out the first few rows of our datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Display the head of the characters dataframe\ndf_characters.head()",
    "Check the structure of the dataframes\ndf_characters.head()",
    " Check the imported datasets\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Display the head of each dataframe to verify data was loaded correctly",
    "Inspect the first few rows of each dataframe to understand its structure and content\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check if script lines contain uppercase words",
    " Print header\nprint(df_episodes.head())\n\n# Prints number of lines per episode\nprint(df_script.groupby('episode_id')['id'].count())",
    "Preview data\ndf_characters.head()",
    "Displays the first few rows of the df_characters DataFrame\ndf_characters.head()",
    "Merge the data into one dataframe for better visualization",
    " Let's take a look at the first five rows of the script lines dataframe.",
    "Description of the datasets.",
    " The character that speaks the most\ndf_script['character_id'].value_counts().idxmax()",
    "Set seed for reproducibility\nnp.random.seed(0)",
    " Check data samples\ndf_characters.head()",
    "Take a look at the first rows from `df_characters` DataFrame\ndf_characters.head()",
    "Set default font size for better visualization\nfont = {'size': 11}\nmatplotlib.rc('font', **font)",
    "Join characters and locations with scripts dataframes\ndf_script_characters = pd.merge(df_script, df_characters, how='inner', left_on='character_id', right_on='id', suffixes=('_script', '_character'))\ndf_script_locations = pd.merge(df_script, df_locations, how='inner', left_on='location_id', right_on='id')",
    " Display the pandas dataframe containing the scripts of the Simpsons episodes\ndf_script",
    " Show the first rows of the characters data frame\ndf_characters.head()",
    "Display all columns of a dataframe\npd.set_option('display.max_columns', None)",
    "Check the number of rows in each data frame\ndf_shape = {\n    \"Episodes\": df_episodes.shape,\n    \"Script\": df_script.shape,\n    \"Characters\": df_characters.shape,\n    \"Locations\": df_locations.shape\n}\n\ndf_shape",
    "Display the first 5 rows of each dataframe to understand the structure of the data.",
    " Display each of the dataframe to understand the structure and the data inside it.",
    "\n# Show first rows of the main tables\nprint(\"Characters:\")\nprint(df_characters.head())\nprint(\"\\nLocations:\")\nprint(df_locations.head())\nprint(\"\\nScript:\")\nprint(df_script.head())\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
    "Check the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "WordCloud generates word cloud data.\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Remove duplicates and missing values in the data\ndf_script = df_script.drop_duplicates(['episode_id', 'number']).dropna()\n\n# Iterating over each row and generating the word cloud for every episode\nfor episode_id, episode_df in tqdm(df_script.groupby('episode_id'), total=len(df_script['episode_id'].unique())):\n    text = ' '.join(episode_df['raw_text'])\n    \n    doc = nlp(text)\n    \n    words = [token.text for token in doc if token.is_alpha and not token.is_stop and len(token.text) > 2]\n    \n    word_freq = Counter(words)\n    \n    wc = WordCloud(width=800, height=800, margin=10).generate_from_frequencies(word_freq)\n    \n    plt.imshow(wc, interpolation='bilinear')\n    plt.axis('off')\n    plt.savefig(f'episode_wordclouds/{episode_id}.png')",
    "Display the general information of the script\ndf_script.info()",
    "Remove bad data from the lines dataset\ndf_script = df_script.astype({'timestamp_in_ms':'float64'}).dropna(subset=['timestamp_in_ms']).astype({'timestamp_in_ms':'int64'})\ndf_script = df_script.dropna(subset=['raw_text']).reset_index(drop=True)\n# df_script.info()",
    "Display the first five rows of the characters dataframe\ndf_characters.head()",
    "Inspect data",
    "Data overview\ndf_script.head()",
    "create directory for storing output\noutput_dir = 'output'\n\n# Ensure the output directory exists\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)",
    "Let's first take a look at the structure of the data and have a peak at the first few rows.",
    " Selecting only the script for the first episode",
    "Remove character ids which are continuous and start which 1 and are present in the charcater csv from the scripts dataframe",
    "\n# Method to remove Special characters, URLs, and mentions\n",
    "Display the first few rows of the characters data\ndf_characters.head()",
    " Data dimensions\nprint(f'Simpsons characters: {df_characters.shape}')\nprint(f'Simpsons locations: {df_locations.shape}')\nprint(f'Simpsons script lines: {df_script.shape}')\nprint(f'Simpsons episodes: {df_episodes.shape}')",
    " Define the directory with NLP models and create a backup.\nnlp_dir = './nlp'\nif os.path.isdir(nlp_dir):\n    !mv $nlp_dir $nlp_dir'_backup'",
    "Install the spaCy package for text preprocessing\n# !pip install spacy\n# !python -m spacy download en_core_web_sm",
    "Character job_text cleaning",
    " Let's take a look at these datasets.",
    "SetFont\nmatplotlib.rcParams['font.family'] = ['Noto Sans CJK JP']",
    "Check the result\ndf_script.head()",
    "Show a preview of the dataset\ndf_script.head()",
    "Set display.max_colwidth to None to display large columns in full\npd.set_option('display.max_colwidth', None)",
    "Fix character_id datatype\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce').astype('Int64')",
    " Print out the first few rows of each dataframe to understand their structure\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "merge script lines with episodes and select character-based script lines",
    "Limit the number of script lines for now\ndf_script = df_script.iloc[:10000]",
    " Set seed for reproducibility\nnp.random.seed(0)",
    "Print the head of df_characters dataframe\ndf_characters.head()",
    "View the first 5 records of characters dataframe\ndf_characters.head()",
    "Check the first few rows of each data frame",
    "Let's start by looking at the first few rows of each of our datasets.",
    " Show the general overview of the data\nprint(\"Character dataframe:\")\nprint(df_characters.head(3))\nprint(\"\\nLocations dataframe:\")\nprint(df_locations.head(3))\nprint(\"\\nScript lines dataframe:\")\nprint(df_script.head(3))\nprint(\"\\nEpisodes dataframe:\")\nprint(df_episodes.head(3))",
    " Display the size and first few rows of each dataframe\nfor df_name, df in zip(['characters', 'locations', 'script', 'episodes'], [df_characters, df_locations, df_script, df_episodes]):\n    print(df_name)\n    print(f'Size: {df.shape}')\n    display(df.head())\n    print()",
    "Optional, specify matplotlib style\nplt.style.use('fivethirtyeight')",
    "pd.set_option('display.max_columns', None)",
    "Inspect the structure of each dataframe\ndf_characters.head()",
    "\ndef count_words(text):\n    return len(text.split())",
    " Test the dataframes loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Remove quotes from 'raw_text'\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\"', '')\n\n# Display the first rows of the dataframe\ndf_script.head()",
    "Display the first few rows of each dataframe to understand its structure and the kind of data we're working with.",
    "Join episode and script data\ndf = df_script.merge(df_episodes, on='episode_id', how='left')",
    " Remove columns with too many missing values\ndf_script.drop(columns=['alignment', 'raw_text'], inplace=True)",
    "Check the dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Limit the number of rows displayed when printing DataFrames\npd.options.display.max_rows = 10",
    "The following will be about what we will do next.",
    "Remove location IDs that don't match with any location in df_locations\nvalid_location_ids = set(df_locations.id)",
    "Set randon seed for reproducibility\nnp.random.seed(0)",
    "Display the first few rows of each dataframe to understand what the data looks like.",
    " Replace f'{gender}:aplha' by f'{gender}:alpha' for the characters dataframe\ndf_characters['gender'] = df_characters['gender'].replace({'f':'female', 'm':'male', 'n':'neutral'})",
    "preview data\nprint(\"Characters:\")\nprint(df_characters.head())\nprint(\"Locations:\")\nprint(df_locations.head())\nprint(\"Script:\")\nprint(df_script.head())\nprint(\"Episodes:\")\nprint(df_episodes.head())",
    "We'll start by exploring the data to understand its structure and contents.",
    "Display options for pandas data frames\npd.set_option('display.max_columns', None)",
    "Optional: If you are using Google Colab and your storage has a folder called 'gdrive', you are able to read the files from 'data/' through there, given the fact that the data folder is directly inside 'gdrive'.",
    "Check the result\ndf_episodes.head()",
    "Display the top rows of each dataframe to understand the structure of the data.",
    "Making sure the size of the data is handled",
    "Create a new column in df_script for the episode number\nepisode_map = {row['id']: row['episode_id'] for index, row in df_script.iterrows()}\ndf_script['episode_number'] = df_script['id'].map(lambda x: episode_map[x])\n\n# Create a new column in df_script for the character\ncharacter_map = {row['id']: row['raw_character_text'] for index, row in df_script.iterrows()}\ndf_script['character'] = df_script['id'].map(lambda x: character_map[x])",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Check whether the Helper label shows up for APIWidget.",
    "Check data structures\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Selecting only the lines spoken by Homer\ndf_homer = df_script[df_script['raw_character_text'] == 'Homer Simpson'].reset_index(drop=True)",
    "df_script.head()",
    " Join the tables such that we can have character and location information in the script table.",
    "Checking the first few rows of the characters dataframe to understand the data",
    "check the data types in each column\ndf_script.dtypes",
    " Check the dfs",
    "Inspect the first few rows of each DataFrame to understand the data",
    "Creating master dataframe with character, location and line information\ndf = pd.merge(df_script, df_characters, on='character_id', how='left')\ndf = pd.merge(df, df_locations, on='location_id', how='left')",
    "Visualization settings\nmatplotlib.rcParams['figure.figsize'] = (10, 5)\n\n# Load the spaCy model\nnlp = spacy.load('en')",
    "# Join the dataframes for simpsons\ndf = df_script.set_index('episode_id').join(df_episodes.set_index('id'), lsuffix='script', rsuffix='ep')\ndf = df.join(df_characters.set_index('id'), on='character_id')",
    "Load spacy language model\nnlp = spacy.load('en_core_web_sm')",
    "# Dataframes first glance\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Display first rows by episodes dataframe",
    " Display the first few rows of the script dataframe\ndf_script.head()",
    "Display the first 5 rows of the script dataframe\ndf_script.head()",
    "display first few rows of each dataframe to understand the data",
    " Set 'id' as the index for quick access",
    "\ndf_episodes.head()",
    "Check if there are any NaNs in the data",
    "Convert text to lower case\ndf_script['raw_text'] = df_script['raw_text'].str.lower()",
    "# Preprocessing\ndf_script = df_script.fillna('')\n\n# Fix datatypes\ndf_script['id'] = df_script['id'].astype(int)\ndf_script['number'] = df_script['number'].astype(int)\ndf_script['raw_text'] = df_script['raw_text'].astype(str)\ndf_script['timestamp_in_ms'] = df_script['timestamp_in_ms'].astype(int)",
    "Check for missing data\ndf_script.isnull().sum()",
    "Check the first 5 rows of each dataframe\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Display a preview of the loaded datasets\ndf_script.head()",
    "# Merge tables\ndf = df_script.merge(df_characters[['id', 'name']], left_on='character_id', right_on='id', suffixes=('_script', '_character'))\ndf = df.merge(df_locations[['id', 'name']], left_on='location_id', right_on='id', suffixes=('_df', '_location'))\ndf = df.merge(df_episodes[['id', 'title', 'original_air_date']], left_on='episode_id', right_on='id', suffixes=('_df', '_episode'))\n\n# Drop redundant columns\ndf.drop(columns=['id_script', 'id_character', 'id_df', 'id_location', 'id_episode'], inplace=True)",
    " Extract the first five items of each dataframe",
    "combine the script with the character and location for each line\ndf_script_full = (\n    df_script\n    .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character'))\n    .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('_script', '_location'))\n)",
    "Inspecting the DataFrame head\ndf_script.head()",
    " Let's take a look at the data.",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Check the content of the 'simpsons_script_lines.csv' dataset\ndf_script.head()",
    "Show first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "# Global variables\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])",
    "Check the structure of the dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "remove the duplicates from the characters and locations dataframes since these are tables that map to the scripts dataframe and the episodes dataframe",
    "Set up matplotlib\nmatplotlib.rcParams['figure.figsize'] = [10, 5]",
    "Print the first 5 rows of each dataframe to understand its structure\nprint(\"Characters:\\n\", df_characters.head(), \"\\n\\n\")\nprint(\"Locations:\\n\", df_locations.head(), \"\\n\\n\")\nprint(\"Script lines:\\n\", df_script.head(), \"\\n\\n\")\nprint(\"Episodes:\\n\", df_episodes.head())",
    "Check the loaded datasets",
    "We'll start by taking a look at the first few lines of each of our DataFrames.",
    "Inspect the character dataset",
    "Add your paths accordingly, as seen below.",
    "Display first 5 rows of each dataframe to understand the data",
    "erequisites for spacy's language model\nnlp = spacy.load('en_core_web_sm')\n\n# Since spacy's language model does not recognize simpsons words, we need to add simpsons vocabulary\nsimpsons_vocab = [\n    \"simpson\", \"hommer\", \"homer\", \"marge\", \"bart\", \"lisa\", \"magie\", \"krusty\", \"milhouse\", \"moe\",\n    \"burns\", \"skinner\", \"ned\", \"flanders\", \"apu\", \"barney\", \"lenny\", \"carl\", \"duff\", \"kang\", \"kodos\",\n    \"fat\", \"tony\", \"snake\", \"gil\", \"willie\", \"abe\", \"ralph\", \"jasper\", \"patty\", \"selma\", \"duffman\", \"troy\", \n    \"lionel\", \"hutz\", \"gil\",\n]",
    " Display the first few lines of each dataframe to get an idea of the kind of information available.",
    "Inspect the structure of the `df_characters` dataframe\ndf_characters.head()",
    "Check for missing data\ndf_script.isnull().sum()",
    "Display the first few rows of the characters DataFrame\ndf_characters.head()",
    " Check that the script lines dataframe loads correctly\ndf_script.head()",
    "# Display the first few rows of the dataframe\ndf_characters.head()",
    "Display options\npd.set_option('display.max_columns', None)",
    "display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Display the first few rows of each dataframe to understand the data",
    "Check the structure of the script dataframe\ndf_script.head()",
    "Check the head of the dataframe",
    "Displays the first few rows of the dataframe to inspect its structure and content.",
    "Inspecting the content of the datasets.",
    "Merge Simpsons scripts with character info\ndf = pd.merge(df_script, df_characters, on='character_id', how='inner')\n\n# Show the first few rows of the dataframe\ndf.head()",
    "Check the shape of the dataframes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "# Let's work first on a very basic visual exploration of the data:\n# Let's look at the number of lines per episode\n\n# Clean the episode column\ndf_script['episode_id'] = df_script['episode_id'].str.extract('(\\d+)').astype(int)\n\n# Count the number of lines per episode\nlines_per_episode = df_script.groupby('episode_id').size()\nlines_per_episode.plot(kind='bar', figsize=(15, 7))",
    "pd.set_option('display.max_columns', None)",
    "Show the first 5 characters of the characters dataframe\ndf_characters.head()",
    "df_script.head()",
    " Display available datasets\nprint('Characters:')\ndisplay(df_characters.head())\nprint('\\nLocations:')\ndisplay(df_locations.head())\nprint('\\nScript:')\ndisplay(df_script.head())\nprint('\\nEpisodes:')\ndisplay(df_episodes.head())",
    "Function to normalize the lines of a character",
    "Preview the data\ndf_characters.head()",
    "Inspect the first few rows of each dataset to understand its structure and content",
    " Let's take a first look at the data.",
    "Add some additional cleaning and encoding steps to our dataframes",
    "Exploring the data: characters, locations, and episodes.",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "rake is a Python implementation of the BLAST protein alignment algorithm.\n\n# Usage:\n# pip install biopython\n# python -m pip install biopython\n\n# Import BLAST tools\nfrom Bio.Blast import NCBIWWW, NCBIXML",
    "Show the first few rows of the characters dataframe\ndf_characters.head()",
    "load spacy model\nnlp = spacy.load('en_core_web_sm')",
    "Set the script data type to string, to ensure it's correctly read from the CSV",
    "\n# We drop the lines without quoting character\ndf_script = df_script.drop(df_script[df_script.raw_character_text.isna()].index)",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    " Set default style for plots\nplt.style.use('seaborn')",
    "Display the first few lines of the dataframe\ndf_characters.head()",
    "Data preprocessing\n# lowercase everything\ndf_script['spoken_words'] = df_script['spoken_words'].str.lower()",
    " Display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "set(base linewidth for matplotlib)\nmatplotlib.rcParams['lines.linewidth'] = 1.0",
    "Keep relevant columns only\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]",
    "The purpose of this code is to import the required datasets using pandas for analysis of the Simpsons scripts. The data is loaded from CSV files using the `pd.read_csv` function and is stored in pandas dataframes `df_characters`, `df_locations`, `df_script`, and `df_episodes`. These dataframes will be used for further analysis and visualization of the Simpsons script data.",
    "Let's print the first couple of rows of each dataframe to see what we're working with.",
    "Set index to take full use of Pandas functionalities\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "Set some configuration options for pandas in order to display data more aesthetically.\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
    "Display the first few rows of the dataframe\ndf_characters.head()",
    "Display all columns for the script dataframe\npd.set_option('display.max_columns', None)\ndf_script.head()",
    "Inspect the structure of the dataframes\n(df_characters.head(), df_locations.head(), \n df_script.head(), df_episodes.head())",
    "Merge the script data with the characters and locations data for better interpretability.",
    "View some basic info\nprint('Script lines:', df_script.shape)\nprint('Episodes:', df_episodes.shape)\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)",
    "Define a variable with the path to the directory containing the seasons\ndirname = 'data/simpsons_episodes/'",
    "df_script = df_script[df_script['speaking_line'] == True].reset_index(drop=True)",
    "Check that all tables have been correctly loaded\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    "\n# Custom imports\nfrom tqdm import tqdm ",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    " Checking the first five rows of each dataframe",
    "Check if dataframes are correctly loaded\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "# Assessing the dataframe quickly\ndf_script.head()",
    "Print the number of rows in each dataframe\nprint(f\"Number of rows in characters dataframe: {len(df_characters)}\")\nprint(f\"Number of rows in locations dataframe: {len(df_locations)}\")\nprint(f\"Number of rows in script dataframe: {len(df_script)}\")\nprint(f\"Number of rows in episodes dataframe: {len(df_episodes)}\")",
    "# Ensure correct versions\nprint(f\"spacy=={spacy.__version__}\")\nprint(f\"pandas=={pd.__version__}\")\nprint(f\"numpy=={np.__version__}\")\nprint(f\"matplotlib=={matplotlib.__version__}\")",
    "Create the necessary folders if they do not exist\nfolders = ['images', 'models', 'data/preprocessed']\nfor f in folders:\n    if not os.path.exists(f):\n        os.makedirs(f)",
    "Check a few entries from each dataframes to understand the structure of the data.",
    "Inspect the structure of the dataframes",
    "# Display the first few rows of the characters DataFrame\ndf_characters.head()",
    "Create a background WordCloud for an image.",
    "Check the loaded dataframes' contents\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check the first few lines of each dataframe",
    "\n#{'characters': df_characters, 'locations': df_locations, 'script': df_script, 'episodes': df_episodes}",
    "Check the first few rows of the characters dataframe\ndf_characters.head()",
    "Check for missing values in the dataset",
    "Remove some irrelevant columns to enhance readability\ndf_script.drop(columns=['norm_text', 'word_count', 'location_id', 'timestamp_in_ms', 'speaking_line', 'raw_text', 'timestamp_in_ms', 'raw_character_text', 'spoken_words', 'normalized_text', 'representation'], inplace=True)",
    "# identifiers should be slugs as per README\ndf_characters.rename(columns= {'id': 'character_id'}, inplace=True)\ndf_locations.rename(columns= {'id': 'location_id'}, inplace=True)\ndf_episodes.rename(columns= {'id': 'episode_id'}, inplace=True)",
    "Displays the first 3 rows of the dataframe",
    "Character name and season columns are currently camel case, let's standardize to snake case by renaming the columns",
    "Set of characters to consider when analyzing the script\ncharacters_set = set(df_characters[df_characters[\"is_main_cast\"] == True].index)\n\n# Set of locations to consider when analyzing the script\nlocations_set = set(df_locations[df_locations[\"normalized\"] == True].index)",
    "Split the dataset into test and training sets",
    "#head of the dataframe\ndf_script.head()",
    "Loads data into dataframes for further analysis.",
    "Filter out episode length less than 20 lines",
    "Sample of how the data looks like\nprint(\"Characters data sample\")\nprint(df_characters.head(n=5))",
    "Build nlp model to use\nnlp = spacy.load(\"en_core_web_sm\")",
    "Display the data head to understand the structure and types of data",
    "Inspect the first 5 lines of df_characters\ndf_characters.head()",
    "Check the format of the script data\ndf_script.head()",
    "Merge character information into the main script DataFrame\ndf_script = pd.merge(\n    df_script, \n    df_characters,\n    how=\"left\",\n    left_on=\"character_id\",\n    right_on=\"id\"\n)\n\n# Merge location info into the main script DataFrame\ndf_script = pd.merge(\n    df_script, \n    df_locations,\n    how=\"left\",\n    left_on=\"location_id\",\n    right_on=\"id\"\n)",
    "Tokenize using Spacy",
    " Check the script dataframe structure\ndf_script.head()",
    "Filter by season",
    "Ensure the 'id' column is unique for all dataframes",
    "remove the 'text' column from df_script to speed up processing, if needed\n# df_script = df_script.drop(columns=['text'])",
    "# View the overall script\ndf_script.head()",
    "path to save outputs\noutput_path = 'output/'",
    "Simple visualisation to have an idea of the different characters.",
    "df_episodes",
    " Display the first few lines of the \"simpsons_characters.csv\" dataset\ndf_characters.head()",
    " Display head of characters table\ndf_characters.head()",
    "Inspecting the structure of script lines dataframe\ndf_script.head()",
    "# We first need to remove any NaN values from the character_name field\ndf_script.dropna(subset=['character_id'], inplace=True)\n\n# Get the characters IDs\ncharacter_ids = df_characters[['id']]\n# Get the characters IDs\nlocation_ids = df_locations[['id']]",
    " Character we are interested in\ncharacter_name = \"Bart Simpson\"",
    "Display the first few lines of the dataframes to understand the data",
    "Tokenizer\nnlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner'])",
    "Check for any NaN values in our dataset\ndf_script.isnull().sum()",
    "Set plot style\nplt.style.use('fivethirtyeight')",
    "Quick spot check into data.",
    "Reduce dataframe size to first 1000 rows for testing\ndf_script = df_script.iloc[:1000]",
    "Display the first 5 rows of the characters DataFrame\ndf_characters.head()",
    " Let's take a look at the structure of the dataframes.",
    " Filter and select dataset\n# Filter dataframe with the episodes of interest by their title\ndf_episodes_selected = df_episodes[df_episodes['title'] == 'Lisa the Simpson'].reset_index(inplace=False, drop=True)\n# We use only the first match\ndf_episodes_selected = df_episodes_selected.iloc[[0]]",
    "df_script = df_script.drop(['id', 'episode_id', 'number', 'raw_text'], axis=1)",
    "Merge the scripts and the characters' databases",
    "Statistics and missing values count for all DataFrames",
    "Display a few rows of the characters DataFrame\ndf_characters.head()",
    "filter out the \"bad\" data\ndf_script = df_script[~df_script.character_id.isna()]\ndf_script = df_script[~df_script.location_id.isna()]",
    "Visualize the most mentioned characters in the script\n# Count the most mentioned characters in the script\ntop_characters = Counter(df_script.loc[df_script['speaking_line'] == 'true', 'character_id'])\ntop_characters = pd.DataFrame(top_characters.most_common(), columns=['character_id', 'count'])\n\n# Convert character_id to merge with df_characters\ntop_characters['character_id'] = top_characters['character_id'].astype(int)\ndf_characters['character_id'] = df_characters['character_id'].astype(int)\n\n# Merge the dataframes\ntop_characters = top_characters.merge(df_characters, on='character_id')\n\ntop_characters.head()",
    " Displaying the records of the characters data.",
    "Check if all data has been imported correctly\ndf_characters.head()",
    "#  Check if script has been loaded correctly\ndf_script.head()",
    "Check if tqdm works",
    "Create a version of the script dataframe which joins the character, location, and episode details with each line.",
    "Merge the datasets to make it more useful for analysis.",
    "Check the first few entries of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Removing unnecessary unnamed columns if any from the dataframes.",
    "Set the 'id' column as the index for each dataframe\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "Display the first few lines of the dataframes to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display a sample of each dataframe\ndf_characters.sample(5)",
    "Setting the style\nplt.style.use('seaborn')",
    "Checking the first 5 rows in the table",
    " Show the first 5 lines of the df_characters DataFrame\ndf_characters.head()",
    "english pipeline\nnlp = spacy.blank(\"id\")",
    " Filter the dataframe to only keep the dialogue lines",
    "Merge location into script data frame\ndf_script = df_script.merge(df_locations, left_on='raw_location_text', right_on='name', how='left').rename(columns={'normalized_name': 'location'})",
    "Create an alias for the pandas library, pd.",
    "Check all the tables first 5 rows",
    "Visualize the number of episodes per season\ndf_episodes['season'].value_counts().sort_index().plot(kind='bar', figsize=(15, 10), color='skyblue')",
    "Optional: Display the first few lines of each dataset to understand its structure\ndf_characters.head()",
    "Inspect the first few rows of each dataframe to understand their structure and content.",
    " Check datatypes and null values\ndf_script.info()",
    "Display the first few rows of the character dataframe\ndf_characters.head()",
    "Import the data and inspect the first few rows to understand its structure\ndf_script.head()",
    "Merge all data into one dataframe\ndf_merged = df_script.merge(df_characters, on='character_id', suffixes=('', '_character'))\ndf_merged = df_merged.merge(df_locations, on='location_id', suffixes=('', '_location'))\ndf_merged = df_merged.merge(df_episodes, on='episode_id', suffixes=('', '_episode'))",
    " Merge Simpsons script with episodes and characters\ndf = df_script.merge(df_episodes, on='episode_id', how='left').merge(df_characters, left_on='character_id', right_on='id', how='left').merge(df_locations, left_on='raw_location_id', right_on='id', how='left')",
    "Check the data size and structure\nprint(\"Characters:\", df_characters.shape)\nprint(\"Locations:\", df_locations.shape)\nprint(\"Script:\", df_script.shape)\nprint(\"Episodes:\", df_episodes.shape)",
    "Script lines contain more information that we won't need for this analysis, so we'll filter the columns we want to keep.",
    " Limit the number of lines in the script dataframe for the sake of example\ndf_script = df_script.iloc[:10000]",
    "Limiting to main characters\nmain_characters = [\n    'marge',\n    'homer',\n    'bart',\n    'lisa',\n    'maggie',\n    'krusty',\n    'moe',\n    'lenny',\n    'carl',\n    'ned',\n    'burns',\n    'skinner',\n    'apu',\n    'abe',\n    'barney',\n    'milhouse',\n    'nelson',\n    'ralph',\n    'jimbo',\n    'patty',\n    'selma',\n    'patty_selma',\n    'martin',\n    'todd',\n    'melt',\n    'milhouse_dad',\n    'milhouse_mom',\n    'skinner_mother',\n    'clancy',\n    'snake',\n    'mrs_krabappel',\n    'principal_knobbe',\n    'captain_mccallister',\n    'fat_tony',\n    'comic_book_guy',\n    'miss_hoover'\n]\n\ndf_script_main = df_script[\n    df_script.raw_character_text.str.lower().isin(main_characters)\n]",
    " Check loaded data\nprint('Characters: {}'.format(df_characters.shape))\nprint('Locations: {}'.format(df_locations.shape))\nprint('Script: {}'.format(df_script.shape))\nprint('Episodes: {}'.format(df_episodes.shape))",
    "Function to load the category of a script line from its line id.",
    "Display sizes\ndf_characters.head()",
    " Displaying first rows of script dataframe\ndf_script.head()",
    "View a few lines of the characters data\ndf_characters.head()",
    "Display the first few lines of each dataframe to get an idea of its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display the first few lines of the characters data frame to understand its structure\ndf_characters.head()",
    "Print the first 5 rows of each dataset for inspection\ndf_characters.head(), df_locations.head(), df_episodes.head(), df_script.head()",
    "Directly print the length of each dataframe",
    "Exploration and data visualization",
    "Let's take a look at the first few lines of the characters and locations DataFrames.",
    "Check character ID 8 lines in the script dataset\ndf_script[df_script.raw_character_text.str.contains('marge', case=False, na=False)].raw_character_text.unique()",
    "Check the presence of null values in the datasets\nprint('Characters:', df_characters.isnull().values.any())\nprint('Locations:', df_locations.isnull().values.any())\nprint('Script:', df_script.isnull().values.any())\nprint('Episodes:', df_episodes.isnull().values.any())",
    "Look at the first few rows of df_script\ndf_script.head()",
    "\n# Print the first 5 lines of each table\nprint('Characters:')\nprint(df_characters.head())\nprint('\\nLocations:')\nprint(df_locations.head())\nprint('\\nScript:')\nprint(df_script.head())\nprint('\\nEpisodes:')\nprint(df_episodes.head())",
    "# The data spans accross 4 tables, which are related between each other with keys.\ndf_characters.head()\n",
    "\n# Take a look at the characters data\ndf_characters.head()",
    " Tokenize script lines using SpaCy",
    " Explore the structure of the data\nprint(f\"Characters: {len(df_characters)}\")\nprint(f\"Locations: {len(df_locations)}\")\nprint(f\"Script lines: {len(df_script)}\")\nprint(f\"Episodes: {len(df_episodes)}\")",
    "Check the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Check the data content",
    "View the first few rows of the characters dataframe\ndf_characters.head()",
    "Define custom functions and classes",
    "matplotlib.rcParams['figure.figsize'] = (10, 7)",
    "Joining datasets",
    "# Extract relevant columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']]\n\n# Merge dataframes\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id')\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id')\n\n# Drop unnecessary columns\ndf_script.drop(columns=['id_x', 'id_y', 'normalized_name', 'normalized_location'], inplace=True)\n\n# Show df_script\ndf_script.head()",
    "Checking for nulls in each dataframe",
    "Fixing some data problems here",
    "Some data is imported to perform exploratory data analysis and natural language processing on a dataset related to \"The Simpsons\" TV show.",
    "Prepare data\n# Merge the datasets\ndf_all = pd.merge(df_script, df_episodes, how='left', on='episode_id')\ndf_all = pd.merge(df_all, df_characters, how='left', on='character_id')\ndf_all = pd.merge(df_all, df_locations, how='left', on='location_id')",
    "Example character\ndf_characters.iloc[6]",
    "Check first 5 rows of each dataset",
    "Set the dimension of word cloud to be created.",
    " Check shape of dataframes\nprint(f\"Characters: {df_characters.shape} | Locations: {df_locations.shape} | Script: {df_script.shape} | Episodes: {df_episodes.shape}\")",
    " Strip leading/trailing whitespaces from character names and location names\ndf_characters['name'] = df_characters['name'].str.strip()\ndf_locations['name'] = df_locations['name'].str.strip()",
    "Filter out characters who have not been assigned to a location\nvalid_characters = df_characters[df_characters['character_id'].isin(df_script['character_id'])]['name']\ndf_script = df_script[df_script['character_id'].isin(df_characters['character_id'])]",
    "Inspect the head of df_characters\ndf_characters.head()",
    "Let's take a quick look at the data to understand its structure and content.",
    "Set path to save files\nimg_path = 'data/img/'",
    " Strip whitespaces in character_id column\ndf_script['character_id'] = df_script['character_id'].str.strip()",
    "Check that the data has been properly loaded\ndf_characters.head()",
    "Load the spaCy model\nnlp = spacy.load('en_core_web_sm')",
    "Get top movie release years\ndf_movies = pd.read_csv('data/movie_metadata.csv')\ndf_movies['title_year'].value_counts().head(10)",
    "# Display the dataframe\n\nprint(df_characters.head())",
    "Inspect the dataframes for any necessary cleaning or preprocessing.",
    "Remove the lines which does not have character, location, and raw_text information.",
    "Display the number of rows and columns for each dataframes\nfor name, dataframe in zip(['Characters', 'Locations', 'Episodes', 'Script'], [df_characters, df_locations, df_episodes, df_script]):\n    print('{}: {} rows, {} columns'.format(name, dataframe.shape[0], dataframe.shape[1]))",
    "###############################################################################\n# Unique Characters, Locations, Episodes\n###############################################################################",
    "Drop the unnecessary 'index' column from each dataframe\ndf_characters.drop('index', axis=1, inplace=True)\ndf_locations.drop('index', axis=1, inplace=True)\ndf_script.drop('index', axis=1, inplace=True)\ndf_episodes.drop('index', axis=1, inplace=True)",
    "if not os.path.exists('figures'):\n    os.makedirs('figures')",
    "Check the first few rows of the characters dataframe\ndf_characters.head()",
    "Now let's take a look at the first few rows of each dataframe to understand the structure and content of the data.",
    "Set up default plotting parameters\nmatplotlib.rc('font', **{'size': 12})\nmatplotlib.rc('grid', **{'color': '0.75', 'linestyle': '-', 'linewidth': 0.5})\nmatplotlib.rc('figure', **{'figsize': (10, 6)})\nmatplotlib.rc('axes', **{'facecolor': '0.95', 'edgecolor': '0.85', 'grid': True})\nmatplotlib.rc('axes', **{'titlesize': 'large', 'labelsize': 'large'})\nmatplotlib.rc('xtick', **{'color': '0.2', 'labelsize': 'large'})\nmatplotlib.rc('ytick', **{'color': '0.2', 'labelsize': 'large'})\nmatplotlib.rc('legend', **{'fontsize': 'large', 'numpoints': 1, 'shadow': True, 'fancybox': True})\nmatplotlib.rc('image', **{'cmap': 'Greys', 'interpolation': 'none', 'aspect': 'equal'})",
    "Inspect dataframes head",
    "GC.collect()  # Garbage collection",
    "optional\npd.set_option('display.max_rows', 300)",
    " Verify the number of rows for each dataframe",
    "Parse the csv\ndf_script.info()",
    "# Display options\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)",
    "Preview the first 5 rows of the script data\ndf_script.head()",
    "df_script.head()",
    " Import Spacy's large english model\nnlp = spacy.load('en_core_web_lg')",
    "# Making sure data has been loaded properly\nprint('Characters - num rows : ', df_characters.shape[0])\nprint('Locations - num rows : ', df_locations.shape[0])\nprint('Script lines - num rows : ', df_script.shape[0])\nprint('Episodes - num rows : ', df_episodes.shape[0])",
    "Check for missing data\ndf_script.isnull().sum()",
    "Check the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Set up path to find the `style` module\nos.sys.path.append('script_parser')",
    "Merge with datasets with script\ndf_merged = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_episode'))\ndf_merged = df_merged.merge(df_characters, on='character_id', suffixes=('_merged', '_character'))\ndf_merged = df_merged.merge(df_locations, on='location_id', suffixes=('_merged', '_location'))",
    "Load the SpaCy model\nnlp = spacy.load('en_core_web_sm')",
    " Check first 5 rows of the characters dataset\ndf_characters.head()",
    "Let's start by doing some basic data exploration to get a better understanding of the datasets.",
    "Custom functions\n# Custom functions\ndef clean_text(text):\n    \"\"\"Clean text data by removing special characters and extra whitespace.\"\"\"\n    return ' '.join(\n        word for word in text.split()\n        if (\n            not word.startswith('@')\n            and not word.startswith('http')\n            and not word.startswith('www')\n        )\n    )",
    "Let's start by looking at the first few rows of the characters, locations, script, and episodes DataFrames.",
    "Define a function to clean and preprocess text data",
    "Checking the first few rows of DataFrame.",
    "Let's check the first rows of each dataframe.",
    "Filter out episode of length 0",
    "Display all columns of the dataframe\npd.set_option('display.max_columns', None)",
    "Remove duplicates from script\ndf_script = df_script.drop_duplicates(subset=['character_id', 'raw_text'])",
    "check the first few rows of the script dataframe\ndf_script.head()",
    " Merge dataframes to get a full view of the data\ndf_episodes_full = df_episodes.merge(df_script, on='episode_id', how='outer')\ndf_episodes_full = df_episodes_full.merge(df_locations, on='location_id', how='outer')\ndf_episodes_full = df_episodes_full.merge(df_characters, left_on='raw_character_text', right_on='name', how='left')",
    "Preview the dataset\ndf_script.head()",
    "Check the recent data before starting the work.",
    " Visualize the number of lines per character\ndf_script['character_id'] = df_script['character_id'].fillna(-1).astype(int)\ndf_script['character_id'] = df_script['character_id'].replace(-1, 'NA')\nlines_per_character = df_script['character_id'].value_counts()\n\nplt.bar(np.arange(30), lines_per_character[:30])\nplt.xticks(np.arange(30), lines_per_character.index[:30], rotation='vertical')\nplt.ylabel('Number of lines')\nplt.title('Number of lines per character')",
    "Merge script data with character and episode information\ndf_script = (\n    df_script\n    .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\n    .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))\n    .merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('', '_episode'))\n)",
    "the first 5 rows of the characters dataframe\ndf_characters.head()",
    "# Show first lines of dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check the first few rows of the characters dataframe.",
    "Filter some seasons\nseasons = list(range(3, 10)) + [11]\n\ndf_script = df_script[df_script.season.isin(seasons)]",
    "Set max_columns and max_colwidth\npd.set_option('display.max_columns', None)\npd.set_option('max_colwidth', None)",
    "Gather info on df_script",
    "Check the introduction of data and cleanup the relevant DataFrames.",
    "Merge script lines with corresponding episodes and characters\ndf_episodes = df_episodes.rename(columns={'id': 'episode_id'})\n\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')\ndf_script = pd.merge(df_script, df_characters, on='character_id')",
    " Take a look at the characters, locations, script and episodes dataframes",
    " Check for and handle missing values",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    "We will start by analyzing the script data.",
    "Set current episode info\ndf_curr_episode = df_episodes[df_episodes['id'] == 4855]\n\n# Set the joint data\ndf_joint = df_script[\n    (df_script['episode_id'] == df_curr_episode['id'].values[0])\n]",
    " Display (head) of those dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Let's take a look at the first few rows of each dataframe to understand what kind of data we are dealing with.",
    "Inspect the first five rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check the content of the 'simpsons_script_lines.csv' file\ndf_script.head()",
    "Plotting a bar plot of the 10 most common characters in the dataset",
    " Remove the first column\ndf_script = df_script.drop(['Unnamed: 0'], axis=1)",
    "Inspect the structure of the characters DataFrame.",
    "Inspect the data",
    "Get the most common words in the entire script\nscript_text = \" \".join(df_script.raw_text)\nscript_text = script_text.lower()  # Convert all text to lower case\nscript_text = \" \".join(script_text.split())  # Remove extra whitespaces\n\n# Download the English model\n!python -m spacy download en_core_web_sm\n\nnlp = spacy.load('en_core_web_sm')\ndoc = nlp(script_text)",
    " Visualisation Preliminaries",
    " Check what the line looks like",
    "Normalize character names\ndef normalize_characters(df):\n    df['normalized_name'] = df.name.str.lower()\n    df['normalized_name'] = df.normalized_name.str.replace(r\"[^\\w\\s]\", '', regex=True)\n\nnormalize_characters(df_characters)",
    "Return the first few records\nfor df in [df_characters, df_locations, df_script, df_episodes]:\n    display(df.head())",
    "Explore the structure of the script DataFrame\nprint(df_script.head())",
    "# Carry the same process out for script data\ndf_script.head()",
    " Display first few rows of the characters dataframe\ndf_characters.head()",
    "Setting up the Word Cloud parameters and extracting the tokens\nwordcloud = WordCloud(width = 800, height = 800, \n                background_color ='white', \n                stopwords = stopwords, \n                min_font_size = 10)",
    "Inspect the data\nprint('Characters:')\nprint(df_characters.head())\nprint('\\nLocations:')\nprint(df_locations.head())\nprint('\\nScript:')\nprint(df_script.head())\nprint('\\nEpisodes:')\nprint(df_episodes.head())",
    "Display all columns so that we can make an informed decision on what to use\npd.options.display.max_columns = None",
    "Extract data for The Simpsons TV show",
    "to magnetic IDE...",
    "Text preprocessing\n# Stop words\nnlp = spacy.load(\"en_core_web_sm\")\nstop_words = spacy.lang.en.stop_words.STOP_WORDS",
    "Checking the structure of the characters dataframe",
    "Inspect the first few rows of the characters dataset\ndf_characters.head()",
    " Display the first few rows of the characters DataFrame\ndf_characters.head()",
    "Merging the dataframes to get more comprehensive information for each line of the script.",
    " Merge script data with respective episode data\ndf_script_episode = pd.merge(df_script,\n                             df_episodes,\n                             left_on='episode_id',\n                             right_on='id',\n                             suffixes=['_script', '_episode'])",
    "# Simple function to inspect the data frames\ndef inspect_data(df, name):\n    print(f\"{name} dataframe info\".center(50, '='))\n    print(df.info())\n    print(f\"{name} dataframe describe\".center(50, '='))\n    print(df.describe(include='all'))",
    "Show all columns\npd.set_option('display.max_columns', None)",
    "Clean up and remove unwated columns in order to speed up data loading and manipulation",
    " Set index to character_id for better handling\ndf_characters.set_index('character_id', inplace=True)",
    " Build List of Episode Script Data\nepisode_script_data = []\nunique_episode_ids = df_script['episode_id'].unique()\nfor episode_id in tqdm(unique_episode_ids, desc=\"Building Episode Script Data\"):\n    episode_lines = df_script[df_script['episode_id'] == episode_id].sort_values(by='timestamp_in_ms')\n    episode_lines = episode_lines.reset_index(inplace=False, drop=True)\n    episode_script_data.append({\n        'episode_id': episode_id,\n        'title': episode_lines.loc[0, 'title'],\n        'script': ' '.join([str(elem) for elem in episode_lines['normalized_text'] if pd.notnull(elem)])\n    })",
    "Set locations to lowercase\ndf_script['raw_location'] = df_script['raw_location'].str.lower()",
    "Print file shapes\nprint(f'Characters: {df_characters.shape}')\nprint(f'Locations: {df_locations.shape}')\nprint(f'Script: {df_script.shape}')\nprint(f'Episodes: {df_episodes.shape}')",
    "Display the first records of the Simpsons characters dataset\ndf_characters.head()",
    "Merge the dataframes together\ndf = df_script.merge(df_characters, how='left', on='character_id')",
    "Print the number of rows in the characters, locations, script and episodes DataFrames\nprint(df_characters .shape[0])\nprint(df_locations.shape[0])\nprint(df_script   .shape[0])\nprint(df_episodes .shape[0])",
    "I will start analyzing the script data. Specifically, I will begin by examining the contents of the `df_script` DataFrame.",
    " Create a new column in df_script with the length of the line of text.",
    "Insane size, check compatibility also on low-RAM environments, e.g. enable arrow-based downcasting.",
    "Check what's in the word script dataframe",
    "Inspect the first few rows of each DataFrame to understand their structures and contents\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Set the 'id' column as the index for each dataframe\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "Merge Locations and Script datasets to get the location of each scene",
    "Check the loaded dataframes",
    "Remove duplicate script lines if any\ndf_script.drop_duplicates(subset='id', keep=False, inplace=True)",
    " Check if the data is correctly loaded",
    "Get the text data from the script dataframe.",
    "Set pandas display options to show full column width\npd.set_option('max_colwidth', None)",
    "replace all regular expression matches with '\\n';\ndf_script['speaking_line'] = df_script['raw_text'].str.replace('[^\\w\\s]','\\n').str.lower();",
    "Merging df_script with character data\ndf_script_chars = pd.merge(df_script, df_characters, left_on='character_id', right_on='id')",
    "Print the first 5 entries of the script dataframe\ndf_script.head()",
    " Display the first few lines of each dataframe to get a sense of the data",
    "Filter characters from the script\nmain_characters = df_characters[df_characters['raw_character_text'].isin(df_script['raw_character_text'].unique())]\nprint(f'Number of unique characters with lines in the script: {len(main_characters)}')",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Deletes all columns containing duplicates in both datasets\ndf_characters = df_characters.drop_duplicates()\ndf_locations = df_locations.drop_duplicates()",
    "Split the raw data to train and test sets.",
    "# Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Show the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Display the first few rows of the dataframe for inspection\ndf_script.head()",
    "Remove unwanted columns from the dataframe",
    "Plot parameters\nfontsize = 15\nfigsize = (15, 8)",
    "Check the shape of each dataframe\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "Display maximum columns when showing the dataframe\npd.set_option('display.max_columns', None)",
    "# Display a few rows of the characters dataframe\ndf_characters.head()",
    "Remove unneeded columns",
    "Setting the directory path for the Simpsons dataset",
    "First, let's investigate the structure of the dataframes.",
    "Check dataframes are correctly loaded\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Define code snippets to preprocess the data further",
    " Limit the number of script lines for faster execution\nLIMIT = 50000\ndf_script = df_script.iloc[:LIMIT]",
    "Create 'simpsons_corpus' and store path to Markovify chain JSON file\nsimpsons_corp_path = 'data/simpsons_corpus.json'",
    "check for missing data in episodes data frame",
    "ve a look at some data from characters table\ndf_characters.head()",
    "Get the list of stopwords from Spacy.",
    "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Check dataframes information\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
    "Milestone 1: WordClouds and Frequency Analysis\n# TODO: Create masks for the Gender of the Characters and their respective WordClouds for several episodes.\n\n# Store the punctuation characters to remove\npunctuation = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'",
    "Merge 'script' with 'episodes' using 'episode_id' as they share this column\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Clean the NaNs\ndf_script = df_script.dropna(subset=['raw_text'])",
    "Merge datasets to match lines with characters and locations\ndf_joined_script = df_script.merge(df_characters, on='character_id', how='left')\ndf_joined_script = df_joined_script.merge(df_locations, on='location_id', how='left')",
    "Creates a column with length of each script line\ndf_script['line_length'] = df_script['raw_text'].str.len()",
    "Selecting relevant columns and dropping rows with NaN\ndf_script = df_script[['episode_id', 'number', 'raw_text']].dropna()",
    "Take a look inside the dataframes.",
    "Select only 10 random episodes due to computation limits\nnp.random.seed(0)\ndf_episode_sample = df_episodes.loc[np.sort(np.random.choice(df_episodes.index, 10, replace=False))]\ndf_episode_sample.reset_index(inplace=True, drop=True)",
    "# Set Pandas to display all of the columns\npd.set_option('display.max_columns', None)",
    "Merge df_script and df_episodes on 'episode_id' to get the actual episode title in the df_script DataFrame\ndf_script = df_script.merge(right=df_episodes, how='inner', on='episode_id')",
    "Set the maximum number of columns/rows printed without truncation\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    "'Jupyter lab' theme\nplt.rcParams.update({'axes.titlesize': 'large', 'figure.titlesize': 'large'})",
    "Create a bar chart with the 10 most frequent characters",
    "Install spacy models\n!python -m spacy download en_core_web_sm",
    "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Create mapping between character name and id\ncharacter_id_mapping = {row['name'].lower(): row['id'] for idx, row in df_characters.iterrows()}",
    "asic data exploration\nprint(f\"Number of characters: {len(df_characters)}\")\nprint(f\"Number of locations: {len(df_locations)}\")\nprint(f\"Number of script lines: {len(df_script)}\")\nprint(f\"Number of episodes: {len(df_episodes)}\")",
    "# Sample\ndf_script.head()",
    "Merge the characters and lines based on the character_id",
    "Load spacy model\nnlp = spacy.load(\"en_core_web_sm\")",
    "Define a function to plot word cloud for given text.",
    "Preprocess script data\ndf_script = df_script[df_script['speaking_line'] == True].reset_index(inplace=False, drop=True)",
    " Define a function to compute the word frequency",
    "Checking the first 5 rows from each dataframe to understand the structure of the data",
    "Show sample of tables",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "View dataframe information\ndf_script.info()",
    " Show head of the dataframe to understand the structure\ndf_script.head()",
    "Check the first records of df_characters, df_locations, df_script and df_episodes to see what kind of data we are dealing with",
    "Check the imported data",
    "Merge the datasets to obtain a single dataset containing all the information needed for analysis.",
    "Data Insights and Statistics",
    "Characters DataFrame\nprint(\"Characters DataFrame\")\ndf_characters.head()",
    "Create a new DataFrame with the main characters and their gender and the script line text",
    " Explore the dataframe\ndf_script.head()",
    "Clean the script of incorrect or empty values and reset index afterward.",
    "View which columns are present\ndf_script.columns",
    "View the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Show the first 5 rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Remove special character from episode titles and transform to lowercase\ndf_episodes['title'] = df_episodes['title'].str.replace('[^A-Za-z0-9 ]+', '').str.lower()",
    "Convert to lower case\ndf_script = df_script.apply(lambda x: x.astype(str).str.lower())",
    " Show first 5 rows of the characters DataFrame.",
    "Uncomment the following lines to debug if something in this notebook goes wrong\n# import pixiedust\n# %%pixie_debugger",
    " Quick look at the data\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
    " Get this NLP party started!",
    " Set Warnings to ignore in notebook\npd.set_option('mode.chained_assignment', None)",
    "\n# Set the seed for reproducibility\nnp.random.seed(0)",
    "Show the first few lines of the data in each dataframe to understand what we are working with.",
    " Apply initial preprocessing steps",
    " Exploratory Data Analysis",
    "Remove records with missing script data\ndf_script = df_script.dropna(subset=['raw_text'])\n\n# Show resulting statistics to ensure records were removed\ndf_script.info()",
    " Sample the data by printing the head of each dataframe",
    "Show the first rows for each dataframe\ndf_list = [df_characters, df_locations, df_script, df_episodes]",
    "function to get the main character of an episode",
    "Select the character's dialogues for sentiment analysis\nmoe_lines = df_script.loc[df_script[\"raw_character_text\"] == \"Moe Szyslak\"][\"spoken_words\"]",
    "View the first few lines of each dataframe to understand the data",
    "df_script.head()",
    "Display some data to have an overview\ndf_script.head()",
    " Show dataframe shapes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "Check basic info on characters and locations dataframe",
    "We will start by analyzing the script data.",
    "Display lines from the df_characters dataframe.",
    "Explore the characters dataset",
    "Preview the characters dataframe\ndf_characters.head()",
    "Check internal constants",
    "Merge the script lines with the episodes and characters dataframes to add the episode and character information\ndf_characters = df_characters.rename(columns={\"id\": \"character_id\"})\ndf_locations = df_locations.rename(columns={\"id\": \"location_id\"})\ndf_script = pd.merge(df_script, df_characters, on='character_id', how='left')\ndf_script = pd.merge(df_script, df_locations, on='location_id', how='left')\ndf_script = pd.merge(df_script, df_episodes, on='episode_id', how='left')\n\n# Sanity check\ndf_script.head()",
    "# Extracting the script for a specific episode\nepisode_id = 168\nscript = df_script[df_script['episode_id'] == episode_id]\nscript",
    "Hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
    "\n# Create dictionary to map locations to characters\nlocation_to_characters = {\n    location: set(df_script[df_script['raw_location_text'] == location]['raw_character_text'])\n    for location in df_script['raw_location_text'].unique()\n}",
    "Display the first 10 records of the character dataset\ndf_characters.head(10)",
    " We will start our analysis by exploring the data and understanding its structure.",
    "Remove rows where character id or locations are missing\ndf_script = df_script.dropna(subset=['character_id', 'location_id'])",
    " Use pandas' head method to print the first 10 rows in df_script\ndf_script.head(10)",
    "replacing empty string with NaN\ndf_script.replace(\"\", np.nan, inplace=True)",
    "Keep only the spoken lines\ndf_script = df_script[df_script.speaking_line].reset_index(inplace=False, drop=True)",
    " Merge episode data into main dataframe",
    "Explore the content of these 4 dataframes\nprint(\"Characters:\\n\", df_characters.head())\nprint(\"\\n\\nLocations:\\n\", df_locations.head())\nprint(\"\\n\\nScript:\\n\", df_script.head())\nprint(\"\\n\\nEpisodes:\\n\", df_episodes.head())",
    " Check the first 5 rows of the characters dataframe.",
    " Check Data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Instanciating a list of stopwords to be removed from the scripts",
    "Show head of the characters dataframe\ndf_characters.head()",
    "Merge all the datasets on 'episode_id' to get a complete view of each episode.",
    "Display examples from each DataFrame\nfor name, df in {'Characters': df_characters, 'Locations': df_locations, 'Script': df_script, 'Episodes': df_episodes}.items():\n    print(f'--- {name} ---')\n    display(df.head(3))",
    "Filtering relevant columns from df_script\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']].rename(\n    columns={'number': 'id', 'raw_text': 'dialogue'}\n)\n\n# Remame Episode id to not conflict with location_id\ndf_script = df_script.rename(columns={'episode_id': 'episode'})",
    "Optional: install spacy language model\n!python -m spacy download en_core_web_sm",
    "I am skipping generated example code because it is too long.",
    " Let's have a look at the structure of the script dataframe.",
    "Replace NaN values with an empty string\ndf_script = df_script.fillna('')",
    "Merge DataFrames",
    "View the first few entries for each dataframe\nprint('Characters')\ndisplay(df_characters.head())\nprint('\\nLocations')\ndisplay(df_locations.head())\nprint('\\nScript lines')\ndisplay(df_script.head())\nprint('\\nEpisodes')\ndisplay(df_episodes.head())",
    "Ensure correct data types for script and episodes\ndf_episodes['id'] = df_episodes['id'].astype(int)\ndf_script['episode_id'] = df_script['episode_id'].astype(int)",
    " Display the first few rows of the characters DataFrame\ndf_characters.head()",
    "check the script data\ndf_script.head()",
    "Let's preview the dataframes",
    "Check the first 10 rows of the characters dataframe",
    " Merge the data using the provided script.",
    "Merge script with characters\ndf_characters_script = df_script.merge(df_characters, left_on='character_id', right_on='character_id')",
    " Checking the first few rows of the characters dataframe.",
    "Checking the first few rows of the characters dataframe",
    "Remove rows with empty strings from the \"normalized_text\" column in df_script\ndf_script = df_script[df_script[\"normalized_text\"].apply(lambda x: x != '')]",
    " Display the first 5 rows of the dataframe containing the script lines.",
    "Set the default plot size for matplotlib for better visibility",
    "Inspect the dataframes by printing the first few rows of each dataframe\nprint('Characters:')\nprint(df_characters.head())\n\nprint('Locations:')\nprint(df_locations.head())\n\nprint('Script:')\nprint(df_script.head())\n\nprint('Episodes:')\nprint(df_episodes.head())",
    " Separate script based on character IDs and episode IDs\nmain_chars = list(df_characters[df_characters['main']] 'id')\n\n\nep_ids = list(df_episodes['id'])\nscripts = {}\n\nfor ep_id in ep_ids:\n    # print(ep_id)\n    \n    df_ep_script = df_script[df_script['episode_id'] == ep_id]\n    \n    if len(df_ep_script) == 0:\n        scripts[ep_id] = ''\n        continue\n    \n    for char_id in main_chars:\n        df_char_ep_script = df_ep_script[df_ep_script['character_id'] == char_id]\n        script = df_char_ep_script['spoken_words'].values\n        script = ' '.join([x for x in script if type(x) == str])\n        \n        scripts[(ep_id, char_id)] = script",
    " Check the number of records mined in each dataset\nprint('Number of characters:', len(df_characters))\nprint('Number of locations:', len(df_locations))\nprint('Number of script lines:', len(df_script))\nprint('Number of episodes:', len(df_episodes))",
    "Aggregate both sentences and raw data by episode_id in one dataframe\nepisodes_dialogues = pd.concat([df_script.groupby('episode_id').apply(lambda x: ' '.join(x['raw_text'])).rename('script'),\n                                df_script.groupby('episode_id').apply(lambda x: ' '.join(x['spoken_words'].dropna())).rename('spoken_words'),\n                                df_episodes.set_index('id')\n                               ], axis=1, join='inner').reset_index(inplace=False)",
    " Import the data from 'simpsons_script_lines.csv' into a pandas DataFrame and display the first 5 rows.",
    "Take a peak at the first few rows of the dataset\ndf_script.head()",
    "Only keep characters IDs that appear in df_characters\ndf_script = df_script[df_script[\"character_id\"].isin(df_characters.character_id.unique())]",
    "set max column with of pandas\npd.set_option('display.max_colwidth', 800)",
    " Let's take a look at the first few rows of each dataframe.",
    "Extract names of episodes",
    " Credits to https://www.kaggle.com/pierremegret/dialogue-lines-of-the-simpsons\n# to provide the data on kaggle.",
    "Additional data cleaning",
    "Display head of all datasets to understand the data",
    "Sanity check on the tables",
    "Show the first rows of scripts data.",
    "Checking the first 5 rows of the script dataset\ndf_script.head()",
    "Create a basic wordcloud for all of the Simpsons scripts\nscript_words = ' '.join(df_script['spoken_words'].fillna(''))\nwordcloud = WordCloud(width = 800, height = 400,\n                background_color ='black',\n                stopwords = STOPWORDS,\n                min_font_size = 10).generate(script_words)\n\n# plot the WordCloud image\nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\n\nplt.show()",
    "Confirm everything looks good so far\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Inspect the first few rows of each dataframe to understand the data.",
    "# Display the first few columns\ndf_characters.head()",
    " Show first data frame\ndf_characters.head()",
    "Check if all columns are read correctly\nprint(\"Columns in characters: \", df_characters.columns.tolist())\nprint(\"Columns in locations: \", df_locations.columns.tolist())\nprint(\"Columns in script: \", df_script.columns.tolist())\nprint(\"Columns in episodes: \", df_episodes.columns.tolist())",
    "\n# Display options\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)",
    "'Inconsequential', 'other', 'TRASH', and 'noise' lines will be dropped.\nsentence_level_scripts = df_script.loc[df_script.raw_text.str.contains('Anonymous|PABF|JABF|TABF') == False].copy()\n\n# The merged dataframe will only consider scripts from the main 22 seasons\nmerged_df = df_episodes[df_episodes.season > 0]",
    "Data at a glance\nprint(f'Characters: {df_characters.shape[0]}')\nprint(f'Locations: {df_locations.shape[0]}')\nprint(f'Lines of script: {df_script.shape[0]}')\nprint(f'Episodes: {df_episodes.shape[0]}')",
    " Check the content of df_characters\ndf_characters.head()",
    "Check first 5 rows of the Characters dataframe\ndf_characters.head()",
    "# These imports will be useful in this notebook\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()",
    "Display the first 5 rows of each dataframe to have an idea on the structure of the data.",
    "Looking at the first few rows of the characters dataset to understand its structure and contents\nprint(df_characters.head())",
    "Create a connection to the database and extract the script lines",
    "We'll need to do some data preprocessing before we can start the analysis.",
    "Inspect the structure of the raw DataFrame for script lines.",
    "import warnings\nwarnings.filterwarnings('ignore')",
    "Let's take a quick look at the datasets we have.",
    "Merge Simpsons script lines with character information\ndf_script['character_name'] = df_script['character_id'].map(df_characters['name'])\ndf_script.head()",
    "Drop rows with NaN\ndf_script = df_script.dropna(subset=['character_id', 'location_id'])",
    "Merge lines of the script with the characters and the locations",
    " Check the data from the characters dataframe",
    "Find the script lines that reference locations.",
    "Preview some dataframes",
    "Visualize the number of lines spoken by each character\nline_count = df_script['character_id'].value_counts()\ntop_characters = line_count.nlargest(10)",
    "Quick look at the data",
    "Merge the script with the characters (to retrieve the character names)",
    "Inspect the content of the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Exploring the data.",
    "Inspect each DataFrame to understand its structure and content",
    "Display configuration\npd.options.display.max_columns = 999\npd.options.display.max_colwidth = 100",
    "Inspect the structure of each dataframe\nprint('\\nCharacters:')\nprint(df_characters.head(2))\nprint('\\nLocations:')\nprint(df_locations.head(2))\nprint('\\nScript:')\nprint(df_script.head(2))\nprint('\\nEpisodes:')\nprint(df_episodes.head(2))",
    " Let's take a look at the first few rows of each dataframe to understand their structure and contents.",
    "We'll start by taking a look at the structure of the datasets and splicing the data.",
    "# Shows the first rows of the table in a Jupyter\ndf_characters.head()",
    "Path to spacy model\nnlp = spacy.load('en_core_web_sm')",
    "Merge episode data into the script data\ndf = pd.merge(df_script, df_episodes, on='episode_id')",
    "Check the first few rows of the characters dataframe\ndf_characters.head()",
    "Set params\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\ntqdm.pandas()",
    "Inspect the characters data\ndf_characters.head()",
    "Set CWD to current folder\nos.chdir(os.path.dirname(os.path.abspath(__file__)))",
    "Print the first few rows of the characters dataframe\ndf_characters.head()",
    "Check that the data has been read in correctly\nfor df in [df_characters, df_locations, df_script, df_episodes]:\n    print(df.head(2))\n    print('-'*50)",
    "Check to see if all imports were successful.\nprint('imports successful')",
    "Display the first few rows of the dataset to understand its structure and content\ndf_script.head()",
    "Inspect dataframe for characters",
    "Let's start by taking an example script line and it's metadata to demonstrate the quality of our dataset.",
    "Remove unwanted characters\ncharacters_to_remove = ['(', ')', '[', ']', '\\\"', '\\'', '\\`']\nfor c in characters_to_remove:\n    df_script['raw_character_text'] = df_script['raw_character_text'].str.replace(c, '')\n\n# Lowercase the character names\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.lower()",
    "Extract the name of the characters, location of the scenes and name of the episodes of the Simpsons dataframe",
    "Func to split the data to moby_dick chunks, args: window=n, overlap=0\ndef split_to_chunks(input_str, window, overlap=0):\n    return [input_str[i:i + window] for i in range(0, len(input_str), window - overlap)]",
    "Check the first few lines of each dataframe",
    "ensuring uniformity of data\ndf_script = df_script[df_script['episode_id'] <= 600]",
    "ention about the script\nscript_columns = df_script.columns\nprint(df_script.columns)",
    "Filter out the newline characters from raw_script column in the script dataset to avoid any problems.",
    "Store the raw data as a global variable for easier access later on\nRAW_DATA = {\n    'characters': df_characters,\n    'locations': df_locations,\n    'script': df_script,\n    'episodes': df_episodes\n}",
    " Installs the en_core_web_sm model for spaCy",
    "Print the head of the dataframe to check its structure\ndf_episodes.head()",
    " option in pandas to display all columns in outputs\npd.set_option('display.max_columns', None)",
    "Description of the datasets",
    "Show the first 5 lines of each dataframe\nfor df, name in zip([df_characters, df_locations, df_script, df_episodes], ['Characters', 'Locations', 'Script', 'Episodes']):\n    print(name)\n    with pd.option_context('display.max_columns', None):\n        display(df.head(5))\n    print('\\n')",
    "Show head of characters dataframe\ndf_characters.head()",
    "Simple EDA to \"get to know\" the data\nprint(\"Characters sample:\")\nprint(df_characters.head(2))\nprint(\"Locations sample:\")\nprint(df_locations.head(2))\nprint(\"Script sample:\")\nprint(df_script.head(5))",
    " Load smaller datasets\ndf_characters_s = pd.read_csv('data/simpsons_characters_small.csv').reset_index(inplace=False, drop=True)\ndf_locations_s = pd.read_csv('data/simpsons_locations_small.csv').reset_index(inplace=False, drop=True)\ndf_script_s = pd.read_csv('data/simpsons_script_lines_small.csv').reset_index(inplace=False, drop=True)\ndf_episodes_s = pd.read_csv('data/simpsons_episodes_small.csv').reset_index(inplace=False, drop=True)",
    "Print the head of the episodes dataframe\nprint(df_episodes.head())",
    " Display general information of dataset characters",
    "Check to see if there are any missing values in the datasets\ndf_characters.isna().sum()",
    "Set the length of all TV script lines to 300 characters or less.",
    "Now let's print the first few rows of each dataframe to see what's inside",
    " Check the first few entries of the characters dataframe\ndf_characters.head()",
    "# Jupyter scatter plot size\nmatplotlib.rcParams['figure.figsize'] = (10.0, 6.0)",
    " Display the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Checking dimensionality of the data\nprint('Characters: ', df_characters.shape)\nprint('Locations: ', df_locations.shape)\nprint('Script: ', df_script.shape)\nprint('Episodes: ', df_episodes.shape)",
    "Set seed for reproducibility\nnp.random.seed(0)",
    "Display all columns as there might be many columns in the datasets\npd.set_option('display.max_columns', None)",
    "I will merge some of the DataFrames, to be able to get all the necessary information in one DataFrame.",
    "Set seed for reproducibility\nnp.random.seed(34)",
    "Specify input and output dataframes",
    "Select only important columns\ndf_script = df_script[['episode_id', 'number', 'raw_text', 'character_id', 'location_id']].copy()",
    "Place the dataset files in a 'data' folder in the same directory as this notebook.",
    "Check the shape of dfs\nprint(df_characters.shape, df_locations.shape, df_script.shape,  df_episodes.shape)",
    "Display dataframes' shape and head\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "We'll also need some basic NLP tools, such as tokenization and lemmatization, for analyzing the script lines.",
    "Merge character lines with character and location data\ndf_merged = df_script.merge(df_characters, on='character_id', suffixes=('', '_char'))\ndf_merged = df_merged.merge(df_locations, on='location_id', suffixes=('', '_loc'))\n\n# Print first few rows\ndf_merged.head()",
    "Display the first few records of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Concatenate last_name and first_name strings\ndf_script['character_name'] = df_script['raw_character_text'].str.lower().str.replace(\" \",\"\")",
    " Look at first rows of the characters dataframe\nprint(\"Characters:\")\ndisplay(df_characters.head(5))\n\n# Look at first rows of the locations dataframe\nprint(\"\\nLocations:\")\ndisplay(df_locations.head(5))\n\n# Look at first rows of the script dataframe\nprint(\"\\nScript:\")\ndisplay(df_script.head(5))\n\n# Look at first rows of the episodes dataframe\nprint(\"\\nEpisodes:\")\ndisplay(df_episodes.head(5))",
    "Let's examine the first few rows of each DataFrame to better understand their structure.",
    "Weight each character's occurrence by the length of the line (expanding counting heavily in longer lines)",
    "Ensure the episode is the full episode and not a short.",
    " Display the first few rows of each dataframe\nprint(\"Characters dataframe:\")\nprint(df_characters.head(), '\\n')\n\nprint(\"Locations dataframe:\")\nprint(df_locations.head(), '\\n')\n\nprint(\"Script dataframe:\")\nprint(df_script.head(), '\\n')\n\nprint(\"Episodes dataframe:\")\nprint(df_episodes.head())",
    " Display the first five rows of the script data\ndf_script.head()",
    " Remove duplicate lines and keep the last version of the line",
    "Show word cloud of the previous amount of words spoken by the character with the most words.",
    "We will use the 'simpsons_script_lines.csv' file to analyze the script lines.",
    "Inspect the dataframes to understand their structure and the information they contain.",
    "Replace nans with empty strings\ndf_characters.fillna(value=\"\", inplace=True)\ndf_locations.fillna(value=\"\", inplace=True)\ndf_script.fillna(value=\"\", inplace=True)\ndf_episodes.fillna(value=\"\", inplace=True)",
    "Display top 5 rows of dataframe\ndf_script.head()",
    "Check the number of records in each dataframe\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Look at the first couple of rows of all the datasets\ndf_script.head(5)",
    "Remove unnecessary columns from df_script",
    "View dataframe info\nprint(df_characters.info())\nprint(df_locations.info())\nprint(df_script.info())\nprint(df_episodes.info())",
    "Displaying the first 3 rows of the script DataFrame to understand its structure\ndf_script.head(3)",
    "Quick overview of the data\nprint(\"Characters:\")\ndisplay(df_characters.head())\n\nprint(\"Locations:\")\ndisplay(df_locations.head())\n\nprint(\"Script:\")\ndisplay(df_script.head())\n\nprint(\"Episodes:\")\ndisplay(df_episodes.head())",
    "Selecting only a specific season data for the analysis due to the memory limitations in the local environment",
    "Create a dictionary mapping episode_id to episode_name to replace\n# episode_id with episode_names in both episode_ids and episode_names\nepisode_id_to_name = df_episodes.set_index('id')['title'].to_dict()\n\n# Replace episode_id with episode_name\ndf_script['episode_id'] = df_script['episode_id'].replace(episode_id_to_name)",
    "Set up lists of characters, locations, episodes, and seasons for later use\ncharacters = df_characters['name'].values.tolist()\nlocations = df_locations['name'].values.tolist()\nepisodes = df_episodes['title'].values.tolist()\nseasons = df_episodes['season'].drop_duplicates().values.tolist()",
    "\n# df_script.head()",
    "Create a spacy model for pre-processing episodes",
    "\ndf_script.head()",
    "We'll start by having a look at the data to understand its structure and content.",
    "Checking the first few rows of each dataframe",
    " set seed for reproducibility\nnp.random.seed(0)",
    "Set up matplotlib.rcParams, then make all plots.",
    "Let's display the first few rows of characters, locations, script and episodes dataframes.",
    " All print() output will be written directly to the Jupyter notebook\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"",
    "Check if each dataframe was correctly loaded\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check the content of the dataset \"Characters\" and the first five rows of the dataframe\nprint(\"Printing the dataframe structure to understand it better\")\nprint(df_characters.head().to_string())",
    "Check what is imported",
    "Print the first 5 lines of the script dataset to inspect its structure\ndf_script.head()",
    " set nlp object\nnlp = spacy.load('en', disable=['ner', 'parser'])",
    "Split name and surname\ndf_characters['name'] = df_characters['name'].apply(lambda x: x.split(' ', 1)[0])\ndf_characters.head()",
    "Exploring dataset",
    " Plot histogram of the episode lengths\ndf_episodes.length.hist(bins=50, alpha=0.5, color='r', edgecolor='black')",
    " Merge script lines with characters, locations and episodes\ndf_script = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=['_script', '_character'], how='left')\ndf_script = df_script.merge(df_locations, left_on='location_id', right_on='id', suffixes=['_script', '_location'], how='left')\ndf_script = df_script.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=['_script', '_episode'], how='left')",
    "Merging the script lines with the characters and locations DataFrames for better readability and analysis.",
    "Check the content of the records in the dataframes to understand the potential features at hand.\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    " Select script from episode 1 and 2\ndf_script_12 = df_script[(df_script[\"episode_id\"]==1) | (df_script[\"episode_id\"]==2)].reset_index(inplace=False, drop=True)",
    "Check the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Preliminary analysis of the dataframes",
    "Merge script with characters\ndf_script_char = df_script.merge(\n    df_characters,\n    left_on='character_id',\n    right_on='id',\n    suffixes=('_script', '_char'))\ndf_script_char.head()",
    "We will now begin exploring the dataset to understand its structure and contents.",
    "Set the correct data types for each Dataframe to optimize the memory usage",
    " Show the first lines of the characters dataframe\ndf_characters.head()",
    " filter some bad rows\ndf_script = df_script[df_script['episode_id'] != 's']\ndf_episodes = df_episodes[df_episodes['id'] != 's']",
    "Inspect the characters dataset\nprint(df_characters.shape)\ndf_characters.head()",
    "Take a look at the structure of script data\ndf_script.head()",
    "Check the data\ndf_script.head()",
    "Let us take a look at the first few rows from each dataframe to figure out their structure.",
    "Show the results of the first table.",
    "Merge relevant columns from the other DataFrames into the main df_script DataFrame\ncols_characters = [\"id\",\"name\",\"normalized_name\",\"gender\"]\ncols_locations = [\"id\",\"name\",\"normalized_name\"]\ncols_episodes = [\"id\",\"title\",\"original_air_date\"]\n\ndf_script = pd.merge(df_script, df_characters[cols_characters], left_on=\"character_id\", right_on=\"id\", suffixes=(\"\", \"_character\")).drop(columns=[\"id\"])\ndf_script = pd.merge(df_script, df_locations[cols_locations], left_on=\"location_id\", right_on=\"id\", suffixes=(\"\", \"_location\")).drop(columns=[\"id\"])\ndf_script = pd.merge(df_script, df_episodes[cols_episodes], left_on=\"episode_id\", right_on=\"id\", suffixes=(\"\", \"_episode\")).drop(columns=[\"id\"])",
    "Inspect the dataframes",
    "Merge characters with script\ndf_script = pd.merge(df_script, df_characters, on='character_id', how='left')",
    "Check the loaded dataframes",
    " #encoding=utf-8",
    "Print some statistics about the data.",
    " Checking the structure of the dataframes\nprint(\"Characters dataframe:\")\nprint(df_characters.info())\n\nprint(\"\\nLocations dataframe:\")\nprint(df_locations.info())\n\nprint(\"\\nScript dataframe:\")\nprint(df_script.info())\n\nprint(\"\\nEpisodes dataframe:\")\nprint(df_episodes.info())",
    "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Create a corpus of documents, i.e. seasons, episodes, scripts\ncorpus = { row[1][\"id\"]: \"\" for row in df_episodes.iterrows() }\n\n# Append all the lines from a given episode to the same document\nfor row in tqdm(df_script.iterrows(), total=df_script.shape[0]):\n    episode_id = row[1]['episode_id']\n    corpus[episode_id] += row[1]['raw_text']",
    "Simple Preprocessing\n# Make sure the text is indeed a string\ndf_script['raw_text'] = df_script['raw_text'].astype(str)\n\n# Simple text cleaning\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\n', ' ')  # Removing newlines\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\r', ' ')  # Removing carriage returns\ndf_script['raw_text'] = df_script['raw_text'].str.replace('\\t', ' ')  # Removing tabs\n\ndf_script['word_count'] = df_script['raw_text'].apply(lambda x: len(x.split(' ')))  # Getting word count",
    "# Show first rows of the characters, locations, and script dataframes\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())",
    "Prepare data for time-sliced analysis.",
    " Using more characters and episodes than previously, we will try to predict which character is saying which line, using two approaches.",
    "Convert raw_text newline characters to html <br> tag\ndf_script['spoken_words'] = df_script['spoken_words'].str.replace('\\n', '<br>')",
    "Display first 5 rows of df_script\ndf_script.head(5)",
    "Function to convert text to lowercase and remove punctuation and extra spaces",
    "Display first 5 rows of the script dataframe.",
    "Check that data has been loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Select main characters\nmain_characters = [\n    'marge_simpson', 'homer_simpson', 'bart_simpson',\n    'lisa_simpson', 'maggie_simpson', 'skinner'\n]\n\n# Filter out lines by main characters\ndf_main_characters = df_script[\n    df_script['raw_character_text'].isin(main_characters)\n].copy()\n\n# Cleanup and drop NaN values\ndf_main_characters['normalized_text'] = (\n    df_main_characters['spoken_words']\n    .str.lower()\n    .str.replace(r'[^\\w\\s]', '', regex=True)\n    .str.replace(r' +', ' ', regex=True)\n    .str.strip()\n)\ndf_main_characters['word_count'] = (\n    df_main_characters['normalized_text'].str.split().str.len()\n)\ndf_main_characters['word_count'] = (\n    df_main_characters['word_count']\n    .where(df_main_characters['word_count'] < 100, 100)\n)\n\ndf_main_characters = df_main_characters.dropna(subset=['normalized_text'])\n\n# Inspect\ndf_main_characters.head()",
    "merge the information from `simpsons_events.csv` into `simpsons_script_lines.csv`\ndf_events = pd.read_csv('data/simpsons_events.csv').reset_index(inplace=False, drop=True)",
    " Display the first few rows of the dataframe\ndf_characters.head()",
    "Explore the first lines of the characters DataFrame\ndf_characters.head()",
    "Display the first few rows of each dataframe to understand the data",
    " Extract characters, locations, and raw text from script data\ncharacters = [str(c).lower() for c in df_characters['character_name']]\nlocations = [str(l).lower() for l in df_locations['raw_location_text']]\nraw_text = [str(t).lower() for t in df_script['raw_text']]",
    "display first few rows of each table\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Setting the index for easier data retrieval and searches\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "Checking if the CSV files have been loaded correctly\ndf_characters.head()",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Is there an error in the original code?",
    "remove columns with mostly nan's",
    "Let's take a look at the first few lines of each dataframe.",
    "Generate word cloud of the entire Simpsons script\nscript = \" \".join(df_script['spoken_words'].fillna(\"\"))",
    "Data cleaning and pre-processing",
    "TODO: Examine dataset shapes and column names",
    "Merge data for a more comprehensive analysis\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id')\ndf_merged = pd.merge(df_merged, df_characters, on='character_id')\ndf_merged = pd.merge(df_merged, df_locations, on='location_id')",
    " Remove NaN values from 'text' column of df_script\ndf_script = df_script[df_script['text'].notna()].reset_index(inplace=False, drop=True)",
    "set the plot size for all the upcoming notebook\nplt.rcParams['figure.figsize'] = [10, 5]",
    " Extracting the names of the characters.",
    " Show the first 5 records for each DataFrame",
    "check files in directory",
    " Visualize the top 20 characters in terms of number of lines in the show\ntop_characters = df_script['character_id'].value_counts().head(20)\ntop_characters = top_characters.to_frame().merge(df_characters, how='left', left_index=True, right_on='id').iloc[:,1]\ntop_characters = top_characters[::-1]\n\nplt.figure(figsize=(10, 8))\nplt.barh(top_characters.index, top_characters.values, color='skyblue')\nplt.xlabel('Number of lines', fontsize=12)\nplt.title('Top 20 characters by number of lines', fontsize=16)\nplt.gca().invert_yaxis()",
    "Extract only parts of the script featuring the Simpson family\ndf_simpsons_script = df_script[(df_script.raw_character_text == 'Marge')\n                      | (df_script.raw_character_text == 'Homer')\n                      | (df_script.raw_character_text == 'Bart')\n                      | (df_script.raw_character_text == 'Lisa')\n                      | (df_script.raw_character_text == 'Maggie')]",
    "View the first 5 rows of the characters dataframe\ndf_characters.head()",
    " Let's display the number of characters, locations, script lines and episodes.",
    " This line ensures that the plots we generate with matplotlib use the 'dark_background' style for a better appearance.",
    " Create a list of episode titles",
    "Show the first 3 examples of df_characters dataframe\ndf_characters.head(3)",
    " Show the head of the script\ndf_script.head()",
    " Validate the integration by printing a few lines of each dataframe",
    "So, we have successfully read all the CSV files into pandas dataframes.",
    "Preview the characters data\ndf_characters.head()",
    "Display the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Remove all mode of address and suffixes from aggregation.",
    "Finding every location mentioned in every one of the scripts in this season",
    " Visualization Utils",
    "Check the dataframes are correctly loaded",
    "Look at what we have in the script DataFrame",
    "Merge df_script, df_episodes and df_characters to provide all the necessary data in one DataFrame",
    "Drop useless columns that contain only NaN.\ndf_episodes = df_episodes.dropna(axis=1, how='all')",
    "view_dataframes(df_characters, df_locations, df_script, df_episodes)",
    "check if datraframe loaded correctly\nprint(df_characters.head())",
    "Configure matplotlib rcParams for a consistent style throughout the notebook\nmatplotlib.rcParams.update({\n    'font.size': 16,\n    'figure.figsize': (10, 8),\n    'axes.grid': True,\n    'axes.axisbelow': True,\n    'axes.labelsize': 16,\n    'axes.titlesize': 20,\n    'axes.linewidth': 2,\n    'lines.linewidth': 3,\n    'lines.markersize': 10,\n    'xtick.labelsize': 16,\n    'ytick.labelsize': 16,\n    'legend.fontsize': 16\n})",
    "Explore the first 5 rows of each of the DataFrames to understand the structure of the data.",
    "Print some introductory information about each dataset, like number of columns, number of samples and the content of the first row",
    "Checking that the data has been loaded correctly\nprint('Characters')\ndisplay(df_characters)\nprint('Locations')\ndisplay(df_locations)\nprint('Script')\ndisplay(df_script)\nprint('Episodes')\ndisplay(df_episodes)",
    "Display top rows of the characters dataframe\ndf_characters.head()",
    "Take a look at the first 5 rows for all datasets.",
    " Merge character, location and episode data into main dataframe for analysis\n# Merge on 'id' in 'df_script' and character_id in 'df_characters'\ndf_merged = df_script.merge(df_characters, left_on='character_id', right_on='id', suffixes=['_script', '_character'])\n\n# Merge on 'id' in previous merge result and 'episode_id' in 'df_episodes'\ndf_merged = df_merged.merge(df_episodes, left_on='episode_id', right_on='id', suffixes=['_merged', '_episode'])\n\n# Merge on 'location_id' in previous merge result and 'id' in 'df_locations'\ndf_merged = df_merged.merge(df_locations, left_on='location_id', right_on='id', suffixes=['_previous', '_location'])",
    " Set the script type to string",
    " Remove punctuation from 'raw_text' feature in the 'df_script' DataFrame\ndf_script['raw_text'] = df_script['raw_text'].str.replace('[^\\w\\s]','')",
    "Merge script and episodes\ndf_script_episodes = pd.merge(df_script, df_episodes, how = 'left', on = ['episode_id'])",
    "Remove unnecessary columns in some dataframes",
    "Loading the data into Pandas DataFrames",
    "Mappings id <-> name\nchar_id_to_name = dict(df_characters[['id', 'name']].values)\nchar_name_to_id = {v: k for k, v in char_id_to_name.items()}\n\nloc_id_to_name = dict(df_locations[['id', 'name']].values)\nloc_name_to_id = {v: k for k, v in loc_id_to_name.items()}",
    " Show All Data for df_characters\nwith pd.option_context('display.max_rows', None, 'display.max_columns', None):\n    display(df_characters.head(5))",
    "a single collaborator is going to be used in this example\nCOLLABORATOR_NAME = 'Colab1'",
    "Find the season/episode with the most lines",
    " Show header of all dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " To display logger output\nimport logging",
    "Reset the index for episodes to ensure all indexes are unique\ndf_episodes.reset_index(inplace=True)",
    "display(df_characters)",
    "Check loaded data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Let's first take a look at these dataframes to see what information we have available.",
    "Install the nlargest package if you haven't yet.\n# You can do this in your terminal with the command `pip install nlargest`.\nfrom nlargest import NLargest",
    "Display a sample of the dataframe containing the script lines",
    "Merge character metadata\ndf_characters_and_locations = pd.merge(\n    df_characters,\n    df_locations,\n    how='outer',\n    left_on='id',\n    right_on='normalized_name'\n)",
    "Inspect data\ndf_characters.head()",
    "Set options for pandas to display dataframes in a readable way\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', -1)",
    " Load the data and display the first few rows of each dataframe",
    " General plotting settings\nmatplotlib.rcParams['figure.figsize'] = [10, 5]\nmatplotlib.rcParams['figure.dpi'] = 80",
    " Show the first entries for the characters table\ndf_characters.head()",
    "Merge episodes and script df\ndf_eps_script = pd.merge(df_episodes, df_script, on='episode_id')",
    "### Data exploration and cleaning",
    "# Display markdown\nfrom IPython.display import display, Markdown",
    "Check the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Show the first 10 rows of the characters dataframe\ndf_characters.head(10)",
    " Quick visualization of the first few rows in the dataframe\ndf_script.head()",
    "Exploratory Data Analysis",
    " Display the first few rows of each dataframe to understand its structure and data",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Check main DataFrames' structure\nprint(df_characters)\nprint(df_locations)\nprint(df_script)\nprint(df_episodes)",
    "Let's display the content of the dataframes to assess their structure and the data they contain.",
    "Check the content of Simpsons characters.",
    "Set configuration options for pandas and matplotlib",
    "A 100% of the wordcloud is being shown\nmatplotlib.rcParams['figure.figsize'] = [20, 12]",
    "Let's examine the data further.",
    "Display the first few lines of each of the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Remove items which weren't referenced in another dataframe",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Visualizing the 10 most frequent locations\ntop_10_locations = list(dict(Counter(df_script['raw_location_text'])).items())\ntop_10_locations.sort(key=lambda x: x[1], reverse=True)\ntop_10_locations = top_10_locations[:10]\n\nplt.bar([x[0] for x in top_10_locations], [x[1] for x in top_10_locations])\nplt.xticks(rotation=90)\nplt.show()",
    "# Explore each dataframe\nprint(\"Characters dataframe:\")\nprint(df_characters.head())\nprint(\"\\nLocations dataframe:\")\nprint(df_locations.head())\nprint(\"\\nScript dataframe:\")\nprint(df_script.head())\nprint(\"\\nEpisodes dataframe:\")\nprint(df_episodes.head())",
    "Merge all the scripts, characters, locations, and episodes into a single dataframe.",
    " Visualize the first few rows of each dataframe to understand its structure\ndf_characters.head()",
    "define a tokenizer function using spacy\nnlp = spacy.load(\"en_core_web_sm\")\ndef spacy_tokenizer(sentence):\n    return [word.lemma_ for word in nlp(sentence) \n            if not (word.is_space or word.is_punct or word.is_stop)]",
    "spacy.prefer_gpu()",
    "# Display the first 5 rows of the characters dataframe\ndf_episodes.head()",
    "Create columns to easily identify character and location speaking or spoken about",
    " Set seed for reproducibility\nnp.random.seed(0)",
    "\ndf_script.head()",
    "Look at the character data.",
    "Display the first 5 rows of each DataFrame to understand the kind of data available\nprint('Characters:')\ndisplay(df_characters.head())\nprint('Locations:')\ndisplay(df_locations.head())\nprint('Script Lines:')\ndisplay(df_script.head())\nprint('Episodes:')\ndisplay(df_episodes.head())",
    "Mapping from location_id to location_name\nlocation_id_to_name = dict(df_locations[['id', 'name']].values)",
    "Inspect the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect the first few lines of the characters dataframe\ndf_characters.head()",
    "Preview the characters dataframe\ndf_characters.head()",
    "Inspect the first few lines of each dataframe to understand their structure and the type of data they contain.",
    "Clean up some of the script line columns to strings.",
    "Extract main characters\nmain_characters = [\"homer\", \"marge\", \"bart\", \"lisa\", \"maggie\", \"skinner\", \"ned\", \"burns\", \"milhouse\", \"moe\", \n                   \"krusty\", \"edna\", \"sideshow\", \"apu\", \"chief\", \"barney\", \"carl\", \"lenny\", \"duffman\", \"selma\", \n                   \"patty\", \"ralph\", \"nelson\", \"todd\", \"mcbain\", \"groundskeeper\", \"maggie's\", \"waylon\", \"rod\", \n                   \"troy\", \"helen\", \"fat tony\", \"lionel\", \"gary\", \"karl\", \"frink\"]",
    "Display maximum columns and rows in dataframes\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)",
    "Add the character information to the script dataframe\ndf_script = df_script.merge(df_characters, how='left', on='character_id')",
    "Customisation\n# Set pandas display options\npd.set_option('display.max_rows', 5)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
    "Quick look at characters data\ndf_characters.head()",
    "merge the episodes with the script data. This will give us script data with episode data included\ndf = df_script.merge(df_episodes, on='episode_id')",
    "Optimizing memory usage",
    "Visualizing the first few rows of the dataframes to better understand the data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Load the pre-trained spacy NLP model\nnlp = spacy.load('en_core_web_sm')",
    "Every dataset loaded successfully.",
    " We can see some simple statistics, as well as the top 10 first tokens.",
    "# Add index in each dataframe\ndf_characters.index.name = 'character_id'\ndf_locations.index.name = 'location_id'\ndf_script.index.name = 'line_id'\ndf_episodes.index.name = 'episode_id'",
    " Set index for faster access\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "printing out attributes of the dataframes",
    "Generate length of dialogues\ndf_script['raw_character_text'] = df_script['raw_character_text'].apply(lambda x: str(x))",
    " Display the first few rows of the dataframe\ndf_script.head()",
    "Let's take a look at some of the data.",
    "The Simpsons Script Analysis for Business Insights and Data Analysis",
    "pd.set_option('display.max_columns', None)",
    "Displaying all the dataframes as there should be direct download source available is allowed under `data` folder.",
    "Explore data\n(df_characters[:5], df_locations[:5], df_script[:5], df_episodes[:5])",
    "Check the first few rows of the dataframe to understand its structure\ndf_script.head()",
    "Initial examination of the data",
    "Display head of characters dataframe",
    "Preview the characters DataFrame\ndf_characters.head()",
    "# Create a DataFrame with the lines relevant to the character 'Homer Simpson' \nhomer_lines = df_script[df_script['character_id'] == 2].reset_index(inplace=False, drop=True)",
    "Function to display a word cloud\ndef plot_wordcloud(text, title, image_name):\n    wordcloud = WordCloud(width = 800, height = 800, \n                background_color ='black', \n                stopwords = None, \n                min_font_size = 10).generate(text)\n    # set the figsize\n    plt.figure(figsize = (8, 8), facecolor = None) \n    plt.imshow(wordcloud) \n    plt.axis(\"off\") \n    plt.tight_layout(pad = 0) \n    plt.title(title, fontsize=20)\n    plt.savefig(f'images/{image_name}.png')\n    plt.show()",
    "Remove script lines that have not spoken by characters and locations that are not known.",
    "Merging character names and script\ndf_characters_script = df_script.merge(\n    df_characters,\n    how='left',\n    left_on='character_id',\n    right_on='id',\n    suffixes=('_script', '_character'),\n)",
    "View columns and first few rows of characters dataframe\ndf_characters.head()",
    "# Some pre-processing\ndf_script = df_script.dropna(subset=['normalized_text'])",
    "Visualisation for df_characters",
    "Merge script with characters and locations\ndf_all = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id')\ndf_all = pd.merge(df_all, df_locations, how='left', left_on='location_id', right_on='id')",
    "Load pre-trained model\nnlp = spacy.load('en_core_web_md')",
    "Merging tables to get all informations in the same place\ndf = df_script.merge(df_episodes, on='episode_id', suffixes=('_script', '_ep'))\ndf = df.merge(df_characters, on='character_id', suffixes=(False, '_ch'))\ndf = df.merge(df_locations, on='location_id', suffixes=(False, '_loc'))",
    "Check whether characters names are duplicated or not.",
    " Preprocess the data\n# Remove NaN values\ndf_characters.dropna(inplace=True)\ndf_locations.dropna(inplace=True)\ndf_script.dropna(inplace=True)\ndf_episodes.dropna(inplace=True)",
    "Print the first few lines of the script data to inspect the structure\nprint(f'Shape: {df_script.shape}')\ndf_script.head()",
    "Insepct the first 5 records of the character dataframe",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Text preprocessing and cleaning",
    "Checking the first few lines of the DataFrames for sanity check.\nprint('Characters:')\nprint(df_characters.head(), end='\\n\\n')\n\nprint('Locations:')\nprint(df_locations.head(), end='\\n\\n')\n\nprint('Script lines:')\nprint(df_script.head(), end='\\n\\n')",
    "Print the first lines of the characters csv.",
    " Display the dataframe\ndf_episodes",
    " Display full DataFrame width\npd.set_option('display.max_colwidth', None)",
    "First, the necessary Python packages are imported. These include standard packages such as `os`, `pandas`, `numpy`, `spacy`, and `matplotlib`, as well as custom packages such as `tqdm` and `Counter`. The `%matplotlib inline` command is also used to ensure that `matplotlib` works correctly with Jupyter.\nThen, four datasets (`df_characters`, `df_locations`, `df_script`, and `df_episodes`) are read from CSV files using `pd.read_csv` and stored in Pandas DataFrames. These datasets contain information about characters, locations, script lines, and episodes from The Simpsons TV show, and will be used for analysis and visualization.",
    "Just continue the code from the last line",
    " Check the content of the 'characters' file",
    "Custom imports\nfrom tqdm import tqdm\nfrom collections import Counter",
    "# We are now ready to start the analysis.",
    "utf-8'decode' codec can't decode byte 0x89 in position 0: invalid start byte",
    "Remove unused dataframes, clean script, save dataframe",
    "Install the spacy 'en' model to preprocess the text.",
    "Check that the imports and data load ran correctly\ndf_script.head()",
    "This code snippet imports the necessary libraries and datasets for the subsequent analysis of Simpson's script data.",
    "Set the seed for reproducibility\nnp.random.seed(0)",
    " Character's names written in other languages to ignore\nsimps_char_names_ignore = ['Eliza Simpson', 'Spanish Homer', 'Harv Bannister', 'Grady Little', 'Roger Meyers', 'Lil\\' Hitler', 'Sylvester Stallone\\'s head', 'Mahatma Gandhi', 'Leon Kompowsky', 'Frankie the Squealer', 'English judge']",
    "jupyter nbconvert --to html notebook.ipynb",
    " Set font style\nfont = {\n    'family': 'DejaVu Sans',\n    'weight': 'normal',\n    'size': 14\n}\nmatplotlib.rc('font', **font)",
    "Let's take a look at the shape of each DataFrame to understand how much data we're dealing with.",
    "Label 'other' as gender for np.nan values in the gender column\ndf_characters['gender'] = df_characters['gender'].replace({np.nan: 'other'})",
    "Set Seaborn aesthetics",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    "Check dataframes load correctly\ndf_script.head()",
    "Display\ndf_characters.head()",
    "# Display how many unique characters and locations there are in The Simpsons\nprint(f\"Number of unique characters: {df_characters.shape[0]}\")\nprint(f\"Number of unique locations: {df_locations.shape[0]}\")",
    "Create a new column 'raw_character_text' in df_script that contains the character's text as it is.",
    "Extend pandas show method to improve visibility of dataframe columns in Jupyter notebooks",
    "Display the first few lines of the dataframe to inspect its structure\ndf_script.head()",
    "Check for broken scripts",
    "Helper function to clean text.",
    "Set 'id' as index for quick search",
    "quick look at the characters dataframe\nprint(f'Size of the dataframe: {len(df_characters)}')\ndf_characters.head()",
    "Create columns scenes and text length, for each line in the script.",
    " Import the Gensim summarization module\nfrom gensim.summarization import summarize",
    "Let's print the number of rows in each dataframe using the shape attribute.",
    "Reading the datasets containing the characters, locations, script lines, and episodes of The Simpsons.",
    "Load SpaCy NLP model\nnlp = spacy.load('en_core_web_sm')",
    "Load the datasets and reset their indices to start from 0.",
    "Display 5 random rows for each dataframe\nprint('The characters dataframe:')\ndisplay(df_characters.sample(5))\n\nprint('The locations dataframe:')\ndisplay(df_locations.sample(5))\n\nprint('The script dataframe:')\ndisplay(df_script.sample(5))\n\nprint('The episodes dataframe:')\ndisplay(df_episodes.sample(5))",
    " What's the complete code?",
    "Display the first few rows of the dataset\ndf_script.head()",
    "Functions for plotting WordClouds",
    "Define the list of episodes for which we have both the script and the subtitles\ncommon_episodes = list(set(df_script[df_script['episode_id'] != -1].episode_id).intersection(set(df_episodes[df_episodes['id'] != -1].id)))",
    " Display first 5 records.\ndf_episodes.head()",
    "Quick overview of the data\nprint(\"Characters\")\nprint(df_characters.head())\nprint(\"\\nLocations\")\nprint(df_locations.head())\nprint(\"\\nScript Lines\")\nprint(df_script.head())\nprint(\"\\nEpisodes\")\nprint(df_episodes.head())",
    "Create a column with all the script lines of an episode",
    "What is the shape of the scripts dataframe?\ndf_script.shape",
    "Checking the first few rows of each dataframe to understand its structure\nprint('Characters')\nprint(df_characters.head())",
    "Set up data for analysis\n# Extract episode number and script from the main dataframe\nepisodes_script = df_script[['episode_id', 'raw_text']]",
    "ensure we're using the correct version of spacy for compatibility\n!pip install spacy==3.0.6",
    "Load the data into dataframes and reset the index to ensure the indexes are correct.",
    "Print dataframe shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    "Filter US only characters",
    "Data from `simpsons_script_lines.csv` will be used since that's where the text data is located.",
    "Let's check the shape of each DataFrame\nprint(\"Characters DataFrame:\", df_characters.shape)\nprint(\"Locations DataFrame:\", df_locations.shape)\nprint(\"Script DataFrame:\", df_script.shape)\nprint(\"Episodes DataFrame:\", df_episodes.shape)",
    "Jupyter notebook configuration\npd.set_option('display.max_columns', None)",
    "Let's inspect the data first.",
    "Show the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Merge datasets",
    "Combien y a-t-il de personnages dans la table `df_characters` ?",
    " Apply ?? over the different dataframes to look samples",
    "Some configuration for pandas and numpy\npd.set_option('display.max_columns', None)\nnp.random.seed(42)",
    " Display first 5 rows of df_characters dataframe\ndf_characters.head()",
    " Drop any missing values in these important fields\nprint(df_script.shape)\ndf_script = df_script.dropna(subset=['episode_id', 'character_id', 'raw_text'])\nprint(df_script.shape)",
    "Apply basic preprocessing\ndf_script = df_script[df_script['episode_id'] != 464]  # Removing faulty lines\ndf_script = df_script[df_script.notnull()]  # Dropping NaN values in all columns",
    "Preview the dataframes to understand their structure and available columns",
    "Setting the index after resetting it with Pandas.",
    "Check the content of the df_script DataFrame\ndf_script.head()",
    "Check for null values\nprint('Null values in df_characters:', df_characters.isnull().sum().sum())\nprint('Null values in df_locations:', df_locations.isnull().sum().sum())\nprint('Null values in df_script:', df_script.isnull().sum().sum())\nprint('Null values in df_episodes:', df_episodes.isnull().sum().sum())",
    "Print the first 5 rows of the episodes dataframe to understand how the data is structured\ndf_episodes.head()",
    " Select only script lines in English\ndf_script_en = df_script[df_script['raw_text'].str.startswith('- ')]",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Merge the necessary data and filter the dataframe rows based on the conditions mentioned in the prompt.",
    " Set display options for pandas dataframe\npd.set_option('display.max_columns', None)",
    "View data shape and general info\ndf_characters.shape",
    "Filter out the 'simpsons_script_lines' and keep only the spoken lines",
    "We're reading the CSV files into pandas DataFrames for further processing and analysis.",
    "To get an insight, let's first look at how the various dataframes look like.",
    " Display the first few rows of each dataframe\ndf_characters.head()",
    " Jupyter-notebook-like help to visualize DataFrames easily\nfrom IPython.display import display",
    " Display the first few rows of each dataframe to get an overview of the data",
    "Display the first few rows of the characters DataFrame\ndf_characters.head()",
    " display the dimensions of the dataframes\nprint(df_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape)",
    "Create new columns\ndf_script['episode_id'] = pd.to_numeric(df_script['episode_id'], errors='coerce')\ndf_script['character_id'] = pd.to_numeric(df_script['character_id'], errors='coerce')\ndf_script['location_id'] = pd.to_numeric(df_script['raw_location_text'], errors='coerce')",
    "Inspect dataframes quickly",
    " Remove nulls values in the script\ndf_script = df_script[df_script.raw_location_text.notnull()]\ndf_script = df_script[df_script.raw_character_text.notnull()]",
    " Set seed for reproducibility\nnp.random.seed(0)",
    " Apply Character and Location Filter\ncharacter_list = ['homer simpson', 'marge simpson', 'bart simpson', 'lisa simpson', 'maggie simpson', 'grampa simpson',\n                  'ned flanders', 'moe szyslak', 'krusty the clown', 'chief wiggum',\n                  'lenny leonard', 'carl carlson', 'waylon smithers', 'milhouse van houten', 'edna krabappel',\n                  'kent brockman', 'nelson muntz', 'apu nahasapeemapetilon', 'sideshow bob',\n                  'reverend lovejoy', 'mrs. krabappel', 'principal skinner', 'mrs. simpson', 'hugo simpson']\n\nlocation_list = ['simpson home', 'moe\\'s tavern', 'springfield nuclear power plant', 'kwik-e-mart',\n                 'springfield elementary school', 'kitchen', 'jake\\'s unisex hair palace', 'springfield street']",
    " Show head of dataset\ndf_script.head()",
    "print(f\"Characters: {df_characters.shape}\")\nprint(f\"Locations: {df_locations.shape}\")\nprint(f\"Script: {df_script.shape}\")\nprint(f\"Episodes: {df_episodes.shape}\")",
    "Create save directory if it doesn't exist\nif not os.path.exists('plots'):\n    os.mkdir('plots')",
    "Display the first 5 rows of each dataframe",
    "Define the path to the word frequency image that we will generate using WordCloud.",
    "Inspecting the data shapes",
    "Let's start by printing the first few rows of each DataFrame to understand our data.",
    "Merge the data into a single dataframe for analysis\ndf_characters_SCRIPT = df_characters.rename(columns={'id':'character_id'}).merge(df_script.rename(columns={'character_id_id':'character_id'}), on='character_id')\ndf_locations_SCRIPT = df_locations.rename(columns={'id':'location_id'}).merge(df_script.rename(columns={'location_id_id':'location_id'}), on='location_id')",
    "Replace NaN values\ndf_characters.replace({np.nan: None}, inplace=True)\ndf_locations.replace({np.nan: None}, inplace=True)\ndf_script.replace({np.nan: None}, inplace=True)\ndf_episodes.replace({np.nan: None}, inplace=True)",
    "Load the pre-trained Spacy NLP model\nnlp = spacy.load('en_core_web_md')",
    "Set the episode ID as the index to make lookups easier\ndf_script.set_index('episode_id', inplace=True)",
    " Select only the episodes corresponding to the first 8 seasons.",
    "Check a few lines of each DataFrame to understand how the data looks like\ndf_characters.head()",
    "Define the relationship between: df_script <-> df_episodes <-> df_characters",
    "# Display the first few rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "Set the index for each dataframe to be the unique identifier for each entry",
    "Setup constants",
    "Inspect the content of the characters dataframe",
    "Initialize spaCy model\nnlp = spacy.load(\"en_core_web_sm\")",
    "Display max columns at pd\npd.set_option('display.max_columns', None)",
    "Set SEED for reproducibility\nSEED = 42",
    "Look at the number of words per line and sentence in the script data\ndf_script['words_per_line'] = df_script['normalized_text'].map(lambda x: len(x.split()))\ndf_script['words_per_sentence'] = df_script['normalized_text'].map(lambda x: len(x.split('.')))\n\n# Plot histograms for the number of words per line and sentence\nplt.figure(figsize=(14, 6))\n\nplt.subplot(1, 2, 1)\nplt.hist(df_script['words_per_line'], bins=200, color='skyblue', edgecolor='black')\nplt.title('Distribution of words per line')\nplt.xlabel('# words')\nplt.ylabel('Frequency')\n\nplt.subplot(1, 2, 2)\nplt.hist(df_script['words_per_sentence'], bins=200, color='lightgreen', edgecolor='black')\nplt.title('Distribution of words per sentence')\nplt.xlabel('# words')\nplt.ylabel('Frequency')\n\nplt.show()",
    "Merge characters, locations, episodes, and script lines\ndf = df_script.merge(df_episodes, on='episode_id', how='inner') \\\n              .merge(df_characters, on='character_id', how='inner') \\\n              .merge(df_locations, on='location_id', how='inner')",
    "Inspect the head of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Select the fields of interest from the dataframes",
    "Check the dataset shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "We will start by doing some exploration of the data.",
    "Inspect the data types and missing values of the characters dataframe.",
    "Show all available columns\npd.set_option('display.max_columns', None)",
    " Display the first 5 rows of each dataframe to display the structure of the data.",
    "Check the first 5 rows of the characters dataframe",
    "Data Analysis",
    "Extract the script for a single episode.",
    "Let's have a look at the data.",
    "Show installed fonts\n[f.name for f in matplotlib.font_manager.fontManager.ttflist]",
    "Let's take a look at the first few lines of each dataframe.",
    "Declare globally-used variables",
    "We will first briefly look at the data.",
    "Set number of rows to be displayed in the output\npd.set_option('display.max_rows', 1000)",
    "Creating necessary folder structure for saving models and tokenizers",
    " Look at first couple of records for the characters, locations and script dataframes to understand what kind of data they contain\ndf_characters.head()",
    " Set a limit on the number of rows and columns displayed by pandas DataFrames\npd.set_option('display.max_rows', 10)\npd.set_option('display.max_columns', 100)",
    "We will now take a look at the imported dataframes to understand their structure and contents.",
    "Connect to sqlite db\nimport sqlite3\n\nconn = sqlite3.connect('data/simpsons_script_database.db')",
    "Join Script Lines and Character Info\nmerged_df = pd.merge(df_script, df_characters, left_on='character_id', right_on='id', suffixes=('_script', '_char'), how='left').fillna(value=np.nan)\n\n# Join Script Lines and Location Info\nmerged_df = pd.merge(merged_df, df_locations, left_on='location_id', right_on='id', suffixes=('_script', '_loc'), how='left').fillna(value=np.nan)",
    "Let's display the first few records of each dataset to understand what we're working with.",
    " Display head of lines\ndf_script.head()",
    "Set text length to take into account\nTEXT_LENGTH = 3",
    "Inspect the datasets",
    " Check the resulting DataFrames\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Manually set the index to the 'id' field\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)",
    "Check if all the data is present\ndf_episodes.head(), df_characters.head(), df_locations.head(), df_script.head()",
    "First, let's take a look at the structure of the datasets.",
    "Let's take a look at the structure of the datasets.",
    "Check the files we have\nprint(\"Simpsons characters\")\nprint(df_characters.head())\nprint(\"\")\nprint(\"Simpsons locations\")\nprint(df_locations.head())\nprint(\"\")\nprint(\"Simpsons script\")\nprint(df_script.head())\nprint(\"\")\nprint(\"Simpsons episodes\")\nprint(df_episodes.head())",
    "Show the number of rows and column in each dataframe\ndf_episodes.shape, df_script.shape, df_characters.shape, df_locations.shape",
    "Show Word Cloud for every Season Word Clouds for each season - top 100 lemmas displayed, sizes based on the number of occurrences in the whole season",
    "Display general information about the data\ndf_episodes.info()",
    "Merge script lines with episode data\ndf = df_script.merge(df_episodes, on='episode_id', how='left')\n\n# Split data into training and validation sets\nnp.random.seed(0)\ndf_train = df.sample(frac=0.8, random_state=0)\ndf_val = df.drop(df_train.index)\n\n# Ensure we have a good mix of classes\nprint(df_train['raw_character_text'].value_counts(normalize=True))",
    "Ensure the correct path for the data folder is set by running the code below:\nos.path.abspath('data')",
    "importing our custom classes and functions",
    " Display number of data points for each table\nprint(f\"Number of points in characters table: {len(df_characters)}\")\nprint(f\"Number of points in locations table: {len(df_locations)}\")\nprint(f\"Number of points in script table: {len(df_script)}\")\nprint(f\"Number of points in episodes table: {len(df_episodes)}\")",
    " Let's count the number of script lines in each episode and store the result in a new dataframe.",
    "Print a first few rows of the first DataFrames, to get a feeling of their structure.\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Change end of line character to simulate a new paragraph\n# Ceate a temporary column with the lines change\ndf_script = df_script.assign(text_changed = df_script['raw_text'] + \"\\n\")\n\n# Group by episode_id and character_id to retrieve the full script of each character in a given episode\ndf_script_episode_level = df_script.groupby(['episode_id', 'character_id']).agg({'text_changed': 'sum'}).reset_index()\n\n# Group by character_id to retrieve the full script of each character in the whole show\ndf_script_character_level = df_script.groupby(['character_id']).agg({'text_changed': 'sum'}).reset_index()",
    "Drop unnecessary columns to save memory\ndf_script.drop(columns=['align', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_image_url', 'episode_id', 'location_id', 'production_code', 'original_air_year', 'id'], inplace=True)",
    "We have successfully imported the necessary libraries and data.",
    "Display script dataframe\ndf_script.head()",
    " Take a quick look at the first few lines of each data frame\ndisplay(df_characters.head(5))\ndisplay(df_locations.head(5))\ndisplay(df_script.head(5))\ndisplay(df_episodes.head(5))",
    " Paths\ndataset_name = 'thesimpsons'\nsaved_path = f'../Datasets/{dataset_name}/'",
    "Let's start by checking the first rows of each dataset to become familiar with the data.",
    " Print schema\nprint(df_script.dtypes)",
    " Display new max rows\npd.set_option('display.max_rows', 500)",
    "Plot WordCloud of character for a specific episode",
    "Merge dataframes",
    " Clean script dataframe\ndf_script = df_script[pd.notnull(df_script['normalized_text'])]\ndf_script = df_script[pd.notnull(df_script['character_id'])]\ndf_script = df_script[df_script['speaking_line'] == True]\ndf_script = df_script[df_script['normalized_text'] != '(END OF PREVIEW)']",
    "Combine the data from multiple dataframes into one dataframe for simplicity and ease of analysis.",
    " Print out the first couple of values from each table to get an understanding of the data.",
    "Inspect the head of the dataframes to understand their structure and contents\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Filter the characters that are actually speaking",
    "Helper functions to display data in a nice format.",
    " Load the spacy model\nnlp = spacy.load('en_core_web_sm')",
    " Join the data together\ndf_script = df_script.join(df_episodes, on='episode_id', rsuffix='_episode', how='left')\ndf_script = df_script.join(df_characters, on='character_id', rsuffix='_character', how='left')\ndf_script = df_script.join(df_locations, on='location_id', rsuffix='_location', how='left')\n\n# Keep relevant columns\ndf_script = df_script[['id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line',\n                       'episode_id', 'name_episode', 'original_air_date', 'production_code',\n                       'season', 'number_in_season', 'number_in_series',\n                       'character_id', 'name_character', 'normalized_name_character', 'gender',\n                       'location_id', 'name_location', 'normalized_name_location']]",
    "Extraire le texte de tous les pisodes",
    " Looks like the code is importing the necessary data using pandas.",
    "Change this to the path of the cloned repo on your machine.\nPATH = \"/content/Springboard-Capstone-Three\"",
    " Let's get an overview of the data",
    "Create out directory if it doesn't exist\nif not os.path.exists('out'):\n    os.makedirs('out')",
    "Displaying the dataframe head as well as the metadata of each dataframe",
    " Take a look at the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Merge lines with character and locations files\ndf_script = pd.merge(df_script, df_characters, on='character_id', how='left')\ndf_script = pd.merge(df_script, df_locations, on='location_id', how='left')\n\n# Merge script with episodes\ndf_script = pd.merge(df_script, df_episodes, on='episode_id', how='left')",
    "Define some utility functions for cleaning text and counting occurences of entities in each field",
    "Create a subset of episodes if needed\ndf_subset_episodes = df_episodes[df_episodes[\"id\"] <= 600].copy()",
    "Get an overview of the datasets\ndf_script",
    " Check dataframes\ndf_script.head()",
    "Merge the episode dataset with the script dataset\ndf_merged = df_script.merge(df_episodes, on='episode_id')",
    "Checking the first couple of scripts in the Simpsons DataFrame",
    "Memory usage of each DataFrame\nprint(\"Memory usage of each DataFrame\")\nprint(df_characters.info(memory_usage='deep'))\nprint(df_locations.info(memory_usage='deep'))\nprint(df_script.info(memory_usage='deep'))\nprint(df_episodes.info(memory_usage='deep'))",
    "Merge the character and location information into the script dataframe\ndf_script = df_script.join(df_characters.set_index('id'), on='character_id')\ndf_script = df_script.join(df_locations.set_index('id'), on='location_id')",
    "Extract the main fields and linking key from the script dataframe.",
    " We start by printing out the begining of each dataframe to see what we are working with\nprint('Characters head')\nprint(df_characters.head())\nprint('\\nLocations head')\nprint(df_locations.head())\nprint('\\nScript head')\nprint(df_script.head())\nprint('\\nEpisodes head')\nprint(df_episodes.head())",
    "Draw countplots for characters and locations\nplt.figure(figsize=(18, 10))\nplt.subplot(2, 1, 1)\nsns.countplot(y='raw_character_text', data=df_script, palette='dark:salmon_r', order=df_script['raw_character_text'].value_counts().index)\nplt.title('Character Counts')\n\nplt.subplot(2, 1, 2)\nsns.countplot(y='raw_location_text', data=df_script, palette='dark:salmon_r', order=df_script['raw_location_text'].value_counts().index)\nplt.title('Location Counts')\n\nplt.tight_layout()\nplt.show()",
    "Drop unnecessary column\ndf_script.drop(columns=['id', 'episode_id', 'number'], inplace=True)",
    "Print the first 5 lines of the dataframe\nprint(df_characters.head())",
    "Shows the first few rows of the script dataframe.",
    "\n# Various functions to clean data for analysis",
    "provide the list of dates an episode first aired",
    "Remove Simpsons lines with empty text\ndf = df_script.copy()\ndf.dropna(subset=['normalized_text'], inplace=True)",
    "Load the spaCy model\nnlp = spacy.load('en_core_web_sm')",
    " Take a look at the first few rows of the dataframe\ndf_episodes.head()",
    "Requirement 1.3: The script must make use of a function from each of the imported libraries at least once.",
    "\ndf_script.shape",
    "Take a look at the character data\ndf_characters.head()",
    "Checking the structure of this table.",
    "Ensure matplotlib uses the `ggplot` style\nplt.style.use('ggplot')",
    "Remove unecessary columns",
    "Convert string representation of list of episodes into a list of integers\ndf_episodes['us_viewers_in_millions'] = df_episodes['us_viewers_in_millions'].apply(lambda x: float(x) if x != 'na' else np.nan)\ndf_episodes['views'] = df_episodes['views'].apply(lambda x: x if x != 'na' else np.nan)",
    " show the scripts dataset\ndf_script.head()",
    "Display the first few rows of the episodes dataframe to understand the data.",
    "This will allow us to simply call head(), tail() or sample() on our dataframe instead of remembering the name of the index column.",
    "Time to look at the files we have loaded!",
    " Set matplotlib style\nplt.style.use('fivethirtyeight')",
    "Preview the first 5 rows of the dataset\ndf_characters.head()",
    "Limit the number of script lines for faster processing time\ndf_script_limit = df_script.sample(n=600000, random_state=1)",
    "Join the script lines with the characters, locations, and episodes dataframes.",
    "Quick exploration of the data",
    "To validate the shapes of each dataframe\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Join the dataset on the character ID",
    "Now let's take a look at the first few rows of our datasets.",
    "For numerical method and manipulations\nfrom scipy.optimize import minimize\n\n# Natural Language Processing\nimport spacy\nnlp = spacy.load('en')",
    "Now, let's take a look at the first few rows of each dataframe.",
    " Display the first 5 lines of the characters DataFrame\ndf_characters.head()",
    "Inspect the first few rows of the first dataframe\ndf_characters.head()",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Display first 5 rows of characters dataframe\ndf_characters.head()",
    "Check the content of the characters CSV file in order to understand if there are inconsistencies or special cases to consider.",
    "Check the content of the file 'simpsons_characters.csv'",
    "Previewing the data.",
    "Merge relevant data\ndf_merged = pd.merge(df_script, df_episodes,\n                     on='episode_id',\n                     how='left')\n\ndf_merged = pd.merge(df_merged, df_characters,\n                     on='character_id',\n                     how='left')\n\ndf_merged = pd.merge(df_merged, df_locations,\n                     on='location_id',\n                     how='left')",
    "Merge character information\ndf_characters = df_characters.rename(columns={'id': 'character_id'})\ndf_script = df_script.merge(df_characters, on='character_id')\n\n# Merge location information\ndf_locations = df_locations.rename(columns={'id': 'location_id'})\ndf_script = df_script.merge(df_locations, on='location_id')\n\n# Merge episode information\ndf_episodes = df_episodes.rename(columns={'id': 'episode_id'})\ndf_script = df_script.merge(df_episodes, on='episode_id')",
    "Merge character data into script data\ndf = pd.merge(df_script, df_characters, how='left', left_on='character_id', right_on='id', suffixes=('_script', '_character'))",
    "Download Spacy English model\n!python -m spacy download en",
    "Merge location and episode data with the script data\ndf_merged = df_script.merge(df_episodes, on='episode_id').merge(df_locations, on='location_id')\n\n# Show a preview\ndf_merged.head()",
    "Create dictionary for episode titles",
    " Reverse episodes index so it matches the script pd (by date)",
    "Checking the imported dataframes",
    "check the first few rows of each dataframe to understand their structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Use the \"utf-8\" encoding to avoid issues with special characters",
    "Inspect the characters dataframe\ndf_characters.head()",
    " Display the head of each dataframe, by calling the head() function on each dataframe.",
    "Checking if the dataframe has been successfully loaded\nprint(df_characters.head())",
    "Only include the parts of the script that have been spoken by a character.",
    " Display first few rows of the dataframe to understand the data better.\ndf_script.head()",
    " Set some parameters for better visualization in matplotlib",
    "Introduction_Implementation cleaned up some of this data and store it in\n# separate files so that these would load faster in Jupyter\n\n# Head of the characters df\nprint(df_characters.head())",
    " Load custom NLP pipeline from disk",
    " Display the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check the loaded datasets\ndf_script.head()",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Set the index of the datasets to the unique id of the associated elements\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)",
    "The script that computes the length of each line in words is given below:",
    " Beautiful display for tables\ndef display_df(df):\n    display(HTML(df.to_html()))",
    "Filter by character\ndf_script['character_id'] = df_script['character_id'].astype(str)  # convert to str for consistency\ndf_characters['id'] = df_characters['id'].astype(str)  # convert to str for consistency",
    "General imports\nimport os",
    " Display the information about the characters dataframe\ndf_characters.info()",
    " Show the first few rows of the characters dataframe\ndf_characters.head()",
    " Allow pandas to display the full content of a column\npd.set_option('display.max_colwidth', None)",
    "View data shapes\nprint('Characters shape:', df_characters.shape)\nprint('Locations shape:', df_locations.shape)\nprint('Script shape:', df_script.shape)\nprint('Episodes shape:', df_episodes.shape)",
    "Limits the number of displayed rows in a pandas DataFrame to improve the output readability\npd.set_option('display.max_rows', 5)",
    "Optional: Remove all production- and location-related script lines (scenes, songs, technical annotations, ...).",
    " Load and display dataframes from CSV files",
    "Merge episodes with scripts\ndf = df_script.merge(df_episodes, on='episode_id')",
    "taken from https://www.kaggle.com/pierremegret/dialogue-lines-of-the-simpsons\n# Some descriptions of the individual dataframes can be found there.",
    "Show figures in this notebook\nmatplotlib.style.use('ggplot')",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Display the first 5 rows of the dataframe containing the characters.",
    "Clean data\ndf_script_clean = df_script.dropna(subset=['raw_text'])\n\n# Preview data\ndf_script_clean.head()",
    "Let's see the first few characters of the script dataframe.",
    " Verify content of dataset\ndf_episodes.head()",
    " Check if we have NaN values in the dataset, True means that we have NaN values, False means that we don't.",
    " Let's preview the data to understand what we have.",
    "A function to display basic info about a dataframe\ndef df_summary(df, title=\"\"):\n    print(f'\\033[1m{title}\\033[0m')\n    print(df.info())",
    "Setting pandas to show all columns when .head() is called on a dataframe\npd.set_option('display.max_columns', None)",
    "Print head of characters dataframe\ndf_characters.head()",
    " Enable jupyter_contrib_nbextensions for easier notebook use\n!jupyter contrib nbextension install",
    "View the first few rows of the dataframe\ndf_script.head()",
    "Load spacy model\nnlp = spacy.load('en_core_web_sm')",
    "Print the first few lines of the characters data frame\nprint(df_characters.head())",
    "Set up colors for plotting\ncolors = {\n    'other': '#adb0ff',\n    'male': '#ffb3e6',\n    'female': '#90d595'\n}",
    "Change these to {inplace = True}",
    "Optional: Preprocess the names if not using scripts/lines for filtering the dialogues\n\ndef preprocess(text):\n    return text.lower()",
    "Create spaCy pipeline\nnlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])",
    " Add character names to script lines dataframe\ndf_script = df_script.merge(df_characters, left_on='character_id', right_index=True)",
    "Filtering out the non-speaking lines",
    " Display the first few characters of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "##### Section 1: DataFrame Cleaning and Preparation #####\n",
    "Set a seed for reproducibility",
    "Setting display configuration to display all columns of the DataFrames in Jupyter notebook",
    "Join locations to scripts\ndf_locations = df_locations.rename(columns={'id': 'location_id'})",
    "Display the first few records of the script dataframe\ndf_script.head()",
    "To ensure that the data has been read correctly, we can display a preview of each DataFrame using the `head()` method.",
    " Merge script lines with characters and episodes\ndf_lines_episodes = df_script.merge(df_characters, on='character_id').merge(df_episodes, on='episode_id').dropna()\n\ndf_lines_episodes.head()",
    " Replace NaN\ndf_script.loc[:, 'speaking_line'] = df_script['speaking_line'].fillna(False).astype(bool)\ndf_script.loc[:, 'character_id'] = pd.to_numeric(df_script['character_id'], downcast='integer', errors='coerce')\ndf_script.loc[:, 'location_id'] = pd.to_numeric(df_script['location_id'], downcast='integer', errors='coerce')",
    " Set the index to the unique identifier\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)\ndf_episodes.set_index('id', inplace=True)\ndf_script.set_index('id', inplace=True)",
    "\ndf_characters.head()",
    " Tokenize the script lines using spacy.",
    "Helper functions and variables",
    "Count Number of lines for each Episode",
    " show the first few rows of the table, for easier understanding\ndf_script.head()",
    "Filter episodes with location_id and character_id\ndf_script = df_script[(df_script['location_id'].notnull()) & (df_script['character_id'].notnull())].reset_index(inplace=False, drop=True)",
    " Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Inspect first few rows of the characters data\nprint(df_characters.head())",
    "Load NLP models\nnlp = spacy.load(\"en_core_web_sm\")",
    "Declare paths to be used\nimport_path = 'data/simpsons_script_lines.csv'\nexport_path = 'data/simpsons_script_lines_preprocessed.csv'",
    " Look at the first few rows of the dataframe\ndf_characters.head()",
    " The lines correspond to XML codes, so we remove them using only the columns related to single lines of speech, and we fill NaN with an empty string\nlines = df_script[['character_id', 'location_id', 'spoken_words']].fillna('')\nlines.head()",
    " Original dataframe sizes\nprint('Characters:', df_characters.shape)\nprint('Locations:', df_locations.shape)\nprint('Script:', df_script.shape)\nprint('Episodes:', df_episodes.shape)",
    " Merge the script lines and the episodes dataframes on the episode_id column\ndf_merged = pd.merge(df_script, df_episodes, on='episode_id', how='outer')",
    "Creation of the \"simpsons_episodes\" table",
    "Display the first 5 rows of the script dataframe\ndf_script.head()",
    " Filter out characters who have spoken too few lines\nMIN_LINES = 500\ncharacter_lines = df_script.groupby('character_id').size()\nvalid_characters = character_lines[character_lines > MIN_LINES].index.tolist()\ndf_script = df_script[df_script['character_id'].isin(valid_characters)]",
    " Merge the script lines with the characters and locations information\ndf_script_char = df_script.merge(df_characters, how=\"left\", left_on=\"character_id\", right_on=\"id\", suffixes=(\"_script\", \"_char\")).drop(\"id_char\", axis=1)\ndf_script_loc = df_script_char.merge(df_locations, how=\"left\", left_on=\"location_id\", right_on=\"id\", suffixes=(\"_script\", \"_loc\")).drop(\"id\", axis=1)\n\n# Filter the main characters and locations\nmain_characters = [\"Lisa Simpson\", \"Bart Simpson\", \"Marge Simpson\", \"Homer Simpson\", \"C. Montgomery Burns\", \"Moe Szyslak\", \"Seymour Skinner\", \"Ned Flanders\", \"Grampa Simpson\", \"Milhouse Van Houten\"]\nmain_locations = [\"Simpson Living Room\", \"Simpson Kitchen\", \"Moe's Tavern\", \"Springfield Elementary School\", \"Kwik-E-Mart\", \"Simpson Backyard\", \"Simpson Car\"]\ndf_main = df_script_loc[df_script_loc[\"raw_character_text\"].isin(main_characters)]\ndf_main = df_main[df_main[\"raw_location_text\"].isin(main_locations)]",
    "Check the downloaded dataito see what we are working with\nprint('characters:', df_characters.shape)\nprint('locations:', df_locations.shape)\nprint('script:', df_script.shape)\nprint('episodes:', df_episodes.shape)",
    " Function to filter non-ascii characters in a string",
    " Let's start by loading the script data and taking a look at the first few rows.",
    "Let's take a glimpse of the first 5 rows of this dataframe-",
    "define the structure of the two tables containing the script and the characters involved.",
    "Sort alignments into character-based dataframes, and write to csv",
    "Check the size of the dataframes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "Visualize the proportion of lines for each character\ndf_characters_counts = pd.merge(df_script, \n                                df_characters, \n                                left_on='character_id', \n                                right_on='id').groupby('name').count()['id'].sort_values()\n\nplot = df_characters_counts.plot(\n    kind='pie',\n    figsize=(12,12),\n    title='Proportion of lines for each character',\n    autopct=lambda p: '{:.0f}% ({:.0f})'.format(p, p/100 * df_characters_counts.sum())\n    )\n\n# Change font size\nfor text in plot.texts:\n    text.set_fontsize(10)\n\nplt.show()",
    "Optional: Set custom Pandas options for viewing better DataFrame visualizations.",
    "Now that we have our datasets loaded into pandas DataFrames, we can start exploring the data and performing some analysis.",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Display all the dataframes to understand what is actually present in them",
    "Filter out bad quality lines and join by episode_id\ndf_script_filtered = df_script[\n    (df_script['speaking_line'] == True)\n    & (df_script['raw_text'].notna())\n][['episode_id', 'raw_text']].groupby('episode_id').agg(lambda x: ' '.join(x)).reset_index()",
    " We will first clean and preprocess the data to get it into a form suitable for analysis.",
    " Merge episode data into main dataframe",
    " First, let's take a look at the structure of the datasets.",
    " Merge episodes, script and characters\ndf = pd.merge(df_episodes, df_script, on='episode_id')\ndf = pd.merge(df, df_characters, on='character_id')",
    "Setting for the length of the lines displayed\npd.options.display.max_colwidth = 200",
    " Read the file containing distinct word and their word type",
    " Drop lines containing unwanted data from df_script\n# Check elements to be removed\ndf_script.replace('\\\\N','')",
    "Combining lines in a single message\ndf_script['spoken_words'] = df_script.groupby('timestamp_in_ms')['spoken_words'].transform(lambda x: ' '.join(x))\ndf_script = df_script.drop_duplicates(subset='timestamp_in_ms').reset_index(drop=True)",
    "We'll look at the first few records of each dataset to understand their structure better.",
    "Merges and filters data",
    "Set the pandas column display options to see the longer text.\npd.set_option('display.max_colwidth', 100)",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Stablish the type of each column, filtering non-numeric and non-string type",
    "Check data integrity\ndf_script.head()",
    "Set the script and entity to load into the DataFrame, and the column titles",
    " Display the first few rows of the characters data frame\ndf_characters.head()",
    "\n# Merge scripts with other tables for better style\ndf_script = pd.merge(df_script, df_episodes, \n                     left_on='episode_id', right_on='id',\n                     suffixes=('_script_line', '_ep')).drop(columns=['id_ep']).rename(columns={'name': 'episode_name', 'number': 'episode_number', 'id_script_line': 'id'})\n\ndf_script = pd.merge(df_script, df_characters, \n                     left_on='character_id', right_on='id',\n                     suffixes=('_script', '_character')).drop(columns=['id_character']).rename(columns={'name': 'character_name', 'normalized_name': 'character_normalized_name', 'id_script': 'id_character'})",
    "Visualize the distribution of the line_count column in the df_script dataframe",
    "Separate script and character lines\ndf_script_lines = df_script[df_script['character_id'].notna()]\ndf_character_lines = pd.merge(df_script_lines, df_characters, left_on='character_id', right_on='id')",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Helper functions to create WordClouds",
    "Filter out bad data",
    "Let's take a look at the first few lines of each DataFrame.",
    "Data preparation",
    "Let's see an overview of these datasets.",
    "Inspect the first 2 rows of the characters dataframe\ndf_characters.head(2)",
    "isplay all columns\npd.set_option('display.max_columns', None)",
    "# Checking for missing lines\n(df_script.isnull().sum() / len(df_script)) * 100",
    "Check dataframes shape\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "From the script dataset, we will use the following columns: character_id, episode_id, location_id, raw_text.",
    "Looking at the first rows of the characters dataframe\ndf_characters.head()",
    "Creating a full df from merging the other dfs.",
    "A subset of the Simpson dataset of interest for our text analysis is extracted. The chosen dataset includes the following tables: script lines, episodes, characters, and locations.",
    "Display the first few rows of the dataframe\ndf_script.head()",
    " For the characters and locations datasets, we only want characters that are in at least 5 episodes, and locations that appeared in at least 3 episodes.",
    "sns.set()",
    " View a sample of each dataframe\nprint('\\nDataframe of Characters:')\nprint(df_characters.sample(5))\nprint('\\nDataframe of Locations:')\nprint(df_locations.sample(5))\nprint('\\nDataframe of Script Lines:')\nprint(df_script.sample(5))\nprint('\\nDataframe of Episodes:')\nprint(df_episodes.sample(5))",
    "Set seed for reproducibility\nnp.random.seed(0)",
    "Initializing spaCy\nnlp = spacy.load(\"en_core_web_sm\")",
    "Remove duplicate columns from the dataframes",
    " Let's take a look at the structure of the datasets.",
    "Replace nans with ''\ndf_script_filtered = df_script[['character_id', 'location_id', 'normalized_text']].fillna('')",
    "Inspect the content of each of these dataframes\nprint(\"Characters\")\ndisplay(df_characters.head())\n\nprint(\"Locations\")\ndisplay(df_locations.head())\n\nprint(\"Script\")\ndisplay(df_script.head())\n\nprint(\"Episodes\")\ndisplay(df_episodes.head())",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Exploratory data analysis (EDA)",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "\ndf_script.head()",
    "Preview the data\nprint('Characters:')\ndisplay(df_characters.head(2))\nprint('Locations:')\ndisplay(df_locations.head(2))\nprint('Script:')\ndisplay(df_script.head(2))\nprint('Episodes:')\ndisplay(df_episodes.head(2))",
    "Merge script lines with character and locations data\ndf_script_char = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id')",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Preview our datasets\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Create global variables for data directory and files\nDATA_DIR = \"data\"",
    "The first part of the notebook examines the scripts to build a simple chatbot.",
    "Visualize the most common words in the script lines using a word cloud",
    "Filter by the Simpsons TV show\ndf_script = df_script[df_script[\"episode_id\"].isin(df_episodes[df_episodes[\"imdb_rating\"] > 7.5][\"id\"])]",
    "Build a dictionary for characters and locations for easier access",
    "Create an instance of the English spacy tokenizer model.",
    " Clean the data\ndf_script = df_script[df_script[\"utterance\"].notna()]\ndf_script = df_script[df_script[\"raw_text\"].notna()]\ndf_script = df_script[df_script[\"character_id\"].notna()]\ndf_script = df_script[df_script[\"location_id\"].notna()]\ndf_script = df_script[df_script[\"episode_id\"].notna()]",
    "Limit the number of script lines (for quicker testing)\ndf_script = df_script[:1000]",
    "To ensure the data is loaded properly, let's print out the first few rows of each dataframe.",
    "Check the first few rows of the characters dataframe\ndf_characters.head()",
    " Let's take a look at the structure of the datasets.",
    "Previewing the dataframes",
    "Just ensure that the path to the data files is correct.",
    "Check first few rows of characters dataframe\ndf_characters.head()",
    "Quickly show basic information for each data frame\nprint('characters:')\nprint(df_characters.info())\nprint('locations:')\nprint(df_locations.info())\nprint('script:')\nprint(df_script.info())\nprint('episodes:')\nprint(df_episodes.info())",
    "merging everything in one table",
    "Examine the first few rows of the characters dataset\ndf_characters.head()",
    "Inspect the first few rows of the characters dataframe\ndf_characters.head()",
    "Exemplo como utilizar a base de dados \ndf_characters.head()",
    "Display first few rows of each dataframe to understand structure and contents",
    " For simple scripts such as the one below, how do we represent the lines of the next script across the known characters_data?",
    "Display the first 5 rows of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Visualize the dataframe(s)",
    "Check the first few rows of the characters dataframe\ndf_characters.head()",
    "Slight clean up to ensure consistency (convert to lower case)",
    "Function to remove accents from characters",
    "def preprocess_dialogue(dialogue):\n    \"\"\"\n    Function to preprocess dialogue text data\n    \n    Args:\n    dialogue - A string containing the dialogue\n    \n    Returns:\n    clean_dialogue - The preprocessed and cleaned dialogue\n    \"\"\"\n    # Convert to lowercase\n    dialogue = dialogue.lower()\n    \n    # Remove extra whitespaces\n    dialogue = ' '.join(dialogue.split())\n    \n    # Replace 'uh-huh' with 'yes'\n    dialogue = dialogue.replace('uh-huh', 'yes')\n    \n    # Replace 'uh-uh' with 'no'\n    dialogue = dialogue.replace('uh-uh', 'no')\n    \n    # Remove laughter 'haha', 'hahaha', 'hahahaha', etc\n    dialogue = dialogue.replace('ha', '')\n    \n    return dialogue",
    " Inspect the first few rows of each dataframe\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    "df_script.head()",
    " Display the first few rows of each dataframe to understand the data",
    "print('Characters:', len(df_characters))\nprint('Locations:', len(df_locations))\nprint('Script Lines:', len(df_script))\nprint('Episodes:', len(df_episodes))",
    "Get an overview of our datasets\nprint('Characters dataset:')\nprint(df_characters.head())\nprint('\\nLocations dataset:')\nprint(df_locations.head())\nprint('\\nScript lines dataset:')\nprint(df_script.head())\nprint('\\nEpisodes dataset:')\nprint(df_episodes.head())",
    " Limit the number of rows to speed up the development of the notebook\n# df_script = df_script.head(15000)",
    "Open the script lines dataset and join with relevant others",
    "In order for this code to run, make sure you have the necessary data files in the specified paths or change the paths to match the location of the data files on your system.",
    " To display the whole content of the dataframe without being cut off\npd.set_option('display.max_colwidth', -1)",
    "# View the first few rows of the characters dataframe\ndf_characters.head()",
    "Set the first column as the index in all DataFrames for easier access",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    "Filter out all the non-Simpsons lines from the dataframe",
    "Check that the dataframes have been loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Filter out the non-spoken lines from the dataset and save the result in a new dataframe of its own.",
    "That's all for now - let's get started with the data visualization!",
    " Set SEED for reproducibility\nSEED = 42",
    "Check for any missing or incomplete data in the characters, locations, script, and episodes dataframes",
    "# Show first rows\ndf_script.head()",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "According to the script data, each line is labeled with a character, and an episode.",
    "Checking the first few rows of the characters data frame",
    "Display all dataframes - Checking Data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Limit of records to read from each data frame.\nLIMIT = int(1e6)",
    "# Get all lines and characters of an episode\ndef get_episode_lines_chars(season, episode):\n    df_episode = df_script[(df_script[\"season\"]==season) & (df_script[\"episode\"]==episode)]\n    df_episode_chars = df_episode[\"character_id\"].value_counts().to_frame().merge(df_characters, left_index=True, right_on=\"id\")\n    df_episode_chars.columns = [\"count\", \"character_id\", \"name\", \"normalized_name\", \"gender\", \"description\", \"color\", \"image\"]\n    \n    return df_episode, df_episode_chars",
    "Remove column containing index\ndf_episodes = df_episodes.iloc[:, 1:]",
    " visualize the first few rows of the characters dataframe\ndf_characters.head()",
    "Looking at the data",
    " We should also take a look at the first few lines of each DataFrame to understand their structure and data.",
    "Checking whether the data was loaded correctly\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "I am not able to provide the next part of the code as it seems to be referencing external data and files that I do not have access to.",
    "Print the first 5 rows of the script dataframe\nprint(df_script.head())",
    "Hints: The code is reading multiple CSV files into pandas dataframes.",
    "View the first few entries of the characters dataframe\ndf_characters.head()",
    " Setting the seed for reproducibility\nnp.random.seed(0)",
    "# Filter the dataframe to only include spoken lines\ndf_script = df_script.loc[df_script['speaking_line'] == True].reset_index(inplace=False, drop=True)",
    "Display the list of available script lines.",
    "check the structure of the scripts dataframe\ndf_script.head()",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Visualise the first characters of the DataFrame 'df_characters'",
    "Check the content of the dataframes and the columns\ndf_script.head()",
    "inspect first 5 rows of script dataframe\ndf_script.head()",
    " Display the first few rows of each dataframe to understand the data",
    " Load dialogues set\ndf_script = pd.read_csv('data/simpsons_script_lines.csv', error_bad_lines=False)\nprint(df_script.head())",
    "Let's take a look at a few lines from each table to understand its structure.",
    "Plot the 10 characters with the most dialogue",
    "Remove duplicate locations and characters",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "\nprint(\"Characters Dataset:\")\nprint(df_characters)",
    "Verify the data has been correctly loaded.\ndf_characters.head()",
    " Show the script lines dataframe\ndf_script.head()",
    "View the first few rows of the script data\ndf_script.head()",
    "Set pandas to show all columns in head()\npd.set_option('display.max_columns', None)",
    "Display the first 5 rows of each of the 4 DataFrames\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Creating data folder if it doesn't exist\nif not os.path.exists('data'):\n    os.makedirs('data')",
    "Check the dataframe sizes\nprint('Characters:', len(df_characters))\nprint('Locations:', len(df_locations))\nprint('Script lines:', len(df_script))\nprint('Episodes:', len(df_episodes))",
    "Check the contents of these dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "# Display the first 5 rows of each dataframe\nprint(\"Characters:\")\nprint(df_characters.head())\nprint(\"\\nLocations:\")\nprint(df_locations.head())\nprint(\"\\nScript:\")\nprint(df_script.head())\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
    " Preprocess columns for easier access",
    "display the first few rows of each dataframe to understand its structure\ndf_characters.head()",
    "Extract useful columns\ndf_characters = df_characters[['id', 'name']]\ndf_locations = df_locations[['id', 'name']]\ndf_episodes = df_episodes[['id', 'title']]",
    " Set some Pandas specific options for better display\npd.set_option('display.max_columns', None)",
    "Checking for the head of the characters dataframe",
    "Checking the data type of each column in df_script",
    "# remove unused columns\ndf_script.drop(columns=['number', 'raw_text', 'timestamp_in_ms'], inplace=True)",
    " Show head of characters DataFrame",
    "Merge episodes data with characters data\ndf = df_script.merge(df_episodes, on='episode_id').merge(df_characters, on='character_id').merge(df_locations, on='location_id')",
    "Check the dataframe shapes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "View a sample\nprint(df_script.sample(5))",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Display the first few rows of each dataframe to understand the data",
    "Set pandas to display wide tables properly\npd.set_option('display.max_columns', 500)",
    "Let's see the first entries of the characters dataframe.",
    "Selecting scripts from the most frequently occurring characters and locations",
    " Join the dataframes to obtain a single unified dataframe containing all information.",
    "Install spaCy models\n!python -m spacy download en_core_web_sm",
    "Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Now let's have a quick look at our data.",
    "Remove rows with empty lines and strip white spaces from any columns containing strings\nfor df in [df_characters, df_locations, df_script, df_episodes]:\n    starting_shape = df.shape\n    for col in df.columns:\n        if df[col].dtype == object:  # dtype 'object' means it's a string\n            df[col] = df[col].str.strip()  # Remove leading/trailing white spaces\n            df = df[df[col].notna()]  # Remove rows with empty strings\n    print(f\"Before removal - {df} shape: {starting_shape}, after removal: {df.shape}\")",
    "Inspecting and cleaning the data",
    "Merge the datasets to get a single dataframe",
    " Ignore the warnings\nimport warnings\nwarnings.filterwarnings('ignore')",
    " Function to select the main character of an episode\ndef get_main_character(speaker):\n    main_characters = df_characters[df_characters.main_character == 1].character.tolist()\n    if speaker in main_characters:\n        return speaker\n    return 'other'",
    " Show the first rows of the dataset to understand the structure\ndf_script.head()",
    "Check a few lines of the `df_characters` dataframe",
    "\ndf_script.head()",
    "The csv files are being read and loaded into pandas dataframes for further analysis and processing.",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Clean the character list by removing non-speaker tokens\ndf_characters = df_characters[~df_characters['normalized_text'].isin(['string', 'music', 'singing', 'gasps'])]",
    "Put all the text data into lowercase\ndf_script['normalized_text'] = df_script['raw_text'].apply(lambda x: x.lower())",
    " Leave only lines\ndf_lines = df_script[df_script['speaking_line']]\ndf_lines = df_lines.merge(df_characters[['name', 'character_id']], on='character_id')",
    "Set up styles\nplt.style.use('fivethirtyeight')\nmatplotlib.rcParams.update({\n    'font.size': 12,\n    'figure.figsize': (15, 5),\n    'axes.labelsize': 10,\n    'axes.titlesize': 14,\n    'xtick.labelsize': 10,\n    'ytick.labelsize': 10,\n    'legend.fontsize': 10\n})",
    "Inspect the script dataframe",
    " Set Pandas to display all columns\npd.set_option('display.max_columns', None)",
    " Data Cleaning",
    " Let's first start by focusing on the script data.",
    "Let's take a look at the contents of these DataFrames.",
    "Merge episode data into script\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left')",
    "Set pd to print 100 columns max\npd.set_option('display.max_columns', 100)",
    "Optional: use all columns\npd.set_option('display.max_columns', None)",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Displaying the 3 datasets per quick check.",
    "Ensure the script and episodes have the same number of seasons, with the season/episode format consistent across both datasets.",
    " Preview the first 5 lines of the dataframe\ndf_episodes.head()",
    "Check one of the dataset to see what it looks like\ndf_locations.head()",
    " prepare nltk's stop words\nnlp = spacy.load(\"en_core_web_sm\")",
    "Let's take a glance at the first five rows of the dataset to understand its structure and content.",
    "Check the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Display the first 5 rows of the script dataframe\ndf_script.head()",
    " Load spacy\nnlp = spacy.load('en_core_web_sm')",
    " display the first 5 script lines\ndf_script.head()",
    " Simplify DataFrame and lowercase the episode name\ndf_characters = df_characters[['id', 'name']].rename({'id': 'character_id', 'name': 'character_name'}, axis=1)\n\n# Simplify DataFrame and lowercase the episode name\ndf_episodes = df_episodes[['id', 'title', 'original_air_date', 'production_code']].rename({'id': 'episode_id', 'title': 'episode_title'}, axis=1)\ndf_episodes['episode_title'] = df_episodes['episode_title'].str.lower()",
    "appearances = df_script['raw_character_text'].value_counts().reset_index()\nappearances.columns = ['raw_character_text', 'num_appearances']",
    "Let's check the data in each dataframe.",
    "Set matplotlib style\nmatplotlib.rcParams['font.size'] = 18\nmatplotlib.rcParams['figure.figsize'] = (15, 10)",
    "Printing dataframes and number of rows in each dataframe\nprint(f\"# of characters: {len(df_characters)}\")\nprint(f\"# of locations: {len(df_locations)}\")\nprint(f\"# of script_lines: {len(df_script)}\")\nprint(f\"# of episodes: {len(df_episodes)}\")",
    "Get rid of some unnamed columns\ndf_characters.columns = df_characters.columns.str.replace('Unnamed: [0-9]+', '')",
    "Display the first few records of each dataframe to understand its structure\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Check that each episode in script_lines.csv refers to an actual episode.",
    "Extract just the lines of a single episode to make the example more managable\nepisode_mask = (df_script['episode_id'] == 1) & (df_script['character_id'] == 9)\ndf_script = df_script[episode_mask]",
    " Examine the first few rows of data from the 'simpsons_characters.csv' file\ndf_characters.head()",
    "View the structure of the characters dataframe",
    " Let's check the first lines of each dataframe.",
    "Check the loaded dataset\nfor name, data in (\n    ('Characters', df_characters), \n    ('Locations', df_locations), \n    ('Script lines', df_script), \n    ('Episodes', df_episodes)\n):\n    print(f'{name}:')\n    print(data.info())\n    display(data.head())\n    print('\\n\\n')",
    "Inspect the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "join locations and characters\ndf_joined = df_locations.merge(\n    df_characters,\n    left_on='location_id',\n    right_on='location_id',\n    how='inner'\n)",
    "Let's take a brief look at these files.",
    " Exploring the characters dataframe",
    "Select an episode at random\nnp.random.seed(42)\nepisode_id = np.random.choice(df_script['episode_id'].unique())\ndf_script[df_script['episode_id'] == episode_id].head(10)",
    " Check the data to examine if it has been loaded correctly.",
    "Set up matplotlib style\nplt.style.use('fivethirtyeight')",
    " Display\ndf_episodes.head()",
    "# Print heads to verify\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Keep original column names for later reference\noriginal_columns = df_script.columns",
    "Get the list of seasons\nseasons = df_episodes['season'].unique()",
    "Count the number of script lines by character\nscript_lines_count = df_script['character_id'].value_counts()",
    "Limit the data to the first 20 seasons for efficiency\ndf_script = df_script[df_script['episode_id'] <= 44186]",
    "Inspect the characters dataframe\ndf_characters.head()",
    "For the word cloud, we'll use spaCy for pre-processing and then Matplotlib for rendering.",
    "Check if all datasets were loaded correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Sample of the characters dataset\ndf_characters.head()",
    "reate a new column for the episode_df mapping to imdb_id\ndf_episodes['imdb_id'] = df_episodes['id'].apply(lambda x: 'tt' + str(1000000+x))",
    "df_characters.head()",
    "Display the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_episodes.head(), df_script.head()",
    "Create a new dataframe that merges lines and characters dataframes on character id, then merges result with locations dataframe on location id.",
    "Check the head of the table to get an idea of the table schemata",
    "Merge the dialog lines with the character and location tables\ndf_ep_char_loc_lines = df_script.merge(\n    df_characters,\n    left_on='character_id',\n    right_on='id',\n    suffixes=('','_character')\n).merge(\n    df_locations,\n    left_on='location_id',\n    right_on='id',\n    suffixes=('','_location')\n)\n\ndf_ep_char_loc_lines.head()",
    " Display the DataFrame to make sure the conversion looks good.\ndf_characters.head()",
    "Display the first few rows of the table to check the proper loading of data\ndf_characters.head()",
    "Merge script and episodes\ndf_merged = df_script.merge(df_episodes, on='episode_id')",
    "Merge episodes with script\ndf_episodes = df_episodes.rename(columns={'id':'episode_id'})\ndf_script = pd.merge(df_script, df_episodes, on='episode_id')",
    "Properties of the dataset\nprint(f\"Number of characters: {df_characters.shape[0]}\")\nprint(df_characters.head())",
    "Setting seed for reproducibility\nnp.random.seed(0)",
    "Create a dictionary mapping episode_id to episode title.",
    "Print the first rows of each dataset to understand the structure of the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    " Let's take a look at the characters dataset first.",
    "Function to get the character name from a normalized character id\ndef get_character_name(character_id):\n    return (df_characters[df_characters['id'] == character_id]['name'].values[0])",
    "Display types and size of dataframes for the Simpsons data.",
    "Setting the Seed\nnp.random.seed(0)",
    " Show first 3 character rows\ndf_characters.head(3)",
    " Split the raw text script into its components.",
    "Use the following line to remove the script line used for talks:\n# (by putting it in the footer and then reading the CSV)",
    " Let's start by taking a look at the first few rows of each dataframe.",
    " Set the number of words after which a \"...\" should show in print\npd.set_option('display.max_colwidth', 20)",
    "Check loaded DataFrame\ndf_script.head()",
    " Display some info\ndf_characters.info()\ndf_locations.info()\ndf_script.info()\ndf_episodes.info()",
    "Show full column and row information:",
    "Filter out episode titles that are in df_script but not in df_episodes",
    " It's plain to observe that we may need an write to the database.",
    "# Total script lines\nprint('Total script lines:', df_script.shape[0])",
    "Optionally for spacy\nnlp = spacy.load('en')",
    " Combine script lines with characters and locations\ndf_script_full = pd.merge(df_script, df_characters, on='character_id', how='left')\ndf_script_full = pd.merge(df_script_full, df_locations, on='location_id', how='left')",
    "Let's first display general info about the characters dataframe (e.g. no of entries, no of columns, columns names, data types, and memory usage).",
    "Merge the datasets on episode id",
    "Display the first few rows of the dataframe\ndf_script.head()",
    " Download the SpaCy model for English if not already downloaded\npython -m spacy download en",
    "Merge episodes and script with character and location details\ndf = df_script.merge(df_episodes, on='episode_id')  # Merge episodes with script\ndf = df.merge(df_characters, on='character_id')  # Merge characters with episode-script\ndf = df.merge(df_locations, on='location_id')  # Merge locations with episode-script",
    " Sample the data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Check the content of the script lines DataFrame\ndf_script.head()",
    "Fix dataset inconsistencies and errors",
    "Show the number of scenes, number of characters, and number of locations.",
    "Remove rows with missing values because the missing values might affect the analysis.",
    " Explore the characters dataframe\ndf_characters.head()",
    "Create \"simpsons_script_lines\" table from \"script_lines\" table\ndf_script_new = df_script.join(df_episodes, on='episode_id', rsuffix='_ep')\ndf_script_new = df_script_new.join(df_characters, on='character_id', rsuffix='_char')\ndf_script_new = df_script_new.join(df_locations, on='location_id', rsuffix='_loc').drop(\n                       ['episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', \n                        'location_id', 'raw_text', 'normalized_text', 'timestamp_in_ms', 'word_count', \"image_id\", \n                        \"production_code\", \"original_air_date\", \"id\", \"video_url\", \"show_id\", \"imdb_title_id\", \n                        \"imdb_id\" , \"script_id\", \"production_code\", \"image_id_char\", \"url_char\", \"filter\", \"license\", \n                        \"image_id_loc\", \"url_loc\"], axis=1).reset_index(inplace=False, drop=True)",
    " Load the data from the CSV files and reset the index of each DataFrame.",
    " Our df_script dataframe contains different kind of information id, episode_id, number, raw_text, speaking_line, character_id, location_id, and timestamp.",
    " Show the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Let's explore the data we have.",
    "print('Characters shape:', df_characters.shape)\nprint('Locations shape:', df_locations.shape)\nprint('Script shape:', df_script.shape)\nprint('Episodes shape:', df_episodes.shape)",
    "General properties\nprint(f\"Number of unique characters: {df_characters.shape[0]}\")\nprint(f\"Number of unique locations:  {df_locations.shape[0]}\")\nprint(f\"Number of episodes:           {df_episodes.shape[0]}\")",
    "# Show first rows of the datasets\ndisplay(df_characters.head())\ndisplay(df_locations.head())\ndisplay(df_script.head())\ndisplay(df_episodes.head())",
    " Print head of script lines dataframe\ndf_script.head()",
    " Select only the first 10 episodes for simplicity\ndf_script = df_script[df_script[\"episode_id\"].isin(df_episodes[\"id\"].values[:10])].reset_index(inplace=False, drop=True)",
    " How many lines of script do we have?",
    " Remove rows with missing values in the specified column\ndf_script = df_script.dropna(subset=['raw_text'])",
    "Initial exploration of datasets",
    "Print out all the tables to see their structure\nprint('Characters:')\nprint(df_characters.head())\nprint('\\nLocations:')\nprint(df_locations.head())\nprint('\\nScript:')\nprint(df_script.head())\nprint('\\nEpisodes:')\nprint(df_episodes.head())",
    " Limit the amount of rows displayed for better display in Jupyter notebook\npd.set_option('display.max_rows', 5)\npd.set_option('display.max_columns', 500)",
    " Display the first few rows of the dataframe for characters\ndf_characters.head()",
    "Set custom color palette for matplotlib",
    "Merge Simpsons script lines with character and location information\ndf_script_char = df_script.merge(df_characters, on='character_id', suffixes=('', '_char'))\ndf_script_loc = df_script_char.join(df_locations.rename({'location_id':'raw_location_text'}, axis=1).set_index('raw_location_text'), on='raw_location_text')",
    "Get a preview of the df_characters dataframe\ndf_characters.head()",
    " To make the script smaller, we will only use the first 10,000 rows of `df_script`.\ndf_script = df_script.iloc[:10000]",
    " Merge dataset\ndf_characters.drop(['slug'], axis=1, inplace=True)\ndf_episodes.drop(['image_url', 'video_url'], axis=1, inplace=True)",
    "Display available columns in each dataframe\nprint(\"Characters columns:\", df_characters.columns)\nprint(\"Locations columns:\", df_locations.columns)\nprint(\"Script columns:\", df_script.columns)\nprint(\"Episodes columns:\", df_episodes.columns)",
    " Set the seed for reproducibility",
    "Create a limited number of connections and a limited number of command functions.",
    "Check that everything is loaded correctly\nprint(df_characters.head(1))\nprint(df_locations.head(1))\nprint(df_script.head(1))\nprint(df_episodes.head(1))",
    "Checking the first few rows of the dataframe for visual inspection",
    "As the next step, we will now preprocess the script data before performing any analysis.",
    " Data folder path\ndata_folder = 'data/'",
    "Filter out lines from the script that were not included in a specific episode\ndf_script = df_script[df_script.episode_id.isin(df_episodes['id'])]",
    " Inspect the contents of the characters dataframe\ndf_characters.head()",
    "Set pandas display options for better visualisation\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)",
    " Check the content of the characters dataframe\ndf_characters.head()",
    "Inspect first 5 rows of the characters dataframe",
    "View the dimensions of the dataframes\nprint(\"Characters dimensions: \", df_characters.shape)\nprint(\"Locations dimensions: \", df_locations.shape)\nprint(\"Script dimensions: \", df_script.shape)\nprint(\"Episodes dimensions: \", df_episodes.shape)",
    " Display all columns of the dataframe\npd.set_option('display.max_columns', None)",
    "# Show the first 5 rows of the episodes dataframe\ndf_episodes.head()",
    "Check the content for each dataframe\nprint(\"\\nContent of characters dataframe\")\nprint(df_characters.head())\n\nprint(\"\\nContent of locations dataframe\")\nprint(df_locations.head())\n\nprint(\"\\nContent of script dataframe\")\nprint(df_script.head())\n\nprint(\"\\nContent of episodes dataframe\")\nprint(df_episodes.head())",
    "Show the first 5 rows of the characters DataFrame\ndf_characters.head()",
    "Looking at the distribution of the character lines in the dataset before and after removing the 'NaN's.",
    "Check dataframe sizes\ndf_episodes.shape, df_characters.shape, df_script.shape, df_locations.shape",
    " Visualize the first few rows of the characters dataframe\ndf_characters.head()",
    "Inspect the characters dataframe to understand its structure and contents\ndf_characters.info()",
    "Preview dataframe with characters",
    "Checking the data\ndf_characters.head()",
    "tqdm.pandas()",
    "View first 5 records of characters dataframe",
    " Encode characters, locations and episodes",
    "Display the first 5 rows of each dataframe to understand their structure and the data they contain.",
    " Show the first 5 rows of the script dataframe\ndf_script.head(5)",
    "Merge dataframes",
    "Create a list of all episode names",
    "\n# Quick look at the data\ndf_characters.head()",
    "Convert timestamp_in and timestamp_out columns to datetime format",
    "Check the size of each dataset\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Display number of rows in each dataset\nprint(\"Number of rows in characters dataset:\", len(df_characters))\nprint(\"Number of rows in locations dataset:\", len(df_locations))\nprint(\"Number of rows in script dataset:\", len(df_script))\nprint(\"Number of rows in episodes dataset:\", len(df_episodes))",
    "Quick Look at the Data",
    "Columns from the df_characters Dataframe\nprint(df_characters.columns)",
    "Get the \"Characters\" and \"Locations\" columns from the \"Script\" DataFrame in order to study only those lines that are related to characters and locations.",
    "Merge the datasets together to create a unified view of the data.",
    "Quick look at the data\ndf_episodes.head()",
    "# Strip plotlines (out of memory exception, beware!)\nMAX_LINES = 100000\ndf_script = df_script[:MAX_LINES]\ndf_script = df_script[df_script['character_id'] != 2]  # Remove lines by Homer\ndf_script = df_script[df_script['raw_text'] != '']  # Remove empty lines",
    "Display the first 5 rows of the characters DataFrame\ndf_characters.head()",
    "df_script.head()",
    "Filter out non-conversational lines such as scene changes",
    "# There is a known wrong character in the dataset\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.replace('docter', 'doctor')\n\n# Lower case for character names and locations\ndf_characters['character_name'] = df_characters['character_name'].str.lower()\ndf_locations['raw_location_text'] = df_locations['raw_location_text'].str.lower()\ndf_script['raw_character_text'] = df_script['raw_character_text'].str.lower()\ndf_script['raw_location_text'] = df_script['raw_location_text'].str.lower()",
    "Define the paths to the season folders and the file names for all seasons.",
    "Limiting the amount of characters to load, for performance reasons\nMAX_CHARACTER = 50\n\n#Some lines have NAs, let's get read of them\ndf_script = df_script.dropna(subset=['raw_character_text', 'spoken_words'])\n\n# Distribution of characters\nchar_counter = Counter(df_script['raw_character_text'])\n\n# Make sure that the most common characters are valid ones\nfor k in char_counter:\n    if k not in df_characters[\"Character\"].values:\n        print(k)",
    "Helper function to split array values into rows while duplicating the rest of the columns\ndef splitDataFrameList(df, target_column):\n    '''\n    Accepts a column with multiple types of delimited data and returns a \n    DataFrame with each entry for the target column separated out.\n    '''\n    #DataFrame containing multiple type of columns as a single column\n    row_accumulator = []\n\n    def splitListToRows(row, row_accumulator, target_column):\n        split_row = row[target_column]\n        if isinstance(split_row, list) and len(split_row) > 0:\n            for s in split_row:\n                new_row = row.to_dict()\n                new_row[target_column] = s\n                row_accumulator.append(new_row)\n        else:\n            new_row = row.to_dict()\n            new_row[target_column] = split_row\n            row_accumulator.append(new_row)\n\n    df.apply(splitListToRows, axis=1, args=(row_accumulator, target_column))\n    new_df = pd.DataFrame(row_accumulator)\n    return new_df",
    "optional: set a threshold for script lines length to filter out the long script lines\nthreshold = 500",
    "Visualize the missing data\nimport missingno as msno",
    " Set the `index` of the `DataFrame` `df_script` to be the column `'id'`\ndf_script.set_index('id', inplace=True)",
    "Display available columns for each dataset\nprint('Characters:', df_characters.columns.tolist())\nprint('Locations:', df_locations.columns.tolist())\nprint('Script:', df_script.columns.tolist())\nprint('Episodes:', df_episodes.columns.tolist())",
    "# Show first rows\ndf_characters.head()",
    " Display the first 5 rows of each DataFrame\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "inspect the contents of the characters dataframe\ndf_characters.head()",
    "Set the max width of columns to display for dataframes\npd.set_option('display.max_colwidth', 500)",
    "Check out the first 5 characters' dataframe.",
    "Check that the dfs are read correctly\ndf_characters.head()",
    "Displaying the data and checking dtypes to understand the data better\nprint(df_characters.head())\nprint(df_characters.dtypes)\n\nprint(df_locations.head())\nprint(df_locations.dtypes)\n\nprint(df_script.head())\nprint(df_script.dtypes)\n\nprint(df_episodes.head())\nprint(df_episodes.dtypes)",
    " View the dataframe containing the script lines\ndf_script.head()",
    "Get the first five rows of the characters dataframe.",
    "Download the spacy model\n! python -m spacy download en_core_web_sm",
    "RP - Carga de mdulos adiconales",
    "Preview the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Display all columns from the script DataFrame\npd.set_option('display.max_columns', None)",
    " Display a preview of each dataframe\nprint('Characters:')\ndisplay(df_characters.head())\nprint('\\nLocations:')\ndisplay(df_locations.head())\nprint('\\nScript:')\ndisplay(df_script.head())\nprint('\\nEpisodes:')\ndisplay(df_episodes.head())",
    "Normalize whitespace in columns\nfor col in ['raw_text','speaking_line','normalized_text','word_count']:\n    if df_script[col].dtype == 'object':\n        df_script[col] = df_script[col].apply(lambda x: ' '.join(x.split()))",
    "Compute and display the number of characters, locations, and lines in the dataset",
    "Clean the dataframes from potentially corrupted rows\ndf_script = df_script.dropna(subset=['character_id', 'location_id', 'id']).reset_index(inplace=False, drop=True)\ndf_episodes = df_episodes.dropna(subset=['id', 'original_air_date']).reset_index(inplace=False, drop=True)",
    " Show the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Check for missing values\nmissing_values_df = pd.DataFrame(df_script.isnull().sum(), columns=['missing values'])\nmissing_values_df['percentage'] = round(missing_values_df['missing values'] / df_script.shape[0] * 100, 2)\nmissing_values_df = missing_values_df[missing_values_df['missing values'] > 0]\nmissing_values_df = missing_values_df.sort_values(by='missing values', ascending=False)\n\nmissing_values_df",
    " Quick look at the character dataset\nprint(\"Shape of the data:\", df_characters.shape)\ndf_characters.head()",
    "Merge characters, locations, episodes, and script lines.\ndf_merged = df_script.merge(df_episodes, on='episode_id') \\\n    .merge(df_characters, on='character_id') \\\n    .merge(df_locations, on='location_id')\n\nprint('Number of merged rows:', df_merged.shape[0])\n\n# Display the merged dataframe\ndf_merged.head()",
    "#API KEY not available for the moment. Hidden away for running purposes.\nSPOTIFY_API_KEY = '123456789abcdefghijklmnopqrstuvwxyz'",
    " Spotless data ;)",
    "Visualizing missing values in the data",
    "Get scripts for the first 5 seasons",
    "Output the first few lines of the script dataframe\ndf_script.head()",
    "Let's take a look at the first 5 rows of each dataframe to understand their structure and the type of data they contain.",
    "Load the spaCy model\nnlp = spacy.load('en_core_web_sm')",
    "Show the first 5 rows of the characters dataframe",
    "Join lines with df_episodes to find out show details",
    "Inspect the characters DataFrame",
    "Load Spacy's English language models\nnlp = spacy.load('en')",
    " We re-use some utilities for pre-processing.",
    "Check that the datasets were loaded correctly\nprint(\"Characters:\")\nprint(df_characters.head())\n\nprint(\"\\nLocations:\")\nprint(df_locations.head())\n\nprint(\"\\nScript:\")\nprint(df_script.head())\n\nprint(\"\\nEpisodes:\")\nprint(df_episodes.head())",
    "Print the first few rows of each dataframe to understand the data",
    "Preview the Simpsons characters dataset\ndf_characters.head()",
    "Visualize the top 20 characters by number of lines\nplt.figure(figsize=(14, 8))\ntop_characters = df_script['character_id'].value_counts().head(20)\ntop_characters_names = [df_characters[df_characters['id'] == i]['name'].values[0] for i in top_characters.index]\ntop_characters_names\nplt.bar(top_characters_names, top_characters.values)\nplt.xticks(rotation=90)\nplt.title('Top 20 characters by number of lines')\nplt.show()",
    "Declare a function for tokenizing the data using spacy",
    "Dropping columns with no useful data",
    "l Setup spaCy\n# print(\"Loading spaCy language model...\")\nnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])",
    "Look at the first 5 rows in each dataset\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Extract the list of main characters from the DataFrame",
    "Look at the first 5 rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
    "# Filter English lines\ndf_script_en = df_script[df_script['raw_character_text'].isin(df_characters[df_characters['character_id'] > 0]['character_name'])].copy()",
    "Inspect the Characters dataframe",
    "Look at the first 3 rows of the episodes DataFrame.\ndf_episodes.head(3)",
    "Create the 'simpsons' directory if it doesn't exist\nif not os.path.exists('simpsons'):\n    os.makedirs('simpsons')",
    "Use the head function to display the first few records of the DataFrame\ndf_characters.head()",
    "We are reading the datasets from CSV files and resetting the index of each dataframe.",
    "Inspect contents of the 'simpsons_script_lines.csv' file\ndf_script.head()",
    "Checking the content of the dataframes",
    "Let's first take a look at the structure of the data frames.",
    "Check the data schema",
    "sns.set(style=\"whitegrid\")\nplt.figure(figsize=(8,5))",
    "to display all columns in the dataframes\npd.set_option('display.max_columns', None)",
    " Examine the structure of these DataFrames",
    "Merge data using the common keys",
    "# Load spacy pre-trained model\nnlp = spacy.load('en')",
    "Check the loaded data",
    "Connections -- Create PostgreSQL tables and upload the DataFrames",
    " Sample the data in order to understand its structure and contents\nprint(\"Sample from the characters dataframe:\")\nprint(df_characters.sample(5))\nprint(\"\\n\")\nprint(\"Sample from the locations dataframe:\")\nprint(df_locations.sample(5))\nprint(\"\\n\")",
    "Check the first few rows of each dataframe to understand how the data is structured",
    " View the first few rows of the characters dataframe\ndf_characters.head()",
    "Check the first 5 rows of the script dataframe to have an idea of the data",
    "Redo the imports with the correct syntax",
    "Display all the columns and the first five rows of the df_characters dataframe\ndf_characters.head()",
    " Display the first few lines of each table to get a sense of the data",
    "Display the loaded data\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Add the full transcripts to the dataframe\ndf_transcripts = df_script.groupby('episode_id').apply(lambda x: ' '.join(x['normalized_text'])).reset_index()\ndf_transcripts.columns = ['episode_id', 'transcript']\n\ndf_episodes = df_episodes.set_index('id')\ndf_episodes['full_transcript'] = df_transcripts.set_index('episode_id')",
    "To view the first few rows of each DataFrame, we can simply use the head() method.",
    "Create character id to character name dictionary",
    "Remove the 'Unnamed: 0' column from all dataframes since it is not needed",
    "Merge character data into script data\ndf_script_characters = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id')",
    "Let's take a look at the structure of the dataframes and the first few rows:",
    " Merge characters and locations into the script dataframe\ndf_script = df_script.merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=(None, '_character'))\ndf_script = df_script.merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=(None, '_location'))",
    "Takes around 30 seconds to import 1.3 million script lines",
    "Remove duplicates from dataframe",
    "Display the first few rows of the dataframe containing characters",
    " Set the `nlp` variable to the SpaCy model for English and disable parsing\nnlp = spacy.load('en', disable=['parser'])",
    "Functions and Classes\ndef getNameMap(df_map, key_col, value_col):\n    '''\n    Get a dictionary using two columns one for the key and one for the value\n    Parameters\n    ----------\n    df_map: pd.DataFrame\n            DataFrame with the key-value mapping\n    key_col: str\n            Name of the column with the keys\n    value_col:str\n            Name of the column with the values\n            \n    Returns\n    -------\n    name_map: Dictionary\n            Dictionary with the mapping of the DataFrame\n    '''\n    name_map = dict(zip(df_map[key_col], df_map[value_col]))\n    return name_map",
    "Print the first 3 lines of df_characters\ndf_characters.head(3)",
    " Inspect DataFrame details\nprint(\"\\n\\n==== Characters ====\")\nprint(df_characters.info())\n\nprint(\"\\n\\n==== Locations ====\")\nprint(df_locations.info())\n\nprint(\"\\n\\n==== Episodes ====\")\nprint(df_episodes.info())\n\nprint(\"\\n\\n==== Script Lines ====\")\nprint(df_script.info())",
    "Check the columns present in the datasets\nprint('Characters:', df_characters.columns)\nprint('Locations:', df_locations.columns)\nprint('Script:', df_script.columns)\nprint('Episodes:', df_episodes.columns)",
    "Remove values where the speech is not defined, and episode is not defined\ndf_script = df_script.replace({pd.np.nan: None})\ndf_script = df_script[df_script.speech.str.len() > 0]\ndf_script = df_script[df_script.episode_id.notnull()]",
    "Visual (Bar) representation of the split between female and male characters in the Simpsons",
    " We use the spaCy library for named entity recognition. Let's load the English language model for spaCy.",
    "\n",
    "Display the first few rows of the dataframe containing the characters in the Simpsons dataset.",
    "TODO: Show first 5 rows of df_characters",
    "Set up the episods' index as integer",
    "Inspect the dataframes to understand their structure and the kind of information they contain.",
    " Remove invalid episode_ids from df_script\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'].values)]",
    "# Fix issue with character names\ndf_characters['normalized_name'] = df_characters['normalized_name'].replace('lisa & bart', 'lisa, bart')\n\n# Display first few characters\ndf_characters.head()",
    "optional: using Seaborn for better plot styling\nimport seaborn as sns",
    "Check for any NaN's in the data",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Check the dataframe shapes",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    "Remove unwanted columns\ndf_script = df_script[['episode_id', 'character_id', 'location_id', 'raw_text']]\n\n# Drop rows with missing values\ndf_script = df_script.dropna()",
    "Inspect Dataframes",
    "## 2. Data exploration",
    "Define a function to print the n topics that we have fit in the model\ndef print_topics(model, vectorizer, top_n=10):\n    for idx, topic in enumerate(model.components_):\n        print(\"Topic %d:\" % (idx))\n        print([(vectorizer.get_feature_names_out()[i], topic[i])\n                        for i in topic.argsort()[:-top_n - 1:-1]])",
    "Load NLP model\nnlp = spacy.load('en_core_web_sm')\n\n# Check if the NLP model is loaded successfully\nnlp.vocab.length",
    "# Print the first few rows of the dataframe\ndf_characters.head()",
    "Show first few rows of the characters dataframe\ndf_characters.head()",
    " Check if all datasets have been successfully loaded\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "inspect data\nprint(\"Characters data frame\")\nprint(df_characters.head())\nprint(\"\\nScript data frame\")\nprint(df_script.head())",
    "Check the data\ndf_script.head()",
    "Let's check what the scripts DataFrame looks like.",
    "# Look at the first three lines\ndf_script.head(3)",
    "Check if we're in the correct folder",
    "Filter script to only keep spoken lines from characters\nspoken_lines = df_script[(df_script['character_id'] != 2) & (df_script['character_id'].notnull())]",
    "Setting `character_id` as the index\ndf_characters.set_index('id', inplace=True)\n\n# Let's print the first 5 rows of the characters DataFrame\ndf_characters.head()",
    "# Let's display each dataset to understand its structure\ndf_characters.head()",
    "Display the first few rows of the dataframe to understand its structure\ndf_script.head()",
    " Look at the unique values for season and episode\n(df_episodes\n .loc[lambda df: df.season == 1]\n .episode\n .unique())",
    " Displaying the scripts dataset\ndf_script",
    " Drop rows in the data that are NaN in the speaking_line column\ndf_script = df_script.dropna(subset=['speaking_line'])",
    "Displays the output from the function instead of just showing the last plot\nmatplotlib.use('module://ipykernel.pylab.backend_inline')",
    "Set display options for dataframes",
    "Merging dataframes for comprehensive dataframe of Simpsons data\ndf = df_script.merge(df_episodes, how=\"left\", on=\"episode_id\")\ndf = df.merge(df_characters, how=\"left\", left_on=\"character_id\", right_on=\"id\").rename(columns={\"name\": \"character_name\"})\ndf = df.merge(df_locations, how=\"left\", left_on=\"location_id\", right_on=\"id\").rename(columns={\"name\": \"location_name\"})\n\n# Save the merged dataframe for future use\ndf.to_pickle(\"data/simpsons_dataframe.pkl\")",
    "Matplotlib improvements\nmatplotlib.use('TkAgg')",
    "Check that the dataframes were imported correctly\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Let's inspect these DataFrames to understand the data better.",
    "Display the first few rows of each dataframe to get an understanding of the data",
    "Filter out bad script lines\ndf_script_good = df_script.loc[df_script['speaking_line'] == 'true']\n# Remove bad characters\ndf_script_good = df_script_good[df_script_good['normalized_text'] != \"\"]\n# Remove non-primary characters\ndf_script_good = df_script_good[df_script_good['raw_character_text'] != \"\"]\n# Rename text column\ndf_script_good = df_script_good.rename({'normalized_text': 'text'}, axis=1)\n# add episode number and name to script lines\ndf_script_good = pd.merge(df_script_good, df_episodes[['id', 'title', 'season', 'number']], left_on='episode_id', right_on='id')",
    "set pandas to display wide data tables in full to make it easier to understand the data\npd.set_option('display.max_columns', None)",
    "View the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Let's start by looking at the structure of the dataframes and the first few rows of each dataframe.",
    "# Display first few rows of the dataframe\ndf_script.head()",
    "Display the number of records for each dataframe\nprint('Number of records in characters: {}'.format(len(df_characters)))\nprint('Number of records in locations: {}'.format(len(df_locations)))\nprint('Number of records in episodes: {}'.format(len(df_episodes)))\nprint('Number of records in script: {}'.format(len(df_script)))",
    "Simplify dataframe\ndf_script_simple = df_script[['episode_id', 'number', 'raw_text', 'timestamp_in_ms']]",
    "Show top 20 script lines",
    " Let's take a look at the data in each of these dataframes.",
    "Inspect dataframesidency and common features",
    "# Remove empty lines\ndf_script = df_script.dropna(subset=['raw_text'])",
    "Checking the characters dataframe",
    "Display the first few rows of the dataframe to understand its structure\nprint(df_script.head())",
    "Display the first few rows of each dataframe to understand its structure and contents.",
    "Set random seed for reproducibility\nnp.random.seed(0)",
    "Inspect and process the data",
    "Display some information about the characters dataframe\nprint('Number of entries: ', df_characters.shape[0])\nprint('Number of columns: ', df_characters.shape[1])\nprint('\\nColumns with their datatypes:')\nprint(df_characters.dtypes)\nprint('\\nColumn names:')\nprint(df_characters.columns)\nprint('\\n')",
    "check missings\ndf_script.isnull().sum()",
    "check the data files and whether they all have been loaded successfully",
    "Display the three first rows for the characters dataframe\ndf_characters.head(3)",
    "Check the first few rows of df_characters\ndf_characters.head()",
    "View the first few rows of the characters dataframe\ndf_characters.head()",
    "Merge the datasets to get more context and consistency",
    "Set the path for the visuals.",
    " Print the shape of each DataFrame\nprint(f'Shapes: Characters={df_characters.shape}, Locations={df_locations.shape}, Script={df_script.shape}, Episodes={df_episodes.shape}')",
    "Generate a dataframe containing script lines with the character and location names.",
    "Set seed for reproducibility\nnp.random.seed(0)",
    "Merge the files",
    " set index to episode_id for easier access\ndf_episodes = df_episodes.set_index('id')",
    "View the first few columns of the characters DataFrame\ndf_characters.head()",
    "Code to set up NLP model and visualize word frequencies",
    " Preview the 'simpsons_characters.csv' table\ndf_characters.head()",
    " Display the first 5 rows of the dataframe containing the script lines.",
    "Set pandas print options to make it more human friendly\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 30)\npd.set_option('display.max_colwidth', None)",
    "View the characters dataframe\ndf_characters.head()",
    "Print number of characters, locations, script lines and episodes\nprint(len(df_characters), len(df_locations), len(df_script), len(df_episodes))",
    "Inspect the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Merge the script with the characters and locations\ndf_script = df_script.merge(df_episodes, on='episode_id', how='left').merge(df_characters, on='character_id', how='left').merge(df_locations, on='location_id', how='left')",
    " Set the dataframe's index to the `id` column, these ids will then be used to link data in the other dataframes",
    "This code snippet demonstrates the use of several Python libraries for data analysis and visualization. It reads data from CSV files using pandas, performs some preprocessing, and sets up the environment for further analysis. The code also includes custom imports for additional functionality.",
    "Clean the script and the character names",
    "Extract the lines from the episode where Homer says 'doh'",
    "\n# Displaying first 5 records\ndf_characters.head()",
    "Species the type of data in the datasets\nprint('Characters dataset:')\nprint(df_characters.dtypes)\nprint('\\nLocations dataset:')\nprint(df_locations.dtypes)\nprint('\\nScript dataset:')\nprint(df_script.dtypes)\nprint('\\nEpisodes dataset:')\nprint(df_episodes.dtypes)",
    "Get all the speakers from the script\nspeakers = df_script['character_id']\n\n# Count the number of dialogues per speaker\nspeaker_counts = speakers.value_counts()\n\n# Display dataframe of speaker counts\ndf_speaker_counts = pd.DataFrame(speaker_counts)\ndf_speaker_counts.columns = ['dialogue_count']\ndf_speaker_counts.index.names = ['character_id']\ndf_speaker_counts.reset_index(inplace=True)",
    "language model\nnlp = spacy.load('en_core_web_sm')",
    "Create temporally sorted dataframes to facilitate the creation of animations.",
    " Displaying the first few lines of the dataframes to understand the data better.",
    "Display settings for pandas dataframes\npd.set_option('display.max_columns', None)",
    "\n# Fix some inconsistencies in the script dataset\n# Filter the data to remove unwanted records\n# Generate new features",
    "Check if the script table is correct\ndf_script.head()",
    "Load the data from the CSV files into pandas DataFrames.",
    "# Display first 5 records of characters dataframe\ndf_characters.head()",
    " Display general information on the datasets\nprint('Characters dataframe:', df_characters.shape)\nprint('Locations dataframe:', df_locations.shape)\nprint('Script lines dataframe:', df_script.shape)\nprint('Episodes dataframe:', df_episodes.shape)",
    "Check the contents of the characters DataFrame\ndf_characters.head()",
    " Display the first few rows of the characters dataframe\ndf_characters.head()",
    " Supprimer les script_lines qui ne sont pas dans simpsons_episodes",
    "Check the first 5 entries of the characters, locations, script and episodes datasets.",
    "Create temporary files folder if it doesn't exist\ntemp_folder = './data/tmp'\nos.makedirs(temp_folder, exist_ok=True)",
    " Display some sampling of the data\ndf_script.sample(5)",
    "Filter out characters that are not lines\ndf_characters = df_characters[df_characters['character_id'].isin(df_script['character_id'])]",
    "Show the first few rows of the dataframe containing the script data\ndf_script.head()",
    " Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Examine dataframe structure\ndf_characters.head()",
    "Explore the dataframe shape (columns and samples)",
    "Check the content of the characters dataframe\ndf_characters.head()",
    " Set the character_id column as the index for the characters and locations DataFrames\ndf_characters.set_index('id', inplace=True)\ndf_locations.set_index('id', inplace=True)",
    "\n# Join the main table with the character and location information\ndf = df_script.merge(df_characters, on='character_id', how='left')\ndf = df.merge(df_locations, on='location_id', how='left')\n\n# Remove script lines with no spoken words and associate them to a given episode\ndf = df[~df.raw_text.isna()]\ndf = df.merge(df_episodes, on='episode_id', how='left')",
    "Here we are reading CSV files using pandas and storing them in dataframes for further processing.",
    "count the null values in the dataframe\ndf_script.isnull().sum()",
    "# Display the first few rows of the dataframe\ndf_episodes.head()",
    "Remove columns that we don't need from the dataframes",
    "Join dataframes",
    "Explore the data and find an interesting question to answer",
    "Display the top 5 rows of the characters dataframe\ndf_characters.head()",
    "Check the files\nprint('Characters: ', df_characters.shape)\nprint('Locations: ', df_locations.shape)\nprint('Script: ', df_script.shape)\nprint('Episodes: ', df_episodes.shape)",
    "Setting the index of the datasets",
    "data exploration\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Check first few rows of characters dataframe\ndf_characters.head()",
    " Good job! Now we have successfully imported the necessary datasets for our analysis.",
    " Display the first few rows of each dataframe to understand the data",
    "Display the first 5 rows of the data\ndf_characters.head()",
    "Examine the contents of the characters dataset",
    "Get rid of experimental and unsued file that may still be in the workspace",
    "Checking the contents of the character dataframe",
    "Load the preprocessed script as it was computed before in script_preprocessing.ipynb\ndf_script_processed = pd.read_csv('data/simpsons_script_lines_preprocessed.csv')",
    "Checking the first 5 rows of each dataframe",
    "select only the lines spoken by Homer Simpson\ndf_homer = df_script[df_script['character_id'] == 2]\n\n# inspect the result\ndf_homer.head()",
    "Get an overview of the data\ndf_script.head()",
    "df_script.head()",
    " Specify data types for each column in the episodes dataframe for space efficiency\ndtypes = {\n    'id': 'uint32',\n    'title': 'category',\n    'original_air_date': 'datetime64',\n    'production_code': 'object',\n    'season': 'uint8',\n    'number_in_season': 'uint8',\n    'number_in_series': 'uint16',\n    'us_viewers_in_millions': 'float32',\n    'views': 'uint32',\n    'imdb_rating': 'float32',\n    'imdb_votes': 'uint32',\n    'image_url': 'object',\n    'video_url': 'object',\n    'special_features': 'object',\n    'writers': 'object',\n    'directors': 'object',\n    'guest_stars': 'object'\n}\n\n# Apply the data types to the episodes dataframe\ndf_episodes = df_episodes.astype(dtypes)",
    "View the first 5 rows of the characters dataframe.",
    "Basic info on df_script\nprint(df_script.info())",
    "Choose an episode at random for this analysis\nep = df_episodes.sample(1)\nep",
    "Create Doc class from spacy annotations",
    "Looking at the data for the first time\nprint(f\"Characters data shape: {df_characters.shape}\")\nprint(f\"Locations data shape: {df_locations.shape}\")\nprint(f\"Script data shape: {df_script.shape}\")\nprint(f\"Episodes data shape: {df_episodes.shape}\")",
    "Inspect data shape\nprint(f'df_characters shape: {df_characters.shape}')\nprint(f'df_locations shape: {df_locations.shape}')\nprint(f'df_script shape: {df_script.shape}')\nprint(f'df_episodes shape: {df_episodes.shape}')",
    " Mapping for names and locations\ndf_characters['raw_character_text'].replace({'\\s{2,}': ' ', '^ ': '', '$ ': ''}, inplace=True, regex=True)\ndf_locations['raw_location_text'].replace({'\\s{2,}': ' ', '^ ': '', '$ ': ''}, inplace=True, regex=True)\ndf_script['raw_character_text'].replace({'\\s{2,}': ' ', '^ ': '', '$ ': ''}, inplace=True, regex=True)\ndf_script['raw_location_text'].replace({'\\s{2,}': ' ', '^ ': '', '$ ': ''}, inplace=True, regex=True)",
    "Some cleanup\ndf_script = df_script[df_script['episode_id'].isin(df_episodes['id'])]",
    "# Merge scripts with characters\ndf_script_info = df_script.merge(df_characters, how='left', left_on='character_id', right_on='character_id', suffixes=('_script', '_character'))",
    "Merge episodes data to get the name of the episodes along with the script data\ndf_script = pd.merge(df_script, df_episodes[['id', 'title', 'original_air_date']], left_on='episode_id', right_on='id')",
    "Checking the shape of each DataFrame\nprint(f'Shapes: characters = {df_characters.shape}, locations = {df_locations.shape}, script = {df_script.shape}, episodes = {df_episodes.shape}')",
    "Some Data Cleaning",
    "# Verify the import\ndf_script.head()",
    "Utility functions\ndef generate_wordcloud(text):\n    wordcloud = WordCloud(width=800, height=400, max_font_size=100, background_color=\"white\").generate(text)\n    plt.figure(figsize=(15, 10))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis('off')\n    plt.show()",
    "Show the first 5 rows of the characters dataframe\ndf_characters.head()",
    "Add a new column to script dataframe that stores if the line is spoken by a character or not",
    " Generate a DataFrame with only the data we are interested in\ndf_script_mentions = df_script[(df_script.raw_character_text != ' ') & \n                     (df_script.raw_character_text != 'Marge_Simpson') & \n                     (df_script.raw_character_text != 'Lisa_Simpson') & \n                     (df_script.raw_character_text != 'Bart_Simpson') & \n                     (df_script.raw_character_text != 'Homer_Simpson') & \n                     (df_script.raw_character_text != 'Couch_Gag')].reset_index(inplace=False, drop=True)",
    "Create a dataframe keeping only the line with their episode's data",
    " text processing and nlp\nnlp = spacy.load('en_core_web_md')",
    "Display the first few lines of each dataset to understand its structure and the available fields",
    "EDA\n\n# Investigate the number of unique characters, locations and episodes\nnum_characters = df_characters['name'].nunique()\nnum_locations = df_locations['name'].nunique()\nnum_episodes = df_episodes['title'].nunique()\n\nnum_characters, num_locations, num_episodes",
    " Set a seed for reproducibility",
    "Load spacy model\nnlp = spacy.load('en_core_web_sm')",
    "Prints datasets' head",
    "Inspecting the data frames",
    " Visualize the first few rows of each dataframe to understand the data",
    " Let's quickly inspect the dataframes",
    "Preview the dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Let's have a look at the first few rows of the characters dataframe.",
    "Select only the necessary columns for this MVP (Minimum Viable Product) in the df_script dataframe.",
    "Select rows where \"raw_text\" contains \"donut\"\ndf_script_donuts = df_script[df_script['raw_text'].str.contains('donut')]",
    "Separate the quotes from the script in test/training",
    "Create a new column for script data that contains the episode data",
    "Check the original dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Show the first 5 rows of the characters dataframe\ndf_characters.head()",
    "skipping the possible \"locale is not supported\" warning\n# No longer needed in pandas 1.1.0\npd.plotting.register_matplotlib_converters()",
    " We fixed the index during loading, so we don't have to reset them here",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    " extract characters, locations and script\ncharacters = df_characters['normalized_text'].values.tolist()\nlocations = df_locations['normalized_text'].values.tolist()\nscript = df_script['normalized_text'].values.tolist()",
    "Merge the dataframes at the hand of the episode_id.",
    " Load the provided datasets",
    " Set the random seed for reproducibility",
    " The script would continue by exploring and analyzing the datasets, but the provided code is enough to load the necessary data and proceed with the analysis.",
    "Extract all the unique locations from the scripts\nall_lines = list(df_script['raw_text'])\nall_locations = []\nfor line in all_lines:\n    try:\n        line = line.split(' ')\n        line = list(filter(lambda x: x != '', line)) # Remove spaces\n        all_locations.append(line[1])\n    except:\n        pass",
    "Load spacy models\nnlp = spacy.load('en_core_web_sm')",
    "Data directiory\nroot_data_dir = '/kaggle/input/the-simpsons/thesimpsons/'\n\n# Check the content of the directory\nfor root, _, files in os.walk(root_data_dir):\n    level = root.replace(root_data_dir, '').count(os.sep)\n    indent = ' ' * 4 * (level)\n    logger.info('{}{}/'.format(indent, os.path.basename(root)))\n    subindent = ' ' * 4 * (level + 1)\n    for f in files:\n        logger.info('{}{}'.format(subindent, f))",
    " The first cell of the Jupyter notebook, imports libraries and custom packages, loads the necessary data files using pandas, and sets up matplotlib for visualization.",
    "Show a preview of the characters dataframe\ndf_characters.head()",
    "# Show head of data\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Display some basic information about the characters dataframe\ndf_characters.info()",
    " Checking the structure of the loaded datasets",
    "Inspect the first few rows of each DataFrame to understand the data",
    "Cleaning data to remove any unnecessary columns and data.",
    "\n# Scraping script information\n#",
    "Change values that are \"bad\" to NaN so that I can easily inspect if I have any of these in the dataset",
    "Look at the available data\nprint(df_characters.columns)\nprint(df_locations.columns)\nprint(df_script.columns)\nprint(df_episodes.columns)",
    "Preview the first few rows of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Visualize the most common words in the script lines of The Simpsons using WordCloud",
    "Load locally saved stop words, to use common stop word list\nwith open('data/stopwords.txt', 'r') as f:\n    stopwords = f.read().split('\\n')",
    "Display some samples of each dataframes.",
    "Select only rows with canonical values of 1\ndf_script = df_script[df_script[\"raw_text\"].notna()]",
    "Display the first 5 rows of the characters dataframe\ndf_characters.head()",
    " Print top 5 rows of the characters dataset\ndf_characters.head()",
    "Check the size of the dataframes\ndf_characters.shape, df_locations.shape, df_script.shape, df_episodes.shape",
    "Check out the first few rows of the characters dataset\ndf_characters.head()",
    "\n# Selected season\nseason_number = 8",
    "Display the first 5 rows of each dataframe to understand the data",
    "Initial data exploration",
    "Count the number of episodes where \"Bart\" is mentioned\ndf_script[df_script['raw_text'].str.contains('Bart')]['episode_id'].nunique()",
    "We will quickly have a look at the data to figure how we can proceed further.",
    "Realizamos un prstamo de alias para la apariencia del set de datos en los cuadernos de jupyter.",
    "n. of characters and n. of locations\nn_characters = len(df_characters)\nn_locations = len(df_locations)",
    "ill the missing values in the DataFrame",
    "Check the imported dataframes\nprint(df_characters.head(3))\nprint(df_locations.head(3))\nprint(df_script.head(3))\nprint(df_episodes.head(3))",
    "Check the content inside the dataframe",
    "Print the amount of rows in each dataframe\nprint(f'Characters df shape: {df_characters.shape}')\nprint(f'Locations df shape: {df_locations.shape}')\nprint(f'Script df shape: {df_script.shape}')\nprint(f'Episodes df shape: {df_episodes.shape}')",
    "Take a peak at what the dataframes looks like\nprint(df_characters.head())\nprint(df_locations.head())\nprint(df_script.head())\nprint(df_episodes.head())",
    "Displaying the first data frame (characters)\ndf_characters.head()",
    "# Print size of the script dataframe\nprint('Number of dialogue lines in the dataset: ', df_script.shape[0])",
    " Set seed for reproducibility\nnp.random.seed(0)",
    "Merge the data into a single dataframe\ndf = (\n    df_script\n    .merge(df_characters, how='left', left_on='character_id', right_on='id', suffixes=('', '_character'))\n    .merge(df_locations, how='left', left_on='location_id', right_on='id', suffixes=('', '_location'))\n    .merge(df_episodes, how='left', left_on='episode_id', right_on='id', suffixes=('', '_episode'))\n)",
    "Merge the script data with the character and location data to add character and location information to each line in the script.",
    "Display columns to identify the data available in each DataFrame\nprint(\"Characters DataFrame columns: \", df_characters.columns)\nprint(\"Locations DataFrame columns: \", df_locations.columns)\nprint(\"Script DataFrame columns: \", df_script.columns)\nprint(\"Episodes DataFrame columns: \", df_episodes.columns)",
    " view dataframes\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    "Inspecting the first rows of the characters dataframe",
    "# Load English language model and spacy parser\nnlp = spacy.load('en_core_web_sm')\nnlp.max_length = 10000000",
    "Inspect dataframe shapes\nprint(df_characters.shape)\nprint(df_locations.shape)\nprint(df_script.shape)\nprint(df_episodes.shape)",
    "Let's display the first few lines of each dataset to understand their structure and contents.",
    "Check the first few rows of the characters dataframe\ndf_characters.head()",
    "Display first and last rows of the characters DataFrame\nprint(df_characters.head(1))\nprint(df_characters.tail(1))",
    " Display the head of the characters dataframe\ndf_characters.head()",
    " Let's take a look at the data we have.",
    "Set the series_id values to have the sames type as df_episodes['id'] to facilitate the upcoming merge",
    "Limiting data to first 10,000 records for quicker results\ndf_script = df_script.head(10000)",
    "# Set numpy random seed for reproducibility\nnp.random.seed(0)",
    "I commented out the lines creating the dataframes to avoid re-running them when unnecessary.",
    "Remove unnecessary columns\ndf_characters = df_characters[['id', 'name']]\ndf_locations = df_locations[['id', 'name']]\ndf_episodes = df_episodes[['id', 'title', 'original_air_date']]",
    "Join scripts, characters, locations, and episodes in one dataframe",
    "Just look up the head of all the dataframe to see everything looks fine\nfor df in [df_characters, df_locations, df_script, df_episodes]:\n    print(df.head())",
    "Inspect basic structure of the data\ndf_script.head()",
    "Take a look at the characters data\ndf_characters.head()",
    " Set random seed for reproducibility\nnp.random.seed(0)",
    " -*-*-*-*-*-* Transform the database -*-*-*-*-*-*-\n# Remove entries with unidentified speaker, locations, or without a proper script\ndf_script = df_script[df_script[\"raw_text\"] != ''][[\"episode_id\", \"id\", \"character_id\", \"raw_text\"]]",
    "Join \"lines\" and \"episodes\" DataFrame on \"episode_id\"\ndf = df_script.join(df_episodes, on='episode_id')",
    "Merge the script lines with their respective episodes\ndf_script = df_script.merge(df_episodes, on='episode_id', suffixes=('', '_episode'))",
    " Display the first few lines of each dataframe\ndf_characters.head(), df_locations.head(), df_script.head(), df_episodes.head()",
    " Clean and process the character and raw script dataframes",
    "Set default style for plots",
    "# Setting the style of the visualizations\nplt.style.use('seaborn')",
    "Display of a few samples of datas\nprint('Dataset examples')\nprint('\\nCharacters')\nprint(df_characters.sample(5))\nprint('\\nLocations')\nprint(df_locations.sample(5))\nprint('\\nScript')\nprint(df_script.sample(5))\nprint('\\nEpisodes')\nprint(df_episodes.sample(5))",
    "Remove unwanted columns and simplify the characters dataframe",
    "Unable to access the Simpsons dataset for character, location, script, and episodes.",
    " Let's take a look at the first few rows of each dataset to understand its structure.",
    "Tutorials will typically use this to make the resulting data frames simpler to work with\ndf_characters.simpsons_character_id = df_characters.simpsons_character_id.astype('int32')\ndf_locations.simpsons_location_id = df_locations.simpsons_location_id.astype('int32')\ndf_episodes.simpsons_episode_id = df_episodes.simpsons_episode_id.astype('int32')\ndf_script.simpsons_script_line_id = df_script.simpsons_script_line_id.astype('int32')\ndf_script.simpsons_character_id = df_script.simpsons_character_id.astype('int32')\ndf_script.simpsons_location_id = df_script.simpsons_location_id.astype('Int32')\ndf_script.simpsons_location_id = df_script.simpsons_location_id.astype('Int32')",
    "Show some basic information about the datasets\nprint('Characters')\ndisplay(df_characters.head())\nprint('Locations')\ndisplay(df_locations.head())\nprint('Script')\ndisplay(df_script.head())\nprint('Episodes')\ndisplay(df_episodes.head())",
    " Limit the script data to only the characters in df_characters\ndf_script_lim = df_script[df_script[\"raw_character_text\"].isin(df_characters.character_text)]",
    " Wordcloud for simpsons words",
    "Ensure the script is sorted by episode and id\ndf_script = df_script.sort_values(by=['episode_id', 'id']).reset_index(inplace=False, drop=True)",
    "Clean up memory\ndel df_characters, df_locations, df_episodes",
    "Inspect the script data\ndf_script.head()",
    "Join locations, characters and script data\ndf_locations = df_locations.merge(df_script, left_on='id', right_on='location_id', suffixes=('_location', ''))\ndf_locations = df_locations.merge(df_episodes, on='episode_id', suffixes=('_location', '_episode'))\ndf_characters = df_characters.merge(df_script, left_on='id', right_on='character_id', suffixes=('_character', ''))",
    " Let's start by visualizing a word cloud of the most common words in the script lines.",
    "Data Preprocessing",
    "Print the head of each dataset to understand what kind of data we are working with.",
    "Merge episodes with locations and characters\ndf_episodes['id'] = df_episodes['id'].astype(int)\ndf_locations['id'] = df_locations['id'].astype(int)\ndf_characters['id'] = df_characters['id'].astype(int)",
    "Set\npd.set_option('display.max_columns', None)",
    "# Print dataset's shape and first rows\nprint(\"Characters dataset's shape:\")\nprint(df_characters.shape)\nprint(\"\\nCharacters dataset's initial rows:\")\nprint(df_characters.head())",
    "Try to print the shapes of the acquired datasets to get a feeling of the data",
    "Set up a basic word cloud using WordCloud.",
    "Remove unnecessary columns and NA values from df_script"
]