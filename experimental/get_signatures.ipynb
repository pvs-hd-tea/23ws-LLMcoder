{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcoder.analyze.SignatureAnalyzer import SignatureAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SignatureAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"import numpy as np\n",
    "from pandas import DataFrame\n",
    "import matplotlib\n",
    "\n",
    "np.random.randn(1000, 2)\n",
    "df = DataFrame()\n",
    "np.array(1, 2, 3)\n",
    "\n",
    "matplotlib.pyplot.plot(np.random.randn(1000, 2))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import_aliases={'np': 'numpy', 'matplotlib': 'matplotlib'}\n",
      "direct_imports={'DataFrame': 'pandas'}\n",
      "function_calls=[('np', 'random.randn')]\n",
      "module_alias='np' func_name='random.randn'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'random.randn',\n",
       "  'signature': None,\n",
       "  'doc': 'randn(d0, d1, ..., dn)\\n\\nReturn a sample (or samples) from the \"standard normal\" distribution.\\n\\n.. note::\\n    This is a convenience function for users porting code from Matlab,\\n    and wraps `standard_normal`. That function takes a\\n    tuple to specify the size of the output, which is consistent with\\n    other NumPy functions like `numpy.zeros` and `numpy.ones`.\\n\\n.. note::\\n    New code should use the\\n    `~numpy.random.Generator.standard_normal`\\n    method of a `~numpy.random.Generator` instance instead;\\n    please see the :ref:`random-quick-start`.\\n\\nIf positive int_like arguments are provided, `randn` generates an array\\nof shape ``(d0, d1, ..., dn)``, filled\\nwith random floats sampled from a univariate \"normal\" (Gaussian)\\ndistribution of mean 0 and variance 1. A single float randomly sampled\\nfrom the distribution is returned if no argument is provided.\\n\\nParameters\\n----------\\nd0, d1, ..., dn : int, optional\\n    The dimensions of the returned array, must be non-negative.\\n    If no argument is given a single Python float is returned.\\n\\nReturns\\n-------\\nZ : ndarray or float\\n    A ``(d0, d1, ..., dn)``-shaped array of floating-point samples from\\n    the standard normal distribution, or a single such float if\\n    no parameters were supplied.\\n\\nSee Also\\n--------\\nstandard_normal : Similar, but takes a tuple as its argument.\\nnormal : Also accepts mu and sigma arguments.\\nrandom.Generator.standard_normal: which should be used for new code.\\n\\nNotes\\n-----\\nFor random samples from the normal distribution with mean ``mu`` and\\nstandard deviation ``sigma``, use::\\n\\n    sigma * np.random.randn(...) + mu\\n\\nExamples\\n--------\\n>>> np.random.randn()\\n2.1923875335537315  # random\\n\\nTwo-by-four array of samples from the normal distribution with\\nmean 3 and standard deviation 2.5:\\n\\n>>> 3 + 2.5 * np.random.randn(2, 4)\\narray([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random\\n       [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.get_signature_and_doc(\"get_signature_test.py\", \"randn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import inspect\n",
    "import os\n",
    "import re\n",
    "# import builtins\n",
    "import tempfile\n",
    "from collections import namedtuple\n",
    "from typing import Generator\n",
    "\n",
    "\n",
    "Import = namedtuple(\"Import\", [\"module\", \"name\", \"alias\"])\n",
    "\n",
    "def get_imports(path: str, query: str | list[str] | None = None) -> Generator:\n",
    "    if isinstance(query, str):\n",
    "        query = [query]\n",
    "    elif isinstance(query, list) and not query:\n",
    "        print(\"Empty query specified.\")\n",
    "        return\n",
    "\n",
    "    with open(path) as fh:\n",
    "        root = ast.parse(fh.read(), path)\n",
    "\n",
    "    for node in ast.walk(root):\n",
    "        if isinstance(node, ast.Import):\n",
    "            for alias in node.names:\n",
    "                module = alias.name\n",
    "                module_name = alias.asname if alias.asname else alias.name\n",
    "                if query:\n",
    "                    for q in query:\n",
    "                        if q.startswith(module_name + \".\") or q == module_name:\n",
    "                            yield Import([module], q.split('.')[-1], module_name)\n",
    "                else:\n",
    "                    yield Import([module], None, module_name)\n",
    "        elif isinstance(node, ast.ImportFrom):\n",
    "            if node.module is None:\n",
    "                continue\n",
    "            for alias in node.names:\n",
    "                module = node.module.split('.')\n",
    "                name = alias.name\n",
    "                asname = alias.asname if alias.asname else name\n",
    "                if query:\n",
    "                    if name in query or asname in query:\n",
    "                        yield Import(module, name, asname)\n",
    "                else:\n",
    "                    yield Import(module, name, asname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import(module=['numpy'], name=None, alias='np')\n",
      "Import(module=['pandas'], name='DataFrame', alias='DataFrame')\n",
      "Import(module=['matplotlib'], name=None, alias='matplotlib')\n"
     ]
    }
   ],
   "source": [
    "for i in get_imports(\"get_signature_test.py\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signature_and_doc(path: str, query: str | list[str] | None) -> list[dict]:\n",
    "        \"\"\"\n",
    "        Get the signature and documentation of a function or class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str\n",
    "            Path to the Python file. Can be temporary.\n",
    "        query : str | list[str] | None\n",
    "            The query string to search for. E.g. a function name or a class name.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[dict]\n",
    "            A list of dictionaries containing the signature and documentation of every match to the query.\n",
    "        \"\"\"\n",
    "        signature_and_doc = []\n",
    "\n",
    "\n",
    "        for imp in get_imports(path, query):\n",
    "            try:\n",
    "                module_path = '.'.join(imp.module) if imp.module else imp.name[0]\n",
    "\n",
    "                if imp.name:  # Specific class/function is imported\n",
    "                    obj = __import__(module_path, fromlist=[imp.name[-1]])\n",
    "                    attr = getattr(obj, imp.name[-1], None)\n",
    "                else:  # Entire module is imported\n",
    "                    obj = __import__(module_path)\n",
    "                    attr = obj\n",
    "\n",
    "                # Check if the attr is callable or has a signature\n",
    "                if callable(attr):\n",
    "                    sig = inspect.signature(attr)\n",
    "                    doc = inspect.getdoc(attr)\n",
    "                    signature_and_doc.append({\n",
    "                        \"name\": imp.alias if imp.alias else imp.name[-1] if imp.name else module_path,\n",
    "                        \"signature\": str(sig),\n",
    "                        \"doc\": doc\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"No callable attribute found for {module_path}\")\n",
    "\n",
    "            except (ImportError, AttributeError, TypeError) as e:\n",
    "                print(f\"Error handling {module_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "        return signature_and_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No callable attribute found for numpy\n",
      "No callable attribute found for pandas\n",
      "No callable attribute found for matplotlib\n"
     ]
    }
   ],
   "source": [
    "for i in get_signature_and_doc(\"get_signature_test.py\", None):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_function_calls(code: str):\n",
    "    \"\"\"\n",
    "    Parse the Python code and find all function or class calls.\n",
    "    \"\"\"\n",
    "    root = ast.parse(code)\n",
    "    function_calls = []\n",
    "\n",
    "    for node in ast.walk(root):\n",
    "        if isinstance(node, ast.Call) and isinstance(node.func, ast.Attribute):\n",
    "            # This is a function or class call, like es.ElasticsearchStore()\n",
    "            module_alias = node.func.value.id\n",
    "            func_name = node.func.attr\n",
    "            function_calls.append((module_alias, func_name))\n",
    "\n",
    "    return function_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('es', 'ElasticsearchStore')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_function_calls(\"es.ElasticsearchStore()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import ast\n",
    "\n",
    "# Assume get_imports function is defined elsewhere\n",
    "\n",
    "def find_function_calls(code: str, query: str | list[str] | None):\n",
    "    root = ast.parse(code)\n",
    "    function_calls = []\n",
    "\n",
    "    if isinstance(query, str):\n",
    "        query = [query]\n",
    "\n",
    "    for node in ast.walk(root):\n",
    "        if isinstance(node, ast.Call):\n",
    "            if isinstance(node.func, ast.Attribute):\n",
    "                # Handle nested attributes\n",
    "                attribute_chain = []\n",
    "                current = node.func\n",
    "                while isinstance(current, ast.Attribute):\n",
    "                    attribute_chain.append(current.attr)\n",
    "                    current = current.value\n",
    "                if isinstance(current, ast.Name):\n",
    "                    attribute_chain.append(current.id)\n",
    "                attribute_chain.reverse()\n",
    "                module_alias = attribute_chain[0]\n",
    "                func_name = '.'.join(attribute_chain[1:])\n",
    "            elif isinstance(node.func, ast.Name):\n",
    "                # Direct function call\n",
    "                module_alias = None\n",
    "                func_name = node.func.id\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if not query or func_name in query or '.'.join(attribute_chain) in query:\n",
    "                function_calls.append((module_alias, func_name))\n",
    "\n",
    "    return function_calls\n",
    "\n",
    "def get_signature_and_doc(path: str, query: str | list[str] | None = None) -> list[dict]:\n",
    "    signature_and_doc = []\n",
    "    import_aliases = {}\n",
    "\n",
    "    with open(path) as file:\n",
    "        code = file.read()\n",
    "\n",
    "    # Get all imports\n",
    "    for imp in get_imports(path):\n",
    "        full_module = '.'.join(imp.module) if imp.module else imp.name[0]\n",
    "        alias = imp.alias if imp.alias else imp.name[-1] if imp.name else full_module\n",
    "        import_aliases[alias] = full_module\n",
    "\n",
    "    # Find all function calls that match the query\n",
    "    function_calls = find_function_calls(code, query)\n",
    "\n",
    "    print(f\"{function_calls=}\")\n",
    "\n",
    "    for module_alias, func_name in function_calls:\n",
    "        try:\n",
    "            if module_alias and module_alias in import_aliases:\n",
    "                module_path = import_aliases[module_alias]\n",
    "                parts = func_name.split('.')\n",
    "                module = __import__(module_path, fromlist=[parts[0]])\n",
    "                attr = module\n",
    "                for part in parts:\n",
    "                    attr = getattr(attr, part, None)\n",
    "            else:\n",
    "                attr = globals().get(func_name, None)\n",
    "\n",
    "            if attr and callable(attr):\n",
    "                try:\n",
    "                    sig = inspect.signature(attr)\n",
    "                    doc = inspect.getdoc(attr)\n",
    "                    signature_and_doc.append({\n",
    "                        \"name\": func_name,\n",
    "                        \"signature\": str(sig),\n",
    "                        \"doc\": doc\n",
    "                    })\n",
    "                except ValueError:\n",
    "                    signature_and_doc.append({\n",
    "                        \"name\": func_name,\n",
    "                        \"signature\": \"Not available for built-in functions\",\n",
    "                        \"doc\": inspect.getdoc(attr)\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"No callable attribute {func_name} found\")\n",
    "\n",
    "        except (ImportError, AttributeError) as e:\n",
    "            print(f\"Error importing {func_name}: {e}\")\n",
    "\n",
    "    return signature_and_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signature_and_doc(path: str, query: str | list[str] | None = None) -> list[dict]:\n",
    "    signature_and_doc = []\n",
    "    import_aliases = {}\n",
    "    direct_imports = {}  # Store direct imports\n",
    "\n",
    "    with open(path) as file:\n",
    "        code = file.read()\n",
    "\n",
    "    # Get all imports\n",
    "    for imp in get_imports(path):\n",
    "        full_module = '.'.join(imp.module) if imp.module else imp.name[0]\n",
    "        if imp.module and imp.name:  # Correctly identify direct imports\n",
    "            direct_imports[imp.name] = full_module\n",
    "        else:\n",
    "            alias = imp.alias if imp.alias else imp.name[-1] if imp.name else full_module\n",
    "            import_aliases[alias] = full_module\n",
    "\n",
    "    print(f\"{import_aliases=}\")\n",
    "    print(f\"{direct_imports=}\")\n",
    "\n",
    "    # Find all function calls that match the query\n",
    "    function_calls = find_function_calls(code, query)\n",
    "\n",
    "    print(f\"{function_calls=}\")\n",
    "\n",
    "    # Match the function calls to the imports\n",
    "    matched_function_calls = []\n",
    "    for module_alias, func_name in function_calls:\n",
    "        if module_alias and module_alias in import_aliases:\n",
    "            matched_function_calls.append((module_alias, func_name))\n",
    "        elif func_name in direct_imports:\n",
    "            matched_function_calls.append((direct_imports[func_name], func_name))\n",
    "        else:\n",
    "            print(f\"No import found for {func_name}\")\n",
    "\n",
    "    for module_alias, func_name in matched_function_calls:\n",
    "        print(f\"{module_alias=} {func_name=}\")\n",
    "        try:\n",
    "            if module_alias and module_alias in import_aliases:\n",
    "                module_path = import_aliases[module_alias]\n",
    "                parts = func_name.split('.')\n",
    "                module = __import__(module_path, fromlist=[parts[0]])\n",
    "                attr = module\n",
    "                for part in parts:\n",
    "                    attr = getattr(attr, part, None)\n",
    "            elif func_name in direct_imports:  # Handle direct imports\n",
    "                module_name = direct_imports[func_name]\n",
    "                module = __import__(module_name, fromlist=[func_name])\n",
    "                attr = getattr(module, func_name, None)\n",
    "            else:\n",
    "                attr = None\n",
    "\n",
    "            if attr and callable(attr):\n",
    "                try:\n",
    "                    sig = inspect.signature(attr)\n",
    "                    doc = inspect.getdoc(attr)\n",
    "                    signature_and_doc.append({\n",
    "                        \"name\": func_name,\n",
    "                        \"signature\": str(sig),\n",
    "                        \"doc\": doc\n",
    "                    })\n",
    "                except ValueError:\n",
    "                    signature_and_doc.append({\n",
    "                        \"name\": func_name,\n",
    "                        \"signature\": None,\n",
    "                        \"doc\": inspect.getdoc(attr)\n",
    "                    })\n",
    "            else:\n",
    "                print(f\"No callable attribute {func_name} found\")\n",
    "\n",
    "        except (ImportError, AttributeError) as e:\n",
    "            print(f\"Error importing {func_name}: {e}\")\n",
    "\n",
    "    return signature_and_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import_aliases={'np': 'numpy', 'matplotlib': 'matplotlib'}\n",
      "direct_imports={'DataFrame': 'pandas'}\n",
      "function_calls=[('np', 'random.randn'), (None, 'DataFrame'), ('np', 'array'), ('matplotlib', 'pyplot.plot'), ('np', 'random.randn')]\n",
      "module_alias='np' func_name='random.randn'\n",
      "module_alias='pandas' func_name='DataFrame'\n",
      "module_alias='np' func_name='array'\n",
      "module_alias='matplotlib' func_name='pyplot.plot'\n",
      "module_alias='np' func_name='random.randn'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'random.randn',\n",
       "  'signature': None,\n",
       "  'doc': 'randn(d0, d1, ..., dn)\\n\\nReturn a sample (or samples) from the \"standard normal\" distribution.\\n\\n.. note::\\n    This is a convenience function for users porting code from Matlab,\\n    and wraps `standard_normal`. That function takes a\\n    tuple to specify the size of the output, which is consistent with\\n    other NumPy functions like `numpy.zeros` and `numpy.ones`.\\n\\n.. note::\\n    New code should use the\\n    `~numpy.random.Generator.standard_normal`\\n    method of a `~numpy.random.Generator` instance instead;\\n    please see the :ref:`random-quick-start`.\\n\\nIf positive int_like arguments are provided, `randn` generates an array\\nof shape ``(d0, d1, ..., dn)``, filled\\nwith random floats sampled from a univariate \"normal\" (Gaussian)\\ndistribution of mean 0 and variance 1. A single float randomly sampled\\nfrom the distribution is returned if no argument is provided.\\n\\nParameters\\n----------\\nd0, d1, ..., dn : int, optional\\n    The dimensions of the returned array, must be non-negative.\\n    If no argument is given a single Python float is returned.\\n\\nReturns\\n-------\\nZ : ndarray or float\\n    A ``(d0, d1, ..., dn)``-shaped array of floating-point samples from\\n    the standard normal distribution, or a single such float if\\n    no parameters were supplied.\\n\\nSee Also\\n--------\\nstandard_normal : Similar, but takes a tuple as its argument.\\nnormal : Also accepts mu and sigma arguments.\\nrandom.Generator.standard_normal: which should be used for new code.\\n\\nNotes\\n-----\\nFor random samples from the normal distribution with mean ``mu`` and\\nstandard deviation ``sigma``, use::\\n\\n    sigma * np.random.randn(...) + mu\\n\\nExamples\\n--------\\n>>> np.random.randn()\\n2.1923875335537315  # random\\n\\nTwo-by-four array of samples from the normal distribution with\\nmean 3 and standard deviation 2.5:\\n\\n>>> 3 + 2.5 * np.random.randn(2, 4)\\narray([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random\\n       [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random'},\n",
       " {'name': 'DataFrame',\n",
       "  'signature': \"(data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, copy: 'bool | None' = None) -> 'None'\",\n",
       "  'doc': 'Two-dimensional, size-mutable, potentially heterogeneous tabular data.\\n\\nData structure also contains labeled axes (rows and columns).\\nArithmetic operations align on both row and column labels. Can be\\nthought of as a dict-like container for Series objects. The primary\\npandas data structure.\\n\\nParameters\\n----------\\ndata : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\\n    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\\n    data is a dict, column order follows insertion-order. If a dict contains Series\\n    which have an index defined, it is aligned by its index. This alignment also\\n    occurs if data is a Series or a DataFrame itself. Alignment is done on\\n    Series/DataFrame inputs.\\n\\n    If data is a list of dicts, column order follows insertion-order.\\n\\nindex : Index or array-like\\n    Index to use for resulting frame. Will default to RangeIndex if\\n    no indexing information part of input data and no index provided.\\ncolumns : Index or array-like\\n    Column labels to use for resulting frame when data does not have them,\\n    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\\n    will perform column selection instead.\\ndtype : dtype, default None\\n    Data type to force. Only a single dtype is allowed. If None, infer.\\ncopy : bool or None, default None\\n    Copy data from inputs.\\n    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\\n    or 2d ndarray input, the default of None behaves like ``copy=False``.\\n    If data is a dict containing one or more Series (possibly of different dtypes),\\n    ``copy=False`` will ensure that these inputs are not copied.\\n\\n    .. versionchanged:: 1.3.0\\n\\nSee Also\\n--------\\nDataFrame.from_records : Constructor from tuples, also record arrays.\\nDataFrame.from_dict : From dicts of Series, arrays, or dicts.\\nread_csv : Read a comma-separated values (csv) file into DataFrame.\\nread_table : Read general delimited file into DataFrame.\\nread_clipboard : Read text from clipboard into DataFrame.\\n\\nNotes\\n-----\\nPlease reference the :ref:`User Guide <basics.dataframe>` for more information.\\n\\nExamples\\n--------\\nConstructing DataFrame from a dictionary.\\n\\n>>> d = {\\'col1\\': [1, 2], \\'col2\\': [3, 4]}\\n>>> df = pd.DataFrame(data=d)\\n>>> df\\n   col1  col2\\n0     1     3\\n1     2     4\\n\\nNotice that the inferred dtype is int64.\\n\\n>>> df.dtypes\\ncol1    int64\\ncol2    int64\\ndtype: object\\n\\nTo enforce a single dtype:\\n\\n>>> df = pd.DataFrame(data=d, dtype=np.int8)\\n>>> df.dtypes\\ncol1    int8\\ncol2    int8\\ndtype: object\\n\\nConstructing DataFrame from a dictionary including Series:\\n\\n>>> d = {\\'col1\\': [0, 1, 2, 3], \\'col2\\': pd.Series([2, 3], index=[2, 3])}\\n>>> pd.DataFrame(data=d, index=[0, 1, 2, 3])\\n   col1  col2\\n0     0   NaN\\n1     1   NaN\\n2     2   2.0\\n3     3   3.0\\n\\nConstructing DataFrame from numpy ndarray:\\n\\n>>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\\n...                    columns=[\\'a\\', \\'b\\', \\'c\\'])\\n>>> df2\\n   a  b  c\\n0  1  2  3\\n1  4  5  6\\n2  7  8  9\\n\\nConstructing DataFrame from a numpy ndarray that has labeled columns:\\n\\n>>> data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\\n...                 dtype=[(\"a\", \"i4\"), (\"b\", \"i4\"), (\"c\", \"i4\")])\\n>>> df3 = pd.DataFrame(data, columns=[\\'c\\', \\'a\\'])\\n...\\n>>> df3\\n   c  a\\n0  3  1\\n1  6  4\\n2  9  7\\n\\nConstructing DataFrame from dataclass:\\n\\n>>> from dataclasses import make_dataclass\\n>>> Point = make_dataclass(\"Point\", [(\"x\", int), (\"y\", int)])\\n>>> pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\\n   x  y\\n0  0  0\\n1  0  3\\n2  2  3\\n\\nConstructing DataFrame from Series/DataFrame:\\n\\n>>> ser = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])\\n>>> df = pd.DataFrame(data=ser, index=[\"a\", \"c\"])\\n>>> df\\n   0\\na  1\\nc  3\\n\\n>>> df1 = pd.DataFrame([1, 2, 3], index=[\"a\", \"b\", \"c\"], columns=[\"x\"])\\n>>> df2 = pd.DataFrame(data=df1, index=[\"a\", \"c\"])\\n>>> df2\\n   x\\na  1\\nc  3'},\n",
       " {'name': 'array',\n",
       "  'signature': None,\n",
       "  'doc': \"array(object, dtype=None, *, copy=True, order='K', subok=False, ndmin=0,\\n      like=None)\\n\\nCreate an array.\\n\\nParameters\\n----------\\nobject : array_like\\n    An array, any object exposing the array interface, an object whose\\n    ``__array__`` method returns an array, or any (nested) sequence.\\n    If object is a scalar, a 0-dimensional array containing object is\\n    returned.\\ndtype : data-type, optional\\n    The desired data-type for the array. If not given, NumPy will try to use\\n    a default ``dtype`` that can represent the values (by applying promotion\\n    rules when necessary.)\\ncopy : bool, optional\\n    If true (default), then the object is copied.  Otherwise, a copy will\\n    only be made if ``__array__`` returns a copy, if obj is a nested\\n    sequence, or if a copy is needed to satisfy any of the other\\n    requirements (``dtype``, ``order``, etc.).\\norder : {'K', 'A', 'C', 'F'}, optional\\n    Specify the memory layout of the array. If object is not an array, the\\n    newly created array will be in C order (row major) unless 'F' is\\n    specified, in which case it will be in Fortran order (column major).\\n    If object is an array the following holds.\\n\\n    ===== ========= ===================================================\\n    order  no copy                     copy=True\\n    ===== ========= ===================================================\\n    'K'   unchanged F & C order preserved, otherwise most similar order\\n    'A'   unchanged F order if input is F and not C, otherwise C order\\n    'C'   C order   C order\\n    'F'   F order   F order\\n    ===== ========= ===================================================\\n\\n    When ``copy=False`` and a copy is made for other reasons, the result is\\n    the same as if ``copy=True``, with some exceptions for 'A', see the\\n    Notes section. The default order is 'K'.\\nsubok : bool, optional\\n    If True, then sub-classes will be passed-through, otherwise\\n    the returned array will be forced to be a base-class array (default).\\nndmin : int, optional\\n    Specifies the minimum number of dimensions that the resulting\\n    array should have.  Ones will be prepended to the shape as\\n    needed to meet this requirement.\\nlike : array_like, optional\\n    Reference object to allow the creation of arrays which are not\\n    NumPy arrays. If an array-like passed in as ``like`` supports\\n    the ``__array_function__`` protocol, the result will be defined\\n    by it. In this case, it ensures the creation of an array object\\n    compatible with that passed in via this argument.\\n\\n    .. versionadded:: 1.20.0\\n\\nReturns\\n-------\\nout : ndarray\\n    An array object satisfying the specified requirements.\\n\\nSee Also\\n--------\\nempty_like : Return an empty array with shape and type of input.\\nones_like : Return an array of ones with shape and type of input.\\nzeros_like : Return an array of zeros with shape and type of input.\\nfull_like : Return a new array with shape of input filled with value.\\nempty : Return a new uninitialized array.\\nones : Return a new array setting values to one.\\nzeros : Return a new array setting values to zero.\\nfull : Return a new array of given shape filled with value.\\n\\n\\nNotes\\n-----\\nWhen order is 'A' and ``object`` is an array in neither 'C' nor 'F' order,\\nand a copy is forced by a change in dtype, then the order of the result is\\nnot necessarily 'C' as expected. This is likely a bug.\\n\\nExamples\\n--------\\n>>> np.array([1, 2, 3])\\narray([1, 2, 3])\\n\\nUpcasting:\\n\\n>>> np.array([1, 2, 3.0])\\narray([ 1.,  2.,  3.])\\n\\nMore than one dimension:\\n\\n>>> np.array([[1, 2], [3, 4]])\\narray([[1, 2],\\n       [3, 4]])\\n\\nMinimum dimensions 2:\\n\\n>>> np.array([1, 2, 3], ndmin=2)\\narray([[1, 2, 3]])\\n\\nType provided:\\n\\n>>> np.array([1, 2, 3], dtype=complex)\\narray([ 1.+0.j,  2.+0.j,  3.+0.j])\\n\\nData-type consisting of more than one element:\\n\\n>>> x = np.array([(1,2),(3,4)],dtype=[('a','<i4'),('b','<i4')])\\n>>> x['a']\\narray([1, 3])\\n\\nCreating an array from sub-classes:\\n\\n>>> np.array(np.mat('1 2; 3 4'))\\narray([[1, 2],\\n       [3, 4]])\\n\\n>>> np.array(np.mat('1 2; 3 4'), subok=True)\\nmatrix([[1, 2],\\n        [3, 4]])\"},\n",
       " {'name': 'pyplot.plot',\n",
       "  'signature': \"(*args: 'float | ArrayLike | str', scalex: 'bool' = True, scaley: 'bool' = True, data=None, **kwargs) -> 'list[Line2D]'\",\n",
       "  'doc': \"Plot y versus x as lines and/or markers.\\n\\nCall signatures::\\n\\n    plot([x], y, [fmt], *, data=None, **kwargs)\\n    plot([x], y, [fmt], [x2], y2, [fmt2], ..., **kwargs)\\n\\nThe coordinates of the points or line nodes are given by *x*, *y*.\\n\\nThe optional parameter *fmt* is a convenient way for defining basic\\nformatting like color, marker and linestyle. It's a shortcut string\\nnotation described in the *Notes* section below.\\n\\n>>> plot(x, y)        # plot x and y using default line style and color\\n>>> plot(x, y, 'bo')  # plot x and y using blue circle markers\\n>>> plot(y)           # plot y using x as index array 0..N-1\\n>>> plot(y, 'r+')     # ditto, but with red plusses\\n\\nYou can use `.Line2D` properties as keyword arguments for more\\ncontrol on the appearance. Line properties and *fmt* can be mixed.\\nThe following two calls yield identical results:\\n\\n>>> plot(x, y, 'go--', linewidth=2, markersize=12)\\n>>> plot(x, y, color='green', marker='o', linestyle='dashed',\\n...      linewidth=2, markersize=12)\\n\\nWhen conflicting with *fmt*, keyword arguments take precedence.\\n\\n\\n**Plotting labelled data**\\n\\nThere's a convenient way for plotting objects with labelled data (i.e.\\ndata that can be accessed by index ``obj['y']``). Instead of giving\\nthe data in *x* and *y*, you can provide the object in the *data*\\nparameter and just give the labels for *x* and *y*::\\n\\n>>> plot('xlabel', 'ylabel', data=obj)\\n\\nAll indexable objects are supported. This could e.g. be a `dict`, a\\n`pandas.DataFrame` or a structured numpy array.\\n\\n\\n**Plotting multiple sets of data**\\n\\nThere are various ways to plot multiple sets of data.\\n\\n- The most straight forward way is just to call `plot` multiple times.\\n  Example:\\n\\n  >>> plot(x1, y1, 'bo')\\n  >>> plot(x2, y2, 'go')\\n\\n- If *x* and/or *y* are 2D arrays a separate data set will be drawn\\n  for every column. If both *x* and *y* are 2D, they must have the\\n  same shape. If only one of them is 2D with shape (N, m) the other\\n  must have length N and will be used for every data set m.\\n\\n  Example:\\n\\n  >>> x = [1, 2, 3]\\n  >>> y = np.array([[1, 2], [3, 4], [5, 6]])\\n  >>> plot(x, y)\\n\\n  is equivalent to:\\n\\n  >>> for col in range(y.shape[1]):\\n  ...     plot(x, y[:, col])\\n\\n- The third way is to specify multiple sets of *[x]*, *y*, *[fmt]*\\n  groups::\\n\\n  >>> plot(x1, y1, 'g^', x2, y2, 'g-')\\n\\n  In this case, any additional keyword argument applies to all\\n  datasets. Also, this syntax cannot be combined with the *data*\\n  parameter.\\n\\nBy default, each line is assigned a different style specified by a\\n'style cycle'. The *fmt* and line property parameters are only\\nnecessary if you want explicit deviations from these defaults.\\nAlternatively, you can also change the style cycle using\\n:rc:`axes.prop_cycle`.\\n\\n\\nParameters\\n----------\\nx, y : array-like or scalar\\n    The horizontal / vertical coordinates of the data points.\\n    *x* values are optional and default to ``range(len(y))``.\\n\\n    Commonly, these parameters are 1D arrays.\\n\\n    They can also be scalars, or two-dimensional (in that case, the\\n    columns represent separate data sets).\\n\\n    These arguments cannot be passed as keywords.\\n\\nfmt : str, optional\\n    A format string, e.g. 'ro' for red circles. See the *Notes*\\n    section for a full description of the format strings.\\n\\n    Format strings are just an abbreviation for quickly setting\\n    basic line properties. All of these and more can also be\\n    controlled by keyword arguments.\\n\\n    This argument cannot be passed as keyword.\\n\\ndata : indexable object, optional\\n    An object with labelled data. If given, provide the label names to\\n    plot in *x* and *y*.\\n\\n    .. note::\\n        Technically there's a slight ambiguity in calls where the\\n        second label is a valid *fmt*. ``plot('n', 'o', data=obj)``\\n        could be ``plt(x, y)`` or ``plt(y, fmt)``. In such cases,\\n        the former interpretation is chosen, but a warning is issued.\\n        You may suppress the warning by adding an empty format string\\n        ``plot('n', 'o', '', data=obj)``.\\n\\nReturns\\n-------\\nlist of `.Line2D`\\n    A list of lines representing the plotted data.\\n\\nOther Parameters\\n----------------\\nscalex, scaley : bool, default: True\\n    These parameters determine if the view limits are adapted to the\\n    data limits. The values are passed on to\\n    `~.axes.Axes.autoscale_view`.\\n\\n**kwargs : `~matplotlib.lines.Line2D` properties, optional\\n    *kwargs* are used to specify properties like a line label (for\\n    auto legends), linewidth, antialiasing, marker face color.\\n    Example::\\n\\n    >>> plot([1, 2, 3], [1, 2, 3], 'go-', label='line 1', linewidth=2)\\n    >>> plot([1, 2, 3], [1, 4, 9], 'rs', label='line 2')\\n\\n    If you specify multiple lines with one plot call, the kwargs apply\\n    to all those lines. In case the label object is iterable, each\\n    element is used as labels for each set of data.\\n\\n    Here is a list of available `.Line2D` properties:\\n\\n    Properties:\\n    agg_filter: a filter function, which takes a (m, n, 3) float array and a dpi value, and returns a (m, n, 3) array and two offsets from the bottom left corner of the image\\n    alpha: scalar or None\\n    animated: bool\\n    antialiased or aa: bool\\n    clip_box: `~matplotlib.transforms.BboxBase` or None\\n    clip_on: bool\\n    clip_path: Patch or (Path, Transform) or None\\n    color or c: color\\n    dash_capstyle: `.CapStyle` or {'butt', 'projecting', 'round'}\\n    dash_joinstyle: `.JoinStyle` or {'miter', 'round', 'bevel'}\\n    dashes: sequence of floats (on/off ink in points) or (None, None)\\n    data: (2, N) array or two 1D arrays\\n    drawstyle or ds: {'default', 'steps', 'steps-pre', 'steps-mid', 'steps-post'}, default: 'default'\\n    figure: `~matplotlib.figure.Figure`\\n    fillstyle: {'full', 'left', 'right', 'bottom', 'top', 'none'}\\n    gapcolor: color or None\\n    gid: str\\n    in_layout: bool\\n    label: object\\n    linestyle or ls: {'-', '--', '-.', ':', '', (offset, on-off-seq), ...}\\n    linewidth or lw: float\\n    marker: marker style string, `~.path.Path` or `~.markers.MarkerStyle`\\n    markeredgecolor or mec: color\\n    markeredgewidth or mew: float\\n    markerfacecolor or mfc: color\\n    markerfacecoloralt or mfcalt: color\\n    markersize or ms: float\\n    markevery: None or int or (int, int) or slice or list[int] or float or (float, float) or list[bool]\\n    mouseover: bool\\n    path_effects: list of `.AbstractPathEffect`\\n    picker: float or callable[[Artist, Event], tuple[bool, dict]]\\n    pickradius: float\\n    rasterized: bool\\n    sketch_params: (scale: float, length: float, randomness: float)\\n    snap: bool or None\\n    solid_capstyle: `.CapStyle` or {'butt', 'projecting', 'round'}\\n    solid_joinstyle: `.JoinStyle` or {'miter', 'round', 'bevel'}\\n    transform: unknown\\n    url: str\\n    visible: bool\\n    xdata: 1D array\\n    ydata: 1D array\\n    zorder: float\\n\\nSee Also\\n--------\\nscatter : XY scatter plot with markers of varying size and/or color (\\n    sometimes also called bubble chart).\\n\\nNotes\\n-----\\n**Format Strings**\\n\\nA format string consists of a part for color, marker and line::\\n\\n    fmt = '[marker][line][color]'\\n\\nEach of them is optional. If not provided, the value from the style\\ncycle is used. Exception: If ``line`` is given, but no ``marker``,\\nthe data will be a line without markers.\\n\\nOther combinations such as ``[color][marker][line]`` are also\\nsupported, but note that their parsing may be ambiguous.\\n\\n**Markers**\\n\\n=============   ===============================\\ncharacter       description\\n=============   ===============================\\n``'.'``         point marker\\n``','``         pixel marker\\n``'o'``         circle marker\\n``'v'``         triangle_down marker\\n``'^'``         triangle_up marker\\n``'<'``         triangle_left marker\\n``'>'``         triangle_right marker\\n``'1'``         tri_down marker\\n``'2'``         tri_up marker\\n``'3'``         tri_left marker\\n``'4'``         tri_right marker\\n``'8'``         octagon marker\\n``'s'``         square marker\\n``'p'``         pentagon marker\\n``'P'``         plus (filled) marker\\n``'*'``         star marker\\n``'h'``         hexagon1 marker\\n``'H'``         hexagon2 marker\\n``'+'``         plus marker\\n``'x'``         x marker\\n``'X'``         x (filled) marker\\n``'D'``         diamond marker\\n``'d'``         thin_diamond marker\\n``'|'``         vline marker\\n``'_'``         hline marker\\n=============   ===============================\\n\\n**Line Styles**\\n\\n=============    ===============================\\ncharacter        description\\n=============    ===============================\\n``'-'``          solid line style\\n``'--'``         dashed line style\\n``'-.'``         dash-dot line style\\n``':'``          dotted line style\\n=============    ===============================\\n\\nExample format strings::\\n\\n    'b'    # blue markers with default shape\\n    'or'   # red circles\\n    '-g'   # green solid line\\n    '--'   # dashed line with default color\\n    '^k:'  # black triangle_up markers connected by a dotted line\\n\\n**Colors**\\n\\nThe supported color abbreviations are the single letter codes\\n\\n=============    ===============================\\ncharacter        color\\n=============    ===============================\\n``'b'``          blue\\n``'g'``          green\\n``'r'``          red\\n``'c'``          cyan\\n``'m'``          magenta\\n``'y'``          yellow\\n``'k'``          black\\n``'w'``          white\\n=============    ===============================\\n\\nand the ``'CN'`` colors that index into the default property cycle.\\n\\nIf the color is the only part of the format string, you can\\nadditionally use any  `matplotlib.colors` spec, e.g. full names\\n(``'green'``) or hex strings (``'#008000'``).\"},\n",
       " {'name': 'random.randn',\n",
       "  'signature': None,\n",
       "  'doc': 'randn(d0, d1, ..., dn)\\n\\nReturn a sample (or samples) from the \"standard normal\" distribution.\\n\\n.. note::\\n    This is a convenience function for users porting code from Matlab,\\n    and wraps `standard_normal`. That function takes a\\n    tuple to specify the size of the output, which is consistent with\\n    other NumPy functions like `numpy.zeros` and `numpy.ones`.\\n\\n.. note::\\n    New code should use the\\n    `~numpy.random.Generator.standard_normal`\\n    method of a `~numpy.random.Generator` instance instead;\\n    please see the :ref:`random-quick-start`.\\n\\nIf positive int_like arguments are provided, `randn` generates an array\\nof shape ``(d0, d1, ..., dn)``, filled\\nwith random floats sampled from a univariate \"normal\" (Gaussian)\\ndistribution of mean 0 and variance 1. A single float randomly sampled\\nfrom the distribution is returned if no argument is provided.\\n\\nParameters\\n----------\\nd0, d1, ..., dn : int, optional\\n    The dimensions of the returned array, must be non-negative.\\n    If no argument is given a single Python float is returned.\\n\\nReturns\\n-------\\nZ : ndarray or float\\n    A ``(d0, d1, ..., dn)``-shaped array of floating-point samples from\\n    the standard normal distribution, or a single such float if\\n    no parameters were supplied.\\n\\nSee Also\\n--------\\nstandard_normal : Similar, but takes a tuple as its argument.\\nnormal : Also accepts mu and sigma arguments.\\nrandom.Generator.standard_normal: which should be used for new code.\\n\\nNotes\\n-----\\nFor random samples from the normal distribution with mean ``mu`` and\\nstandard deviation ``sigma``, use::\\n\\n    sigma * np.random.randn(...) + mu\\n\\nExamples\\n--------\\n>>> np.random.randn()\\n2.1923875335537315  # random\\n\\nTwo-by-four array of samples from the normal distribution with\\nmean 3 and standard deviation 2.5:\\n\\n>>> 3 + 2.5 * np.random.randn(2, 4)\\narray([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random\\n       [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random'}]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_signature_and_doc(\"get_signature_test.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from collections import namedtuple\n",
    "\n",
    "Import = namedtuple(\"Import\", [\"module\", \"name\", \"alias\"])\n",
    "\n",
    "def get_imports(path):\n",
    "    with open(path) as fh:       \n",
    "        root = ast.parse(fh.read(), path)\n",
    "\n",
    "    for node in ast.walk(root):\n",
    "        if isinstance(node, ast.Import):\n",
    "            module = []\n",
    "        elif isinstance(node, ast.ImportFrom): \n",
    "            module = node.module.split('.')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for n in node.names:\n",
    "            yield Import(module, n.name.split('.'), n.asname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import(module=['langchain', 'vectorstores', 'elasticsearch'], name=['ElasticsearchStore'], alias=None)\n",
      "Import(module=[], name=['numpy'], alias='np')\n",
      "Import(module=[], name=['json'], alias=None)\n",
      "Import(module=['pandas'], name=['DataFrame'], alias=None)\n",
      "Import(module=[], name=['matplotlib', 'pyplot'], alias='plt')\n"
     ]
    }
   ],
   "source": [
    "for i in get_imports(\"get_signature_test.py\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signature of ElasticsearchStore: (index_name: str, *, embedding: Optional[langchain_core.embeddings.Embeddings] = None, es_connection: Optional[ForwardRef('Elasticsearch')] = None, es_url: Optional[str] = None, es_cloud_id: Optional[str] = None, es_user: Optional[str] = None, es_api_key: Optional[str] = None, es_password: Optional[str] = None, vector_query_field: str = 'vector', query_field: str = 'text', distance_strategy: Optional[Literal[<DistanceStrategy.COSINE: 'COSINE'>, <DistanceStrategy.DOT_PRODUCT: 'DOT_PRODUCT'>, <DistanceStrategy.EUCLIDEAN_DISTANCE: 'EUCLIDEAN_DISTANCE'>]] = None, strategy: langchain.vectorstores.elasticsearch.BaseRetrievalStrategy = <langchain.vectorstores.elasticsearch.ApproxRetrievalStrategy object at 0x7f03dbd0e790>)\n",
      "Documentation of ElasticsearchStore: `Elasticsearch` vector store.\n",
      "\n",
      "Example:\n",
      "    .. code-block:: python\n",
      "\n",
      "        from langchain.vectorstores import ElasticsearchStore\n",
      "        from langchain.embeddings.openai import OpenAIEmbeddings\n",
      "\n",
      "        embeddings = OpenAIEmbeddings()\n",
      "        vectorstore = ElasticsearchStore(\n",
      "            embedding=OpenAIEmbeddings(),\n",
      "            index_name=\"langchain-demo\",\n",
      "            es_url=\"http://localhost:9200\"\n",
      "        )\n",
      "\n",
      "Args:\n",
      "    index_name: Name of the Elasticsearch index to create.\n",
      "    es_url: URL of the Elasticsearch instance to connect to.\n",
      "    cloud_id: Cloud ID of the Elasticsearch instance to connect to.\n",
      "    es_user: Username to use when connecting to Elasticsearch.\n",
      "    es_password: Password to use when connecting to Elasticsearch.\n",
      "    es_api_key: API key to use when connecting to Elasticsearch.\n",
      "    es_connection: Optional pre-existing Elasticsearch connection.\n",
      "    vector_query_field: Optional. Name of the field to store\n",
      "                        the embedding vectors in.\n",
      "    query_field: O\n",
      "Cannot get signature and documentation of np\n",
      "Cannot get signature and documentation of json\n",
      "Signature of DataFrame: (data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, copy: 'bool | None' = None) -> 'None'\n",
      "Documentation of DataFrame: Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
      "\n",
      "Data structure also contains labeled axes (rows and columns).\n",
      "Arithmetic operations align on both row and column labels. Can be\n",
      "thought of as a dict-like container for Series objects. The primary\n",
      "pandas data structure.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
      "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
      "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
      "    which have an index defined, it is aligned by its index. This alignment also\n",
      "    occurs if data is a Series or a DataFrame itself. Alignment is done on\n",
      "    Series/DataFrame inputs.\n",
      "\n",
      "    If data is a list of dicts, column order follows insertion-order.\n",
      "\n",
      "index : Index or array-like\n",
      "    Index to use for resulting frame. Will default to RangeIndex if\n",
      "    no indexing information part of input data and no index provided.\n",
      "columns : Index or arra\n",
      "Cannot get signature and documentation of plt\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "for imp in get_imports(\"get_signature_test.py\"):\n",
    "    if imp.module:\n",
    "        module = '.'.join(imp.module)\n",
    "    else:\n",
    "        module = imp.name[0]\n",
    "    name = imp.alias if imp.alias else imp.name[0]\n",
    "    try:\n",
    "        obj = __import__(module, fromlist=[name])\n",
    "        obj = getattr(obj, name)\n",
    "        sig = inspect.signature(obj)\n",
    "        doc = inspect.getdoc(obj)\n",
    "        print(f\"Signature of {name}: {sig}\")\n",
    "        print(f\"Documentation of {name}: {doc[:1000]}\")\n",
    "    except (ImportError, AttributeError):\n",
    "        print(f\"Cannot get signature and documentation of {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def extract_import_usages(code):\n",
    "    # Parse the code into an AST\n",
    "    tree = ast.parse(code)\n",
    "\n",
    "    # Mapping of aliases to module names\n",
    "    import_map = {}\n",
    "\n",
    "    # Function to handle import and import from statements\n",
    "    def handle_import(node):\n",
    "        if isinstance(node, ast.Import):\n",
    "            for name in node.names:\n",
    "                import_map[name.asname or name.name] = name.name\n",
    "        elif isinstance(node, ast.ImportFrom):\n",
    "            module = node.module\n",
    "            for name in node.names:\n",
    "                full_name = f\"{module}.{name.name}\"\n",
    "                import_map[name.asname or name.name] = full_name\n",
    "\n",
    "    # Walk the AST and populate the import map\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, (ast.Import, ast.ImportFrom)):\n",
    "            handle_import(node)\n",
    "\n",
    "    # Function to extract function or class usages\n",
    "    def extract_usages(node):\n",
    "        if isinstance(node, ast.Call) and isinstance(node.func, ast.Attribute):\n",
    "            module_name = node.func.value.id\n",
    "            if module_name in import_map:\n",
    "                func_name = node.func.attr\n",
    "                return f\"{import_map[module_name]}.{func_name}\"\n",
    "        elif isinstance(node, ast.Call) and isinstance(node.func, ast.Name):\n",
    "            name = node.func.id\n",
    "            if name in import_map:\n",
    "                return import_map[name]\n",
    "        return None\n",
    "\n",
    "    # Extract and return all usages\n",
    "    usages = [extract_usages(node) for node in ast.walk(tree)]\n",
    "    return [usage for usage in usages if usage is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "\n",
    "def extract_builtin_usages(code):\n",
    "    # Parse the code into an AST\n",
    "    tree = ast.parse(code)\n",
    "\n",
    "    # List of all built-in function names\n",
    "    builtin_functions = [func for func in dir(builtins) if callable(getattr(builtins, func))]\n",
    "\n",
    "    # Function to extract built-in function usages\n",
    "    def extract_usages(node):\n",
    "        if isinstance(node, ast.Call) and isinstance(node.func, ast.Name):\n",
    "            if node.func.id in builtin_functions:\n",
    "                return node.func.id\n",
    "        return None\n",
    "\n",
    "    # Extract and return all built-in function usages\n",
    "    usages = [extract_usages(node) for node in ast.walk(tree)]\n",
    "    return [\"builtins.\" + usage for usage in usages if usage is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "usages = set(extract_import_usages(code))\n",
    "print(usages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "builtin_usages = set(extract_builtin_usages(code))\n",
    "print(builtin_usages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_usages = usages.union(builtin_usages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import importlib\n",
    "\n",
    "def get_signature(usage):\n",
    "    module_name, _, attr_name = usage.rpartition('.')\n",
    "    try:\n",
    "        module = importlib.import_module(module_name)\n",
    "        attr = getattr(module, attr_name)\n",
    "        if callable(attr):\n",
    "            try:\n",
    "                return inspect.signature(attr)\n",
    "            except ValueError:\n",
    "                # For built-in functions, return the docstring as a fallback\n",
    "                return attr.__doc__\n",
    "        else:\n",
    "            return f\"{attr_name} is not callable\"\n",
    "    except ImportError:\n",
    "        return f\"Module {module_name} not found\"\n",
    "    except AttributeError:\n",
    "        return f\"{attr_name} not found in {module_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llmcoder.utils.get_data_dir: (*args: str, create: bool = False) -> str\n",
      "pandas.DataFrame: (data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, copy: 'bool | None' = None) -> 'None'\n",
      "builtins.print: (*args, sep=' ', end='\\n', file=None, flush=False)\n",
      "numpy.array: array(object, dtype=None, *, copy=True, order='K', subok=False, ndmin=0,\n",
      "          like=None)\n",
      "\n",
      "    Create an array.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    object : array_like\n",
      "        An array, any object exposing the array interface, an object whose\n",
      "        ``__array__`` method returns an array, or any (nested) sequence.\n",
      "        If object is a scalar, a 0-dimensional array containing object is\n",
      "        returned.\n",
      "    dtype : data-type, optional\n",
      "        The desired data-type for the array. If not given, NumPy will try to use\n",
      "        a default ``dtype`` that can represent the values (by applying promotion\n",
      "        rules when necessary.)\n",
      "    copy : bool, optional\n",
      "        If true (default), then the object is copied.  Otherwise, a copy will\n",
      "        only be made if ``__array__`` returns a copy, if obj is a nested\n",
      "        sequence, or if a copy is needed to satisfy any of the other\n",
      "        requirements (``dtype``, ``order``, etc.).\n",
      "    order : {'K', 'A', 'C', 'F'}, optional\n",
      "        Specify the memory layout of the array. If object is not an array, the\n",
      "        newly created array will be in C order (row major) unless 'F' is\n",
      "        specified, in which case it will be in Fortran order (column major).\n",
      "        If object is an array the following holds.\n",
      "\n",
      "        ===== ========= ===================================================\n",
      "        order  no copy                     copy=True\n",
      "        ===== ========= ===================================================\n",
      "        'K'   unchanged F & C order preserved, otherwise most similar order\n",
      "        'A'   unchanged F order if input is F and not C, otherwise C order\n",
      "        'C'   C order   C order\n",
      "        'F'   F order   F order\n",
      "        ===== ========= ===================================================\n",
      "\n",
      "        When ``copy=False`` and a copy is made for other reasons, the result is\n",
      "        the same as if ``copy=True``, with some exceptions for 'A', see the\n",
      "        Notes section. The default order is 'K'.\n",
      "    subok : bool, optional\n",
      "        If True, then sub-classes will be passed-through, otherwise\n",
      "        the returned array will be forced to be a base-class array (default).\n",
      "    ndmin : int, optional\n",
      "        Specifies the minimum number of dimensions that the resulting\n",
      "        array should have.  Ones will be prepended to the shape as\n",
      "        needed to meet this requirement.\n",
      "    like : array_like, optional\n",
      "        Reference object to allow the creation of arrays which are not\n",
      "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
      "        the ``__array_function__`` protocol, the result will be defined\n",
      "        by it. In this case, it ensures the creation of an array object\n",
      "        compatible with that passed in via this argument.\n",
      "\n",
      "        .. versionadded:: 1.20.0\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    out : ndarray\n",
      "        An array object satisfying the specified requirements.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    empty_like : Return an empty array with shape and type of input.\n",
      "    ones_like : Return an array of ones with shape and type of input.\n",
      "    zeros_like : Return an array of zeros with shape and type of input.\n",
      "    full_like : Return a new array with shape of input filled with value.\n",
      "    empty : Return a new uninitialized array.\n",
      "    ones : Return a new array setting values to one.\n",
      "    zeros : Return a new array setting values to zero.\n",
      "    full : Return a new array of given shape filled with value.\n",
      "\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    When order is 'A' and ``object`` is an array in neither 'C' nor 'F' order,\n",
      "    and a copy is forced by a change in dtype, then the order of the result is\n",
      "    not necessarily 'C' as expected. This is likely a bug.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.array([1, 2, 3])\n",
      "    array([1, 2, 3])\n",
      "\n",
      "    Upcasting:\n",
      "\n",
      "    >>> np.array([1, 2, 3.0])\n",
      "    array([ 1.,  2.,  3.])\n",
      "\n",
      "    More than one dimension:\n",
      "\n",
      "    >>> np.array([[1, 2], [3, 4]])\n",
      "    array([[1, 2],\n",
      "           [3, 4]])\n",
      "\n",
      "    Minimum dimensions 2:\n",
      "\n",
      "    >>> np.array([1, 2, 3], ndmin=2)\n",
      "    array([[1, 2, 3]])\n",
      "\n",
      "    Type provided:\n",
      "\n",
      "    >>> np.array([1, 2, 3], dtype=complex)\n",
      "    array([ 1.+0.j,  2.+0.j,  3.+0.j])\n",
      "\n",
      "    Data-type consisting of more than one element:\n",
      "\n",
      "    >>> x = np.array([(1,2),(3,4)],dtype=[('a','<i4'),('b','<i4')])\n",
      "    >>> x['a']\n",
      "    array([1, 3])\n",
      "\n",
      "    Creating an array from sub-classes:\n",
      "\n",
      "    >>> np.array(np.mat('1 2; 3 4'))\n",
      "    array([[1, 2],\n",
      "           [3, 4]])\n",
      "\n",
      "    >>> np.array(np.mat('1 2; 3 4'), subok=True)\n",
      "    matrix([[1, 2],\n",
      "            [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "for usage in all_usages:\n",
    "    print(f\"{usage}: {get_signature(usage)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_function_usages_with_args(code):\n",
    "    tree = ast.parse(code)\n",
    "    function_usages = []\n",
    "\n",
    "    for node in ast.walk(tree):\n",
    "        if isinstance(node, ast.Call):\n",
    "            function_name = ''\n",
    "            if isinstance(node.func, ast.Attribute):\n",
    "                function_name = node.func.attr\n",
    "            elif isinstance(node.func, ast.Name):\n",
    "                function_name = node.func.id\n",
    "            \n",
    "            args = [type(arg).__name__ for arg in node.args]  # Extract argument types\n",
    "            kwargs = [type(value).__name__ for key, value in zip(node.keywords, node.keywords)]\n",
    "            function_usages.append((function_name, args, kwargs))\n",
    "\n",
    "    return function_usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('print', ['Call'], []), ('DataFrame', ['Dict'], []), ('DataFrame', ['Constant'], []), ('print', ['Call'], []), ('array', ['List'], []), ('get_data_dir', ['Constant'], [])]\n"
     ]
    }
   ],
   "source": [
    "usages_with_args = extract_function_usages_with_args(code)\n",
    "print(usages_with_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_arg_types(usage_args, sig_params):\n",
    "    \"\"\"\n",
    "    Match the types of arguments in usage against the expected types in the signature.\n",
    "    For simplification, we'll just compare the count and presence of 'args' and 'kwargs'.\n",
    "    \"\"\"\n",
    "    positional_args = [param for param in sig_params.values() if param.kind in [param.POSITIONAL_OR_KEYWORD, param.POSITIONAL_ONLY]]\n",
    "    keyword_args = [param for param in sig_params.values() if param.kind == param.KEYWORD_ONLY]\n",
    "    \n",
    "    # Check positional arguments\n",
    "    if len(usage_args) > len(positional_args):\n",
    "        return False  # Too many arguments\n",
    "\n",
    "    # For simplicity, this version won't delve into deeper type matching\n",
    "    # It assumes that if the count is right, the types are matched.\n",
    "    # In a more advanced implementation, you could attempt to match the types more accurately.\n",
    "\n",
    "    # Check keyword arguments - this implementation assumes correct usage of keyword arguments\n",
    "    # A more advanced implementation would check the actual keyword names and types\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def usage_matches_signature(usage, signature):\n",
    "    func_name, args, kwargs = usage\n",
    "    sig_params = signature.parameters\n",
    "\n",
    "    # Count the number of required positional arguments\n",
    "    required_args_count = sum(1 for param in sig_params.values() if param.default is param.empty and param.kind == param.POSITIONAL_OR_KEYWORD)\n",
    "\n",
    "    # Check if the number of arguments matches\n",
    "    if len(args) < required_args_count:\n",
    "        return False\n",
    "\n",
    "    # Check for excess arguments if the function does not accept variadic arguments\n",
    "    if not any(param.kind == param.VAR_POSITIONAL for param in sig_params.values()):\n",
    "        if len(args) > len(sig_params):\n",
    "            return False\n",
    "        \n",
    "    if not match_arg_types(args, sig_params):\n",
    "        return False\n",
    "\n",
    "    # Further type checks can be added here, based on the types in 'args' and the expected types from 'signature'\n",
    "    # However, this requires a more complex implementation and type inference system\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'builtins.print',\n",
       " 'llmcoder.utils.get_data_dir',\n",
       " 'numpy.array',\n",
       " 'pandas.DataFrame'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('print', ['Call'], []),\n",
       " ('DataFrame', ['Dict'], []),\n",
       " ('DataFrame', ['Constant'], []),\n",
       " ('print', ['Call'], []),\n",
       " ('array', ['List'], []),\n",
       " ('get_data_dir', ['Constant'], [])]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usages_with_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_usage_signature_list(unique_usages, usages_with_args, get_signature_func):\n",
    "    # Map short function names to their fully qualified names\n",
    "    name_mapping = {name.split('.')[-1]: name for name in unique_usages}\n",
    "\n",
    "    usage_signature_list = []\n",
    "\n",
    "    for usage in usages_with_args:\n",
    "        func_name, args, kwargs = usage\n",
    "        qualified_name = name_mapping.get(func_name, func_name)\n",
    "\n",
    "        signature = get_signature_func(qualified_name)\n",
    "        usage_signature_list.append({\n",
    "            \"usage\": usage,\n",
    "            \"signature\": signature\n",
    "        })\n",
    "\n",
    "    return usage_signature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage': ('print', ['Call'], []), 'signature': <Signature (*args, sep=' ', end='\\n', file=None, flush=False)>}\n",
      "{'usage': ('DataFrame', ['Dict'], []), 'signature': <Signature (data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, copy: 'bool | None' = None) -> 'None'>}\n",
      "{'usage': ('DataFrame', ['Constant'], []), 'signature': <Signature (data=None, index: 'Axes | None' = None, columns: 'Axes | None' = None, dtype: 'Dtype | None' = None, copy: 'bool | None' = None) -> 'None'>}\n",
      "{'usage': ('print', ['Call'], []), 'signature': <Signature (*args, sep=' ', end='\\n', file=None, flush=False)>}\n",
      "{'usage': ('array', ['List'], []), 'signature': \"array(object, dtype=None, *, copy=True, order='K', subok=False, ndmin=0,\\n          like=None)\\n\\n    Create an array.\\n\\n    Parameters\\n    ----------\\n    object : array_like\\n        An array, any object exposing the array interface, an object whose\\n        ``__array__`` method returns an array, or any (nested) sequence.\\n        If object is a scalar, a 0-dimensional array containing object is\\n        returned.\\n    dtype : data-type, optional\\n        The desired data-type for the array. If not given, NumPy will try to use\\n        a default ``dtype`` that can represent the values (by applying promotion\\n        rules when necessary.)\\n    copy : bool, optional\\n        If true (default), then the object is copied.  Otherwise, a copy will\\n        only be made if ``__array__`` returns a copy, if obj is a nested\\n        sequence, or if a copy is needed to satisfy any of the other\\n        requirements (``dtype``, ``order``, etc.).\\n    order : {'K', 'A', 'C', 'F'}, optional\\n        Specify the memory layout of the array. If object is not an array, the\\n        newly created array will be in C order (row major) unless 'F' is\\n        specified, in which case it will be in Fortran order (column major).\\n        If object is an array the following holds.\\n\\n        ===== ========= ===================================================\\n        order  no copy                     copy=True\\n        ===== ========= ===================================================\\n        'K'   unchanged F & C order preserved, otherwise most similar order\\n        'A'   unchanged F order if input is F and not C, otherwise C order\\n        'C'   C order   C order\\n        'F'   F order   F order\\n        ===== ========= ===================================================\\n\\n        When ``copy=False`` and a copy is made for other reasons, the result is\\n        the same as if ``copy=True``, with some exceptions for 'A', see the\\n        Notes section. The default order is 'K'.\\n    subok : bool, optional\\n        If True, then sub-classes will be passed-through, otherwise\\n        the returned array will be forced to be a base-class array (default).\\n    ndmin : int, optional\\n        Specifies the minimum number of dimensions that the resulting\\n        array should have.  Ones will be prepended to the shape as\\n        needed to meet this requirement.\\n    like : array_like, optional\\n        Reference object to allow the creation of arrays which are not\\n        NumPy arrays. If an array-like passed in as ``like`` supports\\n        the ``__array_function__`` protocol, the result will be defined\\n        by it. In this case, it ensures the creation of an array object\\n        compatible with that passed in via this argument.\\n\\n        .. versionadded:: 1.20.0\\n\\n    Returns\\n    -------\\n    out : ndarray\\n        An array object satisfying the specified requirements.\\n\\n    See Also\\n    --------\\n    empty_like : Return an empty array with shape and type of input.\\n    ones_like : Return an array of ones with shape and type of input.\\n    zeros_like : Return an array of zeros with shape and type of input.\\n    full_like : Return a new array with shape of input filled with value.\\n    empty : Return a new uninitialized array.\\n    ones : Return a new array setting values to one.\\n    zeros : Return a new array setting values to zero.\\n    full : Return a new array of given shape filled with value.\\n\\n\\n    Notes\\n    -----\\n    When order is 'A' and ``object`` is an array in neither 'C' nor 'F' order,\\n    and a copy is forced by a change in dtype, then the order of the result is\\n    not necessarily 'C' as expected. This is likely a bug.\\n\\n    Examples\\n    --------\\n    >>> np.array([1, 2, 3])\\n    array([1, 2, 3])\\n\\n    Upcasting:\\n\\n    >>> np.array([1, 2, 3.0])\\n    array([ 1.,  2.,  3.])\\n\\n    More than one dimension:\\n\\n    >>> np.array([[1, 2], [3, 4]])\\n    array([[1, 2],\\n           [3, 4]])\\n\\n    Minimum dimensions 2:\\n\\n    >>> np.array([1, 2, 3], ndmin=2)\\n    array([[1, 2, 3]])\\n\\n    Type provided:\\n\\n    >>> np.array([1, 2, 3], dtype=complex)\\n    array([ 1.+0.j,  2.+0.j,  3.+0.j])\\n\\n    Data-type consisting of more than one element:\\n\\n    >>> x = np.array([(1,2),(3,4)],dtype=[('a','<i4'),('b','<i4')])\\n    >>> x['a']\\n    array([1, 3])\\n\\n    Creating an array from sub-classes:\\n\\n    >>> np.array(np.mat('1 2; 3 4'))\\n    array([[1, 2],\\n           [3, 4]])\\n\\n    >>> np.array(np.mat('1 2; 3 4'), subok=True)\\n    matrix([[1, 2],\\n            [3, 4]])\"}\n",
      "{'usage': ('get_data_dir', ['Constant'], []), 'signature': <Signature (*args: str, create: bool = False) -> str>}\n"
     ]
    }
   ],
   "source": [
    "usage_signature_list = create_usage_signature_list(all_usages, usages_with_args, get_signature)\n",
    "for usage_signature in usage_signature_list:\n",
    "    print(usage_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage ('print', ['Call'], []) does not match signature\n",
      "Usage ('DataFrame', ['Dict'], []) matches signature\n",
      "Usage ('DataFrame', ['Constant'], []) matches signature\n",
      "Usage ('print', ['Call'], []) does not match signature\n",
      "Signature for usage ('array', ['List'], []) could not be found\n",
      "Usage ('get_data_dir', ['Constant'], []) does not match signature\n"
     ]
    }
   ],
   "source": [
    "# For each usage, check if the arguments match the signature\n",
    "for usage_signature in usage_signature_list:\n",
    "    usage = usage_signature[\"usage\"]\n",
    "    signature = usage_signature[\"signature\"]\n",
    "    if type(signature) == str:\n",
    "        print(f\"Signature for usage {usage} could not be found\")\n",
    "        continue\n",
    "    if usage_matches_signature(usage, signature):\n",
    "        print(f\"Usage {usage} matches signature\")\n",
    "    else:\n",
    "        print(f\"Usage {usage} does not match signature\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmcoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
